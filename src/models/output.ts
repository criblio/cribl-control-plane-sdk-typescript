/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { remap as remap$ } from "../lib/primitives.js";
import {
  collectExtraKeys as collectExtraKeys$,
  safeParse,
} from "../lib/schemas.js";
import {
  catchUnrecognizedEnum,
  ClosedEnum,
  OpenEnum,
  Unrecognized,
} from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";

export const TypeCloudflareR2 = {
  CloudflareR2: "cloudflare_r2",
} as const;
export type TypeCloudflareR2 = ClosedEnum<typeof TypeCloudflareR2>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodCloudflareR2 = {
  Auto: "auto",
  Secret: "secret",
  Manual: "manual",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodCloudflareR2 = OpenEnum<
  typeof AuthenticationMethodCloudflareR2
>;

/**
 * Signature version to use for signing MinIO requests
 */
export const SignatureVersionCloudflareR2 = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing MinIO requests
 */
export type SignatureVersionCloudflareR2 = OpenEnum<
  typeof SignatureVersionCloudflareR2
>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassCloudflareR2 = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassCloudflareR2 = OpenEnum<
  typeof StorageClassCloudflareR2
>;

/**
 * Server-side encryption for uploaded objects
 */
export const ServerSideEncryptionCloudflareR2 = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
} as const;
/**
 * Server-side encryption for uploaded objects
 */
export type ServerSideEncryptionCloudflareR2 = OpenEnum<
  typeof ServerSideEncryptionCloudflareR2
>;

/**
 * Format of the output data
 */
export const DataFormatCloudflareR2 = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatCloudflareR2 = OpenEnum<typeof DataFormatCloudflareR2>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCloudflareR2 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCloudflareR2 = OpenEnum<
  typeof BackpressureBehaviorCloudflareR2
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionCloudflareR2 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionCloudflareR2 = OpenEnum<
  typeof DiskSpaceProtectionCloudflareR2
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionCloudflareR2 = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionCloudflareR2 = OpenEnum<typeof CompressionCloudflareR2>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelCloudflareR2 = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelCloudflareR2 = OpenEnum<
  typeof CompressionLevelCloudflareR2
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionCloudflareR2 = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionCloudflareR2 = OpenEnum<
  typeof ParquetVersionCloudflareR2
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionCloudflareR2 = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionCloudflareR2 = OpenEnum<
  typeof DataPageVersionCloudflareR2
>;

export type KeyValueMetadatumCloudflareR2 = {
  key?: string | undefined;
  value: string;
};

export type OutputCloudflareR2 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeCloudflareR2;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Cloudflare R2 service URL (example: https://<ACCOUNT_ID>.r2.cloudflarestorage.com)
   */
  endpoint: string;
  /**
   * Name of the destination R2 bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodCloudflareR2 | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
   */
  awsSecretKey?: string | undefined;
  region?: any | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
   */
  destPath?: string | undefined;
  /**
   * Signature version to use for signing MinIO requests
   */
  signatureVersion?: SignatureVersionCloudflareR2 | undefined;
  objectACL?: any | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassCloudflareR2 | undefined;
  /**
   * Server-side encryption for uploaded objects
   */
  serverSideEncryption?: ServerSideEncryptionCloudflareR2 | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatCloudflareR2 | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCloudflareR2 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionCloudflareR2 | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionCloudflareR2 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelCloudflareR2 | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionCloudflareR2 | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionCloudflareR2 | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumCloudflareR2> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeMicrosoftFabric = {
  MicrosoftFabric: "microsoft_fabric",
} as const;
export type TypeMicrosoftFabric = ClosedEnum<typeof TypeMicrosoftFabric>;

/**
 * Control the number of required acknowledgments
 */
export const AcknowledgmentsMicrosoftFabric = {
  /**
   * Leader
   */
  One: 1,
  /**
   * None
   */
  Zero: 0,
  /**
   * All
   */
  Minus1: -1,
} as const;
/**
 * Control the number of required acknowledgments
 */
export type AcknowledgmentsMicrosoftFabric = OpenEnum<
  typeof AcknowledgmentsMicrosoftFabric
>;

/**
 * Format to use to serialize events before writing to the Event Hubs Kafka brokers
 */
export const RecordDataFormatMicrosoftFabric = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Field _raw
   */
  Raw: "raw",
} as const;
/**
 * Format to use to serialize events before writing to the Event Hubs Kafka brokers
 */
export type RecordDataFormatMicrosoftFabric = OpenEnum<
  typeof RecordDataFormatMicrosoftFabric
>;

export const SASLMechanismMicrosoftFabric = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * OAUTHBEARER
   */
  Oauthbearer: "oauthbearer",
} as const;
export type SASLMechanismMicrosoftFabric = OpenEnum<
  typeof SASLMechanismMicrosoftFabric
>;

export const AuthenticationMethodMicrosoftFabric = {
  Secret: "secret",
  Certificate: "certificate",
} as const;
export type AuthenticationMethodMicrosoftFabric = OpenEnum<
  typeof AuthenticationMethodMicrosoftFabric
>;

/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export const MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric = {
  HttpsLoginMicrosoftonlineCom: "https://login.microsoftonline.com",
  HttpsLoginMicrosoftonlineUs: "https://login.microsoftonline.us",
  HttpsLoginPartnerMicrosoftonlineCn:
    "https://login.partner.microsoftonline.cn",
} as const;
/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export type MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric = OpenEnum<
  typeof MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric
>;

/**
 * Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
 */
export type AuthenticationMicrosoftFabric = {
  disabled?: boolean | undefined;
  mechanism?: SASLMechanismMicrosoftFabric | undefined;
  /**
   * The username for authentication. This should always be $ConnectionString.
   */
  username?: string | undefined;
  /**
   * Select or create a stored text secret corresponding to the SASL JASS Password Primary or Password Secondary
   */
  textSecret?: string | undefined;
  clientSecretAuthType?: AuthenticationMethodMicrosoftFabric | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Select or create a stored certificate
   */
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  /**
   * Endpoint used to acquire authentication tokens from Azure
   */
  oauthEndpoint?:
    | MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric
    | undefined;
  /**
   * client_id to pass in the OAuth request parameter
   */
  clientId?: string | undefined;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory
   */
  tenantId?: string | undefined;
  /**
   * Scope to pass in the OAuth request parameter
   */
  scope?: string | undefined;
};

export type TLSSettingsClientSideMicrosoftFabric = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorMicrosoftFabric = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorMicrosoftFabric = OpenEnum<
  typeof BackpressureBehaviorMicrosoftFabric
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeMicrosoftFabric = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeMicrosoftFabric = OpenEnum<typeof ModeMicrosoftFabric>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionMicrosoftFabric = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionMicrosoftFabric = OpenEnum<
  typeof CompressionMicrosoftFabric
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorMicrosoftFabric = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorMicrosoftFabric = OpenEnum<
  typeof QueueFullBehaviorMicrosoftFabric
>;

export type PqControlsMicrosoftFabric = {};

export type OutputMicrosoftFabric = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeMicrosoftFabric;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Topic name from Fabric Eventstream's endpoint
   */
  topic: string;
  /**
   * Control the number of required acknowledgments
   */
  ack?: AcknowledgmentsMicrosoftFabric | undefined;
  /**
   * Format to use to serialize events before writing to the Event Hubs Kafka brokers
   */
  format?: RecordDataFormatMicrosoftFabric | undefined;
  /**
   * Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum number of events in a batch before forcing a flush
   */
  flushEventCount?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to bootstrap server. Using TLS is highly recommended.
   */
  sasl?: AuthenticationMicrosoftFabric | undefined;
  tls?: TLSSettingsClientSideMicrosoftFabric | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorMicrosoftFabric | undefined;
  /**
   * Bootstrap server from Fabric Eventstream's endpoint
   */
  bootstrapServer: string;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeMicrosoftFabric | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionMicrosoftFabric | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorMicrosoftFabric | undefined;
  pqControls?: PqControlsMicrosoftFabric | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDatabricks = {
  Databricks: "databricks",
} as const;
export type TypeDatabricks = ClosedEnum<typeof TypeDatabricks>;

/**
 * Format of the output data
 */
export const DataFormatDatabricks = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatDatabricks = OpenEnum<typeof DataFormatDatabricks>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDatabricks = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDatabricks = OpenEnum<
  typeof BackpressureBehaviorDatabricks
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionDatabricks = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionDatabricks = OpenEnum<
  typeof DiskSpaceProtectionDatabricks
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionDatabricks = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionDatabricks = OpenEnum<typeof CompressionDatabricks>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelDatabricks = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelDatabricks = OpenEnum<
  typeof CompressionLevelDatabricks
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionDatabricks = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionDatabricks = OpenEnum<
  typeof ParquetVersionDatabricks
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionDatabricks = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionDatabricks = OpenEnum<
  typeof DataPageVersionDatabricks
>;

export type KeyValueMetadatumDatabricks = {
  key?: string | undefined;
  value: string;
};

export type OutputDatabricks = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDatabricks;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Optional path to prepend to files before uploading.
   */
  destPath?: string | undefined;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatDatabricks | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDatabricks | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionDatabricks | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Databricks workspace ID
   */
  workspaceId: string;
  /**
   * OAuth scope for Unity Catalog authentication
   */
  scope?: string | undefined;
  /**
   * OAuth client ID for Unity Catalog authentication
   */
  clientId: string;
  /**
   * Name of the catalog to use for the output
   */
  catalog?: string | undefined;
  /**
   * Name of the catalog schema to use for the output
   */
  schema?: string | undefined;
  /**
   * Name of the events volume in Databricks
   */
  eventsVolumeName?: string | undefined;
  /**
   * OAuth client secret for Unity Catalog authentication
   */
  clientTextSecret: string;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionDatabricks | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelDatabricks | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionDatabricks | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionDatabricks | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumDatabricks> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeChronicle = {
  Chronicle: "chronicle",
} as const;
export type TypeChronicle = ClosedEnum<typeof TypeChronicle>;

export const AuthenticationMethodChronicle = {
  ServiceAccount: "serviceAccount",
  ServiceAccountSecret: "serviceAccountSecret",
} as const;
export type AuthenticationMethodChronicle = OpenEnum<
  typeof AuthenticationMethodChronicle
>;

export type ResponseRetrySettingChronicle = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsChronicle = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type ExtraHttpHeaderChronicle = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeChronicle = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeChronicle = OpenEnum<
  typeof FailedRequestLoggingModeChronicle
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorChronicle = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorChronicle = OpenEnum<
  typeof BackpressureBehaviorChronicle
>;

export type CustomLabelChronicle = {
  key: string;
  value: string;
  /**
   * Designate this label for role-based access control and filtering
   */
  rbacEnabled?: boolean | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeChronicle = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeChronicle = OpenEnum<typeof ModeChronicle>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionChronicle = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionChronicle = OpenEnum<typeof CompressionChronicle>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorChronicle = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorChronicle = OpenEnum<
  typeof QueueFullBehaviorChronicle
>;

export type PqControlsChronicle = {};

export type OutputChronicle = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeChronicle;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  apiVersion?: string | undefined;
  authenticationMethod?: AuthenticationMethodChronicle | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingChronicle> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsChronicle | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Regional endpoint to send events to
   */
  region: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderChronicle> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeChronicle | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorChronicle | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  ingestionMethod?: string | undefined;
  /**
   * User-configured environment namespace to identify the data domain the logs originated from. This namespace is used as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
   */
  namespace?: string | undefined;
  /**
   * Default log type value to send to SecOps. Can be overwritten by event field __logType.
   */
  logType: string;
  /**
   * Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  logTextField?: string | undefined;
  /**
   * The Google Cloud Platform (GCP) project ID to send events to
   */
  gcpProjectId: string;
  /**
   * The Google Cloud Platform (GCP) instance to send events to. This is the Chronicle customer uuid.
   */
  gcpInstance: string;
  /**
   * Custom labels to be added to every event
   */
  customLabels?: Array<CustomLabelChronicle> | undefined;
  description?: string | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  serviceAccountCredentialsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeChronicle | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionChronicle | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorChronicle | undefined;
  pqControls?: PqControlsChronicle | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSentinelOneAiSiem = {
  SentinelOneAiSiem: "sentinel_one_ai_siem",
} as const;
export type TypeSentinelOneAiSiem = ClosedEnum<typeof TypeSentinelOneAiSiem>;

/**
 * The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
 */
export const RegionSentinelOneAiSiem = {
  Us: "US",
  Ca: "CA",
  Emea: "EMEA",
  Ap: "AP",
  Aps: "APS",
  Au: "AU",
  Custom: "Custom",
} as const;
/**
 * The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
 */
export type RegionSentinelOneAiSiem = OpenEnum<typeof RegionSentinelOneAiSiem>;

/**
 * Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
 */
export const AISIEMEndpointPath = {
  RootServicesCollectorEvent: "/services/collector/event",
  RootServicesCollectorRaw: "/services/collector/raw",
} as const;
/**
 * Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
 */
export type AISIEMEndpointPath = OpenEnum<typeof AISIEMEndpointPath>;

export type ExtraHttpHeaderSentinelOneAiSiem = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeSentinelOneAiSiem = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeSentinelOneAiSiem = OpenEnum<
  typeof FailedRequestLoggingModeSentinelOneAiSiem
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodSentinelOneAiSiem = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodSentinelOneAiSiem = OpenEnum<
  typeof AuthenticationMethodSentinelOneAiSiem
>;

export type ResponseRetrySettingSentinelOneAiSiem = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsSentinelOneAiSiem = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSentinelOneAiSiem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSentinelOneAiSiem = OpenEnum<
  typeof BackpressureBehaviorSentinelOneAiSiem
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSentinelOneAiSiem = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSentinelOneAiSiem = OpenEnum<typeof ModeSentinelOneAiSiem>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSentinelOneAiSiem = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSentinelOneAiSiem = OpenEnum<
  typeof CompressionSentinelOneAiSiem
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSentinelOneAiSiem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSentinelOneAiSiem = OpenEnum<
  typeof QueueFullBehaviorSentinelOneAiSiem
>;

export type PqControlsSentinelOneAiSiem = {};

export type OutputSentinelOneAiSiem = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSentinelOneAiSiem;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The SentinelOne region to send events to. In most cases you can find the region by either looking at your SentinelOne URL or knowing what geographic region your SentinelOne instance is contained in.
   */
  region?: RegionSentinelOneAiSiem | undefined;
  /**
   * Endpoint to send events to. Use /services/collector/event for structured JSON payloads with standard HEC top-level fields. Use /services/collector/raw for unstructured log lines (plain text).
   */
  endpoint?: AISIEMEndpointPath | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderSentinelOneAiSiem> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?:
    | FailedRequestLoggingModeSentinelOneAiSiem
    | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodSentinelOneAiSiem | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<ResponseRetrySettingSentinelOneAiSiem>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSentinelOneAiSiem | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSentinelOneAiSiem | undefined;
  description?: string | undefined;
  /**
   * In the SentinelOne Console select Policy & Settings then select the Singularity AI SIEM section, API Keys will be at the bottom. Under Log Access Keys select a Write token and copy it here
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Base URL of the endpoint used to send events to, such as https://<Your-S1-Tenant>.sentinelone.net. Must begin with http:// or https://, can include a port number, and no trailing slashes. Matches pattern: ^https?://[a-zA-Z0-9.-]+(:[0-9]+)?$.
   */
  baseUrl?: string | undefined;
  /**
   * Define serverHost for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myServer').
   */
  hostExpression?: string | undefined;
  /**
   * Define logFile for events using a JavaScript expression. You must enclose text constants in quotes (such as, 'myLogFile.txt').
   */
  sourceExpression?: string | undefined;
  /**
   * Define the parser for events using a JavaScript expression. This value helps parse data into AI SIEM. You must enclose text constants in quotes (such as, 'dottedJson'). For custom parsers, substitute 'dottedJson' with your parser's name.
   */
  sourceTypeExpression?: string | undefined;
  /**
   * Define the dataSource.category for events using a JavaScript expression. This value helps categorize data and helps enable extra features in SentinelOne AI SIEM. You must enclose text constants in quotes. The default value is 'security'.
   */
  dataSourceCategoryExpression?: string | undefined;
  /**
   * Define the dataSource.name for events using a JavaScript expression. This value should reflect the type of data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'networkActivity' or 'authLogs').
   */
  dataSourceNameExpression?: string | undefined;
  /**
   * Define the dataSource.vendor for events using a JavaScript expression. This value should reflect the vendor of the data being inserted into AI SIEM. You must enclose text constants in quotes (such as, 'Cisco' or 'Microsoft').
   */
  dataSourceVendorExpression?: string | undefined;
  /**
   * Optionally, define the event.type for events using a JavaScript expression. This value acts as a label, grouping events into meaningful categories. You must enclose text constants in quotes (such as, 'Process Creation' or 'Network Connection').
   */
  eventTypeExpression?: string | undefined;
  /**
   * Define the serverHost for events using a JavaScript expression. This value will be passed to AI SIEM. You must enclose text constants in quotes (such as, 'myServerName').
   */
  host?: string | undefined;
  /**
   * Specify the logFile value to pass as a parameter to SentinelOne AI SIEM. Don't quote this value. The default is cribl.
   */
  source?: string | undefined;
  /**
   * Specify the sourcetype parameter for SentinelOne AI SIEM, which determines the parser. Don't quote this value. For custom parsers, substitute hecRawParser with your parser's name. The default is hecRawParser.
   */
  sourceType?: string | undefined;
  /**
   * Specify the dataSource.category value to pass as a parameter to SentinelOne AI SIEM. This value helps categorize data and enables additional features. Don't quote this value. The default is security.
   */
  dataSourceCategory?: string | undefined;
  /**
   * Specify the dataSource.name value to pass as a parameter to AI SIEM. This value should reflect the type of data being inserted. Don't quote this value. The default is cribl.
   */
  dataSourceName?: string | undefined;
  /**
   * Specify the dataSource.vendorvalue to pass as a parameter to AI SIEM. This value should reflect the vendor of the data being inserted. Don't quote this value. The default is cribl.
   */
  dataSourceVendor?: string | undefined;
  /**
   * Specify the event.type value to pass as an optional parameter to AI SIEM. This value acts as a label, grouping events into meaningful categories like Process Creation, File Modification, or Network Connection. Don't quote this value. By default, this field is empty.
   */
  eventType?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSentinelOneAiSiem | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSentinelOneAiSiem | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSentinelOneAiSiem | undefined;
  pqControls?: PqControlsSentinelOneAiSiem | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDynatraceOtlp = {
  DynatraceOtlp: "dynatrace_otlp",
} as const;
export type TypeDynatraceOtlp = ClosedEnum<typeof TypeDynatraceOtlp>;

/**
 * Select a transport option for Dynatrace
 */
export const ProtocolDynatraceOtlp = {
  /**
   * HTTP
   */
  Http: "http",
} as const;
/**
 * Select a transport option for Dynatrace
 */
export type ProtocolDynatraceOtlp = OpenEnum<typeof ProtocolDynatraceOtlp>;

/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export const OTLPVersionDynatraceOTLP = {
  /**
   * 1.3.1
   */
  OneDot3Dot1: "1.3.1",
} as const;
/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export type OTLPVersionDynatraceOTLP = OpenEnum<
  typeof OTLPVersionDynatraceOTLP
>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const CompressCompressionDynatraceOtlp = {
  /**
   * None
   */
  None: "none",
  /**
   * Deflate
   */
  Deflate: "deflate",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type CompressCompressionDynatraceOtlp = OpenEnum<
  typeof CompressCompressionDynatraceOtlp
>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const HttpCompressCompressionDynatraceOtlp = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type HttpCompressCompressionDynatraceOtlp = OpenEnum<
  typeof HttpCompressCompressionDynatraceOtlp
>;

export type MetadatumDynatraceOtlp = {
  key?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeDynatraceOtlp = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeDynatraceOtlp = OpenEnum<
  typeof FailedRequestLoggingModeDynatraceOtlp
>;

/**
 * Select the type of Dynatrace endpoint configured
 */
export const EndpointType = {
  /**
   * SaaS
   */
  Saas: "saas",
  /**
   * ActiveGate
   */
  Ag: "ag",
} as const;
/**
 * Select the type of Dynatrace endpoint configured
 */
export type EndpointType = OpenEnum<typeof EndpointType>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDynatraceOtlp = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDynatraceOtlp = OpenEnum<
  typeof BackpressureBehaviorDynatraceOtlp
>;

export type ExtraHttpHeaderDynatraceOtlp = {
  name?: string | undefined;
  value: string;
};

export type ResponseRetrySettingDynatraceOtlp = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsDynatraceOtlp = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeDynatraceOtlp = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeDynatraceOtlp = OpenEnum<typeof ModeDynatraceOtlp>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionDynatraceOtlp = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionDynatraceOtlp = OpenEnum<
  typeof PqCompressCompressionDynatraceOtlp
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorDynatraceOtlp = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorDynatraceOtlp = OpenEnum<
  typeof QueueFullBehaviorDynatraceOtlp
>;

export type PqControlsDynatraceOtlp = {};

export type OutputDynatraceOtlp = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDynatraceOtlp;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select a transport option for Dynatrace
   */
  protocol?: ProtocolDynatraceOtlp | undefined;
  /**
   * The endpoint where Dynatrace events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
   */
  endpoint?: string | undefined;
  /**
   * The version of OTLP Protobuf definitions to use when structuring data to send
   */
  otlpVersion?: OTLPVersionDynatraceOTLP | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  compress?: CompressCompressionDynatraceOtlp | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  httpCompress?: HttpCompressCompressionDynatraceOtlp | undefined;
  /**
   * If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpTracesEndpointOverride?: string | undefined;
  /**
   * If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpMetricsEndpointOverride?: string | undefined;
  /**
   * If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpLogsEndpointOverride?: string | undefined;
  /**
   * List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
   */
  metadata?: Array<MetadatumDynatraceOtlp> | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size (in KB) of the request body. The maximum payload size is 4 MB. If this limit is exceeded, the entire OTLP message is dropped
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeDynatraceOtlp | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * How often the sender should ping the peer to keep the connection open
   */
  keepAliveTime?: number | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Select the type of Dynatrace endpoint configured
   */
  endpointType?: EndpointType | undefined;
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  authTokenName?: string | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDynatraceOtlp | undefined;
  description?: string | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderDynatraceOtlp> | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingDynatraceOtlp> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDynatraceOtlp | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeDynatraceOtlp | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionDynatraceOtlp | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorDynatraceOtlp | undefined;
  pqControls?: PqControlsDynatraceOtlp | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDynatraceHTTP = {
  DynatraceHttp: "dynatrace_http",
} as const;
export type TypeDynatraceHTTP = ClosedEnum<typeof TypeDynatraceHTTP>;

/**
 * The method to use when sending events
 */
export const MethodDynatraceHTTP = {
  Post: "POST",
  Put: "PUT",
  Patch: "PATCH",
} as const;
/**
 * The method to use when sending events
 */
export type MethodDynatraceHTTP = OpenEnum<typeof MethodDynatraceHTTP>;

export type ExtraHTTPHeaderDynatraceHTTP = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeDynatraceHTTP = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeDynatraceHTTP = OpenEnum<
  typeof FailedRequestLoggingModeDynatraceHTTP
>;

export type ResponseRetrySettingDynatraceHTTP = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsDynatraceHTTP = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDynatraceHTTP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDynatraceHTTP = OpenEnum<
  typeof BackpressureBehaviorDynatraceHTTP
>;

export const AuthenticationTypeDynatraceHTTP = {
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Token (text secret)
   */
  TextSecret: "textSecret",
} as const;
export type AuthenticationTypeDynatraceHTTP = OpenEnum<
  typeof AuthenticationTypeDynatraceHTTP
>;

/**
 * How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
 */
export const FormatDynatraceHTTP = {
  /**
   * JSON
   */
  JsonArray: "json_array",
  /**
   * Plaintext
   */
  Plaintext: "plaintext",
} as const;
/**
 * How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
 */
export type FormatDynatraceHTTP = OpenEnum<typeof FormatDynatraceHTTP>;

export const Endpoint = {
  /**
   * Cloud
   */
  Cloud: "cloud",
  /**
   * ActiveGate
   */
  ActiveGate: "activeGate",
  /**
   * Manual
   */
  Manual: "manual",
} as const;
export type Endpoint = OpenEnum<typeof Endpoint>;

export const TelemetryType = {
  /**
   * Logs
   */
  Logs: "logs",
  /**
   * Metrics
   */
  Metrics: "metrics",
} as const;
export type TelemetryType = OpenEnum<typeof TelemetryType>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeDynatraceHTTP = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeDynatraceHTTP = OpenEnum<typeof ModeDynatraceHTTP>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionDynatraceHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionDynatraceHTTP = OpenEnum<
  typeof CompressionDynatraceHTTP
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorDynatraceHTTP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorDynatraceHTTP = OpenEnum<
  typeof QueueFullBehaviorDynatraceHTTP
>;

export type PqControlsDynatraceHTTP = {};

export type OutputDynatraceHttp = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDynatraceHTTP;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The method to use when sending events
   */
  method?: MethodDynatraceHTTP | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
   */
  extraHttpHeaders?: Array<ExtraHTTPHeaderDynatraceHTTP> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeDynatraceHTTP | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingDynatraceHTTP> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDynatraceHTTP | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDynatraceHTTP | undefined;
  authType?: AuthenticationTypeDynatraceHTTP | undefined;
  /**
   * How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
   */
  format?: FormatDynatraceHTTP | undefined;
  endpoint?: Endpoint | undefined;
  telemetryType?: TelemetryType | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeDynatraceHTTP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionDynatraceHTTP | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorDynatraceHTTP | undefined;
  pqControls?: PqControlsDynatraceHTTP | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * ID of the environment to send to
   */
  environmentId?: string | undefined;
  /**
   * ActiveGate domain with Log analytics collector module enabled. For example https://{activeGate-domain}:9999/e/{environment-id}/api/v2/logs/ingest.
   */
  activeGateDomain?: string | undefined;
  /**
   * URL to send events to. Can be overwritten by an event's __url field.
   */
  url?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeNetflow = {
  Netflow: "netflow",
} as const;
export type OutputTypeNetflow = ClosedEnum<typeof OutputTypeNetflow>;

export type HostNetflow = {
  /**
   * Destination host
   */
  host: string;
  /**
   * Destination port, default is 2055
   */
  port?: number | undefined;
};

export type OutputNetflow = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeNetflow;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * One or more NetFlow destinations to forward events to
   */
  hosts: Array<HostNetflow>;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every datagram sent will incur a DNS lookup.
   */
  dnsResolvePeriodSec?: number | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeXsiam = {
  Xsiam: "xsiam",
} as const;
export type TypeXsiam = ClosedEnum<typeof TypeXsiam>;

export type ExtraHttpHeaderXsiam = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeXsiam = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeXsiam = OpenEnum<
  typeof FailedRequestLoggingModeXsiam
>;

/**
 * Enter a token directly, or provide a secret referencing a token
 */
export const AuthenticationMethodXsiam = {
  Token: "token",
  Secret: "secret",
} as const;
/**
 * Enter a token directly, or provide a secret referencing a token
 */
export type AuthenticationMethodXsiam = OpenEnum<
  typeof AuthenticationMethodXsiam
>;

export type ResponseRetrySettingXsiam = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsXsiam = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorXsiam = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorXsiam = OpenEnum<
  typeof BackpressureBehaviorXsiam
>;

export type UrlXsiam = {
  url?: any | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeXsiam = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeXsiam = OpenEnum<typeof ModeXsiam>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionXsiam = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionXsiam = OpenEnum<typeof CompressionXsiam>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorXsiam = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorXsiam = OpenEnum<typeof QueueFullBehaviorXsiam>;

export type PqControlsXsiam = {};

export type OutputXsiam = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeXsiam;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderXsiam> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeXsiam | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Enter a token directly, or provide a secret referencing a token
   */
  authType?: AuthenticationMethodXsiam | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingXsiam> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsXsiam | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Maximum number of requests to limit to per second
   */
  throttleRateReqPerSec?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorXsiam | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * XSIAM endpoint URL to send events to, such as https://api-{tenant external URL}/logs/v1/event
   */
  url?: string | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<UrlXsiam> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * XSIAM authentication token
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeXsiam | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionXsiam | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorXsiam | undefined;
  pqControls?: PqControlsXsiam | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeClickHouse = {
  ClickHouse: "click_house",
} as const;
export type TypeClickHouse = ClosedEnum<typeof TypeClickHouse>;

export const AuthenticationTypeClickHouse = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  SslUserCertificate: "sslUserCertificate",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
export type AuthenticationTypeClickHouse = OpenEnum<
  typeof AuthenticationTypeClickHouse
>;

/**
 * Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
 */
export const FormatClickHouse = {
  /**
   * JSONCompactEachRowWithNames
   */
  JsonCompactEachRowWithNames: "json-compact-each-row-with-names",
  /**
   * JSONEachRow
   */
  JsonEachRow: "json-each-row",
} as const;
/**
 * Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
 */
export type FormatClickHouse = OpenEnum<typeof FormatClickHouse>;

/**
 * How event fields are mapped to ClickHouse columns.
 */
export const MappingType = {
  /**
   * Automatic
   */
  Automatic: "automatic",
  /**
   * Custom
   */
  Custom: "custom",
} as const;
/**
 * How event fields are mapped to ClickHouse columns.
 */
export type MappingType = OpenEnum<typeof MappingType>;

export const MinimumTLSVersionClickHouse = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionClickHouse = OpenEnum<
  typeof MinimumTLSVersionClickHouse
>;

export const MaximumTLSVersionClickHouse = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionClickHouse = OpenEnum<
  typeof MaximumTLSVersionClickHouse
>;

export type TLSSettingsClientSideClickHouse = {
  disabled?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: MinimumTLSVersionClickHouse | undefined;
  maxVersion?: MaximumTLSVersionClickHouse | undefined;
};

export type ExtraHttpHeaderClickHouse = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeClickHouse = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeClickHouse = OpenEnum<
  typeof FailedRequestLoggingModeClickHouse
>;

export type ResponseRetrySettingClickHouse = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsClickHouse = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorClickHouse = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorClickHouse = OpenEnum<
  typeof BackpressureBehaviorClickHouse
>;

export type OauthParamClickHouse = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderClickHouse = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type ColumnMapping = {
  /**
   * Name of the column in ClickHouse that will store field value
   */
  columnName: string;
  /**
   * Type of the column in the ClickHouse database
   */
  columnType?: string | undefined;
  /**
   * JavaScript expression to compute value to be inserted into ClickHouse table
   */
  columnValueExpression: string;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeClickHouse = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeClickHouse = OpenEnum<typeof ModeClickHouse>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionClickHouse = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionClickHouse = OpenEnum<typeof CompressionClickHouse>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorClickHouse = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorClickHouse = OpenEnum<
  typeof QueueFullBehaviorClickHouse
>;

export type PqControlsClickHouse = {};

export type OutputClickHouse = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeClickHouse;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * URL of the ClickHouse instance. Example: http://localhost:8123/
   */
  url: string;
  authType?: AuthenticationTypeClickHouse | undefined;
  database: string;
  /**
   * Name of the ClickHouse table where data will be inserted. Name can contain letters (A-Z, a-z), numbers (0-9), and the character "_", and must start with either a letter or the character "_".
   */
  tableName: string;
  /**
   * Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
   */
  format?: FormatClickHouse | undefined;
  /**
   * How event fields are mapped to ClickHouse columns.
   */
  mappingType?: MappingType | undefined;
  /**
   * Collect data into batches for later processing. Disable to write to a ClickHouse table immediately.
   */
  asyncInserts?: boolean | undefined;
  tls?: TLSSettingsClientSideClickHouse | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderClickHouse> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeClickHouse | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingClickHouse> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsClickHouse | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Log the most recent event that fails to match the table schema
   */
  dumpFormatErrorsToDisk?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorClickHouse | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamClickHouse> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderClickHouse> | undefined;
  /**
   * Username for certificate authentication
   */
  sqlUsername?: string | undefined;
  /**
   * Cribl will wait for confirmation that data has been fully inserted into the ClickHouse database before proceeding. Disabling this option can increase throughput, but Cribl won’t be able to verify data has been completely inserted.
   */
  waitForAsyncInserts?: boolean | undefined;
  /**
   * Fields to exclude from sending to ClickHouse
   */
  excludeMappingFields?: Array<string> | undefined;
  /**
   * Retrieves the table schema from ClickHouse and populates the Column Mapping table
   */
  describeTable?: string | undefined;
  columnMappings?: Array<ColumnMapping> | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeClickHouse | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionClickHouse | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorClickHouse | undefined;
  pqControls?: PqControlsClickHouse | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDiskSpool = {
  DiskSpool: "disk_spool",
} as const;
export type TypeDiskSpool = ClosedEnum<typeof TypeDiskSpool>;

/**
 * Data compression format. Default is gzip.
 */
export const CompressionDiskSpool = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format. Default is gzip.
 */
export type CompressionDiskSpool = OpenEnum<typeof CompressionDiskSpool>;

export type OutputDiskSpool = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDiskSpool;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Time period for grouping spooled events. Default is 10m.
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
   */
  maxDataTime?: string | undefined;
  /**
   * Data compression format. Default is gzip.
   */
  compress?: CompressionDiskSpool | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized within the time-buckets. If blank, the event's __partition property is used and otherwise, events go directly into the time-bucket directory.
   */
  partitionExpr?: string | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCriblLake = {
  CriblLake: "cribl_lake",
} as const;
export type TypeCriblLake = ClosedEnum<typeof TypeCriblLake>;

/**
 * Signature version to use for signing S3 requests
 */
export const SignatureVersionCriblLake = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type SignatureVersionCriblLake = OpenEnum<
  typeof SignatureVersionCriblLake
>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLCriblLake = {
  /**
   * Private
   */
  Private: "private",
  /**
   * Public Read Only
   */
  PublicRead: "public-read",
  /**
   * Public Read/Write
   */
  PublicReadWrite: "public-read-write",
  /**
   * Authenticated Read Only
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * AWS EC2 AMI Read Only
   */
  AwsExecRead: "aws-exec-read",
  /**
   * Bucket Owner Read Only
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * Bucket Owner Full Control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLCriblLake = OpenEnum<typeof ObjectACLCriblLake>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassCriblLake = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
  /**
   * Standard, Infrequent Access
   */
  StandardIa: "STANDARD_IA",
  /**
   * One Zone, Infrequent Access
   */
  OnezoneIa: "ONEZONE_IA",
  /**
   * Intelligent Tiering
   */
  IntelligentTiering: "INTELLIGENT_TIERING",
  /**
   * Glacier Flexible Retrieval
   */
  Glacier: "GLACIER",
  /**
   * Glacier Instant Retrieval
   */
  GlacierIr: "GLACIER_IR",
  /**
   * Glacier Deep Archive
   */
  DeepArchive: "DEEP_ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassCriblLake = OpenEnum<typeof StorageClassCriblLake>;

export const ServerSideEncryptionForUploadedObjectsCriblLake = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
  /**
   * AWS KMS Managed Key
   */
  AwsKms: "aws:kms",
} as const;
export type ServerSideEncryptionForUploadedObjectsCriblLake = OpenEnum<
  typeof ServerSideEncryptionForUploadedObjectsCriblLake
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCriblLake = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCriblLake = OpenEnum<
  typeof BackpressureBehaviorCriblLake
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionCriblLake = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionCriblLake = OpenEnum<
  typeof DiskSpaceProtectionCriblLake
>;

export const AwsAuthenticationMethod = {
  Auto: "auto",
  AutoRpc: "auto_rpc",
  Manual: "manual",
} as const;
export type AwsAuthenticationMethod = OpenEnum<typeof AwsAuthenticationMethod>;

export const FormatCriblLake = {
  Json: "json",
  Parquet: "parquet",
  Ddss: "ddss",
} as const;
export type FormatCriblLake = OpenEnum<typeof FormatCriblLake>;

export type OutputCriblLake = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeCriblLake;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket?: string | undefined;
  /**
   * Region where the S3 bucket is located
   */
  region?: string | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
   */
  awsSecretKey?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: SignatureVersionCriblLake | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Lake dataset to send the data to.
   */
  destPath?: string | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLCriblLake | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassCriblLake | undefined;
  serverSideEncryption?:
    | ServerSideEncryptionForUploadedObjectsCriblLake
    | undefined;
  /**
   * ID or ARN of the KMS customer-managed key to use for encryption
   */
  kmsKeyId?: string | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCriblLake | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionCriblLake | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Maximum number of files that can be waiting for upload before backpressure is applied
   */
  maxClosingFilesToBackpressure?: number | undefined;
  awsAuthenticationMethod?: AwsAuthenticationMethod | undefined;
  format?: FormatCriblLake | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  description?: string | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSecurityLake = {
  SecurityLake: "security_lake",
} as const;
export type OutputTypeSecurityLake = ClosedEnum<typeof OutputTypeSecurityLake>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputAuthenticationMethodSecurityLake = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputAuthenticationMethodSecurityLake = OpenEnum<
  typeof OutputAuthenticationMethodSecurityLake
>;

/**
 * Signature version to use for signing Amazon Security Lake requests
 */
export const OutputSignatureVersionSecurityLake = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing Amazon Security Lake requests
 */
export type OutputSignatureVersionSecurityLake = OpenEnum<
  typeof OutputSignatureVersionSecurityLake
>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLSecurityLake = {
  /**
   * Private
   */
  Private: "private",
  /**
   * Public Read Only
   */
  PublicRead: "public-read",
  /**
   * Public Read/Write
   */
  PublicReadWrite: "public-read-write",
  /**
   * Authenticated Read Only
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * AWS EC2 AMI Read Only
   */
  AwsExecRead: "aws-exec-read",
  /**
   * Bucket Owner Read Only
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * Bucket Owner Full Control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLSecurityLake = OpenEnum<typeof ObjectACLSecurityLake>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassSecurityLake = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
  /**
   * Standard, Infrequent Access
   */
  StandardIa: "STANDARD_IA",
  /**
   * One Zone, Infrequent Access
   */
  OnezoneIa: "ONEZONE_IA",
  /**
   * Intelligent Tiering
   */
  IntelligentTiering: "INTELLIGENT_TIERING",
  /**
   * Glacier Flexible Retrieval
   */
  Glacier: "GLACIER",
  /**
   * Glacier Instant Retrieval
   */
  GlacierIr: "GLACIER_IR",
  /**
   * Glacier Deep Archive
   */
  DeepArchive: "DEEP_ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassSecurityLake = OpenEnum<
  typeof StorageClassSecurityLake
>;

export const ServerSideEncryptionForUploadedObjectsSecurityLake = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
  /**
   * AWS KMS Managed Key
   */
  AwsKms: "aws:kms",
} as const;
export type ServerSideEncryptionForUploadedObjectsSecurityLake = OpenEnum<
  typeof ServerSideEncryptionForUploadedObjectsSecurityLake
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSecurityLake = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSecurityLake = OpenEnum<
  typeof BackpressureBehaviorSecurityLake
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionSecurityLake = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionSecurityLake = OpenEnum<
  typeof DiskSpaceProtectionSecurityLake
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionSecurityLake = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionSecurityLake = OpenEnum<
  typeof ParquetVersionSecurityLake
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionSecurityLake = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionSecurityLake = OpenEnum<
  typeof DataPageVersionSecurityLake
>;

export type KeyValueMetadatumSecurityLake = {
  key?: string | undefined;
  value: string;
};

export type OutputSecurityLake = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSecurityLake;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * Region where the Amazon Security Lake is located.
   */
  region: string;
  awsSecretKey?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputAuthenticationMethodSecurityLake | undefined;
  /**
   * Amazon Security Lake service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Amazon Security Lake requests
   */
  signatureVersion?: OutputSignatureVersionSecurityLake | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn: string;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLSecurityLake | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassSecurityLake | undefined;
  serverSideEncryption?:
    | ServerSideEncryptionForUploadedObjectsSecurityLake
    | undefined;
  /**
   * ID or ARN of the KMS customer-managed key to use for encryption
   */
  kmsKeyId?: string | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSecurityLake | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionSecurityLake | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Maximum number of files that can be waiting for upload before backpressure is applied
   */
  maxClosingFilesToBackpressure?: number | undefined;
  /**
   * ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
   */
  accountId: string;
  /**
   * Name of the custom source configured in Amazon Security Lake
   */
  customSource: string;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionSecurityLake | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionSecurityLake | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumSecurityLake> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDlS3 = {
  DlS3: "dl_s3",
} as const;
export type TypeDlS3 = ClosedEnum<typeof TypeDlS3>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodDlS3 = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodDlS3 = OpenEnum<
  typeof AuthenticationMethodDlS3
>;

/**
 * Signature version to use for signing S3 requests
 */
export const SignatureVersionDlS3 = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type SignatureVersionDlS3 = OpenEnum<typeof SignatureVersionDlS3>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLDlS3 = {
  /**
   * Private
   */
  Private: "private",
  /**
   * Public Read Only
   */
  PublicRead: "public-read",
  /**
   * Public Read/Write
   */
  PublicReadWrite: "public-read-write",
  /**
   * Authenticated Read Only
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * AWS EC2 AMI Read Only
   */
  AwsExecRead: "aws-exec-read",
  /**
   * Bucket Owner Read Only
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * Bucket Owner Full Control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLDlS3 = OpenEnum<typeof ObjectACLDlS3>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassDlS3 = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
  /**
   * Standard, Infrequent Access
   */
  StandardIa: "STANDARD_IA",
  /**
   * One Zone, Infrequent Access
   */
  OnezoneIa: "ONEZONE_IA",
  /**
   * Intelligent Tiering
   */
  IntelligentTiering: "INTELLIGENT_TIERING",
  /**
   * Glacier Flexible Retrieval
   */
  Glacier: "GLACIER",
  /**
   * Glacier Instant Retrieval
   */
  GlacierIr: "GLACIER_IR",
  /**
   * Glacier Deep Archive
   */
  DeepArchive: "DEEP_ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassDlS3 = OpenEnum<typeof StorageClassDlS3>;

export const ServerSideEncryptionForUploadedObjectsDlS3 = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
  /**
   * AWS KMS Managed Key
   */
  AwsKms: "aws:kms",
} as const;
export type ServerSideEncryptionForUploadedObjectsDlS3 = OpenEnum<
  typeof ServerSideEncryptionForUploadedObjectsDlS3
>;

/**
 * Format of the output data
 */
export const DataFormatDlS3 = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatDlS3 = OpenEnum<typeof DataFormatDlS3>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDlS3 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDlS3 = OpenEnum<
  typeof BackpressureBehaviorDlS3
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionDlS3 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionDlS3 = OpenEnum<typeof DiskSpaceProtectionDlS3>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionDlS3 = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionDlS3 = OpenEnum<typeof CompressionDlS3>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelDlS3 = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelDlS3 = OpenEnum<typeof CompressionLevelDlS3>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionDlS3 = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionDlS3 = OpenEnum<typeof ParquetVersionDlS3>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionDlS3 = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionDlS3 = OpenEnum<typeof DataPageVersionDlS3>;

export type KeyValueMetadatumDlS3 = {
  key?: string | undefined;
  value: string;
};

export type OutputDlS3 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDlS3;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * Region where the S3 bucket is located
   */
  region?: string | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
   */
  awsSecretKey?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodDlS3 | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: SignatureVersionDlS3 | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
   */
  destPath?: string | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLDlS3 | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassDlS3 | undefined;
  serverSideEncryption?: ServerSideEncryptionForUploadedObjectsDlS3 | undefined;
  /**
   * ID or ARN of the KMS customer-managed key to use for encryption
   */
  kmsKeyId?: string | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatDlS3 | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDlS3 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionDlS3 | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Maximum number of files that can be waiting for upload before backpressure is applied
   */
  maxClosingFilesToBackpressure?: number | undefined;
  /**
   * List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
   */
  partitioningFields?: Array<string> | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionDlS3 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelDlS3 | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionDlS3 | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionDlS3 | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumDlS3> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCrowdstrikeNextGenSiem = {
  CrowdstrikeNextGenSiem: "crowdstrike_next_gen_siem",
} as const;
export type TypeCrowdstrikeNextGenSiem = ClosedEnum<
  typeof TypeCrowdstrikeNextGenSiem
>;

export type ExtraHttpHeaderCrowdstrikeNextGenSiem = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeCrowdstrikeNextGenSiem = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeCrowdstrikeNextGenSiem = OpenEnum<
  typeof FailedRequestLoggingModeCrowdstrikeNextGenSiem
>;

/**
 * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
 */
export const RequestFormatCrowdstrikeNextGenSiem = {
  /**
   * JSON
   */
  Json: "JSON",
  /**
   * Raw
   */
  Raw: "raw",
} as const;
/**
 * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
 */
export type RequestFormatCrowdstrikeNextGenSiem = OpenEnum<
  typeof RequestFormatCrowdstrikeNextGenSiem
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodCrowdstrikeNextGenSiem = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodCrowdstrikeNextGenSiem = OpenEnum<
  typeof AuthenticationMethodCrowdstrikeNextGenSiem
>;

export type ResponseRetrySettingCrowdstrikeNextGenSiem = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsCrowdstrikeNextGenSiem = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCrowdstrikeNextGenSiem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCrowdstrikeNextGenSiem = OpenEnum<
  typeof BackpressureBehaviorCrowdstrikeNextGenSiem
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeCrowdstrikeNextGenSiem = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeCrowdstrikeNextGenSiem = OpenEnum<
  typeof ModeCrowdstrikeNextGenSiem
>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCrowdstrikeNextGenSiem = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCrowdstrikeNextGenSiem = OpenEnum<
  typeof CompressionCrowdstrikeNextGenSiem
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorCrowdstrikeNextGenSiem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorCrowdstrikeNextGenSiem = OpenEnum<
  typeof QueueFullBehaviorCrowdstrikeNextGenSiem
>;

export type PqControlsCrowdstrikeNextGenSiem = {};

export type OutputCrowdstrikeNextGenSiem = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeCrowdstrikeNextGenSiem;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * URL provided from a CrowdStrike data connector.
   *
   * @remarks
   * Example: https://ingest.<region>.crowdstrike.com/api/ingest/hec/<connection-id>/v1/services/collector
   */
  url: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderCrowdstrikeNextGenSiem> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?:
    | FailedRequestLoggingModeCrowdstrikeNextGenSiem
    | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
   */
  format?: RequestFormatCrowdstrikeNextGenSiem | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodCrowdstrikeNextGenSiem | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<ResponseRetrySettingCrowdstrikeNextGenSiem>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsCrowdstrikeNextGenSiem | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCrowdstrikeNextGenSiem | undefined;
  description?: string | undefined;
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeCrowdstrikeNextGenSiem | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionCrowdstrikeNextGenSiem | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorCrowdstrikeNextGenSiem | undefined;
  pqControls?: PqControlsCrowdstrikeNextGenSiem | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeHumioHec = {
  HumioHec: "humio_hec",
} as const;
export type TypeHumioHec = ClosedEnum<typeof TypeHumioHec>;

export type ExtraHttpHeaderHumioHec = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeHumioHec = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeHumioHec = OpenEnum<
  typeof FailedRequestLoggingModeHumioHec
>;

/**
 * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
 */
export const RequestFormatHumioHec = {
  /**
   * JSON
   */
  Json: "JSON",
  /**
   * Raw
   */
  Raw: "raw",
} as const;
/**
 * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
 */
export type RequestFormatHumioHec = OpenEnum<typeof RequestFormatHumioHec>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodHumioHec = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodHumioHec = OpenEnum<
  typeof AuthenticationMethodHumioHec
>;

export type ResponseRetrySettingHumioHec = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsHumioHec = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorHumioHec = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorHumioHec = OpenEnum<
  typeof BackpressureBehaviorHumioHec
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeHumioHec = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeHumioHec = OpenEnum<typeof ModeHumioHec>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionHumioHec = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionHumioHec = OpenEnum<typeof CompressionHumioHec>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorHumioHec = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorHumioHec = OpenEnum<
  typeof QueueFullBehaviorHumioHec
>;

export type PqControlsHumioHec = {};

export type OutputHumioHec = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeHumioHec;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * URL to a CrowdStrike Falcon LogScale endpoint to send events to. Examples: https://cloud.us.humio.com/api/v1/ingest/hec for JSON and https://cloud.us.humio.com/api/v1/ingest/hec/raw for raw
   */
  url?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderHumioHec> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeHumioHec | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
   */
  format?: RequestFormatHumioHec | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodHumioHec | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingHumioHec> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsHumioHec | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorHumioHec | undefined;
  description?: string | undefined;
  /**
   * CrowdStrike Falcon LogScale authentication token
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeHumioHec | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionHumioHec | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorHumioHec | undefined;
  pqControls?: PqControlsHumioHec | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeCriblHTTP = {
  CriblHttp: "cribl_http",
} as const;
export type OutputTypeCriblHTTP = ClosedEnum<typeof OutputTypeCriblHTTP>;

export const OutputMinimumTLSVersionCriblHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionCriblHTTP = OpenEnum<
  typeof OutputMinimumTLSVersionCriblHTTP
>;

export const OutputMaximumTLSVersionCriblHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionCriblHTTP = OpenEnum<
  typeof OutputMaximumTLSVersionCriblHTTP
>;

export type TLSSettingsClientSideCriblHTTP = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionCriblHTTP | undefined;
  maxVersion?: OutputMaximumTLSVersionCriblHTTP | undefined;
};

/**
 * Codec to use to compress the data before sending
 */
export const OutputCompressionCriblHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the data before sending
 */
export type OutputCompressionCriblHTTP = OpenEnum<
  typeof OutputCompressionCriblHTTP
>;

export type ExtraHTTPHeaderCriblHTTP = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeCriblHTTP = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeCriblHTTP = OpenEnum<
  typeof FailedRequestLoggingModeCriblHTTP
>;

export type ResponseRetrySettingCriblHTTP = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsCriblHTTP = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type OutputAuthTokenCriblHTTP = {
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  enabled?: boolean | undefined;
  description?: string | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCriblHTTP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCriblHTTP = OpenEnum<
  typeof BackpressureBehaviorCriblHTTP
>;

export type UrlCriblHTTP = {
  /**
   * URL of a Cribl Worker to send events to, such as http://localhost:10200
   */
  url: string;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeCriblHTTP = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeCriblHTTP = OpenEnum<typeof OutputModeCriblHTTP>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionCriblHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionCriblHTTP = OpenEnum<
  typeof PqCompressCompressionCriblHTTP
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorCriblHTTP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorCriblHTTP = OpenEnum<
  typeof QueueFullBehaviorCriblHTTP
>;

export type OutputPqControlsCriblHTTP = {};

export type OutputCriblHttp = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeCriblHTTP;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  tls?: TLSSettingsClientSideCriblHTTP | undefined;
  /**
   * The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
   */
  tokenTTLMinutes?: number | undefined;
  /**
   * Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
   */
  excludeFields?: Array<string> | undefined;
  /**
   * Codec to use to compress the data before sending
   */
  compression?: OutputCompressionCriblHTTP | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHTTPHeaderCriblHTTP> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeCriblHTTP | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingCriblHTTP> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsCriblHTTP | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl HTTP Source in Cribl.Cloud.
   */
  authTokens?: Array<OutputAuthTokenCriblHTTP> | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCriblHTTP | undefined;
  description?: string | undefined;
  /**
   * URL of a Cribl Worker to send events to, such as http://localhost:10200
   */
  url?: string | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<UrlCriblHTTP> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeCriblHTTP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionCriblHTTP | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorCriblHTTP | undefined;
  pqControls?: OutputPqControlsCriblHTTP | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeCriblTCP = {
  CriblTcp: "cribl_tcp",
} as const;
export type OutputTypeCriblTCP = ClosedEnum<typeof OutputTypeCriblTCP>;

/**
 * Codec to use to compress the data before sending
 */
export const OutputCompressionCriblTCP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the data before sending
 */
export type OutputCompressionCriblTCP = OpenEnum<
  typeof OutputCompressionCriblTCP
>;

export const OutputMinimumTLSVersionCriblTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionCriblTCP = OpenEnum<
  typeof OutputMinimumTLSVersionCriblTCP
>;

export const OutputMaximumTLSVersionCriblTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionCriblTCP = OpenEnum<
  typeof OutputMaximumTLSVersionCriblTCP
>;

export type TLSSettingsClientSideCriblTCP = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionCriblTCP | undefined;
  maxVersion?: OutputMaximumTLSVersionCriblTCP | undefined;
};

export type OutputAuthTokenCriblTCP = {
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  enabled?: boolean | undefined;
  /**
   * Optional token description
   */
  description?: string | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCriblTCP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCriblTCP = OpenEnum<
  typeof BackpressureBehaviorCriblTCP
>;

/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export const TLSCriblTCP = {
  Inherit: "inherit",
  Off: "off",
} as const;
/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export type TLSCriblTCP = OpenEnum<typeof TLSCriblTCP>;

export type HostCriblTCP = {
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Whether to inherit TLS configs from group setting or disable TLS
   */
  tls?: TLSCriblTCP | undefined;
  /**
   * Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
   */
  servername?: string | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeCriblTCP = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeCriblTCP = OpenEnum<typeof OutputModeCriblTCP>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionCriblTCP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionCriblTCP = OpenEnum<
  typeof PqCompressCompressionCriblTCP
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorCriblTCP = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorCriblTCP = OpenEnum<
  typeof QueueFullBehaviorCriblTCP
>;

export type OutputPqControlsCriblTCP = {};

export type OutputCriblTcp = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeCriblTCP;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Use load-balanced destinations
   */
  loadBalanced?: boolean | undefined;
  /**
   * Codec to use to compress the data before sending
   */
  compression?: OutputCompressionCriblTCP | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  tls?: TLSSettingsClientSideCriblTCP | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
   */
  tokenTTLMinutes?: number | undefined;
  /**
   * Shared secrets to be used by connected environments to authorize connections. These tokens should also be installed in Cribl TCP Source in Cribl.Cloud.
   */
  authTokens?: Array<OutputAuthTokenCriblTCP> | undefined;
  /**
   * Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
   */
  excludeFields?: Array<string> | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCriblTCP | undefined;
  description?: string | undefined;
  /**
   * The hostname of the receiver
   */
  host?: string | undefined;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of hosts to load-balance data to
   */
  hosts?: Array<HostCriblTCP> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeCriblTCP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionCriblTCP | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorCriblTCP | undefined;
  pqControls?: OutputPqControlsCriblTCP | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDataset = {
  Dataset: "dataset",
} as const;
export type TypeDataset = ClosedEnum<typeof TypeDataset>;

/**
 * Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
 */
export const DefaultSeveritySeverity = {
  /**
   * 0 - finest
   */
  Finest: "finest",
  /**
   * 1 - finer
   */
  Finer: "finer",
  /**
   * 2 - fine
   */
  Fine: "fine",
  /**
   * 3 - info
   */
  Info: "info",
  /**
   * 4 - warning
   */
  Warning: "warning",
  /**
   * 5 - error
   */
  Error: "error",
  /**
   * 6 - fatal
   */
  Fatal: "fatal",
} as const;
/**
 * Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
 */
export type DefaultSeveritySeverity = OpenEnum<typeof DefaultSeveritySeverity>;

export type ResponseRetrySettingDataset = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsDataset = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * DataSet site to which events should be sent
 */
export const DataSetSite = {
  /**
   * US
   */
  Us: "us",
  /**
   * Europe
   */
  Eu: "eu",
  /**
   * Custom
   */
  Custom: "custom",
} as const;
/**
 * DataSet site to which events should be sent
 */
export type DataSetSite = OpenEnum<typeof DataSetSite>;

export type ExtraHttpHeaderDataset = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeDataset = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeDataset = OpenEnum<
  typeof FailedRequestLoggingModeDataset
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDataset = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDataset = OpenEnum<
  typeof BackpressureBehaviorDataset
>;

/**
 * Enter API key directly, or select a stored secret
 */
export const AuthenticationMethodDataset = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter API key directly, or select a stored secret
 */
export type AuthenticationMethodDataset = OpenEnum<
  typeof AuthenticationMethodDataset
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeDataset = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeDataset = OpenEnum<typeof ModeDataset>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionDataset = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionDataset = OpenEnum<typeof CompressionDataset>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorDataset = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorDataset = OpenEnum<
  typeof QueueFullBehaviorDataset
>;

export type PqControlsDataset = {};

export type OutputDataset = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDataset;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the event field that contains the message or attributes to send. If not specified, all of the event's non-internal fields will be sent as attributes.
   */
  messageField?: string | undefined;
  /**
   * Fields to exclude from the event if the Message field is either unspecified or refers to an object. Ignored if the Message field is a string. If empty, we send all non-internal fields.
   */
  excludeFields?: Array<string> | undefined;
  /**
   * Name of the event field that contains the `serverHost` identifier. If not specified, defaults to `cribl_<outputId>`.
   */
  serverHostField?: string | undefined;
  /**
   * Name of the event field that contains the timestamp. If not specified, defaults to `ts`, `_time`, or `Date.now()`, in that order.
   */
  timestampField?: string | undefined;
  /**
   * Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
   */
  defaultSeverity?: DefaultSeveritySeverity | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingDataset> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDataset | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * DataSet site to which events should be sent
   */
  site?: DataSetSite | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderDataset> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeDataset | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDataset | undefined;
  /**
   * Enter API key directly, or select a stored secret
   */
  authType?: AuthenticationMethodDataset | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeDataset | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionDataset | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorDataset | undefined;
  pqControls?: PqControlsDataset | undefined;
  /**
   * A 'Log Write Access' API key for the DataSet account
   */
  apiKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeServiceNow = {
  ServiceNow: "service_now",
} as const;
export type TypeServiceNow = ClosedEnum<typeof TypeServiceNow>;

/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export const OTLPVersionServiceNow = {
  /**
   * 1.3.1
   */
  OneDot3Dot1: "1.3.1",
} as const;
/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export type OTLPVersionServiceNow = OpenEnum<typeof OTLPVersionServiceNow>;

/**
 * Select a transport option for OpenTelemetry
 */
export const ProtocolServiceNow = {
  /**
   * gRPC
   */
  Grpc: "grpc",
  /**
   * HTTP
   */
  Http: "http",
} as const;
/**
 * Select a transport option for OpenTelemetry
 */
export type ProtocolServiceNow = OpenEnum<typeof ProtocolServiceNow>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const CompressCompressionServiceNow = {
  /**
   * None
   */
  None: "none",
  /**
   * Deflate
   */
  Deflate: "deflate",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type CompressCompressionServiceNow = OpenEnum<
  typeof CompressCompressionServiceNow
>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const HttpCompressCompressionServiceNow = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type HttpCompressCompressionServiceNow = OpenEnum<
  typeof HttpCompressCompressionServiceNow
>;

export type MetadatumServiceNow = {
  key?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeServiceNow = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeServiceNow = OpenEnum<
  typeof FailedRequestLoggingModeServiceNow
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorServiceNow = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorServiceNow = OpenEnum<
  typeof BackpressureBehaviorServiceNow
>;

export type ExtraHttpHeaderServiceNow = {
  name?: string | undefined;
  value: string;
};

export type ResponseRetrySettingServiceNow = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsServiceNow = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export const MinimumTLSVersionServiceNow = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionServiceNow = OpenEnum<
  typeof MinimumTLSVersionServiceNow
>;

export const MaximumTLSVersionServiceNow = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionServiceNow = OpenEnum<
  typeof MaximumTLSVersionServiceNow
>;

export type TLSSettingsClientSideServiceNow = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: MinimumTLSVersionServiceNow | undefined;
  maxVersion?: MaximumTLSVersionServiceNow | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeServiceNow = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeServiceNow = OpenEnum<typeof ModeServiceNow>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionServiceNow = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionServiceNow = OpenEnum<
  typeof PqCompressCompressionServiceNow
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorServiceNow = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorServiceNow = OpenEnum<
  typeof QueueFullBehaviorServiceNow
>;

export type PqControlsServiceNow = {};

export type OutputServiceNow = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeServiceNow;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The endpoint where ServiceNow events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
   */
  endpoint?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  authTokenName?: string | undefined;
  /**
   * The version of OTLP Protobuf definitions to use when structuring data to send
   */
  otlpVersion?: OTLPVersionServiceNow | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Select a transport option for OpenTelemetry
   */
  protocol?: ProtocolServiceNow | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  compress?: CompressCompressionServiceNow | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  httpCompress?: HttpCompressCompressionServiceNow | undefined;
  /**
   * If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpTracesEndpointOverride?: string | undefined;
  /**
   * If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpMetricsEndpointOverride?: string | undefined;
  /**
   * If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpLogsEndpointOverride?: string | undefined;
  /**
   * List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
   */
  metadata?: Array<MetadatumServiceNow> | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeServiceNow | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * How often the sender should ping the peer to keep the connection open
   */
  keepAliveTime?: number | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorServiceNow | undefined;
  description?: string | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderServiceNow> | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingServiceNow> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsServiceNow | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  tls?: TLSSettingsClientSideServiceNow | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeServiceNow | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionServiceNow | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorServiceNow | undefined;
  pqControls?: PqControlsServiceNow | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeOpenTelemetry = {
  OpenTelemetry: "open_telemetry",
} as const;
export type OutputTypeOpenTelemetry = ClosedEnum<
  typeof OutputTypeOpenTelemetry
>;

/**
 * Select a transport option for OpenTelemetry
 */
export const OutputProtocolOpenTelemetry = {
  /**
   * gRPC
   */
  Grpc: "grpc",
  /**
   * HTTP
   */
  Http: "http",
} as const;
/**
 * Select a transport option for OpenTelemetry
 */
export type OutputProtocolOpenTelemetry = OpenEnum<
  typeof OutputProtocolOpenTelemetry
>;

/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export const OutputOTLPVersionOpenTelemetry = {
  /**
   * 0.10.0
   */
  ZeroDot10Dot0: "0.10.0",
  /**
   * 1.3.1
   */
  OneDot3Dot1: "1.3.1",
} as const;
/**
 * The version of OTLP Protobuf definitions to use when structuring data to send
 */
export type OutputOTLPVersionOpenTelemetry = OpenEnum<
  typeof OutputOTLPVersionOpenTelemetry
>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const OutputCompressCompressionOpenTelemetry = {
  /**
   * None
   */
  None: "none",
  /**
   * Deflate
   */
  Deflate: "deflate",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type OutputCompressCompressionOpenTelemetry = OpenEnum<
  typeof OutputCompressCompressionOpenTelemetry
>;

/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export const HttpCompressCompressionOpenTelemetry = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Type of compression to apply to messages sent to the OpenTelemetry endpoint
 */
export type HttpCompressCompressionOpenTelemetry = OpenEnum<
  typeof HttpCompressCompressionOpenTelemetry
>;

/**
 * OpenTelemetry authentication type
 */
export const OutputAuthenticationTypeOpenTelemetry = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * OpenTelemetry authentication type
 */
export type OutputAuthenticationTypeOpenTelemetry = OpenEnum<
  typeof OutputAuthenticationTypeOpenTelemetry
>;

export type OutputMetadatumOpenTelemetry = {
  key?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeOpenTelemetry = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeOpenTelemetry = OpenEnum<
  typeof FailedRequestLoggingModeOpenTelemetry
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorOpenTelemetry = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorOpenTelemetry = OpenEnum<
  typeof BackpressureBehaviorOpenTelemetry
>;

export type OutputOauthParamOpenTelemetry = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OutputOauthHeaderOpenTelemetry = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type ExtraHttpHeaderOpenTelemetry = {
  name?: string | undefined;
  value: string;
};

export type ResponseRetrySettingOpenTelemetry = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsOpenTelemetry = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export const OutputMinimumTLSVersionOpenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionOpenTelemetry = OpenEnum<
  typeof OutputMinimumTLSVersionOpenTelemetry
>;

export const OutputMaximumTLSVersionOpenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionOpenTelemetry = OpenEnum<
  typeof OutputMaximumTLSVersionOpenTelemetry
>;

export type TLSSettingsClientSideOpenTelemetry = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionOpenTelemetry | undefined;
  maxVersion?: OutputMaximumTLSVersionOpenTelemetry | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeOpenTelemetry = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeOpenTelemetry = OpenEnum<typeof OutputModeOpenTelemetry>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionOpenTelemetry = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionOpenTelemetry = OpenEnum<
  typeof PqCompressCompressionOpenTelemetry
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorOpenTelemetry = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorOpenTelemetry = OpenEnum<
  typeof QueueFullBehaviorOpenTelemetry
>;

export type OutputPqControlsOpenTelemetry = {};

export type OutputOpenTelemetry = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeOpenTelemetry;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select a transport option for OpenTelemetry
   */
  protocol?: OutputProtocolOpenTelemetry | undefined;
  /**
   * The endpoint where OTel events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets). Unspecified ports will default to 4317, unless the endpoint is an HTTPS-based URL or TLS is enabled, in which case 443 will be used.
   */
  endpoint: string;
  /**
   * The version of OTLP Protobuf definitions to use when structuring data to send
   */
  otlpVersion?: OutputOTLPVersionOpenTelemetry | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  compress?: OutputCompressCompressionOpenTelemetry | undefined;
  /**
   * Type of compression to apply to messages sent to the OpenTelemetry endpoint
   */
  httpCompress?: HttpCompressCompressionOpenTelemetry | undefined;
  /**
   * OpenTelemetry authentication type
   */
  authType?: OutputAuthenticationTypeOpenTelemetry | undefined;
  /**
   * If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpTracesEndpointOverride?: string | undefined;
  /**
   * If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpMetricsEndpointOverride?: string | undefined;
  /**
   * If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
   */
  httpLogsEndpointOverride?: string | undefined;
  /**
   * List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'.
   */
  metadata?: Array<OutputMetadatumOpenTelemetry> | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeOpenTelemetry | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * How often the sender should ping the peer to keep the connection open
   */
  keepAliveTime?: number | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorOpenTelemetry | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OutputOauthParamOpenTelemetry> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OutputOauthHeaderOpenTelemetry> | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderOpenTelemetry> | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingOpenTelemetry> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsOpenTelemetry | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  tls?: TLSSettingsClientSideOpenTelemetry | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeOpenTelemetry | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionOpenTelemetry | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorOpenTelemetry | undefined;
  pqControls?: OutputPqControlsOpenTelemetry | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeRing = {
  Ring: "ring",
} as const;
export type TypeRing = ClosedEnum<typeof TypeRing>;

/**
 * Format of the output data.
 */
export const DataFormatRing = {
  Json: "json",
  Raw: "raw",
} as const;
/**
 * Format of the output data.
 */
export type DataFormatRing = OpenEnum<typeof DataFormatRing>;

export const OutputDataCompressionFormat = {
  None: "none",
  Gzip: "gzip",
} as const;
export type OutputDataCompressionFormat = OpenEnum<
  typeof OutputDataCompressionFormat
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorRing = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorRing = OpenEnum<
  typeof BackpressureBehaviorRing
>;

export type OutputRing = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeRing;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Format of the output data.
   */
  format?: DataFormatRing | undefined;
  /**
   * JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
   */
  partitionExpr?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: OutputDataCompressionFormat | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
   */
  destPath?: string | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorRing | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypePrometheus = {
  Prometheus: "prometheus",
} as const;
export type OutputTypePrometheus = ClosedEnum<typeof OutputTypePrometheus>;

export type ExtraHttpHeaderPrometheus = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModePrometheus = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModePrometheus = OpenEnum<
  typeof FailedRequestLoggingModePrometheus
>;

export type ResponseRetrySettingPrometheus = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsPrometheus = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorPrometheus = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorPrometheus = OpenEnum<
  typeof BackpressureBehaviorPrometheus
>;

/**
 * Remote Write authentication type
 */
export const AuthenticationTypePrometheus = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Remote Write authentication type
 */
export type AuthenticationTypePrometheus = OpenEnum<
  typeof AuthenticationTypePrometheus
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModePrometheus = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModePrometheus = OpenEnum<typeof OutputModePrometheus>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionPrometheus = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionPrometheus = OpenEnum<
  typeof PqCompressCompressionPrometheus
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorPrometheus = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorPrometheus = OpenEnum<
  typeof QueueFullBehaviorPrometheus
>;

export type OutputPqControlsPrometheus = {};

export type OauthParamPrometheus = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderPrometheus = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type OutputPrometheus = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypePrometheus;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions to generated metrics.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The endpoint to send metrics to
   */
  url: string;
  /**
   * JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
   */
  metricRenameExpr?: string | undefined;
  /**
   * Generate and send metadata (`type` and `metricFamilyName`) requests
   */
  sendMetadata?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderPrometheus> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModePrometheus | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingPrometheus> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsPrometheus | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorPrometheus | undefined;
  /**
   * Remote Write authentication type
   */
  authType?: AuthenticationTypePrometheus | undefined;
  description?: string | undefined;
  /**
   * How frequently metrics metadata is sent out. Value cannot be smaller than the base Flush period set above.
   */
  metricsFlushPeriodSec?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModePrometheus | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionPrometheus | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorPrometheus | undefined;
  pqControls?: OutputPqControlsPrometheus | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamPrometheus> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderPrometheus> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeLoki = {
  Loki: "loki",
} as const;
export type OutputTypeLoki = ClosedEnum<typeof OutputTypeLoki>;

/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export const MessageFormatLoki = {
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
  /**
   * JSON
   */
  Json: "json",
} as const;
/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export type MessageFormatLoki = OpenEnum<typeof MessageFormatLoki>;

export type LabelLoki = {
  name?: string | undefined;
  value: string;
};

export const OutputAuthenticationTypeLoki = {
  /**
   * None
   */
  None: "none",
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Auth token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
} as const;
export type OutputAuthenticationTypeLoki = OpenEnum<
  typeof OutputAuthenticationTypeLoki
>;

export type ExtraHttpHeaderLoki = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeLoki = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeLoki = OpenEnum<
  typeof FailedRequestLoggingModeLoki
>;

export type ResponseRetrySettingLoki = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsLoki = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorLoki = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorLoki = OpenEnum<
  typeof BackpressureBehaviorLoki
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeLoki = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeLoki = OpenEnum<typeof OutputModeLoki>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionLoki = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionLoki = OpenEnum<
  typeof PqCompressCompressionLoki
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorLoki = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorLoki = OpenEnum<typeof QueueFullBehaviorLoki>;

export type OutputPqControlsLoki = {};

export type OutputLoki = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeLoki;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as labels to generated logs.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The endpoint to send logs to
   */
  url: string;
  /**
   * Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  message?: string | undefined;
  /**
   * Format to use when sending logs to Loki (Protobuf or JSON)
   */
  messageFormat?: MessageFormatLoki | undefined;
  /**
   * List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
   */
  labels?: Array<LabelLoki> | undefined;
  authType?: OutputAuthenticationTypeLoki | undefined;
  /**
   * Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki to complain about entries being delivered out of order.
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Defaults to 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderLoki> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeLoki | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingLoki> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsLoki | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Add per-event HTTP headers from the __headers field to outgoing requests. Events with different headers are batched and sent separately.
   */
  enableDynamicHeaders?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorLoki | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Username for authentication
   */
  username?: string | undefined;
  /**
   * Password (API key in Grafana Cloud domain) for authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeLoki | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionLoki | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorLoki | undefined;
  pqControls?: OutputPqControlsLoki | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputGrafanaCloudType2 = {
  GrafanaCloud: "grafana_cloud",
} as const;
export type OutputGrafanaCloudType2 = ClosedEnum<
  typeof OutputGrafanaCloudType2
>;

/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export const OutputGrafanaCloudMessageFormat2 = {
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
  /**
   * JSON
   */
  Json: "json",
} as const;
/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export type OutputGrafanaCloudMessageFormat2 = OpenEnum<
  typeof OutputGrafanaCloudMessageFormat2
>;

export type OutputGrafanaCloudLabel2 = {
  name?: string | undefined;
  value: string;
};

export const OutputGrafanaCloudPrometheusAuthAuthenticationType2 = {
  /**
   * None
   */
  None: "none",
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Auth token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
} as const;
export type OutputGrafanaCloudPrometheusAuthAuthenticationType2 = OpenEnum<
  typeof OutputGrafanaCloudPrometheusAuthAuthenticationType2
>;

export type OutputPrometheusAuth2 = {
  authType?: OutputGrafanaCloudPrometheusAuthAuthenticationType2 | undefined;
  /**
   * Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Username for authentication
   */
  username?: string | undefined;
  /**
   * Password (API key in Grafana Cloud domain) for authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const OutputGrafanaCloudLokiAuthAuthenticationType2 = {
  /**
   * None
   */
  None: "none",
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Auth token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
} as const;
export type OutputGrafanaCloudLokiAuthAuthenticationType2 = OpenEnum<
  typeof OutputGrafanaCloudLokiAuthAuthenticationType2
>;

export type OutputLokiAuth2 = {
  authType?: OutputGrafanaCloudLokiAuthAuthenticationType2 | undefined;
  /**
   * Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Username for authentication
   */
  username?: string | undefined;
  /**
   * Password (API key in Grafana Cloud domain) for authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export type OutputGrafanaCloudExtraHttpHeader2 = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const OutputGrafanaCloudFailedRequestLoggingMode2 = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type OutputGrafanaCloudFailedRequestLoggingMode2 = OpenEnum<
  typeof OutputGrafanaCloudFailedRequestLoggingMode2
>;

export type OutputGrafanaCloudResponseRetrySetting2 = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type OutputGrafanaCloudTimeoutRetrySettings2 = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const OutputGrafanaCloudBackpressureBehavior2 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type OutputGrafanaCloudBackpressureBehavior2 = OpenEnum<
  typeof OutputGrafanaCloudBackpressureBehavior2
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputGrafanaCloudMode2 = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputGrafanaCloudMode2 = OpenEnum<typeof OutputGrafanaCloudMode2>;

/**
 * Codec to use to compress the persisted data
 */
export const OutputGrafanaCloudCompression2 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type OutputGrafanaCloudCompression2 = OpenEnum<
  typeof OutputGrafanaCloudCompression2
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const OutputGrafanaCloudQueueFullBehavior2 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type OutputGrafanaCloudQueueFullBehavior2 = OpenEnum<
  typeof OutputGrafanaCloudQueueFullBehavior2
>;

export type OutputGrafanaCloudPqControls2 = {};

export type OutputGrafanaCloudGrafanaCloud2 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputGrafanaCloudType2;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
   */
  lokiUrl?: string | undefined;
  /**
   * The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
   */
  prometheusUrl: string;
  /**
   * Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  message?: string | undefined;
  /**
   * Format to use when sending logs to Loki (Protobuf or JSON)
   */
  messageFormat?: OutputGrafanaCloudMessageFormat2 | undefined;
  /**
   * List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
   */
  labels?: Array<OutputGrafanaCloudLabel2> | undefined;
  /**
   * JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
   */
  metricRenameExpr?: string | undefined;
  prometheusAuth?: OutputPrometheusAuth2 | undefined;
  lokiAuth?: OutputLokiAuth2 | undefined;
  /**
   * Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<OutputGrafanaCloudExtraHttpHeader2> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?:
    | OutputGrafanaCloudFailedRequestLoggingMode2
    | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<OutputGrafanaCloudResponseRetrySetting2>
    | undefined;
  timeoutRetrySettings?: OutputGrafanaCloudTimeoutRetrySettings2 | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OutputGrafanaCloudBackpressureBehavior2 | undefined;
  description?: string | undefined;
  /**
   * Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
   */
  compress?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputGrafanaCloudMode2 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: OutputGrafanaCloudCompression2 | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: OutputGrafanaCloudQueueFullBehavior2 | undefined;
  pqControls?: OutputGrafanaCloudPqControls2 | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputGrafanaCloudType1 = {
  GrafanaCloud: "grafana_cloud",
} as const;
export type OutputGrafanaCloudType1 = ClosedEnum<
  typeof OutputGrafanaCloudType1
>;

/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export const OutputGrafanaCloudMessageFormat1 = {
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
  /**
   * JSON
   */
  Json: "json",
} as const;
/**
 * Format to use when sending logs to Loki (Protobuf or JSON)
 */
export type OutputGrafanaCloudMessageFormat1 = OpenEnum<
  typeof OutputGrafanaCloudMessageFormat1
>;

export type OutputGrafanaCloudLabel1 = {
  name?: string | undefined;
  value: string;
};

export const OutputGrafanaCloudPrometheusAuthAuthenticationType1 = {
  /**
   * None
   */
  None: "none",
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Auth token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
} as const;
export type OutputGrafanaCloudPrometheusAuthAuthenticationType1 = OpenEnum<
  typeof OutputGrafanaCloudPrometheusAuthAuthenticationType1
>;

export type OutputPrometheusAuth1 = {
  authType?: OutputGrafanaCloudPrometheusAuthAuthenticationType1 | undefined;
  /**
   * Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Username for authentication
   */
  username?: string | undefined;
  /**
   * Password (API key in Grafana Cloud domain) for authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const OutputGrafanaCloudLokiAuthAuthenticationType1 = {
  /**
   * None
   */
  None: "none",
  /**
   * Auth token
   */
  Token: "token",
  /**
   * Auth token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
} as const;
export type OutputGrafanaCloudLokiAuthAuthenticationType1 = OpenEnum<
  typeof OutputGrafanaCloudLokiAuthAuthenticationType1
>;

export type OutputLokiAuth1 = {
  authType?: OutputGrafanaCloudLokiAuthAuthenticationType1 | undefined;
  /**
   * Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Username for authentication
   */
  username?: string | undefined;
  /**
   * Password (API key in Grafana Cloud domain) for authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export type OutputGrafanaCloudExtraHttpHeader1 = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const OutputGrafanaCloudFailedRequestLoggingMode1 = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type OutputGrafanaCloudFailedRequestLoggingMode1 = OpenEnum<
  typeof OutputGrafanaCloudFailedRequestLoggingMode1
>;

export type OutputGrafanaCloudResponseRetrySetting1 = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type OutputGrafanaCloudTimeoutRetrySettings1 = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const OutputGrafanaCloudBackpressureBehavior1 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type OutputGrafanaCloudBackpressureBehavior1 = OpenEnum<
  typeof OutputGrafanaCloudBackpressureBehavior1
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputGrafanaCloudMode1 = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputGrafanaCloudMode1 = OpenEnum<typeof OutputGrafanaCloudMode1>;

/**
 * Codec to use to compress the persisted data
 */
export const OutputGrafanaCloudCompression1 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type OutputGrafanaCloudCompression1 = OpenEnum<
  typeof OutputGrafanaCloudCompression1
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const OutputGrafanaCloudQueueFullBehavior1 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type OutputGrafanaCloudQueueFullBehavior1 = OpenEnum<
  typeof OutputGrafanaCloudQueueFullBehavior1
>;

export type OutputGrafanaCloudPqControls1 = {};

export type OutputGrafanaCloudGrafanaCloud1 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputGrafanaCloudType1;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
   */
  lokiUrl: string;
  /**
   * The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
   */
  prometheusUrl?: string | undefined;
  /**
   * Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  message?: string | undefined;
  /**
   * Format to use when sending logs to Loki (Protobuf or JSON)
   */
  messageFormat?: OutputGrafanaCloudMessageFormat1 | undefined;
  /**
   * List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}'
   */
  labels?: Array<OutputGrafanaCloudLabel1> | undefined;
  /**
   * JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
   */
  metricRenameExpr?: string | undefined;
  prometheusAuth?: OutputPrometheusAuth1 | undefined;
  lokiAuth?: OutputLokiAuth1 | undefined;
  /**
   * Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<OutputGrafanaCloudExtraHttpHeader1> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?:
    | OutputGrafanaCloudFailedRequestLoggingMode1
    | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<OutputGrafanaCloudResponseRetrySetting1>
    | undefined;
  timeoutRetrySettings?: OutputGrafanaCloudTimeoutRetrySettings1 | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OutputGrafanaCloudBackpressureBehavior1 | undefined;
  description?: string | undefined;
  /**
   * Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
   */
  compress?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputGrafanaCloudMode1 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: OutputGrafanaCloudCompression1 | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: OutputGrafanaCloudQueueFullBehavior1 | undefined;
  pqControls?: OutputGrafanaCloudPqControls1 | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export type OutputGrafanaCloud =
  | OutputGrafanaCloudGrafanaCloud1
  | OutputGrafanaCloudGrafanaCloud2;

export const TypeDatadog = {
  Datadog: "datadog",
} as const;
export type TypeDatadog = ClosedEnum<typeof TypeDatadog>;

/**
 * The content type to use when sending logs
 */
export const SendLogsAs = {
  /**
   * text/plain
   */
  Text: "text",
  /**
   * application/json
   */
  Json: "json",
} as const;
/**
 * The content type to use when sending logs
 */
export type SendLogsAs = OpenEnum<typeof SendLogsAs>;

/**
 * Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
 */
export const SeverityDatadog = {
  /**
   * emergency
   */
  Emergency: "emergency",
  /**
   * alert
   */
  Alert: "alert",
  /**
   * critical
   */
  Critical: "critical",
  /**
   * error
   */
  Error: "error",
  /**
   * warning
   */
  Warning: "warning",
  /**
   * notice
   */
  Notice: "notice",
  /**
   * info
   */
  Info: "info",
  /**
   * debug
   */
  Debug: "debug",
} as const;
/**
 * Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
 */
export type SeverityDatadog = OpenEnum<typeof SeverityDatadog>;

/**
 * Datadog site to which events should be sent
 */
export const DatadogSite = {
  /**
   * US
   */
  Us: "us",
  /**
   * US3
   */
  Us3: "us3",
  /**
   * US5
   */
  Us5: "us5",
  /**
   * Europe
   */
  Eu: "eu",
  /**
   * US1-FED
   */
  Fed1: "fed1",
  /**
   * AP1
   */
  Ap1: "ap1",
  /**
   * Custom
   */
  Custom: "custom",
} as const;
/**
 * Datadog site to which events should be sent
 */
export type DatadogSite = OpenEnum<typeof DatadogSite>;

export type ExtraHttpHeaderDatadog = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeDatadog = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeDatadog = OpenEnum<
  typeof FailedRequestLoggingModeDatadog
>;

export type ResponseRetrySettingDatadog = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsDatadog = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorDatadog = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorDatadog = OpenEnum<
  typeof BackpressureBehaviorDatadog
>;

/**
 * Enter API key directly, or select a stored secret
 */
export const AuthenticationMethodDatadog = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter API key directly, or select a stored secret
 */
export type AuthenticationMethodDatadog = OpenEnum<
  typeof AuthenticationMethodDatadog
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeDatadog = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeDatadog = OpenEnum<typeof ModeDatadog>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionDatadog = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionDatadog = OpenEnum<typeof CompressionDatadog>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorDatadog = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorDatadog = OpenEnum<
  typeof QueueFullBehaviorDatadog
>;

export type PqControlsDatadog = {};

export type OutputDatadog = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDatadog;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The content type to use when sending logs
   */
  contentType?: SendLogsAs | undefined;
  /**
   * Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  message?: string | undefined;
  /**
   * Name of the source to send with logs. When you send logs as JSON objects, the event's 'source' field (if set) will override this value.
   */
  source?: string | undefined;
  /**
   * Name of the host to send with logs. When you send logs as JSON objects, the event's 'host' field (if set) will override this value.
   */
  host?: string | undefined;
  /**
   * Name of the service to send with logs. When you send logs as JSON objects, the event's '__service' field (if set) will override this value.
   */
  service?: string | undefined;
  /**
   * List of tags to send with logs, such as 'env:prod' and 'env_staging:east'
   */
  tags?: Array<string> | undefined;
  /**
   * Batch events by API key and the ddtags field on the event. When disabled, batches events only by API key. If incoming events have high cardinality in the ddtags field, disabling this setting may improve Destination performance.
   */
  batchByTags?: boolean | undefined;
  /**
   * Allow API key to be set from the event's '__agent_api_key' field
   */
  allowApiKeyFromEvents?: boolean | undefined;
  /**
   * Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
   */
  severity?: SeverityDatadog | undefined;
  /**
   * Datadog site to which events should be sent
   */
  site?: DatadogSite | undefined;
  /**
   * If not enabled, Datadog will transform 'counter' metrics to 'gauge'. [Learn more about Datadog metrics types.](https://docs.datadoghq.com/metrics/types/?tab=count)
   */
  sendCountersAsCount?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderDatadog> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeDatadog | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingDatadog> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDatadog | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorDatadog | undefined;
  /**
   * Enter API key directly, or select a stored secret
   */
  authType?: AuthenticationMethodDatadog | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeDatadog | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionDatadog | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorDatadog | undefined;
  pqControls?: PqControlsDatadog | undefined;
  /**
   * Organization's API key in Datadog
   */
  apiKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSumoLogic = {
  SumoLogic: "sumo_logic",
} as const;
export type TypeSumoLogic = ClosedEnum<typeof TypeSumoLogic>;

/**
 * Preserve the raw event format instead of JSONifying it
 */
export const DataFormatSumoLogic = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
} as const;
/**
 * Preserve the raw event format instead of JSONifying it
 */
export type DataFormatSumoLogic = OpenEnum<typeof DataFormatSumoLogic>;

export type ExtraHttpHeaderSumoLogic = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeSumoLogic = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeSumoLogic = OpenEnum<
  typeof FailedRequestLoggingModeSumoLogic
>;

export type ResponseRetrySettingSumoLogic = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsSumoLogic = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSumoLogic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSumoLogic = OpenEnum<
  typeof BackpressureBehaviorSumoLogic
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSumoLogic = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSumoLogic = OpenEnum<typeof ModeSumoLogic>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSumoLogic = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSumoLogic = OpenEnum<typeof CompressionSumoLogic>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSumoLogic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSumoLogic = OpenEnum<
  typeof QueueFullBehaviorSumoLogic
>;

export type PqControlsSumoLogic = {};

export type OutputSumoLogic = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSumoLogic;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Sumo Logic HTTP collector URL to which events should be sent
   */
  url: string;
  /**
   * Override the source name configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceName field.
   */
  customSource?: string | undefined;
  /**
   * Override the source category configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceCategory field.
   */
  customCategory?: string | undefined;
  /**
   * Preserve the raw event format instead of JSONifying it
   */
  format?: DataFormatSumoLogic | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderSumoLogic> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeSumoLogic | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingSumoLogic> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSumoLogic | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSumoLogic | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSumoLogic | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSumoLogic | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSumoLogic | undefined;
  pqControls?: PqControlsSumoLogic | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSnmp = {
  Snmp: "snmp",
} as const;
export type OutputTypeSnmp = ClosedEnum<typeof OutputTypeSnmp>;

export type HostSnmp = {
  /**
   * Destination host
   */
  host: string;
  /**
   * Destination port, default is 162
   */
  port?: number | undefined;
};

export type OutputSnmp = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSnmp;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * One or more SNMP destinations to forward traps to
   */
  hosts: Array<HostSnmp>;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every trap sent will incur a DNS lookup.
   */
  dnsResolvePeriodSec?: number | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSqs = {
  Sqs: "sqs",
} as const;
export type OutputTypeSqs = ClosedEnum<typeof OutputTypeSqs>;

/**
 * The queue type used (or created). Defaults to Standard.
 */
export const OutputQueueType = {
  /**
   * Standard
   */
  Standard: "standard",
  /**
   * FIFO
   */
  Fifo: "fifo",
} as const;
/**
 * The queue type used (or created). Defaults to Standard.
 */
export type OutputQueueType = OpenEnum<typeof OutputQueueType>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputAuthenticationMethodSqs = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputAuthenticationMethodSqs = OpenEnum<
  typeof OutputAuthenticationMethodSqs
>;

/**
 * Signature version to use for signing SQS requests
 */
export const OutputSignatureVersionSqs = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing SQS requests
 */
export type OutputSignatureVersionSqs = OpenEnum<
  typeof OutputSignatureVersionSqs
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSqs = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSqs = OpenEnum<typeof BackpressureBehaviorSqs>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeSqs = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeSqs = OpenEnum<typeof OutputModeSqs>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionSqs = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionSqs = OpenEnum<
  typeof PqCompressCompressionSqs
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSqs = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSqs = OpenEnum<typeof QueueFullBehaviorSqs>;

export type OutputPqControlsSqs = {};

export type OutputSqs = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSqs;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * The queue type used (or created). Defaults to Standard.
   */
  queueType: OutputQueueType;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * This parameter applies only to FIFO queues. The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are processed in a FIFO manner. Use event field __messageGroupId to override this value.
   */
  messageGroupId?: string | undefined;
  /**
   * Create queue if it does not exist.
   */
  createQueue?: boolean | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputAuthenticationMethodSqs | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing SQS requests
   */
  signatureVersion?: OutputSignatureVersionSqs | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access SQS
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send. Per the SQS spec, the max allowed value is 256 KB.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSqs | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeSqs | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionSqs | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSqs | undefined;
  pqControls?: OutputPqControlsSqs | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSns = {
  Sns: "sns",
} as const;
export type TypeSns = ClosedEnum<typeof TypeSns>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodSns = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodSns = OpenEnum<typeof AuthenticationMethodSns>;

/**
 * Signature version to use for signing SNS requests
 */
export const SignatureVersionSns = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing SNS requests
 */
export type SignatureVersionSns = OpenEnum<typeof SignatureVersionSns>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSns = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSns = OpenEnum<typeof BackpressureBehaviorSns>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSns = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSns = OpenEnum<typeof ModeSns>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSns = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSns = OpenEnum<typeof CompressionSns>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSns = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSns = OpenEnum<typeof QueueFullBehaviorSns>;

export type PqControlsSns = {};

export type OutputSns = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSns;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The ARN of the SNS topic to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. E.g., 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`
   */
  topicArn: string;
  /**
   * Messages in the same group are processed in a FIFO manner. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  messageGroupId: string;
  /**
   * Maximum number of retries before the output returns an error. Note that not all errors are retryable. The retries use an exponential backoff policy.
   */
  maxRetries?: number | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodSns | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the SNS is located
   */
  region?: string | undefined;
  /**
   * SNS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SNS-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing SNS requests
   */
  signatureVersion?: SignatureVersionSns | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access SNS
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSns | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSns | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSns | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSns | undefined;
  pqControls?: PqControlsSns | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeRouter = {
  Router: "router",
} as const;
export type TypeRouter = ClosedEnum<typeof TypeRouter>;

export type OutputRule = {
  /**
   * JavaScript expression to select events to send to output
   */
  filter: string;
  /**
   * Output to send matching events to
   */
  output: string;
  /**
   * Description of this rule's purpose
   */
  description?: string | undefined;
  /**
   * Flag to control whether to stop the event from being checked against other rules
   */
  final?: boolean | undefined;
};

export type OutputRouter = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeRouter;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Event routing rules
   */
  rules: Array<OutputRule>;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeGraphite = {
  Graphite: "graphite",
} as const;
export type TypeGraphite = ClosedEnum<typeof TypeGraphite>;

/**
 * Protocol to use when communicating with the destination.
 */
export const DestinationProtocolGraphite = {
  /**
   * UDP
   */
  Udp: "udp",
  /**
   * TCP
   */
  Tcp: "tcp",
} as const;
/**
 * Protocol to use when communicating with the destination.
 */
export type DestinationProtocolGraphite = OpenEnum<
  typeof DestinationProtocolGraphite
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorGraphite = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorGraphite = OpenEnum<
  typeof BackpressureBehaviorGraphite
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeGraphite = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeGraphite = OpenEnum<typeof ModeGraphite>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionGraphite = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionGraphite = OpenEnum<typeof CompressionGraphite>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorGraphite = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorGraphite = OpenEnum<
  typeof QueueFullBehaviorGraphite
>;

export type PqControlsGraphite = {};

export type OutputGraphite = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGraphite;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Protocol to use when communicating with the destination.
   */
  protocol?: DestinationProtocolGraphite | undefined;
  /**
   * The hostname of the destination.
   */
  host: string;
  /**
   * Destination port.
   */
  port?: number | undefined;
  /**
   * When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
   */
  mtu?: number | undefined;
  /**
   * When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
   */
  flushPeriodSec?: number | undefined;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
   */
  dnsResolvePeriodSec?: number | undefined;
  description?: string | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorGraphite | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeGraphite | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionGraphite | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorGraphite | undefined;
  pqControls?: PqControlsGraphite | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeStatsdExt = {
  StatsdExt: "statsd_ext",
} as const;
export type TypeStatsdExt = ClosedEnum<typeof TypeStatsdExt>;

/**
 * Protocol to use when communicating with the destination.
 */
export const DestinationProtocolStatsdExt = {
  /**
   * UDP
   */
  Udp: "udp",
  /**
   * TCP
   */
  Tcp: "tcp",
} as const;
/**
 * Protocol to use when communicating with the destination.
 */
export type DestinationProtocolStatsdExt = OpenEnum<
  typeof DestinationProtocolStatsdExt
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorStatsdExt = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorStatsdExt = OpenEnum<
  typeof BackpressureBehaviorStatsdExt
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeStatsdExt = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeStatsdExt = OpenEnum<typeof ModeStatsdExt>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionStatsdExt = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionStatsdExt = OpenEnum<typeof CompressionStatsdExt>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorStatsdExt = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorStatsdExt = OpenEnum<
  typeof QueueFullBehaviorStatsdExt
>;

export type PqControlsStatsdExt = {};

export type OutputStatsdExt = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeStatsdExt;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Protocol to use when communicating with the destination.
   */
  protocol?: DestinationProtocolStatsdExt | undefined;
  /**
   * The hostname of the destination.
   */
  host: string;
  /**
   * Destination port.
   */
  port?: number | undefined;
  /**
   * When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
   */
  mtu?: number | undefined;
  /**
   * When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
   */
  flushPeriodSec?: number | undefined;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
   */
  dnsResolvePeriodSec?: number | undefined;
  description?: string | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorStatsdExt | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeStatsdExt | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionStatsdExt | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorStatsdExt | undefined;
  pqControls?: PqControlsStatsdExt | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeStatsd = {
  Statsd: "statsd",
} as const;
export type TypeStatsd = ClosedEnum<typeof TypeStatsd>;

/**
 * Protocol to use when communicating with the destination.
 */
export const DestinationProtocolStatsd = {
  /**
   * UDP
   */
  Udp: "udp",
  /**
   * TCP
   */
  Tcp: "tcp",
} as const;
/**
 * Protocol to use when communicating with the destination.
 */
export type DestinationProtocolStatsd = OpenEnum<
  typeof DestinationProtocolStatsd
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorStatsd = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorStatsd = OpenEnum<
  typeof BackpressureBehaviorStatsd
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeStatsd = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeStatsd = OpenEnum<typeof ModeStatsd>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionStatsd = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionStatsd = OpenEnum<typeof CompressionStatsd>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorStatsd = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorStatsd = OpenEnum<typeof QueueFullBehaviorStatsd>;

export type PqControlsStatsd = {};

export type OutputStatsd = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeStatsd;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Protocol to use when communicating with the destination.
   */
  protocol?: DestinationProtocolStatsd | undefined;
  /**
   * The hostname of the destination.
   */
  host: string;
  /**
   * Destination port.
   */
  port?: number | undefined;
  /**
   * When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
   */
  mtu?: number | undefined;
  /**
   * When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
   */
  flushPeriodSec?: number | undefined;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
   */
  dnsResolvePeriodSec?: number | undefined;
  description?: string | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorStatsd | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeStatsd | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionStatsd | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorStatsd | undefined;
  pqControls?: PqControlsStatsd | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeMinio = {
  Minio: "minio",
} as const;
export type TypeMinio = ClosedEnum<typeof TypeMinio>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodMinio = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodMinio = OpenEnum<
  typeof AuthenticationMethodMinio
>;

/**
 * Signature version to use for signing MinIO requests
 */
export const SignatureVersionMinio = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing MinIO requests
 */
export type SignatureVersionMinio = OpenEnum<typeof SignatureVersionMinio>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLMinio = {
  /**
   * Private
   */
  Private: "private",
  /**
   * Public Read Only
   */
  PublicRead: "public-read",
  /**
   * Public Read/Write
   */
  PublicReadWrite: "public-read-write",
  /**
   * Authenticated Read Only
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * AWS EC2 AMI Read Only
   */
  AwsExecRead: "aws-exec-read",
  /**
   * Bucket Owner Read Only
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * Bucket Owner Full Control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLMinio = OpenEnum<typeof ObjectACLMinio>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassMinio = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassMinio = OpenEnum<typeof StorageClassMinio>;

/**
 * Server-side encryption for uploaded objects
 */
export const ServerSideEncryptionMinio = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
} as const;
/**
 * Server-side encryption for uploaded objects
 */
export type ServerSideEncryptionMinio = OpenEnum<
  typeof ServerSideEncryptionMinio
>;

/**
 * Format of the output data
 */
export const DataFormatMinio = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatMinio = OpenEnum<typeof DataFormatMinio>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorMinio = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorMinio = OpenEnum<
  typeof BackpressureBehaviorMinio
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionMinio = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionMinio = OpenEnum<
  typeof DiskSpaceProtectionMinio
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionMinio = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionMinio = OpenEnum<typeof CompressionMinio>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelMinio = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelMinio = OpenEnum<typeof CompressionLevelMinio>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionMinio = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionMinio = OpenEnum<typeof ParquetVersionMinio>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionMinio = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionMinio = OpenEnum<typeof DataPageVersionMinio>;

export type KeyValueMetadatumMinio = {
  key?: string | undefined;
  value: string;
};

export type OutputMinio = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeMinio;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * MinIO service url (e.g. http://minioHost:9000)
   */
  endpoint: string;
  /**
   * Name of the destination MinIO bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodMinio | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
   */
  awsSecretKey?: string | undefined;
  /**
   * Region where the MinIO service/cluster is located
   */
  region?: string | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
   */
  destPath?: string | undefined;
  /**
   * Signature version to use for signing MinIO requests
   */
  signatureVersion?: SignatureVersionMinio | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLMinio | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassMinio | undefined;
  /**
   * Server-side encryption for uploaded objects
   */
  serverSideEncryption?: ServerSideEncryptionMinio | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatMinio | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorMinio | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionMinio | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionMinio | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelMinio | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionMinio | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionMinio | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumMinio> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCloudwatch = {
  Cloudwatch: "cloudwatch",
} as const;
export type TypeCloudwatch = ClosedEnum<typeof TypeCloudwatch>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodCloudwatch = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodCloudwatch = OpenEnum<
  typeof AuthenticationMethodCloudwatch
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorCloudwatch = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorCloudwatch = OpenEnum<
  typeof BackpressureBehaviorCloudwatch
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeCloudwatch = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeCloudwatch = OpenEnum<typeof ModeCloudwatch>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCloudwatch = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCloudwatch = OpenEnum<typeof CompressionCloudwatch>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorCloudwatch = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorCloudwatch = OpenEnum<
  typeof QueueFullBehaviorCloudwatch
>;

export type PqControlsCloudwatch = {};

export type OutputCloudwatch = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeCloudwatch;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * CloudWatch log group to associate events with
   */
  logGroupName: string;
  /**
   * Prefix for CloudWatch log stream name. This prefix will be used to generate a unique log stream name per cribl instance, for example: myStream_myHost_myOutputId
   */
  logStreamName: string;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodCloudwatch | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the CloudWatchLogs is located
   */
  region: string;
  /**
   * CloudWatchLogs service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to CloudWatchLogs-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access CloudWatchLogs
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Maximum number of queued batches before blocking
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of each individual record before compression. For non compressible data 1MB is the max recommended size
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorCloudwatch | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeCloudwatch | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionCloudwatch | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorCloudwatch | undefined;
  pqControls?: PqControlsCloudwatch | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeInfluxdb = {
  Influxdb: "influxdb",
} as const;
export type TypeInfluxdb = ClosedEnum<typeof TypeInfluxdb>;

/**
 * Sets the precision for the supplied Unix time values. Defaults to milliseconds.
 */
export const TimestampPrecision = {
  /**
   * Nanoseconds
   */
  Ns: "ns",
  /**
   * Microseconds
   */
  U: "u",
  /**
   * Milliseconds
   */
  Ms: "ms",
  /**
   * Seconds
   */
  S: "s",
  /**
   * Minutes
   */
  M: "m",
  /**
   * Hours
   */
  H: "h",
} as const;
/**
 * Sets the precision for the supplied Unix time values. Defaults to milliseconds.
 */
export type TimestampPrecision = OpenEnum<typeof TimestampPrecision>;

export type ExtraHttpHeaderInfluxdb = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeInfluxdb = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeInfluxdb = OpenEnum<
  typeof FailedRequestLoggingModeInfluxdb
>;

export type ResponseRetrySettingInfluxdb = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsInfluxdb = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorInfluxdb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorInfluxdb = OpenEnum<
  typeof BackpressureBehaviorInfluxdb
>;

/**
 * InfluxDB authentication type
 */
export const AuthenticationTypeInfluxdb = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * InfluxDB authentication type
 */
export type AuthenticationTypeInfluxdb = OpenEnum<
  typeof AuthenticationTypeInfluxdb
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeInfluxdb = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeInfluxdb = OpenEnum<typeof ModeInfluxdb>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionInfluxdb = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionInfluxdb = OpenEnum<typeof CompressionInfluxdb>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorInfluxdb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorInfluxdb = OpenEnum<
  typeof QueueFullBehaviorInfluxdb
>;

export type PqControlsInfluxdb = {};

export type OauthParamInfluxdb = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderInfluxdb = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type OutputInfluxdb = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeInfluxdb;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * URL of an InfluxDB cluster to send events to, e.g., http://localhost:8086/write
   */
  url: string;
  /**
   * The v2 API can be enabled with InfluxDB versions 1.8 and later.
   */
  useV2API?: boolean | undefined;
  /**
   * Sets the precision for the supplied Unix time values. Defaults to milliseconds.
   */
  timestampPrecision?: TimestampPrecision | undefined;
  /**
   * Enabling this will pull the value field from the metric name. E,g, 'db.query.user' will use 'db.query' as the measurement and 'user' as the value field.
   */
  dynamicValueFieldName?: boolean | undefined;
  /**
   * Name of the field in which to store the metric when sending to InfluxDB. If dynamic generation is enabled and fails, this will be used as a fallback.
   */
  valueFieldName?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderInfluxdb> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeInfluxdb | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingInfluxdb> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsInfluxdb | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorInfluxdb | undefined;
  /**
   * InfluxDB authentication type
   */
  authType?: AuthenticationTypeInfluxdb | undefined;
  description?: string | undefined;
  /**
   * Database to write to.
   */
  database?: string | undefined;
  /**
   * Bucket to write to.
   */
  bucket?: string | undefined;
  /**
   * Organization ID for this bucket.
   */
  org?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeInfluxdb | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionInfluxdb | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorInfluxdb | undefined;
  pqControls?: PqControlsInfluxdb | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamInfluxdb> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderInfluxdb> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeNewrelicEvents = {
  NewrelicEvents: "newrelic_events",
} as const;
export type TypeNewrelicEvents = ClosedEnum<typeof TypeNewrelicEvents>;

/**
 * Which New Relic region endpoint to use.
 */
export const RegionNewrelicEvents = {
  /**
   * US
   */
  Us: "US",
  /**
   * Europe
   */
  Eu: "EU",
  /**
   * Custom
   */
  Custom: "Custom",
} as const;
/**
 * Which New Relic region endpoint to use.
 */
export type RegionNewrelicEvents = OpenEnum<typeof RegionNewrelicEvents>;

export type ExtraHttpHeaderNewrelicEvents = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeNewrelicEvents = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeNewrelicEvents = OpenEnum<
  typeof FailedRequestLoggingModeNewrelicEvents
>;

export type ResponseRetrySettingNewrelicEvents = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsNewrelicEvents = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorNewrelicEvents = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorNewrelicEvents = OpenEnum<
  typeof BackpressureBehaviorNewrelicEvents
>;

/**
 * Enter API key directly, or select a stored secret
 */
export const AuthenticationMethodNewrelicEvents = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter API key directly, or select a stored secret
 */
export type AuthenticationMethodNewrelicEvents = OpenEnum<
  typeof AuthenticationMethodNewrelicEvents
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeNewrelicEvents = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeNewrelicEvents = OpenEnum<typeof ModeNewrelicEvents>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionNewrelicEvents = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionNewrelicEvents = OpenEnum<
  typeof CompressionNewrelicEvents
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorNewrelicEvents = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorNewrelicEvents = OpenEnum<
  typeof QueueFullBehaviorNewrelicEvents
>;

export type PqControlsNewrelicEvents = {};

export type OutputNewrelicEvents = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeNewrelicEvents;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Which New Relic region endpoint to use.
   */
  region?: RegionNewrelicEvents | undefined;
  /**
   * New Relic account ID
   */
  accountId: string;
  /**
   * Default eventType to use when not present in an event. For more information, see [here](https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/#reserved-words).
   */
  eventType: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderNewrelicEvents> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeNewrelicEvents | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingNewrelicEvents> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsNewrelicEvents | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorNewrelicEvents | undefined;
  /**
   * Enter API key directly, or select a stored secret
   */
  authType?: AuthenticationMethodNewrelicEvents | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeNewrelicEvents | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionNewrelicEvents | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorNewrelicEvents | undefined;
  pqControls?: PqControlsNewrelicEvents | undefined;
  /**
   * New Relic API key. Can be overridden using __newRelic_apiKey field.
   */
  apiKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeNewrelic = {
  Newrelic: "newrelic",
} as const;
export type TypeNewrelic = ClosedEnum<typeof TypeNewrelic>;

/**
 * Which New Relic region endpoint to use.
 */
export const RegionNewrelic = {
  /**
   * US
   */
  Us: "US",
  /**
   * Europe
   */
  Eu: "EU",
  /**
   * Custom
   */
  Custom: "Custom",
} as const;
/**
 * Which New Relic region endpoint to use.
 */
export type RegionNewrelic = OpenEnum<typeof RegionNewrelic>;

export const FieldName = {
  Service: "service",
  Hostname: "hostname",
  Timestamp: "timestamp",
  AuditId: "auditId",
} as const;
export type FieldName = OpenEnum<typeof FieldName>;

export type MetadatumNewrelic = {
  name: FieldName;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type ExtraHttpHeaderNewrelic = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeNewrelic = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeNewrelic = OpenEnum<
  typeof FailedRequestLoggingModeNewrelic
>;

export type ResponseRetrySettingNewrelic = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsNewrelic = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorNewrelic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorNewrelic = OpenEnum<
  typeof BackpressureBehaviorNewrelic
>;

/**
 * Enter API key directly, or select a stored secret
 */
export const AuthenticationMethodNewrelic = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter API key directly, or select a stored secret
 */
export type AuthenticationMethodNewrelic = OpenEnum<
  typeof AuthenticationMethodNewrelic
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeNewrelic = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeNewrelic = OpenEnum<typeof ModeNewrelic>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionNewrelic = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionNewrelic = OpenEnum<typeof CompressionNewrelic>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorNewrelic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorNewrelic = OpenEnum<
  typeof QueueFullBehaviorNewrelic
>;

export type PqControlsNewrelic = {};

export type OutputNewrelic = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeNewrelic;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Which New Relic region endpoint to use.
   */
  region?: RegionNewrelic | undefined;
  /**
   * Name of the logtype to send with events, e.g.: observability, access_log. The event's 'sourcetype' field (if set) will override this value.
   */
  logType?: string | undefined;
  /**
   * Name of field to send as log message value. If not present, event will be serialized and sent as JSON.
   */
  messageField?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumNewrelic> | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderNewrelic> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeNewrelic | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingNewrelic> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsNewrelic | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorNewrelic | undefined;
  /**
   * Enter API key directly, or select a stored secret
   */
  authType?: AuthenticationMethodNewrelic | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeNewrelic | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionNewrelic | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorNewrelic | undefined;
  pqControls?: PqControlsNewrelic | undefined;
  /**
   * New Relic API key. Can be overridden using __newRelic_apiKey field.
   */
  apiKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeElasticCloud = {
  ElasticCloud: "elastic_cloud",
} as const;
export type TypeElasticCloud = ClosedEnum<typeof TypeElasticCloud>;

export type ExtraHttpHeaderElasticCloud = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeElasticCloud = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeElasticCloud = OpenEnum<
  typeof FailedRequestLoggingModeElasticCloud
>;

export type ExtraParamElasticCloud = {
  name: string;
  value: string;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const AuthenticationMethodElasticCloud = {
  Manual: "manual",
  Secret: "secret",
  ManualAPIKey: "manualAPIKey",
  TextSecret: "textSecret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type AuthenticationMethodElasticCloud = OpenEnum<
  typeof AuthenticationMethodElasticCloud
>;

export type AuthElasticCloud = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: AuthenticationMethodElasticCloud | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Enter API key directly
   */
  manualAPIKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

export type ResponseRetrySettingElasticCloud = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsElasticCloud = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorElasticCloud = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorElasticCloud = OpenEnum<
  typeof BackpressureBehaviorElasticCloud
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeElasticCloud = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeElasticCloud = OpenEnum<typeof ModeElasticCloud>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionElasticCloud = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionElasticCloud = OpenEnum<typeof CompressionElasticCloud>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorElasticCloud = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorElasticCloud = OpenEnum<
  typeof QueueFullBehaviorElasticCloud
>;

export type PqControlsElasticCloud = {};

export type OutputElasticCloud = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeElasticCloud;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enter Cloud ID of the Elastic Cloud environment to send events to
   */
  url: string;
  /**
   * Data stream or index to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
   */
  index: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderElasticCloud> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeElasticCloud | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Extra parameters to use in HTTP requests
   */
  extraParams?: Array<ExtraParamElasticCloud> | undefined;
  auth?: AuthElasticCloud | undefined;
  /**
   * Optional Elastic Cloud Destination pipeline
   */
  elasticPipeline?: string | undefined;
  /**
   * Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
   */
  includeDocId?: boolean | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingElasticCloud> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsElasticCloud | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorElasticCloud | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeElasticCloud | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionElasticCloud | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorElasticCloud | undefined;
  pqControls?: PqControlsElasticCloud | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeElastic = {
  Elastic: "elastic",
} as const;
export type OutputTypeElastic = ClosedEnum<typeof OutputTypeElastic>;

export type OutputExtraHttpHeaderElastic = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeElastic = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeElastic = OpenEnum<
  typeof FailedRequestLoggingModeElastic
>;

export type ResponseRetrySettingElastic = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsElastic = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type ExtraParamElastic = {
  name: string;
  value: string;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const AuthAuthenticationMethodElastic = {
  Manual: "manual",
  Secret: "secret",
  ManualAPIKey: "manualAPIKey",
  TextSecret: "textSecret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type AuthAuthenticationMethodElastic = OpenEnum<
  typeof AuthAuthenticationMethodElastic
>;

export type AuthElastic = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: AuthAuthenticationMethodElastic | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Enter API key directly
   */
  manualAPIKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

/**
 * Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
 */
export const ElasticVersion = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * 6.x
   */
  Six: "6",
  /**
   * 7.x
   */
  Seven: "7",
} as const;
/**
 * Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
 */
export type ElasticVersion = OpenEnum<typeof ElasticVersion>;

/**
 * Action to use when writing events. Must be set to `Create` when writing to a data stream.
 */
export const WriteAction = {
  /**
   * Index
   */
  Index: "index",
  /**
   * Create
   */
  Create: "create",
} as const;
/**
 * Action to use when writing events. Must be set to `Create` when writing to a data stream.
 */
export type WriteAction = OpenEnum<typeof WriteAction>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorElastic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorElastic = OpenEnum<
  typeof BackpressureBehaviorElastic
>;

export type UrlElastic = {
  /**
   * The URL to an Elastic node to send events to. Example: http://elastic:9200/_bulk
   */
  url: string;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeElastic = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeElastic = OpenEnum<typeof OutputModeElastic>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionElastic = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionElastic = OpenEnum<
  typeof PqCompressCompressionElastic
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorElastic = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorElastic = OpenEnum<
  typeof QueueFullBehaviorElastic
>;

export type OutputPqControlsElastic = {};

export type OutputElastic = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeElastic;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * Index or data stream to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
   */
  index: string;
  /**
   * Document type to use for events. Can be overwritten by an event's __type field.
   */
  docType?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<OutputExtraHttpHeaderElastic> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeElastic | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingElastic> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsElastic | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  extraParams?: Array<ExtraParamElastic> | undefined;
  auth?: AuthElastic | undefined;
  /**
   * Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
   */
  elasticVersion?: ElasticVersion | undefined;
  /**
   * Optional Elasticsearch destination pipeline
   */
  elasticPipeline?: string | undefined;
  /**
   * Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
   */
  includeDocId?: boolean | undefined;
  /**
   * Action to use when writing events. Must be set to `Create` when writing to a data stream.
   */
  writeAction?: WriteAction | undefined;
  /**
   * Retry failed events when a bulk request to Elastic is successful, but the response body returns an error for one or more events in the batch
   */
  retryPartialErrors?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorElastic | undefined;
  description?: string | undefined;
  /**
   * The Cloud ID or URL to an Elastic cluster to send events to. Example: http://elastic:9200/_bulk
   */
  url?: string | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<UrlElastic> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeElastic | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionElastic | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorElastic | undefined;
  pqControls?: OutputPqControlsElastic | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeMsk = {
  Msk: "msk",
} as const;
export type OutputTypeMsk = ClosedEnum<typeof OutputTypeMsk>;

/**
 * Control the number of required acknowledgments.
 */
export const AcknowledgmentsMsk = {
  /**
   * Leader
   */
  One: 1,
  /**
   * None
   */
  Zero: 0,
  /**
   * All
   */
  Minus1: -1,
} as const;
/**
 * Control the number of required acknowledgments.
 */
export type AcknowledgmentsMsk = OpenEnum<typeof AcknowledgmentsMsk>;

/**
 * Format to use to serialize events before writing to Kafka.
 */
export const RecordDataFormatMsk = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Field _raw
   */
  Raw: "raw",
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
} as const;
/**
 * Format to use to serialize events before writing to Kafka.
 */
export type RecordDataFormatMsk = OpenEnum<typeof RecordDataFormatMsk>;

/**
 * Codec to use to compress the data before sending to Kafka
 */
export const OutputCompressionMsk = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
  /**
   * Snappy
   */
  Snappy: "snappy",
  /**
   * LZ4
   */
  Lz4: "lz4",
  /**
   * ZSTD
   */
  Zstd: "zstd",
} as const;
/**
 * Codec to use to compress the data before sending to Kafka
 */
export type OutputCompressionMsk = OpenEnum<typeof OutputCompressionMsk>;

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type OutputAuthMsk = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const OutputKafkaSchemaRegistryMinimumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMinimumTLSVersionMsk = OpenEnum<
  typeof OutputKafkaSchemaRegistryMinimumTLSVersionMsk
>;

export const OutputKafkaSchemaRegistryMaximumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMaximumTLSVersionMsk = OpenEnum<
  typeof OutputKafkaSchemaRegistryMaximumTLSVersionMsk
>;

export type OutputKafkaSchemaRegistryTLSSettingsClientSideMsk = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputKafkaSchemaRegistryMinimumTLSVersionMsk | undefined;
  maxVersion?: OutputKafkaSchemaRegistryMaximumTLSVersionMsk | undefined;
};

export type OutputKafkaSchemaRegistryAuthenticationMsk = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: OutputAuthMsk | undefined;
  tls?: OutputKafkaSchemaRegistryTLSSettingsClientSideMsk | undefined;
  /**
   * Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
   */
  defaultKeySchemaId?: number | undefined;
  /**
   * Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
   */
  defaultValueSchemaId?: number | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputAuthenticationMethodMsk = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputAuthenticationMethodMsk = OpenEnum<
  typeof OutputAuthenticationMethodMsk
>;

/**
 * Signature version to use for signing MSK cluster requests
 */
export const OutputSignatureVersionMsk = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing MSK cluster requests
 */
export type OutputSignatureVersionMsk = OpenEnum<
  typeof OutputSignatureVersionMsk
>;

export const OutputMinimumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionMsk = OpenEnum<
  typeof OutputMinimumTLSVersionMsk
>;

export const OutputMaximumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionMsk = OpenEnum<
  typeof OutputMaximumTLSVersionMsk
>;

export type OutputTLSSettingsClientSideMsk = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionMsk | undefined;
  maxVersion?: OutputMaximumTLSVersionMsk | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorMsk = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorMsk = OpenEnum<typeof BackpressureBehaviorMsk>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeMsk = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeMsk = OpenEnum<typeof OutputModeMsk>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionMsk = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionMsk = OpenEnum<
  typeof PqCompressCompressionMsk
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorMsk = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorMsk = OpenEnum<typeof QueueFullBehaviorMsk>;

export type OutputPqControlsMsk = {};

export type OutputMsk = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeMsk;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
   */
  brokers: Array<string>;
  /**
   * The topic to publish events to. Can be overridden using the __topicOut field.
   */
  topic: string;
  /**
   * Control the number of required acknowledgments.
   */
  ack?: AcknowledgmentsMsk | undefined;
  /**
   * Format to use to serialize events before writing to Kafka.
   */
  format?: RecordDataFormatMsk | undefined;
  /**
   * Codec to use to compress the data before sending to Kafka
   */
  compression?: OutputCompressionMsk | undefined;
  /**
   * Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * The maximum number of events you want the Destination to allow in a batch before forcing a flush
   */
  flushEventCount?: number | undefined;
  /**
   * The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
   */
  flushPeriodSec?: number | undefined;
  kafkaSchemaRegistry?: OutputKafkaSchemaRegistryAuthenticationMsk | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputAuthenticationMethodMsk | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the MSK cluster is located
   */
  region: string;
  /**
   * MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing MSK cluster requests
   */
  signatureVersion?: OutputSignatureVersionMsk | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access MSK
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  tls?: OutputTLSSettingsClientSideMsk | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorMsk | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Select a set of Protobuf definitions for the events you want to send
   */
  protobufLibraryId?: string | undefined;
  /**
   * Select the type of object you want the Protobuf definitions to use for event encoding
   */
  protobufEncodingId?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeMsk | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionMsk | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorMsk | undefined;
  pqControls?: OutputPqControlsMsk | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeConfluentCloud = {
  ConfluentCloud: "confluent_cloud",
} as const;
export type OutputTypeConfluentCloud = ClosedEnum<
  typeof OutputTypeConfluentCloud
>;

export const OutputMinimumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionConfluentCloud = OpenEnum<
  typeof OutputMinimumTLSVersionConfluentCloud
>;

export const OutputMaximumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionConfluentCloud = OpenEnum<
  typeof OutputMaximumTLSVersionConfluentCloud
>;

export type OutputTLSSettingsClientSideConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionConfluentCloud | undefined;
  maxVersion?: OutputMaximumTLSVersionConfluentCloud | undefined;
};

/**
 * Control the number of required acknowledgments.
 */
export const AcknowledgmentsConfluentCloud = {
  /**
   * Leader
   */
  One: 1,
  /**
   * None
   */
  Zero: 0,
  /**
   * All
   */
  Minus1: -1,
} as const;
/**
 * Control the number of required acknowledgments.
 */
export type AcknowledgmentsConfluentCloud = OpenEnum<
  typeof AcknowledgmentsConfluentCloud
>;

/**
 * Format to use to serialize events before writing to Kafka.
 */
export const RecordDataFormatConfluentCloud = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Field _raw
   */
  Raw: "raw",
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
} as const;
/**
 * Format to use to serialize events before writing to Kafka.
 */
export type RecordDataFormatConfluentCloud = OpenEnum<
  typeof RecordDataFormatConfluentCloud
>;

/**
 * Codec to use to compress the data before sending to Kafka
 */
export const OutputCompressionConfluentCloud = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
  /**
   * Snappy
   */
  Snappy: "snappy",
  /**
   * LZ4
   */
  Lz4: "lz4",
  /**
   * ZSTD
   */
  Zstd: "zstd",
} as const;
/**
 * Codec to use to compress the data before sending to Kafka
 */
export type OutputCompressionConfluentCloud = OpenEnum<
  typeof OutputCompressionConfluentCloud
>;

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type OutputAuthConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = OpenEnum<
  typeof OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
>;

export const OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = OpenEnum<
  typeof OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
>;

export type OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?:
    | OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
    | undefined;
  maxVersion?:
    | OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
    | undefined;
};

export type OutputKafkaSchemaRegistryAuthenticationConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: OutputAuthConfluentCloud | undefined;
  tls?:
    | OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud
    | undefined;
  /**
   * Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
   */
  defaultKeySchemaId?: number | undefined;
  /**
   * Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
   */
  defaultValueSchemaId?: number | undefined;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const OutputAuthenticationMethodConfluentCloud = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type OutputAuthenticationMethodConfluentCloud = OpenEnum<
  typeof OutputAuthenticationMethodConfluentCloud
>;

export const OutputSASLMechanismConfluentCloud = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * SCRAM-SHA-256
   */
  ScramSha256: "scram-sha-256",
  /**
   * SCRAM-SHA-512
   */
  ScramSha512: "scram-sha-512",
  /**
   * GSSAPI/Kerberos
   */
  Kerberos: "kerberos",
} as const;
export type OutputSASLMechanismConfluentCloud = OpenEnum<
  typeof OutputSASLMechanismConfluentCloud
>;

export type OutputOauthParamConfluentCloud = {
  name: string;
  value: string;
};

export type OutputSaslExtensionConfluentCloud = {
  name: string;
  value: string;
};

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type OutputAuthenticationConfluentCloud = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: OutputAuthenticationMethodConfluentCloud | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  mechanism?: OutputSASLMechanismConfluentCloud | undefined;
  /**
   * Location of keytab file for authentication principal
   */
  keytabLocation?: string | undefined;
  /**
   * Authentication principal, such as `kafka_user@example.com`
   */
  principal?: string | undefined;
  /**
   * Kerberos service class for Kafka brokers, such as `kafka`
   */
  brokerServiceClass?: string | undefined;
  /**
   * Enable OAuth authentication
   */
  oauthEnabled?: boolean | undefined;
  /**
   * URL of the token endpoint to use for OAuth authentication
   */
  tokenUrl?: string | undefined;
  /**
   * Client ID to use for OAuth authentication
   */
  clientId?: string | undefined;
  oauthSecretType?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Additional fields to send to the token endpoint, such as scope or audience
   */
  oauthParams?: Array<OutputOauthParamConfluentCloud> | undefined;
  /**
   * Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
   */
  saslExtensions?: Array<OutputSaslExtensionConfluentCloud> | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorConfluentCloud = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorConfluentCloud = OpenEnum<
  typeof BackpressureBehaviorConfluentCloud
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeConfluentCloud = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeConfluentCloud = OpenEnum<
  typeof OutputModeConfluentCloud
>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionConfluentCloud = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionConfluentCloud = OpenEnum<
  typeof PqCompressCompressionConfluentCloud
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorConfluentCloud = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorConfluentCloud = OpenEnum<
  typeof QueueFullBehaviorConfluentCloud
>;

export type OutputPqControlsConfluentCloud = {};

export type OutputConfluentCloud = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeConfluentCloud;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092.
   */
  brokers: Array<string>;
  tls?: OutputTLSSettingsClientSideConfluentCloud | undefined;
  /**
   * The topic to publish events to. Can be overridden using the __topicOut field.
   */
  topic: string;
  /**
   * Control the number of required acknowledgments.
   */
  ack?: AcknowledgmentsConfluentCloud | undefined;
  /**
   * Format to use to serialize events before writing to Kafka.
   */
  format?: RecordDataFormatConfluentCloud | undefined;
  /**
   * Codec to use to compress the data before sending to Kafka
   */
  compression?: OutputCompressionConfluentCloud | undefined;
  /**
   * Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * The maximum number of events you want the Destination to allow in a batch before forcing a flush
   */
  flushEventCount?: number | undefined;
  /**
   * The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
   */
  flushPeriodSec?: number | undefined;
  kafkaSchemaRegistry?:
    | OutputKafkaSchemaRegistryAuthenticationConfluentCloud
    | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: OutputAuthenticationConfluentCloud | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorConfluentCloud | undefined;
  description?: string | undefined;
  /**
   * Select a set of Protobuf definitions for the events you want to send
   */
  protobufLibraryId?: string | undefined;
  /**
   * Select the type of object you want the Protobuf definitions to use for event encoding
   */
  protobufEncodingId?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeConfluentCloud | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionConfluentCloud | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorConfluentCloud | undefined;
  pqControls?: OutputPqControlsConfluentCloud | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeKafka = {
  Kafka: "kafka",
} as const;
export type OutputTypeKafka = ClosedEnum<typeof OutputTypeKafka>;

/**
 * Control the number of required acknowledgments.
 */
export const AcknowledgmentsKafka = {
  /**
   * Leader
   */
  One: 1,
  /**
   * None
   */
  Zero: 0,
  /**
   * All
   */
  Minus1: -1,
} as const;
/**
 * Control the number of required acknowledgments.
 */
export type AcknowledgmentsKafka = OpenEnum<typeof AcknowledgmentsKafka>;

/**
 * Format to use to serialize events before writing to Kafka.
 */
export const RecordDataFormatKafka = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Field _raw
   */
  Raw: "raw",
  /**
   * Protobuf
   */
  Protobuf: "protobuf",
} as const;
/**
 * Format to use to serialize events before writing to Kafka.
 */
export type RecordDataFormatKafka = OpenEnum<typeof RecordDataFormatKafka>;

/**
 * Codec to use to compress the data before sending to Kafka
 */
export const OutputCompressionKafka = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
  /**
   * Snappy
   */
  Snappy: "snappy",
  /**
   * LZ4
   */
  Lz4: "lz4",
  /**
   * ZSTD
   */
  Zstd: "zstd",
} as const;
/**
 * Codec to use to compress the data before sending to Kafka
 */
export type OutputCompressionKafka = OpenEnum<typeof OutputCompressionKafka>;

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type OutputAuthKafka = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const OutputKafkaSchemaRegistryMinimumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMinimumTLSVersionKafka = OpenEnum<
  typeof OutputKafkaSchemaRegistryMinimumTLSVersionKafka
>;

export const OutputKafkaSchemaRegistryMaximumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputKafkaSchemaRegistryMaximumTLSVersionKafka = OpenEnum<
  typeof OutputKafkaSchemaRegistryMaximumTLSVersionKafka
>;

export type OutputKafkaSchemaRegistryTLSSettingsClientSideKafka = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputKafkaSchemaRegistryMinimumTLSVersionKafka | undefined;
  maxVersion?: OutputKafkaSchemaRegistryMaximumTLSVersionKafka | undefined;
};

export type OutputKafkaSchemaRegistryAuthenticationKafka = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: OutputAuthKafka | undefined;
  tls?: OutputKafkaSchemaRegistryTLSSettingsClientSideKafka | undefined;
  /**
   * Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
   */
  defaultKeySchemaId?: number | undefined;
  /**
   * Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
   */
  defaultValueSchemaId?: number | undefined;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const OutputAuthenticationMethodKafka = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type OutputAuthenticationMethodKafka = OpenEnum<
  typeof OutputAuthenticationMethodKafka
>;

export const OutputSASLMechanismKafka = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * SCRAM-SHA-256
   */
  ScramSha256: "scram-sha-256",
  /**
   * SCRAM-SHA-512
   */
  ScramSha512: "scram-sha-512",
  /**
   * GSSAPI/Kerberos
   */
  Kerberos: "kerberos",
} as const;
export type OutputSASLMechanismKafka = OpenEnum<
  typeof OutputSASLMechanismKafka
>;

export type OutputOauthParamKafka = {
  name: string;
  value: string;
};

export type OutputSaslExtensionKafka = {
  name: string;
  value: string;
};

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type OutputAuthenticationKafka = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: OutputAuthenticationMethodKafka | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  mechanism?: OutputSASLMechanismKafka | undefined;
  /**
   * Location of keytab file for authentication principal
   */
  keytabLocation?: string | undefined;
  /**
   * Authentication principal, such as `kafka_user@example.com`
   */
  principal?: string | undefined;
  /**
   * Kerberos service class for Kafka brokers, such as `kafka`
   */
  brokerServiceClass?: string | undefined;
  /**
   * Enable OAuth authentication
   */
  oauthEnabled?: boolean | undefined;
  /**
   * URL of the token endpoint to use for OAuth authentication
   */
  tokenUrl?: string | undefined;
  /**
   * Client ID to use for OAuth authentication
   */
  clientId?: string | undefined;
  oauthSecretType?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Additional fields to send to the token endpoint, such as scope or audience
   */
  oauthParams?: Array<OutputOauthParamKafka> | undefined;
  /**
   * Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
   */
  saslExtensions?: Array<OutputSaslExtensionKafka> | undefined;
};

export const OutputMinimumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionKafka = OpenEnum<
  typeof OutputMinimumTLSVersionKafka
>;

export const OutputMaximumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionKafka = OpenEnum<
  typeof OutputMaximumTLSVersionKafka
>;

export type OutputTLSSettingsClientSideKafka = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionKafka | undefined;
  maxVersion?: OutputMaximumTLSVersionKafka | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorKafka = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorKafka = OpenEnum<
  typeof BackpressureBehaviorKafka
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeKafka = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeKafka = OpenEnum<typeof OutputModeKafka>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionKafka = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionKafka = OpenEnum<
  typeof PqCompressCompressionKafka
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorKafka = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorKafka = OpenEnum<typeof QueueFullBehaviorKafka>;

export type OutputPqControlsKafka = {};

export type OutputKafka = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeKafka;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
   */
  brokers: Array<string>;
  /**
   * The topic to publish events to. Can be overridden using the __topicOut field.
   */
  topic: string;
  /**
   * Control the number of required acknowledgments.
   */
  ack?: AcknowledgmentsKafka | undefined;
  /**
   * Format to use to serialize events before writing to Kafka.
   */
  format?: RecordDataFormatKafka | undefined;
  /**
   * Codec to use to compress the data before sending to Kafka
   */
  compression?: OutputCompressionKafka | undefined;
  /**
   * Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * The maximum number of events you want the Destination to allow in a batch before forcing a flush
   */
  flushEventCount?: number | undefined;
  /**
   * The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
   */
  flushPeriodSec?: number | undefined;
  kafkaSchemaRegistry?:
    | OutputKafkaSchemaRegistryAuthenticationKafka
    | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: OutputAuthenticationKafka | undefined;
  tls?: OutputTLSSettingsClientSideKafka | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorKafka | undefined;
  description?: string | undefined;
  /**
   * Select a set of Protobuf definitions for the events you want to send
   */
  protobufLibraryId?: string | undefined;
  /**
   * Select the type of object you want the Protobuf definitions to use for event encoding
   */
  protobufEncodingId?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeKafka | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionKafka | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorKafka | undefined;
  pqControls?: OutputPqControlsKafka | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeExabeam = {
  Exabeam: "exabeam",
} as const;
export type TypeExabeam = ClosedEnum<typeof TypeExabeam>;

/**
 * Signature version to use for signing Google Cloud Storage requests
 */
export const SignatureVersionExabeam = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing Google Cloud Storage requests
 */
export type SignatureVersionExabeam = OpenEnum<typeof SignatureVersionExabeam>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLExabeam = {
  /**
   * private
   */
  Private: "private",
  /**
   * bucket-owner-read
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * bucket-owner-full-control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
  /**
   * project-private
   */
  ProjectPrivate: "project-private",
  /**
   * authenticated-read
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * public-read
   */
  PublicRead: "public-read",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLExabeam = OpenEnum<typeof ObjectACLExabeam>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassExabeam = {
  /**
   * Standard Storage
   */
  Standard: "STANDARD",
  /**
   * Nearline Storage
   */
  Nearline: "NEARLINE",
  /**
   * Coldline Storage
   */
  Coldline: "COLDLINE",
  /**
   * Archive Storage
   */
  Archive: "ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassExabeam = OpenEnum<typeof StorageClassExabeam>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorExabeam = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorExabeam = OpenEnum<
  typeof BackpressureBehaviorExabeam
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionExabeam = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionExabeam = OpenEnum<
  typeof DiskSpaceProtectionExabeam
>;

export type OutputExabeam = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeExabeam;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination bucket. A constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a JavaScript Global Variable: `myBucket-${C.vars.myVar}`.
   */
  bucket: string;
  /**
   * Region where the bucket is located
   */
  region: string;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Google Cloud Storage service endpoint
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Google Cloud Storage requests
   */
  signatureVersion?: SignatureVersionExabeam | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLExabeam | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassExabeam | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorExabeam | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionExabeam | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Enter an encoded string containing Exabeam configurations
   */
  encodedConfiguration?: string | undefined;
  /**
   * ID of the Exabeam Collector where data should be sent. Example: 11112222-3333-4444-5555-666677778888
   *
   * @remarks
   */
  collectorInstanceId: string;
  /**
   * Constant or JavaScript expression to create an Exabeam site name. Values that aren't successfully evaluated will be treated as string constants.
   */
  siteName?: string | undefined;
  /**
   * Exabeam site ID. If left blank, @{product} will use the value of the Exabeam site name.
   */
  siteId?: string | undefined;
  timezoneOffset?: string | undefined;
  /**
   * HMAC access key. Can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
   */
  awsApiKey?: string | undefined;
  /**
   * HMAC secret. Can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
   */
  awsSecretKey?: string | undefined;
  description?: string | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeGooglePubsub = {
  GooglePubsub: "google_pubsub",
} as const;
export type OutputTypeGooglePubsub = ClosedEnum<typeof OutputTypeGooglePubsub>;

/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export const OutputGoogleAuthenticationMethodGooglePubsub = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret
   */
  Secret: "secret",
} as const;
/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export type OutputGoogleAuthenticationMethodGooglePubsub = OpenEnum<
  typeof OutputGoogleAuthenticationMethodGooglePubsub
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorGooglePubsub = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorGooglePubsub = OpenEnum<
  typeof BackpressureBehaviorGooglePubsub
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeGooglePubsub = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeGooglePubsub = OpenEnum<typeof OutputModeGooglePubsub>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionGooglePubsub = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionGooglePubsub = OpenEnum<
  typeof PqCompressCompressionGooglePubsub
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorGooglePubsub = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorGooglePubsub = OpenEnum<
  typeof QueueFullBehaviorGooglePubsub
>;

export type OutputPqControlsGooglePubsub = {};

export type OutputGooglePubsub = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeGooglePubsub;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
   */
  googleAuthMethod?: OutputGoogleAuthenticationMethodGooglePubsub | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorGooglePubsub | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeGooglePubsub | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionGooglePubsub | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorGooglePubsub | undefined;
  pqControls?: OutputPqControlsGooglePubsub | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeGoogleCloudLogging = {
  GoogleCloudLogging: "google_cloud_logging",
} as const;
export type TypeGoogleCloudLogging = ClosedEnum<typeof TypeGoogleCloudLogging>;

export const LogLocationType = {
  /**
   * Project
   */
  Project: "project",
  /**
   * Organization
   */
  Organization: "organization",
  /**
   * Billing Account
   */
  BillingAccount: "billingAccount",
  /**
   * Folder
   */
  Folder: "folder",
} as const;
export type LogLocationType = OpenEnum<typeof LogLocationType>;

/**
 * Format to use when sending payload. Defaults to Text.
 */
export const PayloadFormat = {
  /**
   * Text
   */
  Text: "text",
  /**
   * JSON
   */
  Json: "json",
} as const;
/**
 * Format to use when sending payload. Defaults to Text.
 */
export type PayloadFormat = OpenEnum<typeof PayloadFormat>;

export type LogLabel = {
  /**
   * Label name
   */
  label: string;
  /**
   * JavaScript expression to compute the label's value.
   */
  valueExpression: string;
};

export type ResourceTypeLabel = {
  /**
   * Label name
   */
  label: string;
  /**
   * JavaScript expression to compute the label's value.
   */
  valueExpression: string;
};

/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export const GoogleAuthenticationMethodGoogleCloudLogging = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret
   */
  Secret: "secret",
} as const;
/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export type GoogleAuthenticationMethodGoogleCloudLogging = OpenEnum<
  typeof GoogleAuthenticationMethodGoogleCloudLogging
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorGoogleCloudLogging = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorGoogleCloudLogging = OpenEnum<
  typeof BackpressureBehaviorGoogleCloudLogging
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeGoogleCloudLogging = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeGoogleCloudLogging = OpenEnum<typeof ModeGoogleCloudLogging>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionGoogleCloudLogging = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionGoogleCloudLogging = OpenEnum<
  typeof CompressionGoogleCloudLogging
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorGoogleCloudLogging = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorGoogleCloudLogging = OpenEnum<
  typeof QueueFullBehaviorGoogleCloudLogging
>;

export type PqControlsGoogleCloudLogging = {};

export type OutputGoogleCloudLogging = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGoogleCloudLogging;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  logLocationType: LogLocationType;
  /**
   * JavaScript expression to compute the value of the log name. If Validate and correct log name is enabled, invalid characters (characters other than alphanumerics, forward-slashes, underscores, hyphens, and periods) will be replaced with an underscore.
   */
  logNameExpression: string;
  sanitizeLogNames?: boolean | undefined;
  /**
   * Format to use when sending payload. Defaults to Text.
   */
  payloadFormat?: PayloadFormat | undefined;
  /**
   * Labels to apply to the log entry
   */
  logLabels?: Array<LogLabel> | undefined;
  /**
   * JavaScript expression to compute the value of the managed resource type field. Must evaluate to one of the valid values [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types). Defaults to "global".
   */
  resourceTypeExpression?: string | undefined;
  /**
   * Labels to apply to the managed resource. These must correspond to the valid labels for the specified resource type (see [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types)). Otherwise, they will be dropped by Google Cloud Logging.
   */
  resourceTypeLabels?: Array<ResourceTypeLabel> | undefined;
  /**
   * JavaScript expression to compute the value of the severity field. Must evaluate to one of the severity values supported by Google Cloud Logging [here](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logseverity) (case insensitive). Defaults to "DEFAULT".
   */
  severityExpression?: string | undefined;
  /**
   * JavaScript expression to compute the value of the insert ID field.
   */
  insertIdExpression?: string | undefined;
  /**
   * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
   */
  googleAuthMethod?: GoogleAuthenticationMethodGoogleCloudLogging | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * Maximum size, in KB, of the request body.
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Max number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Maximum number of ongoing requests before blocking.
   */
  concurrency?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it.
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum number of requests to limit to per second.
   */
  throttleRateReqPerSec?: number | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request method as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  requestMethodExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request URL as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  requestUrlExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  requestSizeExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request method as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  statusExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP response size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  responseSizeExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request user agent as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  userAgentExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request remote IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  remoteIpExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request server IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  serverIpExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request referer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  refererExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request latency, formatted as <seconds>.<nanoseconds>s (for example, 1.23s). See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  latencyExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request cache lookup as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  cacheLookupExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request cache hit as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  cacheHitExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request cache validated with origin server as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  cacheValidatedExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request cache fill bytes as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  cacheFillBytesExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the HTTP request protocol as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
   */
  protocolExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry operation ID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
   */
  idExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry operation producer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
   */
  producerExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry operation first flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
   */
  firstExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry operation last flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
   */
  lastExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry source location file as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
   */
  fileExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry source location line as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
   */
  lineExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry source location function as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
   */
  functionExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry log split UID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
   */
  uidExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry log split index as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
   */
  indexExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the log entry log split total splits as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
   */
  totalSplitsExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the REST resource name of the trace being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
   */
  traceExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the ID of the cloud trace span associated with the current operation in which the log is being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
   */
  spanIdExpression?: string | undefined;
  /**
   * A JavaScript expression that evaluates to the the sampling decision of the span associated with the log entry. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
   */
  traceSampledExpression?: string | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorGoogleCloudLogging | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * JavaScript expression to compute the value of the folder ID with which log entries should be associated. If Validate and correct log name is enabled, invalid characters (characters other than alphanumerics, forward-slashes, underscores, hyphens, and periods) will be replaced with an underscore.
   */
  logLocationExpression: string;
  /**
   * JavaScript expression to compute the value of the payload. Must evaluate to a JavaScript object value. If an invalid value is encountered it will result in the default value instead. Defaults to the entire event.
   */
  payloadExpression?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeGoogleCloudLogging | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionGoogleCloudLogging | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorGoogleCloudLogging | undefined;
  pqControls?: PqControlsGoogleCloudLogging | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeGoogleCloudStorage = {
  GoogleCloudStorage: "google_cloud_storage",
} as const;
export type TypeGoogleCloudStorage = ClosedEnum<typeof TypeGoogleCloudStorage>;

/**
 * Signature version to use for signing Google Cloud Storage requests
 */
export const SignatureVersionGoogleCloudStorage = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing Google Cloud Storage requests
 */
export type SignatureVersionGoogleCloudStorage = OpenEnum<
  typeof SignatureVersionGoogleCloudStorage
>;

export const AuthenticationMethodGoogleCloudStorage = {
  /**
   * auto
   */
  Auto: "auto",
  /**
   * manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
export type AuthenticationMethodGoogleCloudStorage = OpenEnum<
  typeof AuthenticationMethodGoogleCloudStorage
>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectACLGoogleCloudStorage = {
  /**
   * private
   */
  Private: "private",
  /**
   * bucket-owner-read
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * bucket-owner-full-control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
  /**
   * project-private
   */
  ProjectPrivate: "project-private",
  /**
   * authenticated-read
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * public-read
   */
  PublicRead: "public-read",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectACLGoogleCloudStorage = OpenEnum<
  typeof ObjectACLGoogleCloudStorage
>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassGoogleCloudStorage = {
  /**
   * Standard Storage
   */
  Standard: "STANDARD",
  /**
   * Nearline Storage
   */
  Nearline: "NEARLINE",
  /**
   * Coldline Storage
   */
  Coldline: "COLDLINE",
  /**
   * Archive Storage
   */
  Archive: "ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassGoogleCloudStorage = OpenEnum<
  typeof StorageClassGoogleCloudStorage
>;

/**
 * Format of the output data
 */
export const DataFormatGoogleCloudStorage = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatGoogleCloudStorage = OpenEnum<
  typeof DataFormatGoogleCloudStorage
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorGoogleCloudStorage = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorGoogleCloudStorage = OpenEnum<
  typeof BackpressureBehaviorGoogleCloudStorage
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionGoogleCloudStorage = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionGoogleCloudStorage = OpenEnum<
  typeof DiskSpaceProtectionGoogleCloudStorage
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionGoogleCloudStorage = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionGoogleCloudStorage = OpenEnum<
  typeof CompressionGoogleCloudStorage
>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelGoogleCloudStorage = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelGoogleCloudStorage = OpenEnum<
  typeof CompressionLevelGoogleCloudStorage
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionGoogleCloudStorage = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionGoogleCloudStorage = OpenEnum<
  typeof ParquetVersionGoogleCloudStorage
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionGoogleCloudStorage = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionGoogleCloudStorage = OpenEnum<
  typeof DataPageVersionGoogleCloudStorage
>;

export type KeyValueMetadatumGoogleCloudStorage = {
  key?: string | undefined;
  value: string;
};

export type OutputGoogleCloudStorage = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGoogleCloudStorage;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a Global Variable: `myBucket-${C.vars.myVar}`.
   */
  bucket: string;
  /**
   * Region where the bucket is located
   */
  region: string;
  /**
   * Google Cloud Storage service endpoint
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Google Cloud Storage requests
   */
  signatureVersion?: SignatureVersionGoogleCloudStorage | undefined;
  awsAuthenticationMethod?: AuthenticationMethodGoogleCloudStorage | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
   */
  destPath?: string | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectACLGoogleCloudStorage | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassGoogleCloudStorage | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatGoogleCloudStorage | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorGoogleCloudStorage | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionGoogleCloudStorage | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionGoogleCloudStorage | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelGoogleCloudStorage | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionGoogleCloudStorage | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionGoogleCloudStorage | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumGoogleCloudStorage> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * HMAC access key. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
   */
  awsApiKey?: string | undefined;
  /**
   * HMAC secret. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
   */
  awsSecretKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeGoogleChronicle = {
  GoogleChronicle: "google_chronicle",
} as const;
export type TypeGoogleChronicle = ClosedEnum<typeof TypeGoogleChronicle>;

export const OutputAPIVersion = {
  /**
   * V1
   */
  V1: "v1",
  /**
   * V2
   */
  V2: "v2",
} as const;
export type OutputAPIVersion = OpenEnum<typeof OutputAPIVersion>;

export const AuthenticationMethodGoogleChronicle = {
  /**
   * API key
   */
  Manual: "manual",
  /**
   * API key secret
   */
  Secret: "secret",
  /**
   * Service account credentials
   */
  ServiceAccount: "serviceAccount",
  /**
   * Service account credentials secret
   */
  ServiceAccountSecret: "serviceAccountSecret",
} as const;
export type AuthenticationMethodGoogleChronicle = OpenEnum<
  typeof AuthenticationMethodGoogleChronicle
>;

export type ResponseRetrySettingGoogleChronicle = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsGoogleChronicle = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export const SendEventsAs = {
  /**
   * Unstructured
   */
  Unstructured: "unstructured",
  /**
   * UDM
   */
  Udm: "udm",
} as const;
export type SendEventsAs = OpenEnum<typeof SendEventsAs>;

export type ExtraHttpHeaderGoogleChronicle = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeGoogleChronicle = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeGoogleChronicle = OpenEnum<
  typeof FailedRequestLoggingModeGoogleChronicle
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorGoogleChronicle = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorGoogleChronicle = OpenEnum<
  typeof BackpressureBehaviorGoogleChronicle
>;

export type ExtraLogType = {
  logType: string;
  description?: string | undefined;
};

export type CustomLabelGoogleChronicle = {
  key: string;
  value: string;
};

/**
 * Defines the specific format for UDM events sent to Google SecOps. This must match the type of UDM data being sent.
 */
export const UDMType = {
  Entities: "entities",
  Logs: "logs",
} as const;
/**
 * Defines the specific format for UDM events sent to Google SecOps. This must match the type of UDM data being sent.
 */
export type UDMType = OpenEnum<typeof UDMType>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeGoogleChronicle = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeGoogleChronicle = OpenEnum<typeof ModeGoogleChronicle>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionGoogleChronicle = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionGoogleChronicle = OpenEnum<
  typeof CompressionGoogleChronicle
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorGoogleChronicle = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorGoogleChronicle = OpenEnum<
  typeof QueueFullBehaviorGoogleChronicle
>;

export type PqControlsGoogleChronicle = {};

export type OutputGoogleChronicle = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGoogleChronicle;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  apiVersion?: OutputAPIVersion | undefined;
  authenticationMethod?: AuthenticationMethodGoogleChronicle | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<ResponseRetrySettingGoogleChronicle>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsGoogleChronicle | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  logFormatType?: SendEventsAs | undefined;
  /**
   * Regional endpoint to send events to
   */
  region?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderGoogleChronicle> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?:
    | FailedRequestLoggingModeGoogleChronicle
    | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorGoogleChronicle | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  /**
   * Custom log types. If the value "Custom" is selected in the setting "Default log type" above, the first custom log type in this table will be automatically selected as default log type.
   */
  extraLogTypes?: Array<ExtraLogType> | undefined;
  /**
   * Default log type value to send to SecOps. Can be overwritten by event field __logType.
   */
  logType?: string | undefined;
  /**
   * Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
   */
  logTextField?: string | undefined;
  /**
   * A unique identifier (UUID) for your Google SecOps instance. This is provided by your Google representative and is required for API V2 authentication.
   */
  customerId?: string | undefined;
  /**
   * User-configured environment namespace to identify the data domain the logs originated from. Use namespace as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
   */
  namespace?: string | undefined;
  /**
   * Custom labels to be added to every batch
   */
  customLabels?: Array<CustomLabelGoogleChronicle> | undefined;
  /**
   * Defines the specific format for UDM events sent to Google SecOps. This must match the type of UDM data being sent.
   */
  udmType?: UDMType | undefined;
  /**
   * Organization's API key in Google SecOps
   */
  apiKey?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  apiKeySecret?: string | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  serviceAccountCredentialsSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeGoogleChronicle | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionGoogleChronicle | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorGoogleChronicle | undefined;
  pqControls?: PqControlsGoogleChronicle | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeAzureEventhub = {
  AzureEventhub: "azure_eventhub",
} as const;
export type TypeAzureEventhub = ClosedEnum<typeof TypeAzureEventhub>;

/**
 * Control the number of required acknowledgments
 */
export const AcknowledgmentsAzureEventhub = {
  /**
   * Leader
   */
  One: 1,
  /**
   * None
   */
  Zero: 0,
  /**
   * All
   */
  Minus1: -1,
} as const;
/**
 * Control the number of required acknowledgments
 */
export type AcknowledgmentsAzureEventhub = OpenEnum<
  typeof AcknowledgmentsAzureEventhub
>;

/**
 * Format to use to serialize events before writing to the Event Hubs Kafka brokers
 */
export const RecordDataFormatAzureEventhub = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Field _raw
   */
  Raw: "raw",
} as const;
/**
 * Format to use to serialize events before writing to the Event Hubs Kafka brokers
 */
export type RecordDataFormatAzureEventhub = OpenEnum<
  typeof RecordDataFormatAzureEventhub
>;

/**
 * Enter password directly, or select a stored secret
 */
export const AuthTypeAuthenticationMethodAzureEventhub = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter password directly, or select a stored secret
 */
export type AuthTypeAuthenticationMethodAzureEventhub = OpenEnum<
  typeof AuthTypeAuthenticationMethodAzureEventhub
>;

export const SASLMechanismAzureEventhub = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * OAUTHBEARER
   */
  Oauthbearer: "oauthbearer",
} as const;
export type SASLMechanismAzureEventhub = OpenEnum<
  typeof SASLMechanismAzureEventhub
>;

export const ClientSecretAuthTypeAuthenticationMethodAzureEventhub = {
  Manual: "manual",
  Secret: "secret",
  Certificate: "certificate",
} as const;
export type ClientSecretAuthTypeAuthenticationMethodAzureEventhub = OpenEnum<
  typeof ClientSecretAuthTypeAuthenticationMethodAzureEventhub
>;

/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export const MicrosoftEntraIDAuthenticationEndpointAzureEventhub = {
  HttpsLoginMicrosoftonlineCom: "https://login.microsoftonline.com",
  HttpsLoginMicrosoftonlineUs: "https://login.microsoftonline.us",
  HttpsLoginPartnerMicrosoftonlineCn:
    "https://login.partner.microsoftonline.cn",
} as const;
/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export type MicrosoftEntraIDAuthenticationEndpointAzureEventhub = OpenEnum<
  typeof MicrosoftEntraIDAuthenticationEndpointAzureEventhub
>;

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type AuthenticationAzureEventhub = {
  disabled?: boolean | undefined;
  /**
   * Enter password directly, or select a stored secret
   */
  authType?: AuthTypeAuthenticationMethodAzureEventhub | undefined;
  /**
   * Connection-string primary key, or connection-string secondary key, from the Event Hubs workspace
   */
  password?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  mechanism?: SASLMechanismAzureEventhub | undefined;
  /**
   * The username for authentication. For Event Hubs, this should always be $ConnectionString.
   */
  username?: string | undefined;
  clientSecretAuthType?:
    | ClientSecretAuthTypeAuthenticationMethodAzureEventhub
    | undefined;
  /**
   * client_secret to pass in the OAuth request parameter
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Select or create a stored certificate
   */
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  /**
   * Endpoint used to acquire authentication tokens from Azure
   */
  oauthEndpoint?:
    | MicrosoftEntraIDAuthenticationEndpointAzureEventhub
    | undefined;
  /**
   * client_id to pass in the OAuth request parameter
   */
  clientId?: string | undefined;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory
   */
  tenantId?: string | undefined;
  /**
   * Scope to pass in the OAuth request parameter
   */
  scope?: string | undefined;
};

export type TLSSettingsClientSideAzureEventhub = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorAzureEventhub = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorAzureEventhub = OpenEnum<
  typeof BackpressureBehaviorAzureEventhub
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeAzureEventhub = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeAzureEventhub = OpenEnum<typeof ModeAzureEventhub>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionAzureEventhub = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionAzureEventhub = OpenEnum<
  typeof CompressionAzureEventhub
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorAzureEventhub = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorAzureEventhub = OpenEnum<
  typeof QueueFullBehaviorAzureEventhub
>;

export type PqControlsAzureEventhub = {};

export type OutputAzureEventhub = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeAzureEventhub;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
   */
  brokers: Array<string>;
  /**
   * The name of the Event Hub (Kafka Topic) to publish events. Can be overwritten using field __topicOut.
   */
  topic: string;
  /**
   * Control the number of required acknowledgments
   */
  ack?: AcknowledgmentsAzureEventhub | undefined;
  /**
   * Format to use to serialize events before writing to the Event Hubs Kafka brokers
   */
  format?: RecordDataFormatAzureEventhub | undefined;
  /**
   * Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum number of events in a batch before forcing a flush
   */
  flushEventCount?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: AuthenticationAzureEventhub | undefined;
  tls?: TLSSettingsClientSideAzureEventhub | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorAzureEventhub | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeAzureEventhub | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionAzureEventhub | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorAzureEventhub | undefined;
  pqControls?: PqControlsAzureEventhub | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeHoneycomb = {
  Honeycomb: "honeycomb",
} as const;
export type TypeHoneycomb = ClosedEnum<typeof TypeHoneycomb>;

export type ExtraHttpHeaderHoneycomb = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeHoneycomb = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeHoneycomb = OpenEnum<
  typeof FailedRequestLoggingModeHoneycomb
>;

export type ResponseRetrySettingHoneycomb = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsHoneycomb = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorHoneycomb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorHoneycomb = OpenEnum<
  typeof BackpressureBehaviorHoneycomb
>;

/**
 * Enter API key directly, or select a stored secret
 */
export const AuthenticationMethodHoneycomb = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter API key directly, or select a stored secret
 */
export type AuthenticationMethodHoneycomb = OpenEnum<
  typeof AuthenticationMethodHoneycomb
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeHoneycomb = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeHoneycomb = OpenEnum<typeof ModeHoneycomb>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionHoneycomb = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionHoneycomb = OpenEnum<typeof CompressionHoneycomb>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorHoneycomb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorHoneycomb = OpenEnum<
  typeof QueueFullBehaviorHoneycomb
>;

export type PqControlsHoneycomb = {};

export type OutputHoneycomb = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeHoneycomb;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the dataset to send events to – e.g., observability
   */
  dataset: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderHoneycomb> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeHoneycomb | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingHoneycomb> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsHoneycomb | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorHoneycomb | undefined;
  /**
   * Enter API key directly, or select a stored secret
   */
  authType?: AuthenticationMethodHoneycomb | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeHoneycomb | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionHoneycomb | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorHoneycomb | undefined;
  pqControls?: PqControlsHoneycomb | undefined;
  /**
   * Team API key where the dataset belongs
   */
  team?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeKinesis = {
  Kinesis: "kinesis",
} as const;
export type OutputTypeKinesis = ClosedEnum<typeof OutputTypeKinesis>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputAuthenticationMethodKinesis = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputAuthenticationMethodKinesis = OpenEnum<
  typeof OutputAuthenticationMethodKinesis
>;

/**
 * Signature version to use for signing Kinesis stream requests
 */
export const OutputSignatureVersionKinesis = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing Kinesis stream requests
 */
export type OutputSignatureVersionKinesis = OpenEnum<
  typeof OutputSignatureVersionKinesis
>;

/**
 * Compression type to use for records
 */
export const OutputCompressionKinesis = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Compression type to use for records
 */
export type OutputCompressionKinesis = OpenEnum<
  typeof OutputCompressionKinesis
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorKinesis = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorKinesis = OpenEnum<
  typeof BackpressureBehaviorKinesis
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeKinesis = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeKinesis = OpenEnum<typeof OutputModeKinesis>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionKinesis = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionKinesis = OpenEnum<
  typeof PqCompressCompressionKinesis
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorKinesis = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorKinesis = OpenEnum<
  typeof QueueFullBehaviorKinesis
>;

export type OutputPqControlsKinesis = {};

export type OutputKinesis = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeKinesis;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Kinesis stream name to send events to.
   */
  streamName: string;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputAuthenticationMethodKinesis | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the Kinesis stream is located
   */
  region: string;
  /**
   * Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Kinesis stream requests
   */
  signatureVersion?: OutputSignatureVersionKinesis | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Kinesis stream
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Maximum number of ongoing put requests before blocking.
   */
  concurrency?: number | undefined;
  /**
   * Maximum size (KB) of each individual record before compression. For uncompressed or non-compressible data 1MB is the max recommended size
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Compression type to use for records
   */
  compression?: OutputCompressionKinesis | undefined;
  /**
   * Provides higher stream rate limits, improving delivery speed and reliability by minimizing throttling. See the [ListShards API](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html) documentation for details.
   */
  useListShards?: boolean | undefined;
  /**
   * Batch events into a single record as NDJSON
   */
  asNdjson?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorKinesis | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Maximum number of records to send in a single request
   */
  maxEventsPerFlush?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeKinesis | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionKinesis | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorKinesis | undefined;
  pqControls?: OutputPqControlsKinesis | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeAzureLogs = {
  AzureLogs: "azure_logs",
} as const;
export type TypeAzureLogs = ClosedEnum<typeof TypeAzureLogs>;

export type ExtraHttpHeaderAzureLogs = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeAzureLogs = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeAzureLogs = OpenEnum<
  typeof FailedRequestLoggingModeAzureLogs
>;

export type ResponseRetrySettingAzureLogs = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsAzureLogs = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorAzureLogs = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorAzureLogs = OpenEnum<
  typeof BackpressureBehaviorAzureLogs
>;

/**
 * Enter workspace ID and workspace key directly, or select a stored secret
 */
export const AuthenticationMethodAzureLogs = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter workspace ID and workspace key directly, or select a stored secret
 */
export type AuthenticationMethodAzureLogs = OpenEnum<
  typeof AuthenticationMethodAzureLogs
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeAzureLogs = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeAzureLogs = OpenEnum<typeof ModeAzureLogs>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionAzureLogs = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionAzureLogs = OpenEnum<typeof CompressionAzureLogs>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorAzureLogs = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorAzureLogs = OpenEnum<
  typeof QueueFullBehaviorAzureLogs
>;

export type PqControlsAzureLogs = {};

export type OutputAzureLogs = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeAzureLogs;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
   */
  logType?: string | undefined;
  /**
   * Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
   */
  resourceId?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderAzureLogs> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeAzureLogs | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
   */
  apiUrl?: string | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingAzureLogs> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsAzureLogs | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorAzureLogs | undefined;
  /**
   * Enter workspace ID and workspace key directly, or select a stored secret
   */
  authType?: AuthenticationMethodAzureLogs | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeAzureLogs | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionAzureLogs | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorAzureLogs | undefined;
  pqControls?: PqControlsAzureLogs | undefined;
  /**
   * Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
   */
  workspaceId?: string | undefined;
  /**
   * Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
   */
  workspaceKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  keypairSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeAzureDataExplorer = {
  AzureDataExplorer: "azure_data_explorer",
} as const;
export type TypeAzureDataExplorer = ClosedEnum<typeof TypeAzureDataExplorer>;

export const IngestionMode = {
  /**
   * Batching
   */
  Batching: "batching",
  /**
   * Streaming
   */
  Streaming: "streaming",
} as const;
export type IngestionMode = OpenEnum<typeof IngestionMode>;

/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export const MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer = {
  HttpsLoginMicrosoftonlineCom: "https://login.microsoftonline.com",
  HttpsLoginMicrosoftonlineUs: "https://login.microsoftonline.us",
  HttpsLoginPartnerMicrosoftonlineCn:
    "https://login.partner.microsoftonline.cn",
} as const;
/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export type MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer = OpenEnum<
  typeof MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer
>;

/**
 * The type of OAuth 2.0 client credentials grant flow to use
 */
export const OauthTypeAuthenticationMethod = {
  /**
   * Client secret
   */
  ClientSecret: "clientSecret",
  /**
   * Client secret (text secret)
   */
  ClientTextSecret: "clientTextSecret",
  /**
   * Certificate
   */
  Certificate: "certificate",
} as const;
/**
 * The type of OAuth 2.0 client credentials grant flow to use
 */
export type OauthTypeAuthenticationMethod = OpenEnum<
  typeof OauthTypeAuthenticationMethod
>;

export type CertificateAzureDataExplorer = {
  /**
   * The certificate you registered as credentials for your app in the Azure portal
   */
  certificateName?: string | undefined;
};

/**
 * Format of the output data
 */
export const DataFormatAzureDataExplorer = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatAzureDataExplorer = OpenEnum<
  typeof DataFormatAzureDataExplorer
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressCompressionAzureDataExplorer = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressCompressionAzureDataExplorer = OpenEnum<
  typeof CompressCompressionAzureDataExplorer
>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelAzureDataExplorer = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelAzureDataExplorer = OpenEnum<
  typeof CompressionLevelAzureDataExplorer
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionAzureDataExplorer = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionAzureDataExplorer = OpenEnum<
  typeof ParquetVersionAzureDataExplorer
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionAzureDataExplorer = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionAzureDataExplorer = OpenEnum<
  typeof DataPageVersionAzureDataExplorer
>;

export type KeyValueMetadatumAzureDataExplorer = {
  key?: string | undefined;
  value: string;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorAzureDataExplorer = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorAzureDataExplorer = OpenEnum<
  typeof BackpressureBehaviorAzureDataExplorer
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionAzureDataExplorer = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionAzureDataExplorer = OpenEnum<
  typeof DiskSpaceProtectionAzureDataExplorer
>;

export const PrefixOptional = {
  /**
   * drop-by
   */
  DropBy: "dropBy",
  /**
   * ingest-by
   */
  IngestBy: "ingestBy",
} as const;
export type PrefixOptional = OpenEnum<typeof PrefixOptional>;

export type ExtentTag = {
  prefix?: PrefixOptional | undefined;
  value: string;
};

export type IngestIfNotExist = {
  value: string;
};

/**
 * Level of ingestion status reporting. Defaults to FailuresOnly.
 */
export const ReportLevel = {
  /**
   * FailuresOnly
   */
  FailuresOnly: "failuresOnly",
  /**
   * DoNotReport
   */
  DoNotReport: "doNotReport",
  /**
   * FailuresAndSuccesses
   */
  FailuresAndSuccesses: "failuresAndSuccesses",
} as const;
/**
 * Level of ingestion status reporting. Defaults to FailuresOnly.
 */
export type ReportLevel = OpenEnum<typeof ReportLevel>;

/**
 * Target of the ingestion status reporting. Defaults to Queue.
 */
export const ReportMethod = {
  /**
   * Queue
   */
  Queue: "queue",
  /**
   * Table
   */
  Table: "table",
  /**
   * QueueAndTable
   */
  QueueAndTable: "queueAndTable",
} as const;
/**
 * Target of the ingestion status reporting. Defaults to Queue.
 */
export type ReportMethod = OpenEnum<typeof ReportMethod>;

export type AdditionalProperty = {
  key: string;
  value: string;
};

export type ResponseRetrySettingAzureDataExplorer = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsAzureDataExplorer = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeAzureDataExplorer = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeAzureDataExplorer = OpenEnum<typeof ModeAzureDataExplorer>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionAzureDataExplorer = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionAzureDataExplorer = OpenEnum<
  typeof PqCompressCompressionAzureDataExplorer
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorAzureDataExplorer = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorAzureDataExplorer = OpenEnum<
  typeof QueueFullBehaviorAzureDataExplorer
>;

export type PqControlsAzureDataExplorer = {};

export type OutputAzureDataExplorer = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeAzureDataExplorer;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The base URI for your cluster. Typically, `https://<cluster>.<region>.kusto.windows.net`.
   */
  clusterUrl: string;
  /**
   * Name of the database containing the table where data will be ingested
   */
  database: string;
  /**
   * Name of the table to ingest data into
   */
  table: string;
  /**
   * When saving or starting the Destination, validate the database name and credentials; also validate table name, except when creating a new table. Disable if your Azure app does not have both the Database Viewer and the Table Viewer role.
   */
  validateDatabaseSettings?: boolean | undefined;
  ingestMode?: IngestionMode | undefined;
  /**
   * Endpoint used to acquire authentication tokens from Azure
   */
  oauthEndpoint?:
    | MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer
    | undefined;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory
   */
  tenantId: string;
  /**
   * client_id to pass in the OAuth request parameter
   */
  clientId: string;
  /**
   * Scope to pass in the OAuth request parameter
   */
  scope: string;
  /**
   * The type of OAuth 2.0 client credentials grant flow to use
   */
  oauthType?: OauthTypeAuthenticationMethod | undefined;
  description?: string | undefined;
  /**
   * The client secret that you generated for your app in the Azure portal
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  certificate?: CertificateAzureDataExplorer | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatAzureDataExplorer | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressCompressionAzureDataExplorer | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelAzureDataExplorer | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionAzureDataExplorer | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionAzureDataExplorer | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumAzureDataExplorer> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Send a JSON mapping object instead of specifying an existing named data mapping
   */
  isMappingObj?: boolean | undefined;
  /**
   * Enter a JSON object that defines your desired data mapping
   */
  mappingObj?: string | undefined;
  /**
   * Enter the name of a data mapping associated with your target table. Or, if incoming event and target table fields match exactly, you can leave the field empty.
   */
  mappingRef?: string | undefined;
  /**
   * The ingestion service URI for your cluster. Typically, `https://ingest-<cluster>.<region>.kusto.windows.net`.
   */
  ingestUrl?: string | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorAzureDataExplorer | undefined;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionAzureDataExplorer | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Bypass the data management service's aggregation mechanism
   */
  flushImmediately?: boolean | undefined;
  /**
   * Prevent blob deletion after ingestion is complete
   */
  retainBlobOnSuccess?: boolean | undefined;
  /**
   * Strings or tags associated with the extent (ingested data shard)
   */
  extentTags?: Array<ExtentTag> | undefined;
  /**
   * Prevents duplicate ingestion by verifying whether an extent with the specified ingest-by tag already exists
   */
  ingestIfNotExists?: Array<IngestIfNotExist> | undefined;
  /**
   * Level of ingestion status reporting. Defaults to FailuresOnly.
   */
  reportLevel?: ReportLevel | undefined;
  /**
   * Target of the ingestion status reporting. Defaults to Queue.
   */
  reportMethod?: ReportMethod | undefined;
  /**
   * Optionally, enter additional configuration properties to send to the ingestion service
   */
  additionalProperties?: Array<AdditionalProperty> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<ResponseRetrySettingAzureDataExplorer>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsAzureDataExplorer | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeAzureDataExplorer | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionAzureDataExplorer | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorAzureDataExplorer | undefined;
  pqControls?: PqControlsAzureDataExplorer | undefined;
  additionalProperties1?: { [k: string]: any } | undefined;
};

export const OutputTypeAzureBlob = {
  AzureBlob: "azure_blob",
} as const;
export type OutputTypeAzureBlob = ClosedEnum<typeof OutputTypeAzureBlob>;

/**
 * Format of the output data
 */
export const DataFormatAzureBlob = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatAzureBlob = OpenEnum<typeof DataFormatAzureBlob>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorAzureBlob = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorAzureBlob = OpenEnum<
  typeof BackpressureBehaviorAzureBlob
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionAzureBlob = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionAzureBlob = OpenEnum<
  typeof DiskSpaceProtectionAzureBlob
>;

export const OutputAuthenticationMethodAzureBlob = {
  Manual: "manual",
  Secret: "secret",
  ClientSecret: "clientSecret",
  ClientCert: "clientCert",
} as const;
export type OutputAuthenticationMethodAzureBlob = OpenEnum<
  typeof OutputAuthenticationMethodAzureBlob
>;

export const BlobAccessTier = {
  /**
   * Default account access tier
   */
  Inferred: "Inferred",
  /**
   * Hot tier
   */
  Hot: "Hot",
  /**
   * Cool tier
   */
  Cool: "Cool",
  /**
   * Cold tier
   */
  Cold: "Cold",
  /**
   * Archive tier
   */
  Archive: "Archive",
} as const;
export type BlobAccessTier = OpenEnum<typeof BlobAccessTier>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const OutputCompressionAzureBlob = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type OutputCompressionAzureBlob = OpenEnum<
  typeof OutputCompressionAzureBlob
>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelAzureBlob = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelAzureBlob = OpenEnum<
  typeof CompressionLevelAzureBlob
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionAzureBlob = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionAzureBlob = OpenEnum<typeof ParquetVersionAzureBlob>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionAzureBlob = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionAzureBlob = OpenEnum<
  typeof DataPageVersionAzureBlob
>;

export type KeyValueMetadatumAzureBlob = {
  key?: string | undefined;
  value: string;
};

export type OutputCertificateAzureBlob = {
  /**
   * The certificate you registered as credentials for your app in the Azure portal
   */
  certificateName: string;
};

export type OutputAzureBlob = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeAzureBlob;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The Azure Blob Storage container name. Name can include only lowercase letters, numbers, and hyphens. For dynamic container names, enter a JavaScript expression within quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myContainer-${C.env["CRIBL_WORKER_ID"]}`.
   */
  containerName: string;
  /**
   * Create the configured container in Azure Blob Storage if it does not already exist
   */
  createContainer?: boolean | undefined;
  /**
   * Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`.
   */
  destPath?: string | undefined;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Maximum number of parts to upload in parallel per file
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatAzureBlob | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorAzureBlob | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionAzureBlob | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  authType?: OutputAuthenticationMethodAzureBlob | undefined;
  storageClass?: BlobAccessTier | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: OutputCompressionAzureBlob | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelAzureBlob | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionAzureBlob | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionAzureBlob | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumAzureBlob> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: OutputCertificateAzureBlob | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeS3 = {
  S3: "s3",
} as const;
export type OutputTypeS3 = ClosedEnum<typeof OutputTypeS3>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputAuthenticationMethodS3 = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputAuthenticationMethodS3 = OpenEnum<
  typeof OutputAuthenticationMethodS3
>;

/**
 * Signature version to use for signing S3 requests
 */
export const OutputSignatureVersionS3 = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type OutputSignatureVersionS3 = OpenEnum<
  typeof OutputSignatureVersionS3
>;

/**
 * Object ACL to assign to uploaded objects
 */
export const ObjectAcls3 = {
  /**
   * Private
   */
  Private: "private",
  /**
   * Public Read Only
   */
  PublicRead: "public-read",
  /**
   * Public Read/Write
   */
  PublicReadWrite: "public-read-write",
  /**
   * Authenticated Read Only
   */
  AuthenticatedRead: "authenticated-read",
  /**
   * AWS EC2 AMI Read Only
   */
  AwsExecRead: "aws-exec-read",
  /**
   * Bucket Owner Read Only
   */
  BucketOwnerRead: "bucket-owner-read",
  /**
   * Bucket Owner Full Control
   */
  BucketOwnerFullControl: "bucket-owner-full-control",
} as const;
/**
 * Object ACL to assign to uploaded objects
 */
export type ObjectAcls3 = OpenEnum<typeof ObjectAcls3>;

/**
 * Storage class to select for uploaded objects
 */
export const StorageClassS3 = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
  /**
   * Standard, Infrequent Access
   */
  StandardIa: "STANDARD_IA",
  /**
   * One Zone, Infrequent Access
   */
  OnezoneIa: "ONEZONE_IA",
  /**
   * Intelligent Tiering
   */
  IntelligentTiering: "INTELLIGENT_TIERING",
  /**
   * Glacier Flexible Retrieval
   */
  Glacier: "GLACIER",
  /**
   * Glacier Instant Retrieval
   */
  GlacierIr: "GLACIER_IR",
  /**
   * Glacier Deep Archive
   */
  DeepArchive: "DEEP_ARCHIVE",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type StorageClassS3 = OpenEnum<typeof StorageClassS3>;

export const ServerSideEncryptionForUploadedObjectsS3 = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
  /**
   * AWS KMS Managed Key
   */
  AwsKms: "aws:kms",
} as const;
export type ServerSideEncryptionForUploadedObjectsS3 = OpenEnum<
  typeof ServerSideEncryptionForUploadedObjectsS3
>;

/**
 * Format of the output data
 */
export const DataFormatS3 = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatS3 = OpenEnum<typeof DataFormatS3>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorS3 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorS3 = OpenEnum<typeof BackpressureBehaviorS3>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionS3 = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionS3 = OpenEnum<typeof DiskSpaceProtectionS3>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const OutputCompressionS3 = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type OutputCompressionS3 = OpenEnum<typeof OutputCompressionS3>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelS3 = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelS3 = OpenEnum<typeof CompressionLevelS3>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionS3 = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionS3 = OpenEnum<typeof ParquetVersionS3>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionS3 = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionS3 = OpenEnum<typeof DataPageVersionS3>;

export type KeyValueMetadatumS3 = {
  key?: string | undefined;
  value: string;
};

export type OutputS3 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeS3;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * Region where the S3 bucket is located
   */
  region?: string | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
   */
  awsSecretKey?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputAuthenticationMethodS3 | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: OutputSignatureVersionS3 | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
   */
  destPath?: string | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectAcls3 | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassS3 | undefined;
  serverSideEncryption?: ServerSideEncryptionForUploadedObjectsS3 | undefined;
  /**
   * ID or ARN of the KMS customer-managed key to use for encryption
   */
  kmsKeyId?: string | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatS3 | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorS3 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionS3 | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Maximum number of files that can be waiting for upload before backpressure is applied
   */
  maxClosingFilesToBackpressure?: number | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: OutputCompressionS3 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelS3 | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionS3 | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionS3 | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumS3> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeFilesystem = {
  Filesystem: "filesystem",
} as const;
export type TypeFilesystem = ClosedEnum<typeof TypeFilesystem>;

/**
 * Format of the output data
 */
export const DataFormatFilesystem = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type DataFormatFilesystem = OpenEnum<typeof DataFormatFilesystem>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorFilesystem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorFilesystem = OpenEnum<
  typeof BackpressureBehaviorFilesystem
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const DiskSpaceProtectionFilesystem = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type DiskSpaceProtectionFilesystem = OpenEnum<
  typeof DiskSpaceProtectionFilesystem
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const CompressionFilesystem = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type CompressionFilesystem = OpenEnum<typeof CompressionFilesystem>;

/**
 * Compression level to apply before moving files to final destination
 */
export const CompressionLevelFilesystem = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type CompressionLevelFilesystem = OpenEnum<
  typeof CompressionLevelFilesystem
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const ParquetVersionFilesystem = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type ParquetVersionFilesystem = OpenEnum<
  typeof ParquetVersionFilesystem
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const DataPageVersionFilesystem = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type DataPageVersionFilesystem = OpenEnum<
  typeof DataPageVersionFilesystem
>;

export type KeyValueMetadatumFilesystem = {
  key?: string | undefined;
  value: string;
};

export type OutputFilesystem = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeFilesystem;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Final destination for the output files
   */
  destPath: string;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatFilesystem | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorFilesystem | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionFilesystem | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionFilesystem | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelFilesystem | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionFilesystem | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionFilesystem | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<KeyValueMetadatumFilesystem> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSignalfx = {
  Signalfx: "signalfx",
} as const;
export type TypeSignalfx = ClosedEnum<typeof TypeSignalfx>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodSignalfx = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodSignalfx = OpenEnum<
  typeof AuthenticationMethodSignalfx
>;

export type ExtraHttpHeaderSignalfx = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeSignalfx = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeSignalfx = OpenEnum<
  typeof FailedRequestLoggingModeSignalfx
>;

export type ResponseRetrySettingSignalfx = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsSignalfx = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSignalfx = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSignalfx = OpenEnum<
  typeof BackpressureBehaviorSignalfx
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSignalfx = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSignalfx = OpenEnum<typeof ModeSignalfx>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSignalfx = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSignalfx = OpenEnum<typeof CompressionSignalfx>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSignalfx = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSignalfx = OpenEnum<
  typeof QueueFullBehaviorSignalfx
>;

export type PqControlsSignalfx = {};

export type OutputSignalfx = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSignalfx;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodSignalfx | undefined;
  /**
   * SignalFx realm name, e.g. "us0". For a complete list of available SignalFx realm names, please check [here](https://docs.splunk.com/observability/en/get-started/service-description.html#sd-regions).
   */
  realm?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderSignalfx> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeSignalfx | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingSignalfx> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSignalfx | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSignalfx | undefined;
  description?: string | undefined;
  /**
   * SignalFx API access token (see [here](https://docs.signalfx.com/en/latest/admin-guide/tokens.html#working-with-access-tokens))
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSignalfx | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSignalfx | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSignalfx | undefined;
  pqControls?: PqControlsSignalfx | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWavefront = {
  Wavefront: "wavefront",
} as const;
export type TypeWavefront = ClosedEnum<typeof TypeWavefront>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodWavefront = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodWavefront = OpenEnum<
  typeof AuthenticationMethodWavefront
>;

export type ExtraHttpHeaderWavefront = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeWavefront = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeWavefront = OpenEnum<
  typeof FailedRequestLoggingModeWavefront
>;

export type ResponseRetrySettingWavefront = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsWavefront = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorWavefront = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorWavefront = OpenEnum<
  typeof BackpressureBehaviorWavefront
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeWavefront = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeWavefront = OpenEnum<typeof ModeWavefront>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWavefront = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWavefront = OpenEnum<typeof CompressionWavefront>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorWavefront = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorWavefront = OpenEnum<
  typeof QueueFullBehaviorWavefront
>;

export type PqControlsWavefront = {};

export type OutputWavefront = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeWavefront;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodWavefront | undefined;
  /**
   * WaveFront domain name, e.g. "longboard"
   */
  domain?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderWavefront> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeWavefront | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingWavefront> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsWavefront | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorWavefront | undefined;
  description?: string | undefined;
  /**
   * WaveFront API authentication token (see [here](https://docs.wavefront.com/wavefront_api.html#generating-an-api-token))
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeWavefront | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionWavefront | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorWavefront | undefined;
  pqControls?: PqControlsWavefront | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeTcpjson = {
  Tcpjson: "tcpjson",
} as const;
export type OutputTypeTcpjson = ClosedEnum<typeof OutputTypeTcpjson>;

/**
 * Codec to use to compress the data before sending
 */
export const OutputCompressionTcpjson = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the data before sending
 */
export type OutputCompressionTcpjson = OpenEnum<
  typeof OutputCompressionTcpjson
>;

export const OutputMinimumTLSVersionTcpjson = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionTcpjson = OpenEnum<
  typeof OutputMinimumTLSVersionTcpjson
>;

export const OutputMaximumTLSVersionTcpjson = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionTcpjson = OpenEnum<
  typeof OutputMaximumTLSVersionTcpjson
>;

export type TLSSettingsClientSideTcpjson = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionTcpjson | undefined;
  maxVersion?: OutputMaximumTLSVersionTcpjson | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorTcpjson = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorTcpjson = OpenEnum<
  typeof BackpressureBehaviorTcpjson
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const OutputAuthenticationMethodTcpjson = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type OutputAuthenticationMethodTcpjson = OpenEnum<
  typeof OutputAuthenticationMethodTcpjson
>;

/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export const TLSTcpjson = {
  Inherit: "inherit",
  Off: "off",
} as const;
/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export type TLSTcpjson = OpenEnum<typeof TLSTcpjson>;

export type HostTcpjson = {
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port: number;
  /**
   * Whether to inherit TLS configs from group setting or disable TLS
   */
  tls?: TLSTcpjson | undefined;
  /**
   * Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
   */
  servername?: string | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeTcpjson = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeTcpjson = OpenEnum<typeof OutputModeTcpjson>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionTcpjson = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionTcpjson = OpenEnum<
  typeof PqCompressCompressionTcpjson
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorTcpjson = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorTcpjson = OpenEnum<
  typeof QueueFullBehaviorTcpjson
>;

export type OutputPqControlsTcpjson = {};

export type OutputTcpjson = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeTcpjson;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Use load-balanced destinations
   */
  loadBalanced?: boolean | undefined;
  /**
   * Codec to use to compress the data before sending
   */
  compression?: OutputCompressionTcpjson | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  tls?: TLSSettingsClientSideTcpjson | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
   */
  tokenTTLMinutes?: number | undefined;
  /**
   * Upon connection, send a header-like record containing the auth token and other metadata.This record will not contain an actual event – only subsequent records will.
   */
  sendHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorTcpjson | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: OutputAuthenticationMethodTcpjson | undefined;
  description?: string | undefined;
  /**
   * The hostname of the receiver
   */
  host?: string | undefined;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of hosts to load-balance data to
   */
  hosts?: Array<HostTcpjson> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeTcpjson | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionTcpjson | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorTcpjson | undefined;
  pqControls?: OutputPqControlsTcpjson | undefined;
  /**
   * Optional authentication token to include as part of the connection header
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSplunkHec = {
  SplunkHec: "splunk_hec",
} as const;
export type OutputTypeSplunkHec = ClosedEnum<typeof OutputTypeSplunkHec>;

export const OutputMinimumTLSVersionSplunkHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionSplunkHec = OpenEnum<
  typeof OutputMinimumTLSVersionSplunkHec
>;

export const OutputMaximumTLSVersionSplunkHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionSplunkHec = OpenEnum<
  typeof OutputMaximumTLSVersionSplunkHec
>;

export type TLSSettingsClientSideSplunkHec = {
  disabled?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionSplunkHec | undefined;
  maxVersion?: OutputMaximumTLSVersionSplunkHec | undefined;
};

export type ExtraHttpHeaderSplunkHec = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeSplunkHec = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeSplunkHec = OpenEnum<
  typeof FailedRequestLoggingModeSplunkHec
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const OutputAuthenticationMethodSplunkHec = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type OutputAuthenticationMethodSplunkHec = OpenEnum<
  typeof OutputAuthenticationMethodSplunkHec
>;

export type ResponseRetrySettingSplunkHec = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsSplunkHec = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSplunkHec = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSplunkHec = OpenEnum<
  typeof BackpressureBehaviorSplunkHec
>;

export type UrlSplunkHec = {
  /**
   * URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
   */
  url?: string | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeSplunkHec = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeSplunkHec = OpenEnum<typeof OutputModeSplunkHec>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionSplunkHec = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionSplunkHec = OpenEnum<
  typeof PqCompressCompressionSplunkHec
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSplunkHec = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSplunkHec = OpenEnum<
  typeof QueueFullBehaviorSplunkHec
>;

export type OutputPqControlsSplunkHec = {};

export type OutputSplunkHec = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSplunkHec;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
   */
  nextQueue?: string | undefined;
  /**
   * In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
   */
  tcpRouting?: string | undefined;
  tls?: TLSSettingsClientSideSplunkHec | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderSplunkHec> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeSplunkHec | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Output metrics in multiple-metric format, supported in Splunk 8.0 and above to allow multiple metrics in a single event.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: OutputAuthenticationMethodSplunkHec | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingSplunkHec> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSplunkHec | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSplunkHec | undefined;
  description?: string | undefined;
  /**
   * URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
   */
  url?: string | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<UrlSplunkHec> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Splunk HEC authentication token
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeSplunkHec | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionSplunkHec | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSplunkHec | undefined;
  pqControls?: OutputPqControlsSplunkHec | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSplunkLb = {
  SplunkLb: "splunk_lb",
} as const;
export type TypeSplunkLb = ClosedEnum<typeof TypeSplunkLb>;

/**
 * How to serialize nested fields into index-time fields
 */
export const NestedFieldSerializationSplunkLb = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * How to serialize nested fields into index-time fields
 */
export type NestedFieldSerializationSplunkLb = OpenEnum<
  typeof NestedFieldSerializationSplunkLb
>;

export const MinimumTLSVersionSplunkLb = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionSplunkLb = OpenEnum<
  typeof MinimumTLSVersionSplunkLb
>;

export const MaximumTLSVersionSplunkLb = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionSplunkLb = OpenEnum<
  typeof MaximumTLSVersionSplunkLb
>;

export type TLSSettingsClientSideSplunkLb = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: MinimumTLSVersionSplunkLb | undefined;
  maxVersion?: MaximumTLSVersionSplunkLb | undefined;
};

/**
 * The highest S2S protocol version to advertise during handshake
 */
export const MaxS2SVersionSplunkLb = {
  V3: "v3",
  V4: "v4",
} as const;
/**
 * The highest S2S protocol version to advertise during handshake
 */
export type MaxS2SVersionSplunkLb = OpenEnum<typeof MaxS2SVersionSplunkLb>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSplunkLb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSplunkLb = OpenEnum<
  typeof BackpressureBehaviorSplunkLb
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodSplunkLb = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodSplunkLb = OpenEnum<
  typeof AuthenticationMethodSplunkLb
>;

/**
 * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
 */
export const CompressCompressionSplunkLb = {
  /**
   * Disabled
   */
  Disabled: "disabled",
  /**
   * Automatic
   */
  Auto: "auto",
  /**
   * Always
   */
  Always: "always",
} as const;
/**
 * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
 */
export type CompressCompressionSplunkLb = OpenEnum<
  typeof CompressCompressionSplunkLb
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const IndexerDiscoveryConfigsAuthTokenAuthenticationMethod = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type IndexerDiscoveryConfigsAuthTokenAuthenticationMethod = OpenEnum<
  typeof IndexerDiscoveryConfigsAuthTokenAuthenticationMethod
>;

export type IndexerDiscoveryConfigsAuthToken = {
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: IndexerDiscoveryConfigsAuthTokenAuthenticationMethod | undefined;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const IndexerDiscoveryConfigsAuthenticationMethod = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type IndexerDiscoveryConfigsAuthenticationMethod = OpenEnum<
  typeof IndexerDiscoveryConfigsAuthenticationMethod
>;

/**
 * List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
 */
export type IndexerDiscoveryConfigs = {
  /**
   * Clustering site of the indexers from where indexers need to be discovered. In case of single site cluster, it defaults to 'default' site.
   */
  site?: string | undefined;
  /**
   * Full URI of Splunk cluster manager (scheme://host:port). Example: https://managerAddress:8089
   */
  masterUri: string;
  /**
   * Time interval, in seconds, between two consecutive indexer list fetches from cluster manager
   */
  refreshIntervalSec?: number | undefined;
  /**
   * During indexer discovery, reject cluster manager certificates that are not authorized by the system's CA. Disable to allow untrusted (for example, self-signed) certificates.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Tokens required to authenticate to cluster manager for indexer discovery
   */
  authTokens?: Array<IndexerDiscoveryConfigsAuthToken> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: IndexerDiscoveryConfigsAuthenticationMethod | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export const TLSSplunkLb = {
  Inherit: "inherit",
  Off: "off",
} as const;
/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export type TLSSplunkLb = OpenEnum<typeof TLSSplunkLb>;

export type HostSplunkLb = {
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Whether to inherit TLS configs from group setting or disable TLS
   */
  tls?: TLSSplunkLb | undefined;
  /**
   * Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
   */
  servername?: string | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSplunkLb = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSplunkLb = OpenEnum<typeof ModeSplunkLb>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionSplunkLb = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionSplunkLb = OpenEnum<
  typeof PqCompressCompressionSplunkLb
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSplunkLb = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSplunkLb = OpenEnum<
  typeof QueueFullBehaviorSplunkLb
>;

export type PqControlsSplunkLb = {};

export type OutputSplunkLb = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSplunkLb;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * How to serialize nested fields into index-time fields
   */
  nestedFields?: NestedFieldSerializationSplunkLb | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: TLSSettingsClientSideSplunkLb | undefined;
  /**
   * Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
   */
  enableACK?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * The highest S2S protocol version to advertise during handshake
   */
  maxS2Sversion?: MaxS2SVersionSplunkLb | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSplunkLb | undefined;
  /**
   * Automatically discover indexers in indexer clustering environment.
   */
  indexerDiscovery?: boolean | undefined;
  /**
   * How long (in milliseconds) each LB endpoint can report blocked before the Destination reports unhealthy, blocking the sender. (Grace period for fluctuations.) Use 0 to disable; max 1 minute.
   */
  senderUnhealthyTimeAllowance?: number | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodSplunkLb | undefined;
  description?: string | undefined;
  /**
   * Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
   */
  maxFailedHealthChecks?: number | undefined;
  /**
   * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
   */
  compress?: CompressCompressionSplunkLb | undefined;
  /**
   * List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
   */
  indexerDiscoveryConfigs?: IndexerDiscoveryConfigs | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of Splunk indexers to load-balance data to.
   */
  hosts: Array<HostSplunkLb>;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSplunkLb | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionSplunkLb | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSplunkLb | undefined;
  pqControls?: PqControlsSplunkLb | undefined;
  /**
   * Shared secret token to use when establishing a connection to a Splunk indexer.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSplunk = {
  Splunk: "splunk",
} as const;
export type OutputTypeSplunk = ClosedEnum<typeof OutputTypeSplunk>;

/**
 * How to serialize nested fields into index-time fields
 */
export const NestedFieldSerializationSplunk = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * How to serialize nested fields into index-time fields
 */
export type NestedFieldSerializationSplunk = OpenEnum<
  typeof NestedFieldSerializationSplunk
>;

export const OutputMinimumTLSVersionSplunk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMinimumTLSVersionSplunk = OpenEnum<
  typeof OutputMinimumTLSVersionSplunk
>;

export const OutputMaximumTLSVersionSplunk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type OutputMaximumTLSVersionSplunk = OpenEnum<
  typeof OutputMaximumTLSVersionSplunk
>;

export type TLSSettingsClientSideSplunk = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: OutputMinimumTLSVersionSplunk | undefined;
  maxVersion?: OutputMaximumTLSVersionSplunk | undefined;
};

/**
 * The highest S2S protocol version to advertise during handshake
 */
export const OutputMaxS2SVersionSplunk = {
  V3: "v3",
  V4: "v4",
} as const;
/**
 * The highest S2S protocol version to advertise during handshake
 */
export type OutputMaxS2SVersionSplunk = OpenEnum<
  typeof OutputMaxS2SVersionSplunk
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSplunk = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSplunk = OpenEnum<
  typeof BackpressureBehaviorSplunk
>;

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodSplunk = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodSplunk = OpenEnum<
  typeof AuthenticationMethodSplunk
>;

/**
 * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
 */
export const OutputCompressCompressionSplunk = {
  /**
   * Disabled
   */
  Disabled: "disabled",
  /**
   * Automatic
   */
  Auto: "auto",
  /**
   * Always
   */
  Always: "always",
} as const;
/**
 * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
 */
export type OutputCompressCompressionSplunk = OpenEnum<
  typeof OutputCompressCompressionSplunk
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const OutputModeSplunk = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type OutputModeSplunk = OpenEnum<typeof OutputModeSplunk>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressCompressionSplunk = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressCompressionSplunk = OpenEnum<
  typeof PqCompressCompressionSplunk
>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSplunk = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSplunk = OpenEnum<typeof QueueFullBehaviorSplunk>;

export type OutputPqControlsSplunk = {};

export type OutputSplunk = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSplunk;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * How to serialize nested fields into index-time fields
   */
  nestedFields?: NestedFieldSerializationSplunk | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: TLSSettingsClientSideSplunk | undefined;
  /**
   * Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
   */
  enableACK?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * The highest S2S protocol version to advertise during handshake
   */
  maxS2Sversion?: OutputMaxS2SVersionSplunk | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSplunk | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodSplunk | undefined;
  description?: string | undefined;
  /**
   * Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
   */
  maxFailedHealthChecks?: number | undefined;
  /**
   * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
   */
  compress?: OutputCompressCompressionSplunk | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: OutputModeSplunk | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressCompressionSplunk | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSplunk | undefined;
  pqControls?: OutputPqControlsSplunk | undefined;
  /**
   * Shared secret token to use when establishing a connection to a Splunk indexer.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const OutputTypeSyslog = {
  Syslog: "syslog",
} as const;
export type OutputTypeSyslog = ClosedEnum<typeof OutputTypeSyslog>;

/**
 * The network protocol to use for sending out syslog messages
 */
export const ProtocolSyslog = {
  /**
   * TCP
   */
  Tcp: "tcp",
  /**
   * UDP
   */
  Udp: "udp",
} as const;
/**
 * The network protocol to use for sending out syslog messages
 */
export type ProtocolSyslog = OpenEnum<typeof ProtocolSyslog>;

/**
 * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
 */
export const Facility = {
  Zero: 0,
  One: 1,
  Two: 2,
  Three: 3,
  Four: 4,
  Five: 5,
  Six: 6,
  Seven: 7,
  Eight: 8,
  Nine: 9,
  Ten: 10,
  Eleven: 11,
  Twelve: 12,
  Thirteen: 13,
  Fourteen: 14,
  Fifteen: 15,
  Sixteen: 16,
  Seventeen: 17,
  Eighteen: 18,
  Nineteen: 19,
  Twenty: 20,
  TwentyOne: 21,
} as const;
/**
 * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
 */
export type Facility = OpenEnum<typeof Facility>;

/**
 * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
 */
export const SeveritySyslog = {
  /**
   * emergency
   */
  Zero: 0,
  /**
   * alert
   */
  One: 1,
  /**
   * critical
   */
  Two: 2,
  /**
   * error
   */
  Three: 3,
  /**
   * warning
   */
  Four: 4,
  /**
   * notice
   */
  Five: 5,
  /**
   * info
   */
  Six: 6,
  /**
   * debug
   */
  Seven: 7,
} as const;
/**
 * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
 */
export type SeveritySyslog = OpenEnum<typeof SeveritySyslog>;

/**
 * The syslog message format depending on the receiver's support
 */
export const MessageFormatSyslog = {
  /**
   * RFC3164
   */
  Rfc3164: "rfc3164",
  /**
   * RFC5424
   */
  Rfc5424: "rfc5424",
} as const;
/**
 * The syslog message format depending on the receiver's support
 */
export type MessageFormatSyslog = OpenEnum<typeof MessageFormatSyslog>;

/**
 * Timestamp format to use when serializing event's time field
 */
export const TimestampFormat = {
  /**
   * Syslog
   */
  Syslog: "syslog",
  /**
   * ISO8601
   */
  Iso8601: "iso8601",
} as const;
/**
 * Timestamp format to use when serializing event's time field
 */
export type TimestampFormat = OpenEnum<typeof TimestampFormat>;

/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export const TLSSyslog = {
  Inherit: "inherit",
  Off: "off",
} as const;
/**
 * Whether to inherit TLS configs from group setting or disable TLS
 */
export type TLSSyslog = OpenEnum<typeof TLSSyslog>;

export type HostSyslog = {
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port: number;
  /**
   * Whether to inherit TLS configs from group setting or disable TLS
   */
  tls?: TLSSyslog | undefined;
  /**
   * Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
   */
  servername?: string | undefined;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

export const MinimumTLSVersionSyslog = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionSyslog = OpenEnum<typeof MinimumTLSVersionSyslog>;

export const MaximumTLSVersionSyslog = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionSyslog = OpenEnum<typeof MaximumTLSVersionSyslog>;

export type TLSSettingsClientSideSyslog = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: MinimumTLSVersionSyslog | undefined;
  maxVersion?: MaximumTLSVersionSyslog | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSyslog = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSyslog = OpenEnum<
  typeof BackpressureBehaviorSyslog
>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSyslog = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSyslog = OpenEnum<typeof ModeSyslog>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSyslog = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSyslog = OpenEnum<typeof CompressionSyslog>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSyslog = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSyslog = OpenEnum<typeof QueueFullBehaviorSyslog>;

export type PqControlsSyslog = {};

export type OutputSyslog = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputTypeSyslog;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The network protocol to use for sending out syslog messages
   */
  protocol?: ProtocolSyslog | undefined;
  /**
   * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
   */
  facility?: Facility | undefined;
  /**
   * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
   */
  severity?: SeveritySyslog | undefined;
  /**
   * Default name for device or application that originated the message. Defaults to Cribl, but will be overwritten by value of __appname if set.
   */
  appName?: string | undefined;
  /**
   * The syslog message format depending on the receiver's support
   */
  messageFormat?: MessageFormatSyslog | undefined;
  /**
   * Timestamp format to use when serializing event's time field
   */
  timestampFormat?: TimestampFormat | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Prefix messages with the byte count of the message. If disabled, no prefix will be set, and the message will be appended with a \n.
   */
  octetCountFraming?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  description?: string | undefined;
  /**
   * For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs.  If this setting is disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * The hostname of the receiver
   */
  host?: string | undefined;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of hosts to load-balance data to
   */
  hosts?: Array<HostSyslog> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: TLSSettingsClientSideSyslog | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSyslog | undefined;
  /**
   * Maximum size of syslog messages. Make sure this value is less than or equal to the MTU to avoid UDP packet fragmentation.
   */
  maxRecordSize?: number | undefined;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every message sent will incur a DNS lookup.
   */
  udpDnsResolvePeriodSec?: number | undefined;
  /**
   * Send Syslog traffic using the original event's Source IP and port. To enable this, you must install the external `udp-sender` helper binary at `/usr/bin/udp-sender` on all Worker Nodes and grant it the `CAP_NET_RAW` capability.
   */
  enableIpSpoofing?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSyslog | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSyslog | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSyslog | undefined;
  pqControls?: PqControlsSyslog | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDevnull = {
  Devnull: "devnull",
} as const;
export type TypeDevnull = ClosedEnum<typeof TypeDevnull>;

export type OutputDevnull = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDevnull;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSentinel = {
  Sentinel: "sentinel",
} as const;
export type TypeSentinel = ClosedEnum<typeof TypeSentinel>;

export type ExtraHttpHeaderSentinel = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeSentinel = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeSentinel = OpenEnum<
  typeof FailedRequestLoggingModeSentinel
>;

export type ResponseRetrySettingSentinel = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsSentinel = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorSentinel = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorSentinel = OpenEnum<
  typeof BackpressureBehaviorSentinel
>;

export const AuthType = {
  Oauth: "oauth",
} as const;
export type AuthType = OpenEnum<typeof AuthType>;

/**
 * Enter the data collection endpoint URL or the individual ID
 */
export const EndpointConfiguration = {
  /**
   * URL
   */
  Url: "url",
  /**
   * ID
   */
  Id: "ID",
} as const;
/**
 * Enter the data collection endpoint URL or the individual ID
 */
export type EndpointConfiguration = OpenEnum<typeof EndpointConfiguration>;

export const FormatSentinel = {
  Ndjson: "ndjson",
  JsonArray: "json_array",
  Custom: "custom",
  Advanced: "advanced",
} as const;
export type FormatSentinel = OpenEnum<typeof FormatSentinel>;

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeSentinel = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeSentinel = OpenEnum<typeof ModeSentinel>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSentinel = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSentinel = OpenEnum<typeof CompressionSentinel>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorSentinel = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorSentinel = OpenEnum<
  typeof QueueFullBehaviorSentinel
>;

export type PqControlsSentinel = {};

export type OutputSentinel = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeSentinel;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size (KB) of the request body (defaults to the API's maximum limit of 1000 KB)
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderSentinel> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeSentinel | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingSentinel> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSentinel | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorSentinel | undefined;
  authType?: AuthType | undefined;
  /**
   * URL for OAuth
   */
  loginUrl: string;
  /**
   * Secret parameter value to pass in request body
   */
  secret: string;
  /**
   * JavaScript expression to compute the Client ID for the Azure application. Can be a constant.
   */
  clientId: string;
  /**
   * Scope to pass in the OAuth request
   */
  scope?: string | undefined;
  /**
   * Enter the data collection endpoint URL or the individual ID
   */
  endpointURLConfiguration?: EndpointConfiguration | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  format?: FormatSentinel | undefined;
  /**
   * Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
   */
  customSourceExpression?: string | undefined;
  /**
   * Whether to drop events when the source expression evaluates to null
   */
  customDropWhenNull?: boolean | undefined;
  /**
   * Delimiter string to insert between individual events. Defaults to newline character.
   */
  customEventDelimiter?: string | undefined;
  /**
   * Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
   */
  customContentType?: string | undefined;
  /**
   * Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
   */
  customPayloadExpression?: string | undefined;
  /**
   * HTTP content-type header value
   */
  advancedContentType?: string | undefined;
  /**
   * Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatEventCode?: string | undefined;
  /**
   * Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatPayloadCode?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeSentinel | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionSentinel | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorSentinel | undefined;
  pqControls?: PqControlsSentinel | undefined;
  /**
   * URL to send events to. Can be overwritten by an event's __url field.
   */
  url?: string | undefined;
  /**
   * Immutable ID for the Data Collection Rule (DCR)
   */
  dcrID?: string | undefined;
  /**
   * Data collection endpoint (DCE) URL. In the format: `https://<Endpoint-Name>-<Identifier>.<Region>.ingest.monitor.azure.com`
   */
  dceEndpoint?: string | undefined;
  /**
   * The name of the stream (Sentinel table) in which to store the events
   */
  streamName?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWebhook = {
  Webhook: "webhook",
} as const;
export type TypeWebhook = ClosedEnum<typeof TypeWebhook>;

/**
 * The method to use when sending events
 */
export const MethodWebhook = {
  Post: "POST",
  Put: "PUT",
  Patch: "PATCH",
} as const;
/**
 * The method to use when sending events
 */
export type MethodWebhook = OpenEnum<typeof MethodWebhook>;

/**
 * How to format events before sending out
 */
export const FormatWebhook = {
  /**
   * NDJSON (Newline Delimited JSON)
   */
  Ndjson: "ndjson",
  /**
   * JSON Array
   */
  JsonArray: "json_array",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Advanced
   */
  Advanced: "advanced",
} as const;
/**
 * How to format events before sending out
 */
export type FormatWebhook = OpenEnum<typeof FormatWebhook>;

export type ExtraHttpHeaderWebhook = {
  name?: string | undefined;
  value: string;
};

/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export const FailedRequestLoggingModeWebhook = {
  /**
   * Payload
   */
  Payload: "payload",
  /**
   * Payload + Headers
   */
  PayloadAndHeaders: "payloadAndHeaders",
  /**
   * None
   */
  None: "none",
} as const;
/**
 * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
 */
export type FailedRequestLoggingModeWebhook = OpenEnum<
  typeof FailedRequestLoggingModeWebhook
>;

export type ResponseRetrySettingWebhook = {
  /**
   * The HTTP response status code that will trigger retries
   */
  httpStatus: number;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

export type TimeoutRetrySettingsWebhook = {
  timeoutRetry?: boolean | undefined;
  /**
   * How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
   */
  backoffRate?: number | undefined;
  /**
   * The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackoff?: number | undefined;
};

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const BackpressureBehaviorWebhook = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
  /**
   * Persistent Queue
   */
  Queue: "queue",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type BackpressureBehaviorWebhook = OpenEnum<
  typeof BackpressureBehaviorWebhook
>;

/**
 * Authentication method to use for the HTTP request
 */
export const AuthenticationTypeWebhook = {
  /**
   * None
   */
  None: "none",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
  /**
   * Token
   */
  Token: "token",
  /**
   * Token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * OAuth
   */
  Oauth: "oauth",
} as const;
/**
 * Authentication method to use for the HTTP request
 */
export type AuthenticationTypeWebhook = OpenEnum<
  typeof AuthenticationTypeWebhook
>;

export const MinimumTLSVersionWebhook = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionWebhook = OpenEnum<
  typeof MinimumTLSVersionWebhook
>;

export const MaximumTLSVersionWebhook = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionWebhook = OpenEnum<
  typeof MaximumTLSVersionWebhook
>;

export type TLSSettingsClientSideWebhook = {
  disabled?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: MinimumTLSVersionWebhook | undefined;
  maxVersion?: MaximumTLSVersionWebhook | undefined;
};

/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export const ModeWebhook = {
  /**
   * Error
   */
  Error: "error",
  /**
   * Backpressure
   */
  Always: "always",
  /**
   * Always On
   */
  Backpressure: "backpressure",
} as const;
/**
 * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
 */
export type ModeWebhook = OpenEnum<typeof ModeWebhook>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWebhook = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWebhook = OpenEnum<typeof CompressionWebhook>;

/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export const QueueFullBehaviorWebhook = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop new data
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
 */
export type QueueFullBehaviorWebhook = OpenEnum<
  typeof QueueFullBehaviorWebhook
>;

export type PqControlsWebhook = {};

export type OauthParamWebhook = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderWebhook = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type UrlWebhook = {
  /**
   * URL of a webhook endpoint to send events to, such as http://localhost:10200
   */
  url: string;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
};

export type OutputWebhook = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeWebhook;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The method to use when sending events
   */
  method?: MethodWebhook | undefined;
  /**
   * How to format events before sending out
   */
  format?: FormatWebhook | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
   */
  extraHttpHeaders?: Array<ExtraHttpHeaderWebhook> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: FailedRequestLoggingModeWebhook | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?: Array<ResponseRetrySettingWebhook> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsWebhook | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorWebhook | undefined;
  /**
   * Authentication method to use for the HTTP request
   */
  authType?: AuthenticationTypeWebhook | undefined;
  tls?: TLSSettingsClientSideWebhook | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  description?: string | undefined;
  /**
   * Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
   */
  customSourceExpression?: string | undefined;
  /**
   * Whether to drop events when the source expression evaluates to null
   */
  customDropWhenNull?: boolean | undefined;
  /**
   * Delimiter string to insert between individual events. Defaults to newline character.
   */
  customEventDelimiter?: string | undefined;
  /**
   * Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
   */
  customContentType?: string | undefined;
  /**
   * Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
   */
  customPayloadExpression?: string | undefined;
  /**
   * HTTP content-type header value
   */
  advancedContentType?: string | undefined;
  /**
   * Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatEventCode?: string | undefined;
  /**
   * Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatPayloadCode?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: ModeWebhook | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: CompressionWebhook | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: QueueFullBehaviorWebhook | undefined;
  pqControls?: PqControlsWebhook | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamWebhook> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderWebhook> | undefined;
  /**
   * URL of a webhook endpoint to send events to, such as http://localhost:10200
   */
  url?: string | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<UrlWebhook> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDefault = {
  Default: "default",
} as const;
export type TypeDefault = ClosedEnum<typeof TypeDefault>;

export type OutputDefault = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeDefault;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the default output. This will be used whenever a nonexistent/deleted output is referenced.
   */
  defaultId: string;
  additionalProperties?: { [k: string]: any } | undefined;
};

export type Output =
  | (OutputAzureDataExplorer & { type: "azure_data_explorer" })
  | (OutputSecurityLake & { type: "security_lake" })
  | (OutputChronicle & { type: "chronicle" })
  | (OutputSentinel & { type: "sentinel" })
  | (OutputGoogleCloudLogging & { type: "google_cloud_logging" })
  | (OutputExabeam & { type: "exabeam" })
  | (OutputMsk & { type: "msk" })
  | (OutputCloudwatch & { type: "cloudwatch" })
  | (OutputClickHouse & { type: "click_house" })
  | (OutputDatabricks & { type: "databricks" })
  | (OutputKinesis & { type: "kinesis" })
  | (OutputAzureEventhub & { type: "azure_eventhub" })
  | (OutputGoogleCloudStorage & { type: "google_cloud_storage" })
  | (OutputKafka & { type: "kafka" })
  | (OutputConfluentCloud & { type: "confluent_cloud" })
  | (OutputElasticCloud & { type: "elastic_cloud" })
  | (OutputNewrelicEvents & { type: "newrelic_events" })
  | (OutputMinio & { type: "minio" })
  | (OutputSns & { type: "sns" })
  | (OutputSqs & { type: "sqs" })
  | (OutputMicrosoftFabric & { type: "microsoft_fabric" })
  | (OutputCloudflareR2 & { type: "cloudflare_r2" })
  | (OutputDefault & { type: "default" })
  | (OutputSplunk & { type: "splunk" })
  | (OutputSplunkLb & { type: "splunk_lb" })
  | (OutputFilesystem & { type: "filesystem" })
  | (OutputS3 & { type: "s3" })
  | (OutputAzureBlob & { type: "azure_blob" })
  | (OutputHoneycomb & { type: "honeycomb" })
  | (OutputGooglePubsub & { type: "google_pubsub" })
  | (OutputElastic & { type: "elastic" })
  | (OutputInfluxdb & { type: "influxdb" })
  | (OutputStatsd & { type: "statsd" })
  | (OutputStatsdExt & { type: "statsd_ext" })
  | (OutputGraphite & { type: "graphite" })
  | (OutputRouter & { type: "router" })
  | (OutputSnmp & { type: "snmp" })
  | (OutputSumoLogic & { type: "sumo_logic" })
  | (OutputLoki & { type: "loki" })
  | (OutputPrometheus & { type: "prometheus" })
  | (OutputOpenTelemetry & { type: "open_telemetry" })
  | (OutputServiceNow & { type: "service_now" })
  | (OutputCrowdstrikeNextGenSiem & { type: "crowdstrike_next_gen_siem" })
  | (OutputDlS3 & { type: "dl_s3" })
  | (OutputNetflow & { type: "netflow" })
  | (OutputDynatraceOtlp & { type: "dynatrace_otlp" })
  | (OutputWebhook & { type: "webhook" })
  | (OutputDevnull & { type: "devnull" })
  | (OutputSyslog & { type: "syslog" })
  | (OutputSplunkHec & { type: "splunk_hec" })
  | (OutputTcpjson & { type: "tcpjson" })
  | (OutputWavefront & { type: "wavefront" })
  | (OutputSignalfx & { type: "signalfx" })
  | (OutputAzureLogs & { type: "azure_logs" })
  | (OutputGoogleChronicle & { type: "google_chronicle" })
  | (OutputNewrelic & { type: "newrelic" })
  | (OutputDatadog & { type: "datadog" })
  | (OutputRing & { type: "ring" })
  | (OutputDataset & { type: "dataset" })
  | (OutputCriblTcp & { type: "cribl_tcp" })
  | (OutputCriblHttp & { type: "cribl_http" })
  | (OutputHumioHec & { type: "humio_hec" })
  | (OutputCriblLake & { type: "cribl_lake" })
  | (OutputDiskSpool & { type: "disk_spool" })
  | (OutputXsiam & { type: "xsiam" })
  | (OutputDynatraceHttp & { type: "dynatrace_http" })
  | (OutputSentinelOneAiSiem & { type: "sentinel_one_ai_siem" })
  | (
    | OutputGrafanaCloudGrafanaCloud1
    | OutputGrafanaCloudGrafanaCloud2 & { type: "grafana_cloud" }
  );

/** @internal */
export const TypeCloudflareR2$inboundSchema: z.ZodNativeEnum<
  typeof TypeCloudflareR2
> = z.nativeEnum(TypeCloudflareR2);
/** @internal */
export const TypeCloudflareR2$outboundSchema: z.ZodNativeEnum<
  typeof TypeCloudflareR2
> = TypeCloudflareR2$inboundSchema;

/** @internal */
export const AuthenticationMethodCloudflareR2$inboundSchema: z.ZodType<
  AuthenticationMethodCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodCloudflareR2$outboundSchema: z.ZodType<
  AuthenticationMethodCloudflareR2,
  z.ZodTypeDef,
  AuthenticationMethodCloudflareR2
> = z.union([
  z.nativeEnum(AuthenticationMethodCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionCloudflareR2$inboundSchema: z.ZodType<
  SignatureVersionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionCloudflareR2$outboundSchema: z.ZodType<
  SignatureVersionCloudflareR2,
  z.ZodTypeDef,
  SignatureVersionCloudflareR2
> = z.union([
  z.nativeEnum(SignatureVersionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassCloudflareR2$inboundSchema: z.ZodType<
  StorageClassCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassCloudflareR2$outboundSchema: z.ZodType<
  StorageClassCloudflareR2,
  z.ZodTypeDef,
  StorageClassCloudflareR2
> = z.union([
  z.nativeEnum(StorageClassCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionCloudflareR2$inboundSchema: z.ZodType<
  ServerSideEncryptionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ServerSideEncryptionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ServerSideEncryptionCloudflareR2$outboundSchema: z.ZodType<
  ServerSideEncryptionCloudflareR2,
  z.ZodTypeDef,
  ServerSideEncryptionCloudflareR2
> = z.union([
  z.nativeEnum(ServerSideEncryptionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataFormatCloudflareR2$inboundSchema: z.ZodType<
  DataFormatCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatCloudflareR2$outboundSchema: z.ZodType<
  DataFormatCloudflareR2,
  z.ZodTypeDef,
  DataFormatCloudflareR2
> = z.union([
  z.nativeEnum(DataFormatCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorCloudflareR2$inboundSchema: z.ZodType<
  BackpressureBehaviorCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorCloudflareR2$outboundSchema: z.ZodType<
  BackpressureBehaviorCloudflareR2,
  z.ZodTypeDef,
  BackpressureBehaviorCloudflareR2
> = z.union([
  z.nativeEnum(BackpressureBehaviorCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionCloudflareR2$inboundSchema: z.ZodType<
  DiskSpaceProtectionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionCloudflareR2$outboundSchema: z.ZodType<
  DiskSpaceProtectionCloudflareR2,
  z.ZodTypeDef,
  DiskSpaceProtectionCloudflareR2
> = z.union([
  z.nativeEnum(DiskSpaceProtectionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCloudflareR2$inboundSchema: z.ZodType<
  CompressionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCloudflareR2$outboundSchema: z.ZodType<
  CompressionCloudflareR2,
  z.ZodTypeDef,
  CompressionCloudflareR2
> = z.union([
  z.nativeEnum(CompressionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelCloudflareR2$inboundSchema: z.ZodType<
  CompressionLevelCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelCloudflareR2$outboundSchema: z.ZodType<
  CompressionLevelCloudflareR2,
  z.ZodTypeDef,
  CompressionLevelCloudflareR2
> = z.union([
  z.nativeEnum(CompressionLevelCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionCloudflareR2$inboundSchema: z.ZodType<
  ParquetVersionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionCloudflareR2$outboundSchema: z.ZodType<
  ParquetVersionCloudflareR2,
  z.ZodTypeDef,
  ParquetVersionCloudflareR2
> = z.union([
  z.nativeEnum(ParquetVersionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionCloudflareR2$inboundSchema: z.ZodType<
  DataPageVersionCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionCloudflareR2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionCloudflareR2$outboundSchema: z.ZodType<
  DataPageVersionCloudflareR2,
  z.ZodTypeDef,
  DataPageVersionCloudflareR2
> = z.union([
  z.nativeEnum(DataPageVersionCloudflareR2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumCloudflareR2$inboundSchema: z.ZodType<
  KeyValueMetadatumCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumCloudflareR2$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumCloudflareR2$outboundSchema: z.ZodType<
  KeyValueMetadatumCloudflareR2$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumCloudflareR2
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumCloudflareR2ToJSON(
  keyValueMetadatumCloudflareR2: KeyValueMetadatumCloudflareR2,
): string {
  return JSON.stringify(
    KeyValueMetadatumCloudflareR2$outboundSchema.parse(
      keyValueMetadatumCloudflareR2,
    ),
  );
}
export function keyValueMetadatumCloudflareR2FromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumCloudflareR2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumCloudflareR2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumCloudflareR2' from JSON`,
  );
}

/** @internal */
export const OutputCloudflareR2$inboundSchema: z.ZodType<
  OutputCloudflareR2,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCloudflareR2$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    endpoint: z.string(),
    bucket: z.string(),
    awsAuthenticationMethod: AuthenticationMethodCloudflareR2$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.any().optional(),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    destPath: z.string().optional(),
    signatureVersion: SignatureVersionCloudflareR2$inboundSchema.default("v4"),
    objectACL: z.any().optional(),
    storageClass: StorageClassCloudflareR2$inboundSchema.optional(),
    serverSideEncryption: ServerSideEncryptionCloudflareR2$inboundSchema
      .optional(),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    verifyPermissions: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatCloudflareR2$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorCloudflareR2$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionCloudflareR2$inboundSchema
      .default("block"),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxConcurrentFileParts: z.number().default(4),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    compress: CompressionCloudflareR2$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelCloudflareR2$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionCloudflareR2$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionCloudflareR2$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumCloudflareR2$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCloudflareR2$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  endpoint: string;
  bucket: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: any | undefined;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath?: string | undefined;
  signatureVersion: string;
  objectACL?: any | undefined;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  verifyPermissions: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumCloudflareR2$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCloudflareR2$outboundSchema: z.ZodType<
  OutputCloudflareR2$Outbound,
  z.ZodTypeDef,
  OutputCloudflareR2
> = z.object({
  id: z.string().optional(),
  type: TypeCloudflareR2$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  endpoint: z.string(),
  bucket: z.string(),
  awsAuthenticationMethod: AuthenticationMethodCloudflareR2$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.any().optional(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().optional(),
  signatureVersion: SignatureVersionCloudflareR2$outboundSchema.default("v4"),
  objectACL: z.any().optional(),
  storageClass: StorageClassCloudflareR2$outboundSchema.optional(),
  serverSideEncryption: ServerSideEncryptionCloudflareR2$outboundSchema
    .optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  verifyPermissions: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatCloudflareR2$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorCloudflareR2$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionCloudflareR2$outboundSchema
    .default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: CompressionCloudflareR2$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelCloudflareR2$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionCloudflareR2$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionCloudflareR2$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumCloudflareR2$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCloudflareR2ToJSON(
  outputCloudflareR2: OutputCloudflareR2,
): string {
  return JSON.stringify(
    OutputCloudflareR2$outboundSchema.parse(outputCloudflareR2),
  );
}
export function outputCloudflareR2FromJSON(
  jsonString: string,
): SafeParseResult<OutputCloudflareR2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCloudflareR2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCloudflareR2' from JSON`,
  );
}

/** @internal */
export const TypeMicrosoftFabric$inboundSchema: z.ZodNativeEnum<
  typeof TypeMicrosoftFabric
> = z.nativeEnum(TypeMicrosoftFabric);
/** @internal */
export const TypeMicrosoftFabric$outboundSchema: z.ZodNativeEnum<
  typeof TypeMicrosoftFabric
> = TypeMicrosoftFabric$inboundSchema;

/** @internal */
export const AcknowledgmentsMicrosoftFabric$inboundSchema: z.ZodType<
  AcknowledgmentsMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AcknowledgmentsMicrosoftFabric),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AcknowledgmentsMicrosoftFabric$outboundSchema: z.ZodType<
  AcknowledgmentsMicrosoftFabric,
  z.ZodTypeDef,
  AcknowledgmentsMicrosoftFabric
> = z.union([
  z.nativeEnum(AcknowledgmentsMicrosoftFabric),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const RecordDataFormatMicrosoftFabric$inboundSchema: z.ZodType<
  RecordDataFormatMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordDataFormatMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordDataFormatMicrosoftFabric$outboundSchema: z.ZodType<
  RecordDataFormatMicrosoftFabric,
  z.ZodTypeDef,
  RecordDataFormatMicrosoftFabric
> = z.union([
  z.nativeEnum(RecordDataFormatMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SASLMechanismMicrosoftFabric$inboundSchema: z.ZodType<
  SASLMechanismMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SASLMechanismMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SASLMechanismMicrosoftFabric$outboundSchema: z.ZodType<
  SASLMechanismMicrosoftFabric,
  z.ZodTypeDef,
  SASLMechanismMicrosoftFabric
> = z.union([
  z.nativeEnum(SASLMechanismMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodMicrosoftFabric$inboundSchema: z.ZodType<
  AuthenticationMethodMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodMicrosoftFabric$outboundSchema: z.ZodType<
  AuthenticationMethodMicrosoftFabric,
  z.ZodTypeDef,
  AuthenticationMethodMicrosoftFabric
> = z.union([
  z.nativeEnum(AuthenticationMethodMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric$inboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric$outboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric,
    z.ZodTypeDef,
    MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric
  > = z.union([
    z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const AuthenticationMicrosoftFabric$inboundSchema: z.ZodType<
  AuthenticationMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  mechanism: SASLMechanismMicrosoftFabric$inboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  textSecret: z.string().optional(),
  clientSecretAuthType: AuthenticationMethodMicrosoftFabric$inboundSchema
    .default("secret"),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint:
    MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric$inboundSchema.default(
      "https://login.microsoftonline.com",
    ),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});
/** @internal */
export type AuthenticationMicrosoftFabric$Outbound = {
  disabled: boolean;
  mechanism: string;
  username: string;
  textSecret?: string | undefined;
  clientSecretAuthType: string;
  clientTextSecret?: string | undefined;
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  oauthEndpoint: string;
  clientId?: string | undefined;
  tenantId?: string | undefined;
  scope?: string | undefined;
};

/** @internal */
export const AuthenticationMicrosoftFabric$outboundSchema: z.ZodType<
  AuthenticationMicrosoftFabric$Outbound,
  z.ZodTypeDef,
  AuthenticationMicrosoftFabric
> = z.object({
  disabled: z.boolean().default(false),
  mechanism: SASLMechanismMicrosoftFabric$outboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  textSecret: z.string().optional(),
  clientSecretAuthType: AuthenticationMethodMicrosoftFabric$outboundSchema
    .default("secret"),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint:
    MicrosoftEntraIDAuthenticationEndpointMicrosoftFabric$outboundSchema
      .default("https://login.microsoftonline.com"),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});

export function authenticationMicrosoftFabricToJSON(
  authenticationMicrosoftFabric: AuthenticationMicrosoftFabric,
): string {
  return JSON.stringify(
    AuthenticationMicrosoftFabric$outboundSchema.parse(
      authenticationMicrosoftFabric,
    ),
  );
}
export function authenticationMicrosoftFabricFromJSON(
  jsonString: string,
): SafeParseResult<AuthenticationMicrosoftFabric, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthenticationMicrosoftFabric$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthenticationMicrosoftFabric' from JSON`,
  );
}

/** @internal */
export const TLSSettingsClientSideMicrosoftFabric$inboundSchema: z.ZodType<
  TLSSettingsClientSideMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});
/** @internal */
export type TLSSettingsClientSideMicrosoftFabric$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
};

/** @internal */
export const TLSSettingsClientSideMicrosoftFabric$outboundSchema: z.ZodType<
  TLSSettingsClientSideMicrosoftFabric$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideMicrosoftFabric
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});

export function tlsSettingsClientSideMicrosoftFabricToJSON(
  tlsSettingsClientSideMicrosoftFabric: TLSSettingsClientSideMicrosoftFabric,
): string {
  return JSON.stringify(
    TLSSettingsClientSideMicrosoftFabric$outboundSchema.parse(
      tlsSettingsClientSideMicrosoftFabric,
    ),
  );
}
export function tlsSettingsClientSideMicrosoftFabricFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideMicrosoftFabric, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsClientSideMicrosoftFabric$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideMicrosoftFabric' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorMicrosoftFabric$inboundSchema: z.ZodType<
  BackpressureBehaviorMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorMicrosoftFabric$outboundSchema: z.ZodType<
  BackpressureBehaviorMicrosoftFabric,
  z.ZodTypeDef,
  BackpressureBehaviorMicrosoftFabric
> = z.union([
  z.nativeEnum(BackpressureBehaviorMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeMicrosoftFabric$inboundSchema: z.ZodType<
  ModeMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeMicrosoftFabric$outboundSchema: z.ZodType<
  ModeMicrosoftFabric,
  z.ZodTypeDef,
  ModeMicrosoftFabric
> = z.union([
  z.nativeEnum(ModeMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionMicrosoftFabric$inboundSchema: z.ZodType<
  CompressionMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionMicrosoftFabric$outboundSchema: z.ZodType<
  CompressionMicrosoftFabric,
  z.ZodTypeDef,
  CompressionMicrosoftFabric
> = z.union([
  z.nativeEnum(CompressionMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorMicrosoftFabric$inboundSchema: z.ZodType<
  QueueFullBehaviorMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorMicrosoftFabric),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorMicrosoftFabric$outboundSchema: z.ZodType<
  QueueFullBehaviorMicrosoftFabric,
  z.ZodTypeDef,
  QueueFullBehaviorMicrosoftFabric
> = z.union([
  z.nativeEnum(QueueFullBehaviorMicrosoftFabric),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsMicrosoftFabric$inboundSchema: z.ZodType<
  PqControlsMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsMicrosoftFabric$Outbound = {};

/** @internal */
export const PqControlsMicrosoftFabric$outboundSchema: z.ZodType<
  PqControlsMicrosoftFabric$Outbound,
  z.ZodTypeDef,
  PqControlsMicrosoftFabric
> = z.object({});

export function pqControlsMicrosoftFabricToJSON(
  pqControlsMicrosoftFabric: PqControlsMicrosoftFabric,
): string {
  return JSON.stringify(
    PqControlsMicrosoftFabric$outboundSchema.parse(pqControlsMicrosoftFabric),
  );
}
export function pqControlsMicrosoftFabricFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsMicrosoftFabric, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsMicrosoftFabric$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsMicrosoftFabric' from JSON`,
  );
}

/** @internal */
export const OutputMicrosoftFabric$inboundSchema: z.ZodType<
  OutputMicrosoftFabric,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeMicrosoftFabric$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    topic: z.string(),
    ack: AcknowledgmentsMicrosoftFabric$inboundSchema.default(1),
    format: RecordDataFormatMicrosoftFabric$inboundSchema.default("json"),
    maxRecordSizeKB: z.number().default(768),
    flushEventCount: z.number().default(1000),
    flushPeriodSec: z.number().default(1),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => AuthenticationMicrosoftFabric$inboundSchema).optional(),
    tls: z.lazy(() => TLSSettingsClientSideMicrosoftFabric$inboundSchema)
      .optional(),
    onBackpressure: BackpressureBehaviorMicrosoftFabric$inboundSchema.default(
      "block",
    ),
    bootstrap_server: z.string(),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeMicrosoftFabric$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionMicrosoftFabric$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorMicrosoftFabric$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsMicrosoftFabric$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
).transform((v) => {
  return remap$(v, {
    "bootstrap_server": "bootstrapServer",
  });
});
/** @internal */
export type OutputMicrosoftFabric$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topic: string;
  ack: number;
  format: string;
  maxRecordSizeKB: number;
  flushEventCount: number;
  flushPeriodSec: number;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: AuthenticationMicrosoftFabric$Outbound | undefined;
  tls?: TLSSettingsClientSideMicrosoftFabric$Outbound | undefined;
  onBackpressure: string;
  bootstrap_server: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsMicrosoftFabric$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputMicrosoftFabric$outboundSchema: z.ZodType<
  OutputMicrosoftFabric$Outbound,
  z.ZodTypeDef,
  OutputMicrosoftFabric
> = z.object({
  id: z.string().optional(),
  type: TypeMicrosoftFabric$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topic: z.string(),
  ack: AcknowledgmentsMicrosoftFabric$outboundSchema.default(1),
  format: RecordDataFormatMicrosoftFabric$outboundSchema.default("json"),
  maxRecordSizeKB: z.number().default(768),
  flushEventCount: z.number().default(1000),
  flushPeriodSec: z.number().default(1),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => AuthenticationMicrosoftFabric$outboundSchema).optional(),
  tls: z.lazy(() => TLSSettingsClientSideMicrosoftFabric$outboundSchema)
    .optional(),
  onBackpressure: BackpressureBehaviorMicrosoftFabric$outboundSchema.default(
    "block",
  ),
  bootstrapServer: z.string(),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeMicrosoftFabric$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionMicrosoftFabric$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorMicrosoftFabric$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsMicrosoftFabric$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      bootstrapServer: "bootstrap_server",
      additionalProperties: null,
    }),
  };
});

export function outputMicrosoftFabricToJSON(
  outputMicrosoftFabric: OutputMicrosoftFabric,
): string {
  return JSON.stringify(
    OutputMicrosoftFabric$outboundSchema.parse(outputMicrosoftFabric),
  );
}
export function outputMicrosoftFabricFromJSON(
  jsonString: string,
): SafeParseResult<OutputMicrosoftFabric, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputMicrosoftFabric$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputMicrosoftFabric' from JSON`,
  );
}

/** @internal */
export const TypeDatabricks$inboundSchema: z.ZodNativeEnum<
  typeof TypeDatabricks
> = z.nativeEnum(TypeDatabricks);
/** @internal */
export const TypeDatabricks$outboundSchema: z.ZodNativeEnum<
  typeof TypeDatabricks
> = TypeDatabricks$inboundSchema;

/** @internal */
export const DataFormatDatabricks$inboundSchema: z.ZodType<
  DataFormatDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatDatabricks$outboundSchema: z.ZodType<
  DataFormatDatabricks,
  z.ZodTypeDef,
  DataFormatDatabricks
> = z.union([
  z.nativeEnum(DataFormatDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorDatabricks$inboundSchema: z.ZodType<
  BackpressureBehaviorDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDatabricks$outboundSchema: z.ZodType<
  BackpressureBehaviorDatabricks,
  z.ZodTypeDef,
  BackpressureBehaviorDatabricks
> = z.union([
  z.nativeEnum(BackpressureBehaviorDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionDatabricks$inboundSchema: z.ZodType<
  DiskSpaceProtectionDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionDatabricks$outboundSchema: z.ZodType<
  DiskSpaceProtectionDatabricks,
  z.ZodTypeDef,
  DiskSpaceProtectionDatabricks
> = z.union([
  z.nativeEnum(DiskSpaceProtectionDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDatabricks$inboundSchema: z.ZodType<
  CompressionDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDatabricks$outboundSchema: z.ZodType<
  CompressionDatabricks,
  z.ZodTypeDef,
  CompressionDatabricks
> = z.union([
  z.nativeEnum(CompressionDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelDatabricks$inboundSchema: z.ZodType<
  CompressionLevelDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelDatabricks$outboundSchema: z.ZodType<
  CompressionLevelDatabricks,
  z.ZodTypeDef,
  CompressionLevelDatabricks
> = z.union([
  z.nativeEnum(CompressionLevelDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionDatabricks$inboundSchema: z.ZodType<
  ParquetVersionDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionDatabricks$outboundSchema: z.ZodType<
  ParquetVersionDatabricks,
  z.ZodTypeDef,
  ParquetVersionDatabricks
> = z.union([
  z.nativeEnum(ParquetVersionDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionDatabricks$inboundSchema: z.ZodType<
  DataPageVersionDatabricks,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionDatabricks),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionDatabricks$outboundSchema: z.ZodType<
  DataPageVersionDatabricks,
  z.ZodTypeDef,
  DataPageVersionDatabricks
> = z.union([
  z.nativeEnum(DataPageVersionDatabricks),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumDatabricks$inboundSchema: z.ZodType<
  KeyValueMetadatumDatabricks,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumDatabricks$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumDatabricks$outboundSchema: z.ZodType<
  KeyValueMetadatumDatabricks$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumDatabricks
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumDatabricksToJSON(
  keyValueMetadatumDatabricks: KeyValueMetadatumDatabricks,
): string {
  return JSON.stringify(
    KeyValueMetadatumDatabricks$outboundSchema.parse(
      keyValueMetadatumDatabricks,
    ),
  );
}
export function keyValueMetadatumDatabricksFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumDatabricks, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumDatabricks$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumDatabricks' from JSON`,
  );
}

/** @internal */
export const OutputDatabricks$inboundSchema: z.ZodType<
  OutputDatabricks,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDatabricks$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    destPath: z.string().default(""),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatDatabricks$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorDatabricks$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionDatabricks$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    workspaceId: z.string(),
    scope: z.string().default("all-apis"),
    clientId: z.string(),
    catalog: z.string().default("main"),
    schema: z.string().default("external"),
    eventsVolumeName: z.string().default("events"),
    clientTextSecret: z.string(),
    timeoutSec: z.number().default(60),
    description: z.string().optional(),
    compress: CompressionDatabricks$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelDatabricks$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionDatabricks$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionDatabricks$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumDatabricks$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDatabricks$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  destPath: string;
  stagePath: string;
  addIdToStagePath: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  workspaceId: string;
  scope: string;
  clientId: string;
  catalog: string;
  schema: string;
  eventsVolumeName: string;
  clientTextSecret: string;
  timeoutSec: number;
  description?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumDatabricks$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDatabricks$outboundSchema: z.ZodType<
  OutputDatabricks$Outbound,
  z.ZodTypeDef,
  OutputDatabricks
> = z.object({
  id: z.string().optional(),
  type: TypeDatabricks$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  destPath: z.string().default(""),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatDatabricks$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorDatabricks$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionDatabricks$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  workspaceId: z.string(),
  scope: z.string().default("all-apis"),
  clientId: z.string(),
  catalog: z.string().default("main"),
  schema: z.string().default("external"),
  eventsVolumeName: z.string().default("events"),
  clientTextSecret: z.string(),
  timeoutSec: z.number().default(60),
  description: z.string().optional(),
  compress: CompressionDatabricks$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelDatabricks$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionDatabricks$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionDatabricks$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumDatabricks$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDatabricksToJSON(
  outputDatabricks: OutputDatabricks,
): string {
  return JSON.stringify(
    OutputDatabricks$outboundSchema.parse(outputDatabricks),
  );
}
export function outputDatabricksFromJSON(
  jsonString: string,
): SafeParseResult<OutputDatabricks, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDatabricks$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDatabricks' from JSON`,
  );
}

/** @internal */
export const TypeChronicle$inboundSchema: z.ZodNativeEnum<
  typeof TypeChronicle
> = z.nativeEnum(TypeChronicle);
/** @internal */
export const TypeChronicle$outboundSchema: z.ZodNativeEnum<
  typeof TypeChronicle
> = TypeChronicle$inboundSchema;

/** @internal */
export const AuthenticationMethodChronicle$inboundSchema: z.ZodType<
  AuthenticationMethodChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodChronicle$outboundSchema: z.ZodType<
  AuthenticationMethodChronicle,
  z.ZodTypeDef,
  AuthenticationMethodChronicle
> = z.union([
  z.nativeEnum(AuthenticationMethodChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingChronicle$inboundSchema: z.ZodType<
  ResponseRetrySettingChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingChronicle$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingChronicle$outboundSchema: z.ZodType<
  ResponseRetrySettingChronicle$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingChronicle
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingChronicleToJSON(
  responseRetrySettingChronicle: ResponseRetrySettingChronicle,
): string {
  return JSON.stringify(
    ResponseRetrySettingChronicle$outboundSchema.parse(
      responseRetrySettingChronicle,
    ),
  );
}
export function responseRetrySettingChronicleFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingChronicle' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsChronicle$inboundSchema: z.ZodType<
  TimeoutRetrySettingsChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsChronicle$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsChronicle$outboundSchema: z.ZodType<
  TimeoutRetrySettingsChronicle$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsChronicle
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsChronicleToJSON(
  timeoutRetrySettingsChronicle: TimeoutRetrySettingsChronicle,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsChronicle$outboundSchema.parse(
      timeoutRetrySettingsChronicle,
    ),
  );
}
export function timeoutRetrySettingsChronicleFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsChronicle' from JSON`,
  );
}

/** @internal */
export const ExtraHttpHeaderChronicle$inboundSchema: z.ZodType<
  ExtraHttpHeaderChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderChronicle$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderChronicle$outboundSchema: z.ZodType<
  ExtraHttpHeaderChronicle$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderChronicle
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderChronicleToJSON(
  extraHttpHeaderChronicle: ExtraHttpHeaderChronicle,
): string {
  return JSON.stringify(
    ExtraHttpHeaderChronicle$outboundSchema.parse(extraHttpHeaderChronicle),
  );
}
export function extraHttpHeaderChronicleFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderChronicle' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeChronicle$inboundSchema: z.ZodType<
  FailedRequestLoggingModeChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeChronicle$outboundSchema: z.ZodType<
  FailedRequestLoggingModeChronicle,
  z.ZodTypeDef,
  FailedRequestLoggingModeChronicle
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorChronicle$inboundSchema: z.ZodType<
  BackpressureBehaviorChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorChronicle$outboundSchema: z.ZodType<
  BackpressureBehaviorChronicle,
  z.ZodTypeDef,
  BackpressureBehaviorChronicle
> = z.union([
  z.nativeEnum(BackpressureBehaviorChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CustomLabelChronicle$inboundSchema: z.ZodType<
  CustomLabelChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string(),
  value: z.string(),
  rbacEnabled: z.boolean().default(false),
});
/** @internal */
export type CustomLabelChronicle$Outbound = {
  key: string;
  value: string;
  rbacEnabled: boolean;
};

/** @internal */
export const CustomLabelChronicle$outboundSchema: z.ZodType<
  CustomLabelChronicle$Outbound,
  z.ZodTypeDef,
  CustomLabelChronicle
> = z.object({
  key: z.string(),
  value: z.string(),
  rbacEnabled: z.boolean().default(false),
});

export function customLabelChronicleToJSON(
  customLabelChronicle: CustomLabelChronicle,
): string {
  return JSON.stringify(
    CustomLabelChronicle$outboundSchema.parse(customLabelChronicle),
  );
}
export function customLabelChronicleFromJSON(
  jsonString: string,
): SafeParseResult<CustomLabelChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CustomLabelChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CustomLabelChronicle' from JSON`,
  );
}

/** @internal */
export const ModeChronicle$inboundSchema: z.ZodType<
  ModeChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeChronicle$outboundSchema: z.ZodType<
  ModeChronicle,
  z.ZodTypeDef,
  ModeChronicle
> = z.union([
  z.nativeEnum(ModeChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionChronicle$inboundSchema: z.ZodType<
  CompressionChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionChronicle$outboundSchema: z.ZodType<
  CompressionChronicle,
  z.ZodTypeDef,
  CompressionChronicle
> = z.union([
  z.nativeEnum(CompressionChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorChronicle$inboundSchema: z.ZodType<
  QueueFullBehaviorChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorChronicle$outboundSchema: z.ZodType<
  QueueFullBehaviorChronicle,
  z.ZodTypeDef,
  QueueFullBehaviorChronicle
> = z.union([
  z.nativeEnum(QueueFullBehaviorChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsChronicle$inboundSchema: z.ZodType<
  PqControlsChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsChronicle$Outbound = {};

/** @internal */
export const PqControlsChronicle$outboundSchema: z.ZodType<
  PqControlsChronicle$Outbound,
  z.ZodTypeDef,
  PqControlsChronicle
> = z.object({});

export function pqControlsChronicleToJSON(
  pqControlsChronicle: PqControlsChronicle,
): string {
  return JSON.stringify(
    PqControlsChronicle$outboundSchema.parse(pqControlsChronicle),
  );
}
export function pqControlsChronicleFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsChronicle' from JSON`,
  );
}

/** @internal */
export const OutputChronicle$inboundSchema: z.ZodType<
  OutputChronicle,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeChronicle$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    apiVersion: z.string().default("v1alpha"),
    authenticationMethod: AuthenticationMethodChronicle$inboundSchema.default(
      "serviceAccount",
    ),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingChronicle$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsChronicle$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    region: z.string(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(90),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderChronicle$inboundSchema),
    ).optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeChronicle$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    useRoundRobinDns: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorChronicle$inboundSchema.default(
      "block",
    ),
    totalMemoryLimitKB: z.number().optional(),
    ingestionMethod: z.string().default("ImportLogs"),
    namespace: z.string().optional(),
    logType: z.string(),
    logTextField: z.string().optional(),
    gcpProjectId: z.string(),
    gcpInstance: z.string(),
    customLabels: z.array(z.lazy(() => CustomLabelChronicle$inboundSchema))
      .optional(),
    description: z.string().optional(),
    serviceAccountCredentials: z.string().optional(),
    serviceAccountCredentialsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeChronicle$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionChronicle$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorChronicle$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsChronicle$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputChronicle$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  apiVersion: string;
  authenticationMethod: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingChronicle$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsChronicle$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  region: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderChronicle$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  useRoundRobinDns: boolean;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  ingestionMethod: string;
  namespace?: string | undefined;
  logType: string;
  logTextField?: string | undefined;
  gcpProjectId: string;
  gcpInstance: string;
  customLabels?: Array<CustomLabelChronicle$Outbound> | undefined;
  description?: string | undefined;
  serviceAccountCredentials?: string | undefined;
  serviceAccountCredentialsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsChronicle$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputChronicle$outboundSchema: z.ZodType<
  OutputChronicle$Outbound,
  z.ZodTypeDef,
  OutputChronicle
> = z.object({
  id: z.string().optional(),
  type: TypeChronicle$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  apiVersion: z.string().default("v1alpha"),
  authenticationMethod: AuthenticationMethodChronicle$outboundSchema.default(
    "serviceAccount",
  ),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingChronicle$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsChronicle$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  region: z.string(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(90),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderChronicle$outboundSchema),
  ).optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeChronicle$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  useRoundRobinDns: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorChronicle$outboundSchema.default("block"),
  totalMemoryLimitKB: z.number().optional(),
  ingestionMethod: z.string().default("ImportLogs"),
  namespace: z.string().optional(),
  logType: z.string(),
  logTextField: z.string().optional(),
  gcpProjectId: z.string(),
  gcpInstance: z.string(),
  customLabels: z.array(z.lazy(() => CustomLabelChronicle$outboundSchema))
    .optional(),
  description: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  serviceAccountCredentialsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeChronicle$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionChronicle$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorChronicle$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsChronicle$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputChronicleToJSON(
  outputChronicle: OutputChronicle,
): string {
  return JSON.stringify(OutputChronicle$outboundSchema.parse(outputChronicle));
}
export function outputChronicleFromJSON(
  jsonString: string,
): SafeParseResult<OutputChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputChronicle' from JSON`,
  );
}

/** @internal */
export const TypeSentinelOneAiSiem$inboundSchema: z.ZodNativeEnum<
  typeof TypeSentinelOneAiSiem
> = z.nativeEnum(TypeSentinelOneAiSiem);
/** @internal */
export const TypeSentinelOneAiSiem$outboundSchema: z.ZodNativeEnum<
  typeof TypeSentinelOneAiSiem
> = TypeSentinelOneAiSiem$inboundSchema;

/** @internal */
export const RegionSentinelOneAiSiem$inboundSchema: z.ZodType<
  RegionSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RegionSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RegionSentinelOneAiSiem$outboundSchema: z.ZodType<
  RegionSentinelOneAiSiem,
  z.ZodTypeDef,
  RegionSentinelOneAiSiem
> = z.union([
  z.nativeEnum(RegionSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AISIEMEndpointPath$inboundSchema: z.ZodType<
  AISIEMEndpointPath,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AISIEMEndpointPath),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AISIEMEndpointPath$outboundSchema: z.ZodType<
  AISIEMEndpointPath,
  z.ZodTypeDef,
  AISIEMEndpointPath
> = z.union([
  z.nativeEnum(AISIEMEndpointPath),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderSentinelOneAiSiem$inboundSchema: z.ZodType<
  ExtraHttpHeaderSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderSentinelOneAiSiem$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderSentinelOneAiSiem$outboundSchema: z.ZodType<
  ExtraHttpHeaderSentinelOneAiSiem$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderSentinelOneAiSiem
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderSentinelOneAiSiemToJSON(
  extraHttpHeaderSentinelOneAiSiem: ExtraHttpHeaderSentinelOneAiSiem,
): string {
  return JSON.stringify(
    ExtraHttpHeaderSentinelOneAiSiem$outboundSchema.parse(
      extraHttpHeaderSentinelOneAiSiem,
    ),
  );
}
export function extraHttpHeaderSentinelOneAiSiemFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderSentinelOneAiSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderSentinelOneAiSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderSentinelOneAiSiem' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeSentinelOneAiSiem$inboundSchema: z.ZodType<
  FailedRequestLoggingModeSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeSentinelOneAiSiem$outboundSchema:
  z.ZodType<
    FailedRequestLoggingModeSentinelOneAiSiem,
    z.ZodTypeDef,
    FailedRequestLoggingModeSentinelOneAiSiem
  > = z.union([
    z.nativeEnum(FailedRequestLoggingModeSentinelOneAiSiem),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const AuthenticationMethodSentinelOneAiSiem$inboundSchema: z.ZodType<
  AuthenticationMethodSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodSentinelOneAiSiem$outboundSchema: z.ZodType<
  AuthenticationMethodSentinelOneAiSiem,
  z.ZodTypeDef,
  AuthenticationMethodSentinelOneAiSiem
> = z.union([
  z.nativeEnum(AuthenticationMethodSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingSentinelOneAiSiem$inboundSchema: z.ZodType<
  ResponseRetrySettingSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingSentinelOneAiSiem$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingSentinelOneAiSiem$outboundSchema: z.ZodType<
  ResponseRetrySettingSentinelOneAiSiem$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingSentinelOneAiSiem
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingSentinelOneAiSiemToJSON(
  responseRetrySettingSentinelOneAiSiem: ResponseRetrySettingSentinelOneAiSiem,
): string {
  return JSON.stringify(
    ResponseRetrySettingSentinelOneAiSiem$outboundSchema.parse(
      responseRetrySettingSentinelOneAiSiem,
    ),
  );
}
export function responseRetrySettingSentinelOneAiSiemFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingSentinelOneAiSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      ResponseRetrySettingSentinelOneAiSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingSentinelOneAiSiem' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsSentinelOneAiSiem$inboundSchema: z.ZodType<
  TimeoutRetrySettingsSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsSentinelOneAiSiem$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsSentinelOneAiSiem$outboundSchema: z.ZodType<
  TimeoutRetrySettingsSentinelOneAiSiem$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsSentinelOneAiSiem
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsSentinelOneAiSiemToJSON(
  timeoutRetrySettingsSentinelOneAiSiem: TimeoutRetrySettingsSentinelOneAiSiem,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsSentinelOneAiSiem$outboundSchema.parse(
      timeoutRetrySettingsSentinelOneAiSiem,
    ),
  );
}
export function timeoutRetrySettingsSentinelOneAiSiemFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsSentinelOneAiSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TimeoutRetrySettingsSentinelOneAiSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsSentinelOneAiSiem' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSentinelOneAiSiem$inboundSchema: z.ZodType<
  BackpressureBehaviorSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSentinelOneAiSiem$outboundSchema: z.ZodType<
  BackpressureBehaviorSentinelOneAiSiem,
  z.ZodTypeDef,
  BackpressureBehaviorSentinelOneAiSiem
> = z.union([
  z.nativeEnum(BackpressureBehaviorSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSentinelOneAiSiem$inboundSchema: z.ZodType<
  ModeSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSentinelOneAiSiem$outboundSchema: z.ZodType<
  ModeSentinelOneAiSiem,
  z.ZodTypeDef,
  ModeSentinelOneAiSiem
> = z.union([
  z.nativeEnum(ModeSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSentinelOneAiSiem$inboundSchema: z.ZodType<
  CompressionSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSentinelOneAiSiem$outboundSchema: z.ZodType<
  CompressionSentinelOneAiSiem,
  z.ZodTypeDef,
  CompressionSentinelOneAiSiem
> = z.union([
  z.nativeEnum(CompressionSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSentinelOneAiSiem$inboundSchema: z.ZodType<
  QueueFullBehaviorSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSentinelOneAiSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSentinelOneAiSiem$outboundSchema: z.ZodType<
  QueueFullBehaviorSentinelOneAiSiem,
  z.ZodTypeDef,
  QueueFullBehaviorSentinelOneAiSiem
> = z.union([
  z.nativeEnum(QueueFullBehaviorSentinelOneAiSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSentinelOneAiSiem$inboundSchema: z.ZodType<
  PqControlsSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSentinelOneAiSiem$Outbound = {};

/** @internal */
export const PqControlsSentinelOneAiSiem$outboundSchema: z.ZodType<
  PqControlsSentinelOneAiSiem$Outbound,
  z.ZodTypeDef,
  PqControlsSentinelOneAiSiem
> = z.object({});

export function pqControlsSentinelOneAiSiemToJSON(
  pqControlsSentinelOneAiSiem: PqControlsSentinelOneAiSiem,
): string {
  return JSON.stringify(
    PqControlsSentinelOneAiSiem$outboundSchema.parse(
      pqControlsSentinelOneAiSiem,
    ),
  );
}
export function pqControlsSentinelOneAiSiemFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSentinelOneAiSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSentinelOneAiSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSentinelOneAiSiem' from JSON`,
  );
}

/** @internal */
export const OutputSentinelOneAiSiem$inboundSchema: z.ZodType<
  OutputSentinelOneAiSiem,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSentinelOneAiSiem$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    region: RegionSentinelOneAiSiem$inboundSchema.default("US"),
    endpoint: AISIEMEndpointPath$inboundSchema.default(
      "/services/collector/event",
    ),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(5120),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(5),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderSentinelOneAiSiem$inboundSchema),
    ).optional(),
    failedRequestLoggingMode:
      FailedRequestLoggingModeSentinelOneAiSiem$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    authType: AuthenticationMethodSentinelOneAiSiem$inboundSchema.default(
      "manual",
    ),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingSentinelOneAiSiem$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsSentinelOneAiSiem$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorSentinelOneAiSiem$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    baseUrl: z.string().default("https://<Your-S1-Tenant>.sentinelone.net"),
    hostExpression: z.string().default("__e.host || C.os.hostname()"),
    sourceExpression: z.string().default(
      "__e.source || (__e.__criblMetrics ? 'metrics' : 'cribl')",
    ),
    sourceTypeExpression: z.string().default("__e.sourcetype || 'dottedJson'"),
    dataSourceCategoryExpression: z.string().default("'security'"),
    dataSourceNameExpression: z.string().default(
      "__e.__dataSourceName || 'cribl'",
    ),
    dataSourceVendorExpression: z.string().default(
      "__e.__dataSourceVendor || 'cribl'",
    ),
    eventTypeExpression: z.string().default(""),
    host: z.string().default("C.os.hostname()"),
    source: z.string().default("cribl"),
    sourceType: z.string().default("hecRawParser"),
    dataSourceCategory: z.string().default("security"),
    dataSourceName: z.string().default("cribl"),
    dataSourceVendor: z.string().default("cribl"),
    eventType: z.string().default(""),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSentinelOneAiSiem$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSentinelOneAiSiem$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSentinelOneAiSiem$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsSentinelOneAiSiem$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSentinelOneAiSiem$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  region: string;
  endpoint: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?:
    | Array<ExtraHttpHeaderSentinelOneAiSiem$Outbound>
    | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  authType: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingSentinelOneAiSiem$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | TimeoutRetrySettingsSentinelOneAiSiem$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  baseUrl: string;
  hostExpression: string;
  sourceExpression: string;
  sourceTypeExpression: string;
  dataSourceCategoryExpression: string;
  dataSourceNameExpression: string;
  dataSourceVendorExpression: string;
  eventTypeExpression: string;
  host: string;
  source: string;
  sourceType: string;
  dataSourceCategory: string;
  dataSourceName: string;
  dataSourceVendor: string;
  eventType: string;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSentinelOneAiSiem$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSentinelOneAiSiem$outboundSchema: z.ZodType<
  OutputSentinelOneAiSiem$Outbound,
  z.ZodTypeDef,
  OutputSentinelOneAiSiem
> = z.object({
  id: z.string().optional(),
  type: TypeSentinelOneAiSiem$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  region: RegionSentinelOneAiSiem$outboundSchema.default("US"),
  endpoint: AISIEMEndpointPath$outboundSchema.default(
    "/services/collector/event",
  ),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(5120),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(5),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderSentinelOneAiSiem$outboundSchema),
  ).optional(),
  failedRequestLoggingMode:
    FailedRequestLoggingModeSentinelOneAiSiem$outboundSchema.default("none"),
  safeHeaders: z.array(z.string()).optional(),
  authType: AuthenticationMethodSentinelOneAiSiem$outboundSchema.default(
    "manual",
  ),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingSentinelOneAiSiem$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsSentinelOneAiSiem$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorSentinelOneAiSiem$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  baseUrl: z.string().default("https://<Your-S1-Tenant>.sentinelone.net"),
  hostExpression: z.string().default("__e.host || C.os.hostname()"),
  sourceExpression: z.string().default(
    "__e.source || (__e.__criblMetrics ? 'metrics' : 'cribl')",
  ),
  sourceTypeExpression: z.string().default("__e.sourcetype || 'dottedJson'"),
  dataSourceCategoryExpression: z.string().default("'security'"),
  dataSourceNameExpression: z.string().default(
    "__e.__dataSourceName || 'cribl'",
  ),
  dataSourceVendorExpression: z.string().default(
    "__e.__dataSourceVendor || 'cribl'",
  ),
  eventTypeExpression: z.string().default(""),
  host: z.string().default("C.os.hostname()"),
  source: z.string().default("cribl"),
  sourceType: z.string().default("hecRawParser"),
  dataSourceCategory: z.string().default("security"),
  dataSourceName: z.string().default("cribl"),
  dataSourceVendor: z.string().default("cribl"),
  eventType: z.string().default(""),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSentinelOneAiSiem$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSentinelOneAiSiem$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSentinelOneAiSiem$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsSentinelOneAiSiem$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSentinelOneAiSiemToJSON(
  outputSentinelOneAiSiem: OutputSentinelOneAiSiem,
): string {
  return JSON.stringify(
    OutputSentinelOneAiSiem$outboundSchema.parse(outputSentinelOneAiSiem),
  );
}
export function outputSentinelOneAiSiemFromJSON(
  jsonString: string,
): SafeParseResult<OutputSentinelOneAiSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSentinelOneAiSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSentinelOneAiSiem' from JSON`,
  );
}

/** @internal */
export const TypeDynatraceOtlp$inboundSchema: z.ZodNativeEnum<
  typeof TypeDynatraceOtlp
> = z.nativeEnum(TypeDynatraceOtlp);
/** @internal */
export const TypeDynatraceOtlp$outboundSchema: z.ZodNativeEnum<
  typeof TypeDynatraceOtlp
> = TypeDynatraceOtlp$inboundSchema;

/** @internal */
export const ProtocolDynatraceOtlp$inboundSchema: z.ZodType<
  ProtocolDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ProtocolDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ProtocolDynatraceOtlp$outboundSchema: z.ZodType<
  ProtocolDynatraceOtlp,
  z.ZodTypeDef,
  ProtocolDynatraceOtlp
> = z.union([
  z.nativeEnum(ProtocolDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OTLPVersionDynatraceOTLP$inboundSchema: z.ZodType<
  OTLPVersionDynatraceOTLP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OTLPVersionDynatraceOTLP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OTLPVersionDynatraceOTLP$outboundSchema: z.ZodType<
  OTLPVersionDynatraceOTLP,
  z.ZodTypeDef,
  OTLPVersionDynatraceOTLP
> = z.union([
  z.nativeEnum(OTLPVersionDynatraceOTLP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressCompressionDynatraceOtlp$inboundSchema: z.ZodType<
  CompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressCompressionDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressCompressionDynatraceOtlp$outboundSchema: z.ZodType<
  CompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  CompressCompressionDynatraceOtlp
> = z.union([
  z.nativeEnum(CompressCompressionDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HttpCompressCompressionDynatraceOtlp$inboundSchema: z.ZodType<
  HttpCompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(HttpCompressCompressionDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const HttpCompressCompressionDynatraceOtlp$outboundSchema: z.ZodType<
  HttpCompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  HttpCompressCompressionDynatraceOtlp
> = z.union([
  z.nativeEnum(HttpCompressCompressionDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumDynatraceOtlp$inboundSchema: z.ZodType<
  MetadatumDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type MetadatumDynatraceOtlp$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const MetadatumDynatraceOtlp$outboundSchema: z.ZodType<
  MetadatumDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  MetadatumDynatraceOtlp
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function metadatumDynatraceOtlpToJSON(
  metadatumDynatraceOtlp: MetadatumDynatraceOtlp,
): string {
  return JSON.stringify(
    MetadatumDynatraceOtlp$outboundSchema.parse(metadatumDynatraceOtlp),
  );
}
export function metadatumDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeDynatraceOtlp$inboundSchema: z.ZodType<
  FailedRequestLoggingModeDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeDynatraceOtlp$outboundSchema: z.ZodType<
  FailedRequestLoggingModeDynatraceOtlp,
  z.ZodTypeDef,
  FailedRequestLoggingModeDynatraceOtlp
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const EndpointType$inboundSchema: z.ZodType<
  EndpointType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(EndpointType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const EndpointType$outboundSchema: z.ZodType<
  EndpointType,
  z.ZodTypeDef,
  EndpointType
> = z.union([
  z.nativeEnum(EndpointType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorDynatraceOtlp$inboundSchema: z.ZodType<
  BackpressureBehaviorDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDynatraceOtlp$outboundSchema: z.ZodType<
  BackpressureBehaviorDynatraceOtlp,
  z.ZodTypeDef,
  BackpressureBehaviorDynatraceOtlp
> = z.union([
  z.nativeEnum(BackpressureBehaviorDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderDynatraceOtlp$inboundSchema: z.ZodType<
  ExtraHttpHeaderDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderDynatraceOtlp$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderDynatraceOtlp$outboundSchema: z.ZodType<
  ExtraHttpHeaderDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderDynatraceOtlp
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderDynatraceOtlpToJSON(
  extraHttpHeaderDynatraceOtlp: ExtraHttpHeaderDynatraceOtlp,
): string {
  return JSON.stringify(
    ExtraHttpHeaderDynatraceOtlp$outboundSchema.parse(
      extraHttpHeaderDynatraceOtlp,
    ),
  );
}
export function extraHttpHeaderDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const ResponseRetrySettingDynatraceOtlp$inboundSchema: z.ZodType<
  ResponseRetrySettingDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingDynatraceOtlp$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingDynatraceOtlp$outboundSchema: z.ZodType<
  ResponseRetrySettingDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingDynatraceOtlp
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingDynatraceOtlpToJSON(
  responseRetrySettingDynatraceOtlp: ResponseRetrySettingDynatraceOtlp,
): string {
  return JSON.stringify(
    ResponseRetrySettingDynatraceOtlp$outboundSchema.parse(
      responseRetrySettingDynatraceOtlp,
    ),
  );
}
export function responseRetrySettingDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsDynatraceOtlp$inboundSchema: z.ZodType<
  TimeoutRetrySettingsDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsDynatraceOtlp$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsDynatraceOtlp$outboundSchema: z.ZodType<
  TimeoutRetrySettingsDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsDynatraceOtlp
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsDynatraceOtlpToJSON(
  timeoutRetrySettingsDynatraceOtlp: TimeoutRetrySettingsDynatraceOtlp,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsDynatraceOtlp$outboundSchema.parse(
      timeoutRetrySettingsDynatraceOtlp,
    ),
  );
}
export function timeoutRetrySettingsDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const ModeDynatraceOtlp$inboundSchema: z.ZodType<
  ModeDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDynatraceOtlp$outboundSchema: z.ZodType<
  ModeDynatraceOtlp,
  z.ZodTypeDef,
  ModeDynatraceOtlp
> = z.union([
  z.nativeEnum(ModeDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionDynatraceOtlp$inboundSchema: z.ZodType<
  PqCompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionDynatraceOtlp$outboundSchema: z.ZodType<
  PqCompressCompressionDynatraceOtlp,
  z.ZodTypeDef,
  PqCompressCompressionDynatraceOtlp
> = z.union([
  z.nativeEnum(PqCompressCompressionDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorDynatraceOtlp$inboundSchema: z.ZodType<
  QueueFullBehaviorDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorDynatraceOtlp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorDynatraceOtlp$outboundSchema: z.ZodType<
  QueueFullBehaviorDynatraceOtlp,
  z.ZodTypeDef,
  QueueFullBehaviorDynatraceOtlp
> = z.union([
  z.nativeEnum(QueueFullBehaviorDynatraceOtlp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDynatraceOtlp$inboundSchema: z.ZodType<
  PqControlsDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDynatraceOtlp$Outbound = {};

/** @internal */
export const PqControlsDynatraceOtlp$outboundSchema: z.ZodType<
  PqControlsDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  PqControlsDynatraceOtlp
> = z.object({});

export function pqControlsDynatraceOtlpToJSON(
  pqControlsDynatraceOtlp: PqControlsDynatraceOtlp,
): string {
  return JSON.stringify(
    PqControlsDynatraceOtlp$outboundSchema.parse(pqControlsDynatraceOtlp),
  );
}
export function pqControlsDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const OutputDynatraceOtlp$inboundSchema: z.ZodType<
  OutputDynatraceOtlp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDynatraceOtlp$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: ProtocolDynatraceOtlp$inboundSchema.default("http"),
    endpoint: z.string().default(
      "https://{your-environment-id}.live.dynatrace.com/api/v2/otlp",
    ),
    otlpVersion: OTLPVersionDynatraceOTLP$inboundSchema.default("1.3.1"),
    compress: CompressCompressionDynatraceOtlp$inboundSchema.default("gzip"),
    httpCompress: HttpCompressCompressionDynatraceOtlp$inboundSchema.default(
      "gzip",
    ),
    httpTracesEndpointOverride: z.string().optional(),
    httpMetricsEndpointOverride: z.string().optional(),
    httpLogsEndpointOverride: z.string().optional(),
    metadata: z.array(z.lazy(() => MetadatumDynatraceOtlp$inboundSchema))
      .optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(2048),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    failedRequestLoggingMode:
      FailedRequestLoggingModeDynatraceOtlp$inboundSchema.default("none"),
    connectionTimeout: z.number().default(10000),
    keepAliveTime: z.number().default(30),
    keepAlive: z.boolean().default(true),
    endpointType: EndpointType$inboundSchema.default("saas"),
    tokenSecret: z.string(),
    authTokenName: z.string().default("Authorization"),
    onBackpressure: BackpressureBehaviorDynatraceOtlp$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    rejectUnauthorized: z.boolean().default(true),
    useRoundRobinDns: z.boolean().default(false),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderDynatraceOtlp$inboundSchema),
    ).optional(),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingDynatraceOtlp$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsDynatraceOtlp$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeDynatraceOtlp$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionDynatraceOtlp$inboundSchema.default(
      "none",
    ),
    pqOnBackpressure: QueueFullBehaviorDynatraceOtlp$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsDynatraceOtlp$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDynatraceOtlp$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  endpoint: string;
  otlpVersion: string;
  compress: string;
  httpCompress: string;
  httpTracesEndpointOverride?: string | undefined;
  httpMetricsEndpointOverride?: string | undefined;
  httpLogsEndpointOverride?: string | undefined;
  metadata?: Array<MetadatumDynatraceOtlp$Outbound> | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  timeoutSec: number;
  flushPeriodSec: number;
  failedRequestLoggingMode: string;
  connectionTimeout: number;
  keepAliveTime: number;
  keepAlive: boolean;
  endpointType: string;
  tokenSecret: string;
  authTokenName: string;
  onBackpressure: string;
  description?: string | undefined;
  rejectUnauthorized: boolean;
  useRoundRobinDns: boolean;
  extraHttpHeaders?: Array<ExtraHttpHeaderDynatraceOtlp$Outbound> | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingDynatraceOtlp$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDynatraceOtlp$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsDynatraceOtlp$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDynatraceOtlp$outboundSchema: z.ZodType<
  OutputDynatraceOtlp$Outbound,
  z.ZodTypeDef,
  OutputDynatraceOtlp
> = z.object({
  id: z.string().optional(),
  type: TypeDynatraceOtlp$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: ProtocolDynatraceOtlp$outboundSchema.default("http"),
  endpoint: z.string().default(
    "https://{your-environment-id}.live.dynatrace.com/api/v2/otlp",
  ),
  otlpVersion: OTLPVersionDynatraceOTLP$outboundSchema.default("1.3.1"),
  compress: CompressCompressionDynatraceOtlp$outboundSchema.default("gzip"),
  httpCompress: HttpCompressCompressionDynatraceOtlp$outboundSchema.default(
    "gzip",
  ),
  httpTracesEndpointOverride: z.string().optional(),
  httpMetricsEndpointOverride: z.string().optional(),
  httpLogsEndpointOverride: z.string().optional(),
  metadata: z.array(z.lazy(() => MetadatumDynatraceOtlp$outboundSchema))
    .optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(2048),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  failedRequestLoggingMode: FailedRequestLoggingModeDynatraceOtlp$outboundSchema
    .default("none"),
  connectionTimeout: z.number().default(10000),
  keepAliveTime: z.number().default(30),
  keepAlive: z.boolean().default(true),
  endpointType: EndpointType$outboundSchema.default("saas"),
  tokenSecret: z.string(),
  authTokenName: z.string().default("Authorization"),
  onBackpressure: BackpressureBehaviorDynatraceOtlp$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  rejectUnauthorized: z.boolean().default(true),
  useRoundRobinDns: z.boolean().default(false),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderDynatraceOtlp$outboundSchema),
  ).optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingDynatraceOtlp$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsDynatraceOtlp$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeDynatraceOtlp$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionDynatraceOtlp$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorDynatraceOtlp$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsDynatraceOtlp$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDynatraceOtlpToJSON(
  outputDynatraceOtlp: OutputDynatraceOtlp,
): string {
  return JSON.stringify(
    OutputDynatraceOtlp$outboundSchema.parse(outputDynatraceOtlp),
  );
}
export function outputDynatraceOtlpFromJSON(
  jsonString: string,
): SafeParseResult<OutputDynatraceOtlp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDynatraceOtlp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDynatraceOtlp' from JSON`,
  );
}

/** @internal */
export const TypeDynatraceHTTP$inboundSchema: z.ZodNativeEnum<
  typeof TypeDynatraceHTTP
> = z.nativeEnum(TypeDynatraceHTTP);
/** @internal */
export const TypeDynatraceHTTP$outboundSchema: z.ZodNativeEnum<
  typeof TypeDynatraceHTTP
> = TypeDynatraceHTTP$inboundSchema;

/** @internal */
export const MethodDynatraceHTTP$inboundSchema: z.ZodType<
  MethodDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MethodDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MethodDynatraceHTTP$outboundSchema: z.ZodType<
  MethodDynatraceHTTP,
  z.ZodTypeDef,
  MethodDynatraceHTTP
> = z.union([
  z.nativeEnum(MethodDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHTTPHeaderDynatraceHTTP$inboundSchema: z.ZodType<
  ExtraHTTPHeaderDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHTTPHeaderDynatraceHTTP$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHTTPHeaderDynatraceHTTP$outboundSchema: z.ZodType<
  ExtraHTTPHeaderDynatraceHTTP$Outbound,
  z.ZodTypeDef,
  ExtraHTTPHeaderDynatraceHTTP
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHTTPHeaderDynatraceHTTPToJSON(
  extraHTTPHeaderDynatraceHTTP: ExtraHTTPHeaderDynatraceHTTP,
): string {
  return JSON.stringify(
    ExtraHTTPHeaderDynatraceHTTP$outboundSchema.parse(
      extraHTTPHeaderDynatraceHTTP,
    ),
  );
}
export function extraHTTPHeaderDynatraceHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHTTPHeaderDynatraceHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHTTPHeaderDynatraceHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHTTPHeaderDynatraceHTTP' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeDynatraceHTTP$inboundSchema: z.ZodType<
  FailedRequestLoggingModeDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeDynatraceHTTP$outboundSchema: z.ZodType<
  FailedRequestLoggingModeDynatraceHTTP,
  z.ZodTypeDef,
  FailedRequestLoggingModeDynatraceHTTP
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingDynatraceHTTP$inboundSchema: z.ZodType<
  ResponseRetrySettingDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingDynatraceHTTP$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingDynatraceHTTP$outboundSchema: z.ZodType<
  ResponseRetrySettingDynatraceHTTP$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingDynatraceHTTP
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingDynatraceHTTPToJSON(
  responseRetrySettingDynatraceHTTP: ResponseRetrySettingDynatraceHTTP,
): string {
  return JSON.stringify(
    ResponseRetrySettingDynatraceHTTP$outboundSchema.parse(
      responseRetrySettingDynatraceHTTP,
    ),
  );
}
export function responseRetrySettingDynatraceHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingDynatraceHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingDynatraceHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingDynatraceHTTP' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsDynatraceHTTP$inboundSchema: z.ZodType<
  TimeoutRetrySettingsDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsDynatraceHTTP$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsDynatraceHTTP$outboundSchema: z.ZodType<
  TimeoutRetrySettingsDynatraceHTTP$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsDynatraceHTTP
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsDynatraceHTTPToJSON(
  timeoutRetrySettingsDynatraceHTTP: TimeoutRetrySettingsDynatraceHTTP,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsDynatraceHTTP$outboundSchema.parse(
      timeoutRetrySettingsDynatraceHTTP,
    ),
  );
}
export function timeoutRetrySettingsDynatraceHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsDynatraceHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsDynatraceHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsDynatraceHTTP' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorDynatraceHTTP$inboundSchema: z.ZodType<
  BackpressureBehaviorDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDynatraceHTTP$outboundSchema: z.ZodType<
  BackpressureBehaviorDynatraceHTTP,
  z.ZodTypeDef,
  BackpressureBehaviorDynatraceHTTP
> = z.union([
  z.nativeEnum(BackpressureBehaviorDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationTypeDynatraceHTTP$inboundSchema: z.ZodType<
  AuthenticationTypeDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeDynatraceHTTP$outboundSchema: z.ZodType<
  AuthenticationTypeDynatraceHTTP,
  z.ZodTypeDef,
  AuthenticationTypeDynatraceHTTP
> = z.union([
  z.nativeEnum(AuthenticationTypeDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FormatDynatraceHTTP$inboundSchema: z.ZodType<
  FormatDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FormatDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FormatDynatraceHTTP$outboundSchema: z.ZodType<
  FormatDynatraceHTTP,
  z.ZodTypeDef,
  FormatDynatraceHTTP
> = z.union([
  z.nativeEnum(FormatDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const Endpoint$inboundSchema: z.ZodType<
  Endpoint,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(Endpoint),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const Endpoint$outboundSchema: z.ZodType<
  Endpoint,
  z.ZodTypeDef,
  Endpoint
> = z.union([
  z.nativeEnum(Endpoint),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TelemetryType$inboundSchema: z.ZodType<
  TelemetryType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TelemetryType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TelemetryType$outboundSchema: z.ZodType<
  TelemetryType,
  z.ZodTypeDef,
  TelemetryType
> = z.union([
  z.nativeEnum(TelemetryType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeDynatraceHTTP$inboundSchema: z.ZodType<
  ModeDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDynatraceHTTP$outboundSchema: z.ZodType<
  ModeDynatraceHTTP,
  z.ZodTypeDef,
  ModeDynatraceHTTP
> = z.union([
  z.nativeEnum(ModeDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDynatraceHTTP$inboundSchema: z.ZodType<
  CompressionDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDynatraceHTTP$outboundSchema: z.ZodType<
  CompressionDynatraceHTTP,
  z.ZodTypeDef,
  CompressionDynatraceHTTP
> = z.union([
  z.nativeEnum(CompressionDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorDynatraceHTTP$inboundSchema: z.ZodType<
  QueueFullBehaviorDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorDynatraceHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorDynatraceHTTP$outboundSchema: z.ZodType<
  QueueFullBehaviorDynatraceHTTP,
  z.ZodTypeDef,
  QueueFullBehaviorDynatraceHTTP
> = z.union([
  z.nativeEnum(QueueFullBehaviorDynatraceHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDynatraceHTTP$inboundSchema: z.ZodType<
  PqControlsDynatraceHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDynatraceHTTP$Outbound = {};

/** @internal */
export const PqControlsDynatraceHTTP$outboundSchema: z.ZodType<
  PqControlsDynatraceHTTP$Outbound,
  z.ZodTypeDef,
  PqControlsDynatraceHTTP
> = z.object({});

export function pqControlsDynatraceHTTPToJSON(
  pqControlsDynatraceHTTP: PqControlsDynatraceHTTP,
): string {
  return JSON.stringify(
    PqControlsDynatraceHTTP$outboundSchema.parse(pqControlsDynatraceHTTP),
  );
}
export function pqControlsDynatraceHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDynatraceHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDynatraceHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDynatraceHTTP' from JSON`,
  );
}

/** @internal */
export const OutputDynatraceHttp$inboundSchema: z.ZodType<
  OutputDynatraceHttp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDynatraceHTTP$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    method: MethodDynatraceHTTP$inboundSchema.default("POST"),
    keepAlive: z.boolean().default(true),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHTTPHeaderDynatraceHTTP$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode:
      FailedRequestLoggingModeDynatraceHTTP$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingDynatraceHTTP$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsDynatraceHTTP$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorDynatraceHTTP$inboundSchema.default(
      "block",
    ),
    authType: AuthenticationTypeDynatraceHTTP$inboundSchema.default("token"),
    format: FormatDynatraceHTTP$inboundSchema.default("json_array"),
    endpoint: Endpoint$inboundSchema.default("cloud"),
    telemetryType: TelemetryType$inboundSchema.default("logs"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeDynatraceHTTP$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionDynatraceHTTP$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorDynatraceHTTP$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsDynatraceHTTP$inboundSchema).optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    environmentId: z.string().optional(),
    activeGateDomain: z.string().optional(),
    url: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDynatraceHttp$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  method: string;
  keepAlive: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHTTPHeaderDynatraceHTTP$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingDynatraceHTTP$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDynatraceHTTP$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  format: string;
  endpoint: string;
  telemetryType: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsDynatraceHTTP$Outbound | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  environmentId?: string | undefined;
  activeGateDomain?: string | undefined;
  url?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDynatraceHttp$outboundSchema: z.ZodType<
  OutputDynatraceHttp$Outbound,
  z.ZodTypeDef,
  OutputDynatraceHttp
> = z.object({
  id: z.string().optional(),
  type: TypeDynatraceHTTP$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  method: MethodDynatraceHTTP$outboundSchema.default("POST"),
  keepAlive: z.boolean().default(true),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHTTPHeaderDynatraceHTTP$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeDynatraceHTTP$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingDynatraceHTTP$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsDynatraceHTTP$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorDynatraceHTTP$outboundSchema.default(
    "block",
  ),
  authType: AuthenticationTypeDynatraceHTTP$outboundSchema.default("token"),
  format: FormatDynatraceHTTP$outboundSchema.default("json_array"),
  endpoint: Endpoint$outboundSchema.default("cloud"),
  telemetryType: TelemetryType$outboundSchema.default("logs"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeDynatraceHTTP$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionDynatraceHTTP$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorDynatraceHTTP$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsDynatraceHTTP$outboundSchema).optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  environmentId: z.string().optional(),
  activeGateDomain: z.string().optional(),
  url: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDynatraceHttpToJSON(
  outputDynatraceHttp: OutputDynatraceHttp,
): string {
  return JSON.stringify(
    OutputDynatraceHttp$outboundSchema.parse(outputDynatraceHttp),
  );
}
export function outputDynatraceHttpFromJSON(
  jsonString: string,
): SafeParseResult<OutputDynatraceHttp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDynatraceHttp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDynatraceHttp' from JSON`,
  );
}

/** @internal */
export const OutputTypeNetflow$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeNetflow
> = z.nativeEnum(OutputTypeNetflow);
/** @internal */
export const OutputTypeNetflow$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeNetflow
> = OutputTypeNetflow$inboundSchema;

/** @internal */
export const HostNetflow$inboundSchema: z.ZodType<
  HostNetflow,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number().default(2055),
});
/** @internal */
export type HostNetflow$Outbound = {
  host: string;
  port: number;
};

/** @internal */
export const HostNetflow$outboundSchema: z.ZodType<
  HostNetflow$Outbound,
  z.ZodTypeDef,
  HostNetflow
> = z.object({
  host: z.string(),
  port: z.number().default(2055),
});

export function hostNetflowToJSON(hostNetflow: HostNetflow): string {
  return JSON.stringify(HostNetflow$outboundSchema.parse(hostNetflow));
}
export function hostNetflowFromJSON(
  jsonString: string,
): SafeParseResult<HostNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostNetflow' from JSON`,
  );
}

/** @internal */
export const OutputNetflow$inboundSchema: z.ZodType<
  OutputNetflow,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeNetflow$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    hosts: z.array(z.lazy(() => HostNetflow$inboundSchema)),
    dnsResolvePeriodSec: z.number().default(0),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputNetflow$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  hosts: Array<HostNetflow$Outbound>;
  dnsResolvePeriodSec: number;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputNetflow$outboundSchema: z.ZodType<
  OutputNetflow$Outbound,
  z.ZodTypeDef,
  OutputNetflow
> = z.object({
  id: z.string().optional(),
  type: OutputTypeNetflow$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  hosts: z.array(z.lazy(() => HostNetflow$outboundSchema)),
  dnsResolvePeriodSec: z.number().default(0),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputNetflowToJSON(outputNetflow: OutputNetflow): string {
  return JSON.stringify(OutputNetflow$outboundSchema.parse(outputNetflow));
}
export function outputNetflowFromJSON(
  jsonString: string,
): SafeParseResult<OutputNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputNetflow' from JSON`,
  );
}

/** @internal */
export const TypeXsiam$inboundSchema: z.ZodNativeEnum<typeof TypeXsiam> = z
  .nativeEnum(TypeXsiam);
/** @internal */
export const TypeXsiam$outboundSchema: z.ZodNativeEnum<typeof TypeXsiam> =
  TypeXsiam$inboundSchema;

/** @internal */
export const ExtraHttpHeaderXsiam$inboundSchema: z.ZodType<
  ExtraHttpHeaderXsiam,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderXsiam$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderXsiam$outboundSchema: z.ZodType<
  ExtraHttpHeaderXsiam$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderXsiam
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderXsiamToJSON(
  extraHttpHeaderXsiam: ExtraHttpHeaderXsiam,
): string {
  return JSON.stringify(
    ExtraHttpHeaderXsiam$outboundSchema.parse(extraHttpHeaderXsiam),
  );
}
export function extraHttpHeaderXsiamFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderXsiam' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeXsiam$inboundSchema: z.ZodType<
  FailedRequestLoggingModeXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeXsiam$outboundSchema: z.ZodType<
  FailedRequestLoggingModeXsiam,
  z.ZodTypeDef,
  FailedRequestLoggingModeXsiam
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodXsiam$inboundSchema: z.ZodType<
  AuthenticationMethodXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodXsiam$outboundSchema: z.ZodType<
  AuthenticationMethodXsiam,
  z.ZodTypeDef,
  AuthenticationMethodXsiam
> = z.union([
  z.nativeEnum(AuthenticationMethodXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingXsiam$inboundSchema: z.ZodType<
  ResponseRetrySettingXsiam,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingXsiam$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingXsiam$outboundSchema: z.ZodType<
  ResponseRetrySettingXsiam$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingXsiam
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingXsiamToJSON(
  responseRetrySettingXsiam: ResponseRetrySettingXsiam,
): string {
  return JSON.stringify(
    ResponseRetrySettingXsiam$outboundSchema.parse(responseRetrySettingXsiam),
  );
}
export function responseRetrySettingXsiamFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingXsiam' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsXsiam$inboundSchema: z.ZodType<
  TimeoutRetrySettingsXsiam,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsXsiam$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsXsiam$outboundSchema: z.ZodType<
  TimeoutRetrySettingsXsiam$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsXsiam
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsXsiamToJSON(
  timeoutRetrySettingsXsiam: TimeoutRetrySettingsXsiam,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsXsiam$outboundSchema.parse(timeoutRetrySettingsXsiam),
  );
}
export function timeoutRetrySettingsXsiamFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsXsiam' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorXsiam$inboundSchema: z.ZodType<
  BackpressureBehaviorXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorXsiam$outboundSchema: z.ZodType<
  BackpressureBehaviorXsiam,
  z.ZodTypeDef,
  BackpressureBehaviorXsiam
> = z.union([
  z.nativeEnum(BackpressureBehaviorXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const UrlXsiam$inboundSchema: z.ZodType<
  UrlXsiam,
  z.ZodTypeDef,
  unknown
> = z.object({
  url: z.any().optional(),
  weight: z.number().default(1),
});
/** @internal */
export type UrlXsiam$Outbound = {
  url?: any | undefined;
  weight: number;
};

/** @internal */
export const UrlXsiam$outboundSchema: z.ZodType<
  UrlXsiam$Outbound,
  z.ZodTypeDef,
  UrlXsiam
> = z.object({
  url: z.any().optional(),
  weight: z.number().default(1),
});

export function urlXsiamToJSON(urlXsiam: UrlXsiam): string {
  return JSON.stringify(UrlXsiam$outboundSchema.parse(urlXsiam));
}
export function urlXsiamFromJSON(
  jsonString: string,
): SafeParseResult<UrlXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UrlXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UrlXsiam' from JSON`,
  );
}

/** @internal */
export const ModeXsiam$inboundSchema: z.ZodType<
  ModeXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeXsiam$outboundSchema: z.ZodType<
  ModeXsiam,
  z.ZodTypeDef,
  ModeXsiam
> = z.union([
  z.nativeEnum(ModeXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionXsiam$inboundSchema: z.ZodType<
  CompressionXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionXsiam$outboundSchema: z.ZodType<
  CompressionXsiam,
  z.ZodTypeDef,
  CompressionXsiam
> = z.union([
  z.nativeEnum(CompressionXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorXsiam$inboundSchema: z.ZodType<
  QueueFullBehaviorXsiam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorXsiam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorXsiam$outboundSchema: z.ZodType<
  QueueFullBehaviorXsiam,
  z.ZodTypeDef,
  QueueFullBehaviorXsiam
> = z.union([
  z.nativeEnum(QueueFullBehaviorXsiam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsXsiam$inboundSchema: z.ZodType<
  PqControlsXsiam,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsXsiam$Outbound = {};

/** @internal */
export const PqControlsXsiam$outboundSchema: z.ZodType<
  PqControlsXsiam$Outbound,
  z.ZodTypeDef,
  PqControlsXsiam
> = z.object({});

export function pqControlsXsiamToJSON(
  pqControlsXsiam: PqControlsXsiam,
): string {
  return JSON.stringify(PqControlsXsiam$outboundSchema.parse(pqControlsXsiam));
}
export function pqControlsXsiamFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsXsiam' from JSON`,
  );
}

/** @internal */
export const OutputXsiam$inboundSchema: z.ZodType<
  OutputXsiam,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeXsiam$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(false),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(10000),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderXsiam$inboundSchema))
      .optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeXsiam$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    authType: AuthenticationMethodXsiam$inboundSchema.default("token"),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingXsiam$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsXsiam$inboundSchema)
      .optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    throttleRateReqPerSec: z.number().int().default(400),
    onBackpressure: BackpressureBehaviorXsiam$inboundSchema.default("block"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    url: z.string().default("http://localhost:8088/logs/v1/event"),
    useRoundRobinDns: z.boolean().default(false),
    excludeSelf: z.boolean().default(false),
    urls: z.array(z.lazy(() => UrlXsiam$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeXsiam$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionXsiam$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorXsiam$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsXsiam$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputXsiam$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderXsiam$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  authType: string;
  responseRetrySettings?: Array<ResponseRetrySettingXsiam$Outbound> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsXsiam$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  throttleRateReqPerSec: number;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  url: string;
  useRoundRobinDns: boolean;
  excludeSelf: boolean;
  urls?: Array<UrlXsiam$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsXsiam$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputXsiam$outboundSchema: z.ZodType<
  OutputXsiam$Outbound,
  z.ZodTypeDef,
  OutputXsiam
> = z.object({
  id: z.string().optional(),
  type: TypeXsiam$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(false),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(10000),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderXsiam$outboundSchema))
    .optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeXsiam$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  authType: AuthenticationMethodXsiam$outboundSchema.default("token"),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingXsiam$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsXsiam$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  throttleRateReqPerSec: z.number().int().default(400),
  onBackpressure: BackpressureBehaviorXsiam$outboundSchema.default("block"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  url: z.string().default("http://localhost:8088/logs/v1/event"),
  useRoundRobinDns: z.boolean().default(false),
  excludeSelf: z.boolean().default(false),
  urls: z.array(z.lazy(() => UrlXsiam$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeXsiam$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionXsiam$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorXsiam$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsXsiam$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputXsiamToJSON(outputXsiam: OutputXsiam): string {
  return JSON.stringify(OutputXsiam$outboundSchema.parse(outputXsiam));
}
export function outputXsiamFromJSON(
  jsonString: string,
): SafeParseResult<OutputXsiam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputXsiam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputXsiam' from JSON`,
  );
}

/** @internal */
export const TypeClickHouse$inboundSchema: z.ZodNativeEnum<
  typeof TypeClickHouse
> = z.nativeEnum(TypeClickHouse);
/** @internal */
export const TypeClickHouse$outboundSchema: z.ZodNativeEnum<
  typeof TypeClickHouse
> = TypeClickHouse$inboundSchema;

/** @internal */
export const AuthenticationTypeClickHouse$inboundSchema: z.ZodType<
  AuthenticationTypeClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeClickHouse$outboundSchema: z.ZodType<
  AuthenticationTypeClickHouse,
  z.ZodTypeDef,
  AuthenticationTypeClickHouse
> = z.union([
  z.nativeEnum(AuthenticationTypeClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FormatClickHouse$inboundSchema: z.ZodType<
  FormatClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FormatClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FormatClickHouse$outboundSchema: z.ZodType<
  FormatClickHouse,
  z.ZodTypeDef,
  FormatClickHouse
> = z.union([
  z.nativeEnum(FormatClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MappingType$inboundSchema: z.ZodType<
  MappingType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MappingType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MappingType$outboundSchema: z.ZodType<
  MappingType,
  z.ZodTypeDef,
  MappingType
> = z.union([
  z.nativeEnum(MappingType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MinimumTLSVersionClickHouse$inboundSchema: z.ZodType<
  MinimumTLSVersionClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionClickHouse$outboundSchema: z.ZodType<
  MinimumTLSVersionClickHouse,
  z.ZodTypeDef,
  MinimumTLSVersionClickHouse
> = z.union([
  z.nativeEnum(MinimumTLSVersionClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionClickHouse$inboundSchema: z.ZodType<
  MaximumTLSVersionClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionClickHouse$outboundSchema: z.ZodType<
  MaximumTLSVersionClickHouse,
  z.ZodTypeDef,
  MaximumTLSVersionClickHouse
> = z.union([
  z.nativeEnum(MaximumTLSVersionClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideClickHouse$inboundSchema: z.ZodType<
  TLSSettingsClientSideClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionClickHouse$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionClickHouse$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideClickHouse$Outbound = {
  disabled: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideClickHouse$outboundSchema: z.ZodType<
  TLSSettingsClientSideClickHouse$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideClickHouse
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionClickHouse$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionClickHouse$outboundSchema.optional(),
});

export function tlsSettingsClientSideClickHouseToJSON(
  tlsSettingsClientSideClickHouse: TLSSettingsClientSideClickHouse,
): string {
  return JSON.stringify(
    TLSSettingsClientSideClickHouse$outboundSchema.parse(
      tlsSettingsClientSideClickHouse,
    ),
  );
}
export function tlsSettingsClientSideClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideClickHouse' from JSON`,
  );
}

/** @internal */
export const ExtraHttpHeaderClickHouse$inboundSchema: z.ZodType<
  ExtraHttpHeaderClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderClickHouse$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderClickHouse$outboundSchema: z.ZodType<
  ExtraHttpHeaderClickHouse$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderClickHouse
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderClickHouseToJSON(
  extraHttpHeaderClickHouse: ExtraHttpHeaderClickHouse,
): string {
  return JSON.stringify(
    ExtraHttpHeaderClickHouse$outboundSchema.parse(extraHttpHeaderClickHouse),
  );
}
export function extraHttpHeaderClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderClickHouse' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeClickHouse$inboundSchema: z.ZodType<
  FailedRequestLoggingModeClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeClickHouse$outboundSchema: z.ZodType<
  FailedRequestLoggingModeClickHouse,
  z.ZodTypeDef,
  FailedRequestLoggingModeClickHouse
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingClickHouse$inboundSchema: z.ZodType<
  ResponseRetrySettingClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingClickHouse$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingClickHouse$outboundSchema: z.ZodType<
  ResponseRetrySettingClickHouse$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingClickHouse
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingClickHouseToJSON(
  responseRetrySettingClickHouse: ResponseRetrySettingClickHouse,
): string {
  return JSON.stringify(
    ResponseRetrySettingClickHouse$outboundSchema.parse(
      responseRetrySettingClickHouse,
    ),
  );
}
export function responseRetrySettingClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingClickHouse' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsClickHouse$inboundSchema: z.ZodType<
  TimeoutRetrySettingsClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsClickHouse$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsClickHouse$outboundSchema: z.ZodType<
  TimeoutRetrySettingsClickHouse$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsClickHouse
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsClickHouseToJSON(
  timeoutRetrySettingsClickHouse: TimeoutRetrySettingsClickHouse,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsClickHouse$outboundSchema.parse(
      timeoutRetrySettingsClickHouse,
    ),
  );
}
export function timeoutRetrySettingsClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsClickHouse' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorClickHouse$inboundSchema: z.ZodType<
  BackpressureBehaviorClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorClickHouse$outboundSchema: z.ZodType<
  BackpressureBehaviorClickHouse,
  z.ZodTypeDef,
  BackpressureBehaviorClickHouse
> = z.union([
  z.nativeEnum(BackpressureBehaviorClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OauthParamClickHouse$inboundSchema: z.ZodType<
  OauthParamClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamClickHouse$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamClickHouse$outboundSchema: z.ZodType<
  OauthParamClickHouse$Outbound,
  z.ZodTypeDef,
  OauthParamClickHouse
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamClickHouseToJSON(
  oauthParamClickHouse: OauthParamClickHouse,
): string {
  return JSON.stringify(
    OauthParamClickHouse$outboundSchema.parse(oauthParamClickHouse),
  );
}
export function oauthParamClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamClickHouse' from JSON`,
  );
}

/** @internal */
export const OauthHeaderClickHouse$inboundSchema: z.ZodType<
  OauthHeaderClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderClickHouse$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderClickHouse$outboundSchema: z.ZodType<
  OauthHeaderClickHouse$Outbound,
  z.ZodTypeDef,
  OauthHeaderClickHouse
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderClickHouseToJSON(
  oauthHeaderClickHouse: OauthHeaderClickHouse,
): string {
  return JSON.stringify(
    OauthHeaderClickHouse$outboundSchema.parse(oauthHeaderClickHouse),
  );
}
export function oauthHeaderClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderClickHouse' from JSON`,
  );
}

/** @internal */
export const ColumnMapping$inboundSchema: z.ZodType<
  ColumnMapping,
  z.ZodTypeDef,
  unknown
> = z.object({
  columnName: z.string(),
  columnType: z.string().optional(),
  columnValueExpression: z.string(),
});
/** @internal */
export type ColumnMapping$Outbound = {
  columnName: string;
  columnType?: string | undefined;
  columnValueExpression: string;
};

/** @internal */
export const ColumnMapping$outboundSchema: z.ZodType<
  ColumnMapping$Outbound,
  z.ZodTypeDef,
  ColumnMapping
> = z.object({
  columnName: z.string(),
  columnType: z.string().optional(),
  columnValueExpression: z.string(),
});

export function columnMappingToJSON(columnMapping: ColumnMapping): string {
  return JSON.stringify(ColumnMapping$outboundSchema.parse(columnMapping));
}
export function columnMappingFromJSON(
  jsonString: string,
): SafeParseResult<ColumnMapping, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ColumnMapping$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ColumnMapping' from JSON`,
  );
}

/** @internal */
export const ModeClickHouse$inboundSchema: z.ZodType<
  ModeClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeClickHouse$outboundSchema: z.ZodType<
  ModeClickHouse,
  z.ZodTypeDef,
  ModeClickHouse
> = z.union([
  z.nativeEnum(ModeClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionClickHouse$inboundSchema: z.ZodType<
  CompressionClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionClickHouse$outboundSchema: z.ZodType<
  CompressionClickHouse,
  z.ZodTypeDef,
  CompressionClickHouse
> = z.union([
  z.nativeEnum(CompressionClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorClickHouse$inboundSchema: z.ZodType<
  QueueFullBehaviorClickHouse,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorClickHouse),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorClickHouse$outboundSchema: z.ZodType<
  QueueFullBehaviorClickHouse,
  z.ZodTypeDef,
  QueueFullBehaviorClickHouse
> = z.union([
  z.nativeEnum(QueueFullBehaviorClickHouse),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsClickHouse$inboundSchema: z.ZodType<
  PqControlsClickHouse,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsClickHouse$Outbound = {};

/** @internal */
export const PqControlsClickHouse$outboundSchema: z.ZodType<
  PqControlsClickHouse$Outbound,
  z.ZodTypeDef,
  PqControlsClickHouse
> = z.object({});

export function pqControlsClickHouseToJSON(
  pqControlsClickHouse: PqControlsClickHouse,
): string {
  return JSON.stringify(
    PqControlsClickHouse$outboundSchema.parse(pqControlsClickHouse),
  );
}
export function pqControlsClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsClickHouse' from JSON`,
  );
}

/** @internal */
export const OutputClickHouse$inboundSchema: z.ZodType<
  OutputClickHouse,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeClickHouse$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    authType: AuthenticationTypeClickHouse$inboundSchema.default("none"),
    database: z.string(),
    tableName: z.string(),
    format: FormatClickHouse$inboundSchema.default(
      "json-compact-each-row-with-names",
    ),
    mappingType: MappingType$inboundSchema.default("automatic"),
    asyncInserts: z.boolean().default(false),
    tls: z.lazy(() => TLSSettingsClientSideClickHouse$inboundSchema).optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderClickHouse$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeClickHouse$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingClickHouse$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsClickHouse$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    dumpFormatErrorsToDisk: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorClickHouse$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamClickHouse$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderClickHouse$inboundSchema))
      .optional(),
    sqlUsername: z.string().optional(),
    waitForAsyncInserts: z.boolean().default(true),
    excludeMappingFields: z.array(z.string()).optional(),
    describeTable: z.string().optional(),
    columnMappings: z.array(z.lazy(() => ColumnMapping$inboundSchema))
      .optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeClickHouse$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionClickHouse$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorClickHouse$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsClickHouse$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputClickHouse$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  authType: string;
  database: string;
  tableName: string;
  format: string;
  mappingType: string;
  asyncInserts: boolean;
  tls?: TLSSettingsClientSideClickHouse$Outbound | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderClickHouse$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingClickHouse$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsClickHouse$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  dumpFormatErrorsToDisk: boolean;
  onBackpressure: string;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamClickHouse$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderClickHouse$Outbound> | undefined;
  sqlUsername?: string | undefined;
  waitForAsyncInserts: boolean;
  excludeMappingFields?: Array<string> | undefined;
  describeTable?: string | undefined;
  columnMappings?: Array<ColumnMapping$Outbound> | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsClickHouse$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputClickHouse$outboundSchema: z.ZodType<
  OutputClickHouse$Outbound,
  z.ZodTypeDef,
  OutputClickHouse
> = z.object({
  id: z.string().optional(),
  type: TypeClickHouse$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  authType: AuthenticationTypeClickHouse$outboundSchema.default("none"),
  database: z.string(),
  tableName: z.string(),
  format: FormatClickHouse$outboundSchema.default(
    "json-compact-each-row-with-names",
  ),
  mappingType: MappingType$outboundSchema.default("automatic"),
  asyncInserts: z.boolean().default(false),
  tls: z.lazy(() => TLSSettingsClientSideClickHouse$outboundSchema).optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderClickHouse$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeClickHouse$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingClickHouse$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsClickHouse$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  dumpFormatErrorsToDisk: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorClickHouse$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamClickHouse$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderClickHouse$outboundSchema))
    .optional(),
  sqlUsername: z.string().optional(),
  waitForAsyncInserts: z.boolean().default(true),
  excludeMappingFields: z.array(z.string()).optional(),
  describeTable: z.string().optional(),
  columnMappings: z.array(z.lazy(() => ColumnMapping$outboundSchema))
    .optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeClickHouse$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionClickHouse$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorClickHouse$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsClickHouse$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputClickHouseToJSON(
  outputClickHouse: OutputClickHouse,
): string {
  return JSON.stringify(
    OutputClickHouse$outboundSchema.parse(outputClickHouse),
  );
}
export function outputClickHouseFromJSON(
  jsonString: string,
): SafeParseResult<OutputClickHouse, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputClickHouse$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputClickHouse' from JSON`,
  );
}

/** @internal */
export const TypeDiskSpool$inboundSchema: z.ZodNativeEnum<
  typeof TypeDiskSpool
> = z.nativeEnum(TypeDiskSpool);
/** @internal */
export const TypeDiskSpool$outboundSchema: z.ZodNativeEnum<
  typeof TypeDiskSpool
> = TypeDiskSpool$inboundSchema;

/** @internal */
export const CompressionDiskSpool$inboundSchema: z.ZodType<
  CompressionDiskSpool,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDiskSpool),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDiskSpool$outboundSchema: z.ZodType<
  CompressionDiskSpool,
  z.ZodTypeDef,
  CompressionDiskSpool
> = z.union([
  z.nativeEnum(CompressionDiskSpool),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputDiskSpool$inboundSchema: z.ZodType<
  OutputDiskSpool,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDiskSpool$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    timeWindow: z.string().default("10m"),
    maxDataSize: z.string().default("1GB"),
    maxDataTime: z.string().default("24h"),
    compress: CompressionDiskSpool$inboundSchema.default("gzip"),
    partitionExpr: z.string().optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDiskSpool$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  partitionExpr?: string | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDiskSpool$outboundSchema: z.ZodType<
  OutputDiskSpool$Outbound,
  z.ZodTypeDef,
  OutputDiskSpool
> = z.object({
  id: z.string().optional(),
  type: TypeDiskSpool$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: CompressionDiskSpool$outboundSchema.default("gzip"),
  partitionExpr: z.string().optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDiskSpoolToJSON(
  outputDiskSpool: OutputDiskSpool,
): string {
  return JSON.stringify(OutputDiskSpool$outboundSchema.parse(outputDiskSpool));
}
export function outputDiskSpoolFromJSON(
  jsonString: string,
): SafeParseResult<OutputDiskSpool, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDiskSpool$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDiskSpool' from JSON`,
  );
}

/** @internal */
export const TypeCriblLake$inboundSchema: z.ZodNativeEnum<
  typeof TypeCriblLake
> = z.nativeEnum(TypeCriblLake);
/** @internal */
export const TypeCriblLake$outboundSchema: z.ZodNativeEnum<
  typeof TypeCriblLake
> = TypeCriblLake$inboundSchema;

/** @internal */
export const SignatureVersionCriblLake$inboundSchema: z.ZodType<
  SignatureVersionCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionCriblLake$outboundSchema: z.ZodType<
  SignatureVersionCriblLake,
  z.ZodTypeDef,
  SignatureVersionCriblLake
> = z.union([
  z.nativeEnum(SignatureVersionCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLCriblLake$inboundSchema: z.ZodType<
  ObjectACLCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLCriblLake$outboundSchema: z.ZodType<
  ObjectACLCriblLake,
  z.ZodTypeDef,
  ObjectACLCriblLake
> = z.union([
  z.nativeEnum(ObjectACLCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassCriblLake$inboundSchema: z.ZodType<
  StorageClassCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassCriblLake$outboundSchema: z.ZodType<
  StorageClassCriblLake,
  z.ZodTypeDef,
  StorageClassCriblLake
> = z.union([
  z.nativeEnum(StorageClassCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionForUploadedObjectsCriblLake$inboundSchema:
  z.ZodType<
    ServerSideEncryptionForUploadedObjectsCriblLake,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(ServerSideEncryptionForUploadedObjectsCriblLake),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ServerSideEncryptionForUploadedObjectsCriblLake$outboundSchema:
  z.ZodType<
    ServerSideEncryptionForUploadedObjectsCriblLake,
    z.ZodTypeDef,
    ServerSideEncryptionForUploadedObjectsCriblLake
  > = z.union([
    z.nativeEnum(ServerSideEncryptionForUploadedObjectsCriblLake),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const BackpressureBehaviorCriblLake$inboundSchema: z.ZodType<
  BackpressureBehaviorCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorCriblLake$outboundSchema: z.ZodType<
  BackpressureBehaviorCriblLake,
  z.ZodTypeDef,
  BackpressureBehaviorCriblLake
> = z.union([
  z.nativeEnum(BackpressureBehaviorCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionCriblLake$inboundSchema: z.ZodType<
  DiskSpaceProtectionCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionCriblLake$outboundSchema: z.ZodType<
  DiskSpaceProtectionCriblLake,
  z.ZodTypeDef,
  DiskSpaceProtectionCriblLake
> = z.union([
  z.nativeEnum(DiskSpaceProtectionCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AwsAuthenticationMethod$inboundSchema: z.ZodType<
  AwsAuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AwsAuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AwsAuthenticationMethod$outboundSchema: z.ZodType<
  AwsAuthenticationMethod,
  z.ZodTypeDef,
  AwsAuthenticationMethod
> = z.union([
  z.nativeEnum(AwsAuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FormatCriblLake$inboundSchema: z.ZodType<
  FormatCriblLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FormatCriblLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FormatCriblLake$outboundSchema: z.ZodType<
  FormatCriblLake,
  z.ZodTypeDef,
  FormatCriblLake
> = z.union([
  z.nativeEnum(FormatCriblLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCriblLake$inboundSchema: z.ZodType<
  OutputCriblLake,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCriblLake$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string().optional(),
    region: z.string().optional(),
    awsSecretKey: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionCriblLake$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    destPath: z.string().optional(),
    objectACL: ObjectACLCriblLake$inboundSchema.default("private"),
    storageClass: StorageClassCriblLake$inboundSchema.optional(),
    serverSideEncryption:
      ServerSideEncryptionForUploadedObjectsCriblLake$inboundSchema.optional(),
    kmsKeyId: z.string().optional(),
    removeEmptyDirs: z.boolean().default(true),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(64),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorCriblLake$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionCriblLake$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(300),
    verifyPermissions: z.boolean().default(true),
    maxClosingFilesToBackpressure: z.number().default(100),
    awsAuthenticationMethod: AwsAuthenticationMethod$inboundSchema.default(
      "auto",
    ),
    format: FormatCriblLake$inboundSchema.optional(),
    maxConcurrentFileParts: z.number().default(1),
    description: z.string().optional(),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCriblLake$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket?: string | undefined;
  region?: string | undefined;
  awsSecretKey?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath?: string | undefined;
  objectACL: string;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  kmsKeyId?: string | undefined;
  removeEmptyDirs: boolean;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  verifyPermissions: boolean;
  maxClosingFilesToBackpressure: number;
  awsAuthenticationMethod: string;
  format?: string | undefined;
  maxConcurrentFileParts: number;
  description?: string | undefined;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCriblLake$outboundSchema: z.ZodType<
  OutputCriblLake$Outbound,
  z.ZodTypeDef,
  OutputCriblLake
> = z.object({
  id: z.string().optional(),
  type: TypeCriblLake$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string().optional(),
  region: z.string().optional(),
  awsSecretKey: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionCriblLake$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().optional(),
  objectACL: ObjectACLCriblLake$outboundSchema.default("private"),
  storageClass: StorageClassCriblLake$outboundSchema.optional(),
  serverSideEncryption:
    ServerSideEncryptionForUploadedObjectsCriblLake$outboundSchema.optional(),
  kmsKeyId: z.string().optional(),
  removeEmptyDirs: z.boolean().default(true),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(64),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorCriblLake$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionCriblLake$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(300),
  verifyPermissions: z.boolean().default(true),
  maxClosingFilesToBackpressure: z.number().default(100),
  awsAuthenticationMethod: AwsAuthenticationMethod$outboundSchema.default(
    "auto",
  ),
  format: FormatCriblLake$outboundSchema.optional(),
  maxConcurrentFileParts: z.number().default(1),
  description: z.string().optional(),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCriblLakeToJSON(
  outputCriblLake: OutputCriblLake,
): string {
  return JSON.stringify(OutputCriblLake$outboundSchema.parse(outputCriblLake));
}
export function outputCriblLakeFromJSON(
  jsonString: string,
): SafeParseResult<OutputCriblLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCriblLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCriblLake' from JSON`,
  );
}

/** @internal */
export const OutputTypeSecurityLake$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSecurityLake
> = z.nativeEnum(OutputTypeSecurityLake);
/** @internal */
export const OutputTypeSecurityLake$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSecurityLake
> = OutputTypeSecurityLake$inboundSchema;

/** @internal */
export const OutputAuthenticationMethodSecurityLake$inboundSchema: z.ZodType<
  OutputAuthenticationMethodSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodSecurityLake$outboundSchema: z.ZodType<
  OutputAuthenticationMethodSecurityLake,
  z.ZodTypeDef,
  OutputAuthenticationMethodSecurityLake
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSignatureVersionSecurityLake$inboundSchema: z.ZodType<
  OutputSignatureVersionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSignatureVersionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSignatureVersionSecurityLake$outboundSchema: z.ZodType<
  OutputSignatureVersionSecurityLake,
  z.ZodTypeDef,
  OutputSignatureVersionSecurityLake
> = z.union([
  z.nativeEnum(OutputSignatureVersionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLSecurityLake$inboundSchema: z.ZodType<
  ObjectACLSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLSecurityLake$outboundSchema: z.ZodType<
  ObjectACLSecurityLake,
  z.ZodTypeDef,
  ObjectACLSecurityLake
> = z.union([
  z.nativeEnum(ObjectACLSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassSecurityLake$inboundSchema: z.ZodType<
  StorageClassSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassSecurityLake$outboundSchema: z.ZodType<
  StorageClassSecurityLake,
  z.ZodTypeDef,
  StorageClassSecurityLake
> = z.union([
  z.nativeEnum(StorageClassSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionForUploadedObjectsSecurityLake$inboundSchema:
  z.ZodType<
    ServerSideEncryptionForUploadedObjectsSecurityLake,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(ServerSideEncryptionForUploadedObjectsSecurityLake),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ServerSideEncryptionForUploadedObjectsSecurityLake$outboundSchema:
  z.ZodType<
    ServerSideEncryptionForUploadedObjectsSecurityLake,
    z.ZodTypeDef,
    ServerSideEncryptionForUploadedObjectsSecurityLake
  > = z.union([
    z.nativeEnum(ServerSideEncryptionForUploadedObjectsSecurityLake),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const BackpressureBehaviorSecurityLake$inboundSchema: z.ZodType<
  BackpressureBehaviorSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSecurityLake$outboundSchema: z.ZodType<
  BackpressureBehaviorSecurityLake,
  z.ZodTypeDef,
  BackpressureBehaviorSecurityLake
> = z.union([
  z.nativeEnum(BackpressureBehaviorSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionSecurityLake$inboundSchema: z.ZodType<
  DiskSpaceProtectionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionSecurityLake$outboundSchema: z.ZodType<
  DiskSpaceProtectionSecurityLake,
  z.ZodTypeDef,
  DiskSpaceProtectionSecurityLake
> = z.union([
  z.nativeEnum(DiskSpaceProtectionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionSecurityLake$inboundSchema: z.ZodType<
  ParquetVersionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionSecurityLake$outboundSchema: z.ZodType<
  ParquetVersionSecurityLake,
  z.ZodTypeDef,
  ParquetVersionSecurityLake
> = z.union([
  z.nativeEnum(ParquetVersionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionSecurityLake$inboundSchema: z.ZodType<
  DataPageVersionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionSecurityLake$outboundSchema: z.ZodType<
  DataPageVersionSecurityLake,
  z.ZodTypeDef,
  DataPageVersionSecurityLake
> = z.union([
  z.nativeEnum(DataPageVersionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumSecurityLake$inboundSchema: z.ZodType<
  KeyValueMetadatumSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumSecurityLake$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumSecurityLake$outboundSchema: z.ZodType<
  KeyValueMetadatumSecurityLake$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumSecurityLake
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumSecurityLakeToJSON(
  keyValueMetadatumSecurityLake: KeyValueMetadatumSecurityLake,
): string {
  return JSON.stringify(
    KeyValueMetadatumSecurityLake$outboundSchema.parse(
      keyValueMetadatumSecurityLake,
    ),
  );
}
export function keyValueMetadatumSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumSecurityLake' from JSON`,
  );
}

/** @internal */
export const OutputSecurityLake$inboundSchema: z.ZodType<
  OutputSecurityLake,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSecurityLake$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string(),
    region: z.string(),
    awsSecretKey: z.string().optional(),
    awsAuthenticationMethod:
      OutputAuthenticationMethodSecurityLake$inboundSchema.default("auto"),
    endpoint: z.string().optional(),
    signatureVersion: OutputSignatureVersionSecurityLake$inboundSchema.default(
      "v4",
    ),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    objectACL: ObjectACLSecurityLake$inboundSchema.default("private"),
    storageClass: StorageClassSecurityLake$inboundSchema.optional(),
    serverSideEncryption:
      ServerSideEncryptionForUploadedObjectsSecurityLake$inboundSchema
        .optional(),
    kmsKeyId: z.string().optional(),
    removeEmptyDirs: z.boolean().default(true),
    baseFileName: z.string().default("`CriblOut`"),
    maxFileSizeMB: z.number().default(32),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorSecurityLake$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionSecurityLake$inboundSchema
      .default("block"),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxConcurrentFileParts: z.number().default(4),
    verifyPermissions: z.boolean().default(true),
    maxClosingFilesToBackpressure: z.number().default(100),
    accountId: z.string(),
    customSource: z.string(),
    automaticSchema: z.boolean().default(false),
    parquetVersion: ParquetVersionSecurityLake$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionSecurityLake$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumSecurityLake$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    parquetSchema: z.string().optional(),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSecurityLake$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region: string;
  awsSecretKey?: string | undefined;
  awsAuthenticationMethod: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn: string;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  stagePath: string;
  addIdToStagePath: boolean;
  objectACL: string;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  kmsKeyId?: string | undefined;
  removeEmptyDirs: boolean;
  baseFileName: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  verifyPermissions: boolean;
  maxClosingFilesToBackpressure: number;
  accountId: string;
  customSource: string;
  automaticSchema: boolean;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumSecurityLake$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  parquetSchema?: string | undefined;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSecurityLake$outboundSchema: z.ZodType<
  OutputSecurityLake$Outbound,
  z.ZodTypeDef,
  OutputSecurityLake
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSecurityLake$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string(),
  awsSecretKey: z.string().optional(),
  awsAuthenticationMethod: OutputAuthenticationMethodSecurityLake$outboundSchema
    .default("auto"),
  endpoint: z.string().optional(),
  signatureVersion: OutputSignatureVersionSecurityLake$outboundSchema.default(
    "v4",
  ),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  objectACL: ObjectACLSecurityLake$outboundSchema.default("private"),
  storageClass: StorageClassSecurityLake$outboundSchema.optional(),
  serverSideEncryption:
    ServerSideEncryptionForUploadedObjectsSecurityLake$outboundSchema
      .optional(),
  kmsKeyId: z.string().optional(),
  removeEmptyDirs: z.boolean().default(true),
  baseFileName: z.string().default("`CriblOut`"),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorSecurityLake$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionSecurityLake$outboundSchema
    .default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  verifyPermissions: z.boolean().default(true),
  maxClosingFilesToBackpressure: z.number().default(100),
  accountId: z.string(),
  customSource: z.string(),
  automaticSchema: z.boolean().default(false),
  parquetVersion: ParquetVersionSecurityLake$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionSecurityLake$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumSecurityLake$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  parquetSchema: z.string().optional(),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSecurityLakeToJSON(
  outputSecurityLake: OutputSecurityLake,
): string {
  return JSON.stringify(
    OutputSecurityLake$outboundSchema.parse(outputSecurityLake),
  );
}
export function outputSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<OutputSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSecurityLake' from JSON`,
  );
}

/** @internal */
export const TypeDlS3$inboundSchema: z.ZodNativeEnum<typeof TypeDlS3> = z
  .nativeEnum(TypeDlS3);
/** @internal */
export const TypeDlS3$outboundSchema: z.ZodNativeEnum<typeof TypeDlS3> =
  TypeDlS3$inboundSchema;

/** @internal */
export const AuthenticationMethodDlS3$inboundSchema: z.ZodType<
  AuthenticationMethodDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodDlS3$outboundSchema: z.ZodType<
  AuthenticationMethodDlS3,
  z.ZodTypeDef,
  AuthenticationMethodDlS3
> = z.union([
  z.nativeEnum(AuthenticationMethodDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionDlS3$inboundSchema: z.ZodType<
  SignatureVersionDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionDlS3$outboundSchema: z.ZodType<
  SignatureVersionDlS3,
  z.ZodTypeDef,
  SignatureVersionDlS3
> = z.union([
  z.nativeEnum(SignatureVersionDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLDlS3$inboundSchema: z.ZodType<
  ObjectACLDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLDlS3$outboundSchema: z.ZodType<
  ObjectACLDlS3,
  z.ZodTypeDef,
  ObjectACLDlS3
> = z.union([
  z.nativeEnum(ObjectACLDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassDlS3$inboundSchema: z.ZodType<
  StorageClassDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassDlS3$outboundSchema: z.ZodType<
  StorageClassDlS3,
  z.ZodTypeDef,
  StorageClassDlS3
> = z.union([
  z.nativeEnum(StorageClassDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionForUploadedObjectsDlS3$inboundSchema:
  z.ZodType<ServerSideEncryptionForUploadedObjectsDlS3, z.ZodTypeDef, unknown> =
    z
      .union([
        z.nativeEnum(ServerSideEncryptionForUploadedObjectsDlS3),
        z.string().transform(catchUnrecognizedEnum),
      ]);
/** @internal */
export const ServerSideEncryptionForUploadedObjectsDlS3$outboundSchema:
  z.ZodType<
    ServerSideEncryptionForUploadedObjectsDlS3,
    z.ZodTypeDef,
    ServerSideEncryptionForUploadedObjectsDlS3
  > = z.union([
    z.nativeEnum(ServerSideEncryptionForUploadedObjectsDlS3),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const DataFormatDlS3$inboundSchema: z.ZodType<
  DataFormatDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatDlS3$outboundSchema: z.ZodType<
  DataFormatDlS3,
  z.ZodTypeDef,
  DataFormatDlS3
> = z.union([
  z.nativeEnum(DataFormatDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorDlS3$inboundSchema: z.ZodType<
  BackpressureBehaviorDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDlS3$outboundSchema: z.ZodType<
  BackpressureBehaviorDlS3,
  z.ZodTypeDef,
  BackpressureBehaviorDlS3
> = z.union([
  z.nativeEnum(BackpressureBehaviorDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionDlS3$inboundSchema: z.ZodType<
  DiskSpaceProtectionDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionDlS3$outboundSchema: z.ZodType<
  DiskSpaceProtectionDlS3,
  z.ZodTypeDef,
  DiskSpaceProtectionDlS3
> = z.union([
  z.nativeEnum(DiskSpaceProtectionDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDlS3$inboundSchema: z.ZodType<
  CompressionDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDlS3$outboundSchema: z.ZodType<
  CompressionDlS3,
  z.ZodTypeDef,
  CompressionDlS3
> = z.union([
  z.nativeEnum(CompressionDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelDlS3$inboundSchema: z.ZodType<
  CompressionLevelDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelDlS3$outboundSchema: z.ZodType<
  CompressionLevelDlS3,
  z.ZodTypeDef,
  CompressionLevelDlS3
> = z.union([
  z.nativeEnum(CompressionLevelDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionDlS3$inboundSchema: z.ZodType<
  ParquetVersionDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionDlS3$outboundSchema: z.ZodType<
  ParquetVersionDlS3,
  z.ZodTypeDef,
  ParquetVersionDlS3
> = z.union([
  z.nativeEnum(ParquetVersionDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionDlS3$inboundSchema: z.ZodType<
  DataPageVersionDlS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionDlS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionDlS3$outboundSchema: z.ZodType<
  DataPageVersionDlS3,
  z.ZodTypeDef,
  DataPageVersionDlS3
> = z.union([
  z.nativeEnum(DataPageVersionDlS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumDlS3$inboundSchema: z.ZodType<
  KeyValueMetadatumDlS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumDlS3$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumDlS3$outboundSchema: z.ZodType<
  KeyValueMetadatumDlS3$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumDlS3
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumDlS3ToJSON(
  keyValueMetadatumDlS3: KeyValueMetadatumDlS3,
): string {
  return JSON.stringify(
    KeyValueMetadatumDlS3$outboundSchema.parse(keyValueMetadatumDlS3),
  );
}
export function keyValueMetadatumDlS3FromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumDlS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumDlS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumDlS3' from JSON`,
  );
}

/** @internal */
export const OutputDlS3$inboundSchema: z.ZodType<
  OutputDlS3,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDlS3$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string(),
    region: z.string().optional(),
    awsSecretKey: z.string().optional(),
    awsAuthenticationMethod: AuthenticationMethodDlS3$inboundSchema.default(
      "auto",
    ),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionDlS3$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    destPath: z.string().default(""),
    objectACL: ObjectACLDlS3$inboundSchema.default("private"),
    storageClass: StorageClassDlS3$inboundSchema.optional(),
    serverSideEncryption:
      ServerSideEncryptionForUploadedObjectsDlS3$inboundSchema.optional(),
    kmsKeyId: z.string().optional(),
    removeEmptyDirs: z.boolean().default(true),
    format: DataFormatDlS3$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorDlS3$inboundSchema.default("block"),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionDlS3$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxConcurrentFileParts: z.number().default(4),
    verifyPermissions: z.boolean().default(true),
    maxClosingFilesToBackpressure: z.number().default(100),
    partitioningFields: z.array(z.string()).optional(),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    compress: CompressionDlS3$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelDlS3$inboundSchema.default("best_speed"),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionDlS3$inboundSchema.default("PARQUET_2_6"),
    parquetDataPageVersion: DataPageVersionDlS3$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(z.lazy(() => KeyValueMetadatumDlS3$inboundSchema))
      .optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDlS3$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region?: string | undefined;
  awsSecretKey?: string | undefined;
  awsAuthenticationMethod: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath: string;
  objectACL: string;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  kmsKeyId?: string | undefined;
  removeEmptyDirs: boolean;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  verifyPermissions: boolean;
  maxClosingFilesToBackpressure: number;
  partitioningFields?: Array<string> | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumDlS3$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDlS3$outboundSchema: z.ZodType<
  OutputDlS3$Outbound,
  z.ZodTypeDef,
  OutputDlS3
> = z.object({
  id: z.string().optional(),
  type: TypeDlS3$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsAuthenticationMethod: AuthenticationMethodDlS3$outboundSchema.default(
    "auto",
  ),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionDlS3$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().default(""),
  objectACL: ObjectACLDlS3$outboundSchema.default("private"),
  storageClass: StorageClassDlS3$outboundSchema.optional(),
  serverSideEncryption:
    ServerSideEncryptionForUploadedObjectsDlS3$outboundSchema.optional(),
  kmsKeyId: z.string().optional(),
  removeEmptyDirs: z.boolean().default(true),
  format: DataFormatDlS3$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorDlS3$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionDlS3$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  verifyPermissions: z.boolean().default(true),
  maxClosingFilesToBackpressure: z.number().default(100),
  partitioningFields: z.array(z.string()).optional(),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: CompressionDlS3$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelDlS3$outboundSchema.default("best_speed"),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionDlS3$outboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionDlS3$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(z.lazy(() => KeyValueMetadatumDlS3$outboundSchema))
    .optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDlS3ToJSON(outputDlS3: OutputDlS3): string {
  return JSON.stringify(OutputDlS3$outboundSchema.parse(outputDlS3));
}
export function outputDlS3FromJSON(
  jsonString: string,
): SafeParseResult<OutputDlS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDlS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDlS3' from JSON`,
  );
}

/** @internal */
export const TypeCrowdstrikeNextGenSiem$inboundSchema: z.ZodNativeEnum<
  typeof TypeCrowdstrikeNextGenSiem
> = z.nativeEnum(TypeCrowdstrikeNextGenSiem);
/** @internal */
export const TypeCrowdstrikeNextGenSiem$outboundSchema: z.ZodNativeEnum<
  typeof TypeCrowdstrikeNextGenSiem
> = TypeCrowdstrikeNextGenSiem$inboundSchema;

/** @internal */
export const ExtraHttpHeaderCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  ExtraHttpHeaderCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderCrowdstrikeNextGenSiem$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  ExtraHttpHeaderCrowdstrikeNextGenSiem$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderCrowdstrikeNextGenSiem
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderCrowdstrikeNextGenSiemToJSON(
  extraHttpHeaderCrowdstrikeNextGenSiem: ExtraHttpHeaderCrowdstrikeNextGenSiem,
): string {
  return JSON.stringify(
    ExtraHttpHeaderCrowdstrikeNextGenSiem$outboundSchema.parse(
      extraHttpHeaderCrowdstrikeNextGenSiem,
    ),
  );
}
export function extraHttpHeaderCrowdstrikeNextGenSiemFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderCrowdstrikeNextGenSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      ExtraHttpHeaderCrowdstrikeNextGenSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderCrowdstrikeNextGenSiem' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeCrowdstrikeNextGenSiem$inboundSchema:
  z.ZodType<
    FailedRequestLoggingModeCrowdstrikeNextGenSiem,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(FailedRequestLoggingModeCrowdstrikeNextGenSiem),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const FailedRequestLoggingModeCrowdstrikeNextGenSiem$outboundSchema:
  z.ZodType<
    FailedRequestLoggingModeCrowdstrikeNextGenSiem,
    z.ZodTypeDef,
    FailedRequestLoggingModeCrowdstrikeNextGenSiem
  > = z.union([
    z.nativeEnum(FailedRequestLoggingModeCrowdstrikeNextGenSiem),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const RequestFormatCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  RequestFormatCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RequestFormatCrowdstrikeNextGenSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RequestFormatCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  RequestFormatCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  RequestFormatCrowdstrikeNextGenSiem
> = z.union([
  z.nativeEnum(RequestFormatCrowdstrikeNextGenSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodCrowdstrikeNextGenSiem$inboundSchema:
  z.ZodType<AuthenticationMethodCrowdstrikeNextGenSiem, z.ZodTypeDef, unknown> =
    z
      .union([
        z.nativeEnum(AuthenticationMethodCrowdstrikeNextGenSiem),
        z.string().transform(catchUnrecognizedEnum),
      ]);
/** @internal */
export const AuthenticationMethodCrowdstrikeNextGenSiem$outboundSchema:
  z.ZodType<
    AuthenticationMethodCrowdstrikeNextGenSiem,
    z.ZodTypeDef,
    AuthenticationMethodCrowdstrikeNextGenSiem
  > = z.union([
    z.nativeEnum(AuthenticationMethodCrowdstrikeNextGenSiem),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const ResponseRetrySettingCrowdstrikeNextGenSiem$inboundSchema:
  z.ZodType<ResponseRetrySettingCrowdstrikeNextGenSiem, z.ZodTypeDef, unknown> =
    z.object({
      httpStatus: z.number(),
      initialBackoff: z.number().default(1000),
      backoffRate: z.number().default(2),
      maxBackoff: z.number().default(10000),
    });
/** @internal */
export type ResponseRetrySettingCrowdstrikeNextGenSiem$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingCrowdstrikeNextGenSiem$outboundSchema:
  z.ZodType<
    ResponseRetrySettingCrowdstrikeNextGenSiem$Outbound,
    z.ZodTypeDef,
    ResponseRetrySettingCrowdstrikeNextGenSiem
  > = z.object({
    httpStatus: z.number(),
    initialBackoff: z.number().default(1000),
    backoffRate: z.number().default(2),
    maxBackoff: z.number().default(10000),
  });

export function responseRetrySettingCrowdstrikeNextGenSiemToJSON(
  responseRetrySettingCrowdstrikeNextGenSiem:
    ResponseRetrySettingCrowdstrikeNextGenSiem,
): string {
  return JSON.stringify(
    ResponseRetrySettingCrowdstrikeNextGenSiem$outboundSchema.parse(
      responseRetrySettingCrowdstrikeNextGenSiem,
    ),
  );
}
export function responseRetrySettingCrowdstrikeNextGenSiemFromJSON(
  jsonString: string,
): SafeParseResult<
  ResponseRetrySettingCrowdstrikeNextGenSiem,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      ResponseRetrySettingCrowdstrikeNextGenSiem$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'ResponseRetrySettingCrowdstrikeNextGenSiem' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsCrowdstrikeNextGenSiem$inboundSchema:
  z.ZodType<TimeoutRetrySettingsCrowdstrikeNextGenSiem, z.ZodTypeDef, unknown> =
    z.object({
      timeoutRetry: z.boolean().default(false),
      initialBackoff: z.number().default(1000),
      backoffRate: z.number().default(2),
      maxBackoff: z.number().default(10000),
    });
/** @internal */
export type TimeoutRetrySettingsCrowdstrikeNextGenSiem$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsCrowdstrikeNextGenSiem$outboundSchema:
  z.ZodType<
    TimeoutRetrySettingsCrowdstrikeNextGenSiem$Outbound,
    z.ZodTypeDef,
    TimeoutRetrySettingsCrowdstrikeNextGenSiem
  > = z.object({
    timeoutRetry: z.boolean().default(false),
    initialBackoff: z.number().default(1000),
    backoffRate: z.number().default(2),
    maxBackoff: z.number().default(10000),
  });

export function timeoutRetrySettingsCrowdstrikeNextGenSiemToJSON(
  timeoutRetrySettingsCrowdstrikeNextGenSiem:
    TimeoutRetrySettingsCrowdstrikeNextGenSiem,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsCrowdstrikeNextGenSiem$outboundSchema.parse(
      timeoutRetrySettingsCrowdstrikeNextGenSiem,
    ),
  );
}
export function timeoutRetrySettingsCrowdstrikeNextGenSiemFromJSON(
  jsonString: string,
): SafeParseResult<
  TimeoutRetrySettingsCrowdstrikeNextGenSiem,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      TimeoutRetrySettingsCrowdstrikeNextGenSiem$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'TimeoutRetrySettingsCrowdstrikeNextGenSiem' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorCrowdstrikeNextGenSiem$inboundSchema:
  z.ZodType<BackpressureBehaviorCrowdstrikeNextGenSiem, z.ZodTypeDef, unknown> =
    z
      .union([
        z.nativeEnum(BackpressureBehaviorCrowdstrikeNextGenSiem),
        z.string().transform(catchUnrecognizedEnum),
      ]);
/** @internal */
export const BackpressureBehaviorCrowdstrikeNextGenSiem$outboundSchema:
  z.ZodType<
    BackpressureBehaviorCrowdstrikeNextGenSiem,
    z.ZodTypeDef,
    BackpressureBehaviorCrowdstrikeNextGenSiem
  > = z.union([
    z.nativeEnum(BackpressureBehaviorCrowdstrikeNextGenSiem),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const ModeCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  ModeCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCrowdstrikeNextGenSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  ModeCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  ModeCrowdstrikeNextGenSiem
> = z.union([
  z.nativeEnum(ModeCrowdstrikeNextGenSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  CompressionCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCrowdstrikeNextGenSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  CompressionCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  CompressionCrowdstrikeNextGenSiem
> = z.union([
  z.nativeEnum(CompressionCrowdstrikeNextGenSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  QueueFullBehaviorCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorCrowdstrikeNextGenSiem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  QueueFullBehaviorCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  QueueFullBehaviorCrowdstrikeNextGenSiem
> = z.union([
  z.nativeEnum(QueueFullBehaviorCrowdstrikeNextGenSiem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  PqControlsCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCrowdstrikeNextGenSiem$Outbound = {};

/** @internal */
export const PqControlsCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  PqControlsCrowdstrikeNextGenSiem$Outbound,
  z.ZodTypeDef,
  PqControlsCrowdstrikeNextGenSiem
> = z.object({});

export function pqControlsCrowdstrikeNextGenSiemToJSON(
  pqControlsCrowdstrikeNextGenSiem: PqControlsCrowdstrikeNextGenSiem,
): string {
  return JSON.stringify(
    PqControlsCrowdstrikeNextGenSiem$outboundSchema.parse(
      pqControlsCrowdstrikeNextGenSiem,
    ),
  );
}
export function pqControlsCrowdstrikeNextGenSiemFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCrowdstrikeNextGenSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCrowdstrikeNextGenSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCrowdstrikeNextGenSiem' from JSON`,
  );
}

/** @internal */
export const OutputCrowdstrikeNextGenSiem$inboundSchema: z.ZodType<
  OutputCrowdstrikeNextGenSiem,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCrowdstrikeNextGenSiem$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderCrowdstrikeNextGenSiem$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(true),
    failedRequestLoggingMode:
      FailedRequestLoggingModeCrowdstrikeNextGenSiem$inboundSchema.default(
        "none",
      ),
    safeHeaders: z.array(z.string()).optional(),
    format: RequestFormatCrowdstrikeNextGenSiem$inboundSchema.default("JSON"),
    authType: AuthenticationMethodCrowdstrikeNextGenSiem$inboundSchema.default(
      "manual",
    ),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingCrowdstrikeNextGenSiem$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsCrowdstrikeNextGenSiem$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorCrowdstrikeNextGenSiem$inboundSchema
      .default("block"),
    description: z.string().optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeCrowdstrikeNextGenSiem$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionCrowdstrikeNextGenSiem$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorCrowdstrikeNextGenSiem$inboundSchema
      .default("block"),
    pqControls: z.lazy(() => PqControlsCrowdstrikeNextGenSiem$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCrowdstrikeNextGenSiem$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?:
    | Array<ExtraHttpHeaderCrowdstrikeNextGenSiem$Outbound>
    | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  format: string;
  authType: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingCrowdstrikeNextGenSiem$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | TimeoutRetrySettingsCrowdstrikeNextGenSiem$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsCrowdstrikeNextGenSiem$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCrowdstrikeNextGenSiem$outboundSchema: z.ZodType<
  OutputCrowdstrikeNextGenSiem$Outbound,
  z.ZodTypeDef,
  OutputCrowdstrikeNextGenSiem
> = z.object({
  id: z.string().optional(),
  type: TypeCrowdstrikeNextGenSiem$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderCrowdstrikeNextGenSiem$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(true),
  failedRequestLoggingMode:
    FailedRequestLoggingModeCrowdstrikeNextGenSiem$outboundSchema.default(
      "none",
    ),
  safeHeaders: z.array(z.string()).optional(),
  format: RequestFormatCrowdstrikeNextGenSiem$outboundSchema.default("JSON"),
  authType: AuthenticationMethodCrowdstrikeNextGenSiem$outboundSchema.default(
    "manual",
  ),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingCrowdstrikeNextGenSiem$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsCrowdstrikeNextGenSiem$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorCrowdstrikeNextGenSiem$outboundSchema
    .default("block"),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeCrowdstrikeNextGenSiem$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionCrowdstrikeNextGenSiem$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorCrowdstrikeNextGenSiem$outboundSchema
    .default("block"),
  pqControls: z.lazy(() => PqControlsCrowdstrikeNextGenSiem$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCrowdstrikeNextGenSiemToJSON(
  outputCrowdstrikeNextGenSiem: OutputCrowdstrikeNextGenSiem,
): string {
  return JSON.stringify(
    OutputCrowdstrikeNextGenSiem$outboundSchema.parse(
      outputCrowdstrikeNextGenSiem,
    ),
  );
}
export function outputCrowdstrikeNextGenSiemFromJSON(
  jsonString: string,
): SafeParseResult<OutputCrowdstrikeNextGenSiem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCrowdstrikeNextGenSiem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCrowdstrikeNextGenSiem' from JSON`,
  );
}

/** @internal */
export const TypeHumioHec$inboundSchema: z.ZodNativeEnum<typeof TypeHumioHec> =
  z.nativeEnum(TypeHumioHec);
/** @internal */
export const TypeHumioHec$outboundSchema: z.ZodNativeEnum<typeof TypeHumioHec> =
  TypeHumioHec$inboundSchema;

/** @internal */
export const ExtraHttpHeaderHumioHec$inboundSchema: z.ZodType<
  ExtraHttpHeaderHumioHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderHumioHec$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderHumioHec$outboundSchema: z.ZodType<
  ExtraHttpHeaderHumioHec$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderHumioHec
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderHumioHecToJSON(
  extraHttpHeaderHumioHec: ExtraHttpHeaderHumioHec,
): string {
  return JSON.stringify(
    ExtraHttpHeaderHumioHec$outboundSchema.parse(extraHttpHeaderHumioHec),
  );
}
export function extraHttpHeaderHumioHecFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderHumioHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderHumioHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderHumioHec' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeHumioHec$inboundSchema: z.ZodType<
  FailedRequestLoggingModeHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeHumioHec$outboundSchema: z.ZodType<
  FailedRequestLoggingModeHumioHec,
  z.ZodTypeDef,
  FailedRequestLoggingModeHumioHec
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RequestFormatHumioHec$inboundSchema: z.ZodType<
  RequestFormatHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RequestFormatHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RequestFormatHumioHec$outboundSchema: z.ZodType<
  RequestFormatHumioHec,
  z.ZodTypeDef,
  RequestFormatHumioHec
> = z.union([
  z.nativeEnum(RequestFormatHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodHumioHec$inboundSchema: z.ZodType<
  AuthenticationMethodHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodHumioHec$outboundSchema: z.ZodType<
  AuthenticationMethodHumioHec,
  z.ZodTypeDef,
  AuthenticationMethodHumioHec
> = z.union([
  z.nativeEnum(AuthenticationMethodHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingHumioHec$inboundSchema: z.ZodType<
  ResponseRetrySettingHumioHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingHumioHec$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingHumioHec$outboundSchema: z.ZodType<
  ResponseRetrySettingHumioHec$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingHumioHec
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingHumioHecToJSON(
  responseRetrySettingHumioHec: ResponseRetrySettingHumioHec,
): string {
  return JSON.stringify(
    ResponseRetrySettingHumioHec$outboundSchema.parse(
      responseRetrySettingHumioHec,
    ),
  );
}
export function responseRetrySettingHumioHecFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingHumioHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingHumioHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingHumioHec' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsHumioHec$inboundSchema: z.ZodType<
  TimeoutRetrySettingsHumioHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsHumioHec$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsHumioHec$outboundSchema: z.ZodType<
  TimeoutRetrySettingsHumioHec$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsHumioHec
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsHumioHecToJSON(
  timeoutRetrySettingsHumioHec: TimeoutRetrySettingsHumioHec,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsHumioHec$outboundSchema.parse(
      timeoutRetrySettingsHumioHec,
    ),
  );
}
export function timeoutRetrySettingsHumioHecFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsHumioHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsHumioHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsHumioHec' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorHumioHec$inboundSchema: z.ZodType<
  BackpressureBehaviorHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorHumioHec$outboundSchema: z.ZodType<
  BackpressureBehaviorHumioHec,
  z.ZodTypeDef,
  BackpressureBehaviorHumioHec
> = z.union([
  z.nativeEnum(BackpressureBehaviorHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeHumioHec$inboundSchema: z.ZodType<
  ModeHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeHumioHec$outboundSchema: z.ZodType<
  ModeHumioHec,
  z.ZodTypeDef,
  ModeHumioHec
> = z.union([
  z.nativeEnum(ModeHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionHumioHec$inboundSchema: z.ZodType<
  CompressionHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionHumioHec$outboundSchema: z.ZodType<
  CompressionHumioHec,
  z.ZodTypeDef,
  CompressionHumioHec
> = z.union([
  z.nativeEnum(CompressionHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorHumioHec$inboundSchema: z.ZodType<
  QueueFullBehaviorHumioHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorHumioHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorHumioHec$outboundSchema: z.ZodType<
  QueueFullBehaviorHumioHec,
  z.ZodTypeDef,
  QueueFullBehaviorHumioHec
> = z.union([
  z.nativeEnum(QueueFullBehaviorHumioHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsHumioHec$inboundSchema: z.ZodType<
  PqControlsHumioHec,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsHumioHec$Outbound = {};

/** @internal */
export const PqControlsHumioHec$outboundSchema: z.ZodType<
  PqControlsHumioHec$Outbound,
  z.ZodTypeDef,
  PqControlsHumioHec
> = z.object({});

export function pqControlsHumioHecToJSON(
  pqControlsHumioHec: PqControlsHumioHec,
): string {
  return JSON.stringify(
    PqControlsHumioHec$outboundSchema.parse(pqControlsHumioHec),
  );
}
export function pqControlsHumioHecFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsHumioHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsHumioHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsHumioHec' from JSON`,
  );
}

/** @internal */
export const OutputHumioHec$inboundSchema: z.ZodType<
  OutputHumioHec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeHumioHec$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string().default("https://cloud.us.humio.com/api/v1/ingest/hec"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderHumioHec$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(true),
    failedRequestLoggingMode: FailedRequestLoggingModeHumioHec$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    format: RequestFormatHumioHec$inboundSchema.default("JSON"),
    authType: AuthenticationMethodHumioHec$inboundSchema.default("manual"),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingHumioHec$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsHumioHec$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorHumioHec$inboundSchema.default("block"),
    description: z.string().optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeHumioHec$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionHumioHec$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorHumioHec$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsHumioHec$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputHumioHec$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderHumioHec$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  format: string;
  authType: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingHumioHec$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsHumioHec$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsHumioHec$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputHumioHec$outboundSchema: z.ZodType<
  OutputHumioHec$Outbound,
  z.ZodTypeDef,
  OutputHumioHec
> = z.object({
  id: z.string().optional(),
  type: TypeHumioHec$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string().default("https://cloud.us.humio.com/api/v1/ingest/hec"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderHumioHec$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(true),
  failedRequestLoggingMode: FailedRequestLoggingModeHumioHec$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  format: RequestFormatHumioHec$outboundSchema.default("JSON"),
  authType: AuthenticationMethodHumioHec$outboundSchema.default("manual"),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingHumioHec$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsHumioHec$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorHumioHec$outboundSchema.default("block"),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeHumioHec$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionHumioHec$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorHumioHec$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsHumioHec$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputHumioHecToJSON(outputHumioHec: OutputHumioHec): string {
  return JSON.stringify(OutputHumioHec$outboundSchema.parse(outputHumioHec));
}
export function outputHumioHecFromJSON(
  jsonString: string,
): SafeParseResult<OutputHumioHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputHumioHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputHumioHec' from JSON`,
  );
}

/** @internal */
export const OutputTypeCriblHTTP$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeCriblHTTP
> = z.nativeEnum(OutputTypeCriblHTTP);
/** @internal */
export const OutputTypeCriblHTTP$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeCriblHTTP
> = OutputTypeCriblHTTP$inboundSchema;

/** @internal */
export const OutputMinimumTLSVersionCriblHTTP$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionCriblHTTP$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  OutputMinimumTLSVersionCriblHTTP
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionCriblHTTP$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionCriblHTTP$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  OutputMaximumTLSVersionCriblHTTP
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideCriblHTTP$inboundSchema: z.ZodType<
  TLSSettingsClientSideCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionCriblHTTP$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionCriblHTTP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideCriblHTTP$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideCriblHTTP$outboundSchema: z.ZodType<
  TLSSettingsClientSideCriblHTTP$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideCriblHTTP
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionCriblHTTP$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionCriblHTTP$outboundSchema.optional(),
});

export function tlsSettingsClientSideCriblHTTPToJSON(
  tlsSettingsClientSideCriblHTTP: TLSSettingsClientSideCriblHTTP,
): string {
  return JSON.stringify(
    TLSSettingsClientSideCriblHTTP$outboundSchema.parse(
      tlsSettingsClientSideCriblHTTP,
    ),
  );
}
export function tlsSettingsClientSideCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideCriblHTTP' from JSON`,
  );
}

/** @internal */
export const OutputCompressionCriblHTTP$inboundSchema: z.ZodType<
  OutputCompressionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionCriblHTTP$outboundSchema: z.ZodType<
  OutputCompressionCriblHTTP,
  z.ZodTypeDef,
  OutputCompressionCriblHTTP
> = z.union([
  z.nativeEnum(OutputCompressionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHTTPHeaderCriblHTTP$inboundSchema: z.ZodType<
  ExtraHTTPHeaderCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHTTPHeaderCriblHTTP$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHTTPHeaderCriblHTTP$outboundSchema: z.ZodType<
  ExtraHTTPHeaderCriblHTTP$Outbound,
  z.ZodTypeDef,
  ExtraHTTPHeaderCriblHTTP
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHTTPHeaderCriblHTTPToJSON(
  extraHTTPHeaderCriblHTTP: ExtraHTTPHeaderCriblHTTP,
): string {
  return JSON.stringify(
    ExtraHTTPHeaderCriblHTTP$outboundSchema.parse(extraHTTPHeaderCriblHTTP),
  );
}
export function extraHTTPHeaderCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHTTPHeaderCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHTTPHeaderCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHTTPHeaderCriblHTTP' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeCriblHTTP$inboundSchema: z.ZodType<
  FailedRequestLoggingModeCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeCriblHTTP$outboundSchema: z.ZodType<
  FailedRequestLoggingModeCriblHTTP,
  z.ZodTypeDef,
  FailedRequestLoggingModeCriblHTTP
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingCriblHTTP$inboundSchema: z.ZodType<
  ResponseRetrySettingCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingCriblHTTP$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingCriblHTTP$outboundSchema: z.ZodType<
  ResponseRetrySettingCriblHTTP$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingCriblHTTP
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingCriblHTTPToJSON(
  responseRetrySettingCriblHTTP: ResponseRetrySettingCriblHTTP,
): string {
  return JSON.stringify(
    ResponseRetrySettingCriblHTTP$outboundSchema.parse(
      responseRetrySettingCriblHTTP,
    ),
  );
}
export function responseRetrySettingCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingCriblHTTP' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsCriblHTTP$inboundSchema: z.ZodType<
  TimeoutRetrySettingsCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(true),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsCriblHTTP$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsCriblHTTP$outboundSchema: z.ZodType<
  TimeoutRetrySettingsCriblHTTP$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsCriblHTTP
> = z.object({
  timeoutRetry: z.boolean().default(true),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsCriblHTTPToJSON(
  timeoutRetrySettingsCriblHTTP: TimeoutRetrySettingsCriblHTTP,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsCriblHTTP$outboundSchema.parse(
      timeoutRetrySettingsCriblHTTP,
    ),
  );
}
export function timeoutRetrySettingsCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsCriblHTTP' from JSON`,
  );
}

/** @internal */
export const OutputAuthTokenCriblHTTP$inboundSchema: z.ZodType<
  OutputAuthTokenCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});
/** @internal */
export type OutputAuthTokenCriblHTTP$Outbound = {
  tokenSecret: string;
  enabled: boolean;
  description?: string | undefined;
};

/** @internal */
export const OutputAuthTokenCriblHTTP$outboundSchema: z.ZodType<
  OutputAuthTokenCriblHTTP$Outbound,
  z.ZodTypeDef,
  OutputAuthTokenCriblHTTP
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});

export function outputAuthTokenCriblHTTPToJSON(
  outputAuthTokenCriblHTTP: OutputAuthTokenCriblHTTP,
): string {
  return JSON.stringify(
    OutputAuthTokenCriblHTTP$outboundSchema.parse(outputAuthTokenCriblHTTP),
  );
}
export function outputAuthTokenCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthTokenCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthTokenCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthTokenCriblHTTP' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorCriblHTTP$inboundSchema: z.ZodType<
  BackpressureBehaviorCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorCriblHTTP$outboundSchema: z.ZodType<
  BackpressureBehaviorCriblHTTP,
  z.ZodTypeDef,
  BackpressureBehaviorCriblHTTP
> = z.union([
  z.nativeEnum(BackpressureBehaviorCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const UrlCriblHTTP$inboundSchema: z.ZodType<
  UrlCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});
/** @internal */
export type UrlCriblHTTP$Outbound = {
  url: string;
  weight: number;
};

/** @internal */
export const UrlCriblHTTP$outboundSchema: z.ZodType<
  UrlCriblHTTP$Outbound,
  z.ZodTypeDef,
  UrlCriblHTTP
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});

export function urlCriblHTTPToJSON(urlCriblHTTP: UrlCriblHTTP): string {
  return JSON.stringify(UrlCriblHTTP$outboundSchema.parse(urlCriblHTTP));
}
export function urlCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<UrlCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UrlCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UrlCriblHTTP' from JSON`,
  );
}

/** @internal */
export const OutputModeCriblHTTP$inboundSchema: z.ZodType<
  OutputModeCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeCriblHTTP$outboundSchema: z.ZodType<
  OutputModeCriblHTTP,
  z.ZodTypeDef,
  OutputModeCriblHTTP
> = z.union([
  z.nativeEnum(OutputModeCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionCriblHTTP$inboundSchema: z.ZodType<
  PqCompressCompressionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionCriblHTTP$outboundSchema: z.ZodType<
  PqCompressCompressionCriblHTTP,
  z.ZodTypeDef,
  PqCompressCompressionCriblHTTP
> = z.union([
  z.nativeEnum(PqCompressCompressionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorCriblHTTP$inboundSchema: z.ZodType<
  QueueFullBehaviorCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorCriblHTTP$outboundSchema: z.ZodType<
  QueueFullBehaviorCriblHTTP,
  z.ZodTypeDef,
  QueueFullBehaviorCriblHTTP
> = z.union([
  z.nativeEnum(QueueFullBehaviorCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsCriblHTTP$inboundSchema: z.ZodType<
  OutputPqControlsCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsCriblHTTP$Outbound = {};

/** @internal */
export const OutputPqControlsCriblHTTP$outboundSchema: z.ZodType<
  OutputPqControlsCriblHTTP$Outbound,
  z.ZodTypeDef,
  OutputPqControlsCriblHTTP
> = z.object({});

export function outputPqControlsCriblHTTPToJSON(
  outputPqControlsCriblHTTP: OutputPqControlsCriblHTTP,
): string {
  return JSON.stringify(
    OutputPqControlsCriblHTTP$outboundSchema.parse(outputPqControlsCriblHTTP),
  );
}
export function outputPqControlsCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsCriblHTTP' from JSON`,
  );
}

/** @internal */
export const OutputCriblHttp$inboundSchema: z.ZodType<
  OutputCriblHttp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeCriblHTTP$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(true),
    tls: z.lazy(() => TLSSettingsClientSideCriblHTTP$inboundSchema).optional(),
    tokenTTLMinutes: z.number().default(60),
    excludeFields: z.array(z.string()).optional(),
    compression: OutputCompressionCriblHTTP$inboundSchema.default("gzip"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHTTPHeaderCriblHTTP$inboundSchema),
    ).optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeCriblHTTP$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingCriblHTTP$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsCriblHTTP$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    authTokens: z.array(z.lazy(() => OutputAuthTokenCriblHTTP$inboundSchema))
      .optional(),
    onBackpressure: BackpressureBehaviorCriblHTTP$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    url: z.string().optional(),
    useRoundRobinDns: z.boolean().default(false),
    excludeSelf: z.boolean().default(false),
    urls: z.array(z.lazy(() => UrlCriblHTTP$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeCriblHTTP$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionCriblHTTP$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorCriblHTTP$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsCriblHTTP$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCriblHttp$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  tls?: TLSSettingsClientSideCriblHTTP$Outbound | undefined;
  tokenTTLMinutes: number;
  excludeFields?: Array<string> | undefined;
  compression: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHTTPHeaderCriblHTTP$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingCriblHTTP$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsCriblHTTP$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  authTokens?: Array<OutputAuthTokenCriblHTTP$Outbound> | undefined;
  onBackpressure: string;
  description?: string | undefined;
  url?: string | undefined;
  useRoundRobinDns: boolean;
  excludeSelf: boolean;
  urls?: Array<UrlCriblHTTP$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsCriblHTTP$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCriblHttp$outboundSchema: z.ZodType<
  OutputCriblHttp$Outbound,
  z.ZodTypeDef,
  OutputCriblHttp
> = z.object({
  id: z.string().optional(),
  type: OutputTypeCriblHTTP$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(true),
  tls: z.lazy(() => TLSSettingsClientSideCriblHTTP$outboundSchema).optional(),
  tokenTTLMinutes: z.number().default(60),
  excludeFields: z.array(z.string()).optional(),
  compression: OutputCompressionCriblHTTP$outboundSchema.default("gzip"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHTTPHeaderCriblHTTP$outboundSchema),
  ).optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeCriblHTTP$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingCriblHTTP$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsCriblHTTP$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  authTokens: z.array(z.lazy(() => OutputAuthTokenCriblHTTP$outboundSchema))
    .optional(),
  onBackpressure: BackpressureBehaviorCriblHTTP$outboundSchema.default("block"),
  description: z.string().optional(),
  url: z.string().optional(),
  useRoundRobinDns: z.boolean().default(false),
  excludeSelf: z.boolean().default(false),
  urls: z.array(z.lazy(() => UrlCriblHTTP$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeCriblHTTP$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionCriblHTTP$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorCriblHTTP$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsCriblHTTP$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCriblHttpToJSON(
  outputCriblHttp: OutputCriblHttp,
): string {
  return JSON.stringify(OutputCriblHttp$outboundSchema.parse(outputCriblHttp));
}
export function outputCriblHttpFromJSON(
  jsonString: string,
): SafeParseResult<OutputCriblHttp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCriblHttp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCriblHttp' from JSON`,
  );
}

/** @internal */
export const OutputTypeCriblTCP$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeCriblTCP
> = z.nativeEnum(OutputTypeCriblTCP);
/** @internal */
export const OutputTypeCriblTCP$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeCriblTCP
> = OutputTypeCriblTCP$inboundSchema;

/** @internal */
export const OutputCompressionCriblTCP$inboundSchema: z.ZodType<
  OutputCompressionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionCriblTCP$outboundSchema: z.ZodType<
  OutputCompressionCriblTCP,
  z.ZodTypeDef,
  OutputCompressionCriblTCP
> = z.union([
  z.nativeEnum(OutputCompressionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMinimumTLSVersionCriblTCP$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionCriblTCP$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionCriblTCP,
  z.ZodTypeDef,
  OutputMinimumTLSVersionCriblTCP
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionCriblTCP$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionCriblTCP$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionCriblTCP,
  z.ZodTypeDef,
  OutputMaximumTLSVersionCriblTCP
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideCriblTCP$inboundSchema: z.ZodType<
  TLSSettingsClientSideCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionCriblTCP$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionCriblTCP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideCriblTCP$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideCriblTCP$outboundSchema: z.ZodType<
  TLSSettingsClientSideCriblTCP$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideCriblTCP
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionCriblTCP$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionCriblTCP$outboundSchema.optional(),
});

export function tlsSettingsClientSideCriblTCPToJSON(
  tlsSettingsClientSideCriblTCP: TLSSettingsClientSideCriblTCP,
): string {
  return JSON.stringify(
    TLSSettingsClientSideCriblTCP$outboundSchema.parse(
      tlsSettingsClientSideCriblTCP,
    ),
  );
}
export function tlsSettingsClientSideCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideCriblTCP' from JSON`,
  );
}

/** @internal */
export const OutputAuthTokenCriblTCP$inboundSchema: z.ZodType<
  OutputAuthTokenCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});
/** @internal */
export type OutputAuthTokenCriblTCP$Outbound = {
  tokenSecret: string;
  enabled: boolean;
  description?: string | undefined;
};

/** @internal */
export const OutputAuthTokenCriblTCP$outboundSchema: z.ZodType<
  OutputAuthTokenCriblTCP$Outbound,
  z.ZodTypeDef,
  OutputAuthTokenCriblTCP
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});

export function outputAuthTokenCriblTCPToJSON(
  outputAuthTokenCriblTCP: OutputAuthTokenCriblTCP,
): string {
  return JSON.stringify(
    OutputAuthTokenCriblTCP$outboundSchema.parse(outputAuthTokenCriblTCP),
  );
}
export function outputAuthTokenCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthTokenCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthTokenCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthTokenCriblTCP' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorCriblTCP$inboundSchema: z.ZodType<
  BackpressureBehaviorCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorCriblTCP$outboundSchema: z.ZodType<
  BackpressureBehaviorCriblTCP,
  z.ZodTypeDef,
  BackpressureBehaviorCriblTCP
> = z.union([
  z.nativeEnum(BackpressureBehaviorCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSCriblTCP$inboundSchema: z.ZodType<
  TLSCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TLSCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TLSCriblTCP$outboundSchema: z.ZodType<
  TLSCriblTCP,
  z.ZodTypeDef,
  TLSCriblTCP
> = z.union([
  z.nativeEnum(TLSCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HostCriblTCP$inboundSchema: z.ZodType<
  HostCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number().default(10300),
  tls: TLSCriblTCP$inboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});
/** @internal */
export type HostCriblTCP$Outbound = {
  host: string;
  port: number;
  tls: string;
  servername?: string | undefined;
  weight: number;
};

/** @internal */
export const HostCriblTCP$outboundSchema: z.ZodType<
  HostCriblTCP$Outbound,
  z.ZodTypeDef,
  HostCriblTCP
> = z.object({
  host: z.string(),
  port: z.number().default(10300),
  tls: TLSCriblTCP$outboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});

export function hostCriblTCPToJSON(hostCriblTCP: HostCriblTCP): string {
  return JSON.stringify(HostCriblTCP$outboundSchema.parse(hostCriblTCP));
}
export function hostCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<HostCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostCriblTCP' from JSON`,
  );
}

/** @internal */
export const OutputModeCriblTCP$inboundSchema: z.ZodType<
  OutputModeCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeCriblTCP$outboundSchema: z.ZodType<
  OutputModeCriblTCP,
  z.ZodTypeDef,
  OutputModeCriblTCP
> = z.union([
  z.nativeEnum(OutputModeCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionCriblTCP$inboundSchema: z.ZodType<
  PqCompressCompressionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionCriblTCP$outboundSchema: z.ZodType<
  PqCompressCompressionCriblTCP,
  z.ZodTypeDef,
  PqCompressCompressionCriblTCP
> = z.union([
  z.nativeEnum(PqCompressCompressionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorCriblTCP$inboundSchema: z.ZodType<
  QueueFullBehaviorCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorCriblTCP$outboundSchema: z.ZodType<
  QueueFullBehaviorCriblTCP,
  z.ZodTypeDef,
  QueueFullBehaviorCriblTCP
> = z.union([
  z.nativeEnum(QueueFullBehaviorCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsCriblTCP$inboundSchema: z.ZodType<
  OutputPqControlsCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsCriblTCP$Outbound = {};

/** @internal */
export const OutputPqControlsCriblTCP$outboundSchema: z.ZodType<
  OutputPqControlsCriblTCP$Outbound,
  z.ZodTypeDef,
  OutputPqControlsCriblTCP
> = z.object({});

export function outputPqControlsCriblTCPToJSON(
  outputPqControlsCriblTCP: OutputPqControlsCriblTCP,
): string {
  return JSON.stringify(
    OutputPqControlsCriblTCP$outboundSchema.parse(outputPqControlsCriblTCP),
  );
}
export function outputPqControlsCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsCriblTCP' from JSON`,
  );
}

/** @internal */
export const OutputCriblTcp$inboundSchema: z.ZodType<
  OutputCriblTcp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeCriblTCP$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(true),
    compression: OutputCompressionCriblTCP$inboundSchema.default("gzip"),
    logFailedRequests: z.boolean().default(false),
    throttleRatePerSec: z.string().default("0"),
    tls: z.lazy(() => TLSSettingsClientSideCriblTCP$inboundSchema).optional(),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    tokenTTLMinutes: z.number().default(60),
    authTokens: z.array(z.lazy(() => OutputAuthTokenCriblTCP$inboundSchema))
      .optional(),
    excludeFields: z.array(z.string()).optional(),
    onBackpressure: BackpressureBehaviorCriblTCP$inboundSchema.default("block"),
    description: z.string().optional(),
    host: z.string().optional(),
    port: z.number().default(10300),
    excludeSelf: z.boolean().default(false),
    hosts: z.array(z.lazy(() => HostCriblTCP$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    maxConcurrentSenders: z.number().default(0),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeCriblTCP$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionCriblTCP$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorCriblTCP$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsCriblTCP$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCriblTcp$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  compression: string;
  logFailedRequests: boolean;
  throttleRatePerSec: string;
  tls?: TLSSettingsClientSideCriblTCP$Outbound | undefined;
  connectionTimeout: number;
  writeTimeout: number;
  tokenTTLMinutes: number;
  authTokens?: Array<OutputAuthTokenCriblTCP$Outbound> | undefined;
  excludeFields?: Array<string> | undefined;
  onBackpressure: string;
  description?: string | undefined;
  host?: string | undefined;
  port: number;
  excludeSelf: boolean;
  hosts?: Array<HostCriblTCP$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  maxConcurrentSenders: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsCriblTCP$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCriblTcp$outboundSchema: z.ZodType<
  OutputCriblTcp$Outbound,
  z.ZodTypeDef,
  OutputCriblTcp
> = z.object({
  id: z.string().optional(),
  type: OutputTypeCriblTCP$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(true),
  compression: OutputCompressionCriblTCP$outboundSchema.default("gzip"),
  logFailedRequests: z.boolean().default(false),
  throttleRatePerSec: z.string().default("0"),
  tls: z.lazy(() => TLSSettingsClientSideCriblTCP$outboundSchema).optional(),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  tokenTTLMinutes: z.number().default(60),
  authTokens: z.array(z.lazy(() => OutputAuthTokenCriblTCP$outboundSchema))
    .optional(),
  excludeFields: z.array(z.string()).optional(),
  onBackpressure: BackpressureBehaviorCriblTCP$outboundSchema.default("block"),
  description: z.string().optional(),
  host: z.string().optional(),
  port: z.number().default(10300),
  excludeSelf: z.boolean().default(false),
  hosts: z.array(z.lazy(() => HostCriblTCP$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  maxConcurrentSenders: z.number().default(0),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeCriblTCP$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionCriblTCP$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorCriblTCP$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsCriblTCP$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCriblTcpToJSON(outputCriblTcp: OutputCriblTcp): string {
  return JSON.stringify(OutputCriblTcp$outboundSchema.parse(outputCriblTcp));
}
export function outputCriblTcpFromJSON(
  jsonString: string,
): SafeParseResult<OutputCriblTcp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCriblTcp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCriblTcp' from JSON`,
  );
}

/** @internal */
export const TypeDataset$inboundSchema: z.ZodNativeEnum<typeof TypeDataset> = z
  .nativeEnum(TypeDataset);
/** @internal */
export const TypeDataset$outboundSchema: z.ZodNativeEnum<typeof TypeDataset> =
  TypeDataset$inboundSchema;

/** @internal */
export const DefaultSeveritySeverity$inboundSchema: z.ZodType<
  DefaultSeveritySeverity,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DefaultSeveritySeverity),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DefaultSeveritySeverity$outboundSchema: z.ZodType<
  DefaultSeveritySeverity,
  z.ZodTypeDef,
  DefaultSeveritySeverity
> = z.union([
  z.nativeEnum(DefaultSeveritySeverity),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingDataset$inboundSchema: z.ZodType<
  ResponseRetrySettingDataset,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingDataset$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingDataset$outboundSchema: z.ZodType<
  ResponseRetrySettingDataset$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingDataset
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingDatasetToJSON(
  responseRetrySettingDataset: ResponseRetrySettingDataset,
): string {
  return JSON.stringify(
    ResponseRetrySettingDataset$outboundSchema.parse(
      responseRetrySettingDataset,
    ),
  );
}
export function responseRetrySettingDatasetFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingDataset, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingDataset$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingDataset' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsDataset$inboundSchema: z.ZodType<
  TimeoutRetrySettingsDataset,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsDataset$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsDataset$outboundSchema: z.ZodType<
  TimeoutRetrySettingsDataset$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsDataset
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsDatasetToJSON(
  timeoutRetrySettingsDataset: TimeoutRetrySettingsDataset,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsDataset$outboundSchema.parse(
      timeoutRetrySettingsDataset,
    ),
  );
}
export function timeoutRetrySettingsDatasetFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsDataset, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsDataset$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsDataset' from JSON`,
  );
}

/** @internal */
export const DataSetSite$inboundSchema: z.ZodType<
  DataSetSite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataSetSite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataSetSite$outboundSchema: z.ZodType<
  DataSetSite,
  z.ZodTypeDef,
  DataSetSite
> = z.union([
  z.nativeEnum(DataSetSite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderDataset$inboundSchema: z.ZodType<
  ExtraHttpHeaderDataset,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderDataset$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderDataset$outboundSchema: z.ZodType<
  ExtraHttpHeaderDataset$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderDataset
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderDatasetToJSON(
  extraHttpHeaderDataset: ExtraHttpHeaderDataset,
): string {
  return JSON.stringify(
    ExtraHttpHeaderDataset$outboundSchema.parse(extraHttpHeaderDataset),
  );
}
export function extraHttpHeaderDatasetFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderDataset, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderDataset$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderDataset' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeDataset$inboundSchema: z.ZodType<
  FailedRequestLoggingModeDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeDataset$outboundSchema: z.ZodType<
  FailedRequestLoggingModeDataset,
  z.ZodTypeDef,
  FailedRequestLoggingModeDataset
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorDataset$inboundSchema: z.ZodType<
  BackpressureBehaviorDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDataset$outboundSchema: z.ZodType<
  BackpressureBehaviorDataset,
  z.ZodTypeDef,
  BackpressureBehaviorDataset
> = z.union([
  z.nativeEnum(BackpressureBehaviorDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodDataset$inboundSchema: z.ZodType<
  AuthenticationMethodDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodDataset$outboundSchema: z.ZodType<
  AuthenticationMethodDataset,
  z.ZodTypeDef,
  AuthenticationMethodDataset
> = z.union([
  z.nativeEnum(AuthenticationMethodDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeDataset$inboundSchema: z.ZodType<
  ModeDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDataset$outboundSchema: z.ZodType<
  ModeDataset,
  z.ZodTypeDef,
  ModeDataset
> = z.union([
  z.nativeEnum(ModeDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDataset$inboundSchema: z.ZodType<
  CompressionDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDataset$outboundSchema: z.ZodType<
  CompressionDataset,
  z.ZodTypeDef,
  CompressionDataset
> = z.union([
  z.nativeEnum(CompressionDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorDataset$inboundSchema: z.ZodType<
  QueueFullBehaviorDataset,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorDataset),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorDataset$outboundSchema: z.ZodType<
  QueueFullBehaviorDataset,
  z.ZodTypeDef,
  QueueFullBehaviorDataset
> = z.union([
  z.nativeEnum(QueueFullBehaviorDataset),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDataset$inboundSchema: z.ZodType<
  PqControlsDataset,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDataset$Outbound = {};

/** @internal */
export const PqControlsDataset$outboundSchema: z.ZodType<
  PqControlsDataset$Outbound,
  z.ZodTypeDef,
  PqControlsDataset
> = z.object({});

export function pqControlsDatasetToJSON(
  pqControlsDataset: PqControlsDataset,
): string {
  return JSON.stringify(
    PqControlsDataset$outboundSchema.parse(pqControlsDataset),
  );
}
export function pqControlsDatasetFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDataset, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDataset$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDataset' from JSON`,
  );
}

/** @internal */
export const OutputDataset$inboundSchema: z.ZodType<
  OutputDataset,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDataset$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    messageField: z.string().optional(),
    excludeFields: z.array(z.string()).optional(),
    serverHostField: z.string().optional(),
    timestampField: z.string().optional(),
    defaultSeverity: DefaultSeveritySeverity$inboundSchema.default("info"),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingDataset$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsDataset$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    site: DataSetSite$inboundSchema.default("us"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderDataset$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeDataset$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    onBackpressure: BackpressureBehaviorDataset$inboundSchema.default("block"),
    authType: AuthenticationMethodDataset$inboundSchema.default("manual"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    customUrl: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeDataset$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionDataset$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorDataset$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsDataset$inboundSchema).optional(),
    apiKey: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDataset$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  messageField?: string | undefined;
  excludeFields?: Array<string> | undefined;
  serverHostField?: string | undefined;
  timestampField?: string | undefined;
  defaultSeverity: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingDataset$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDataset$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  site: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderDataset$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  onBackpressure: string;
  authType: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsDataset$Outbound | undefined;
  apiKey?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDataset$outboundSchema: z.ZodType<
  OutputDataset$Outbound,
  z.ZodTypeDef,
  OutputDataset
> = z.object({
  id: z.string().optional(),
  type: TypeDataset$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  messageField: z.string().optional(),
  excludeFields: z.array(z.string()).optional(),
  serverHostField: z.string().optional(),
  timestampField: z.string().optional(),
  defaultSeverity: DefaultSeveritySeverity$outboundSchema.default("info"),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingDataset$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsDataset$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  site: DataSetSite$outboundSchema.default("us"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderDataset$outboundSchema))
    .optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeDataset$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  onBackpressure: BackpressureBehaviorDataset$outboundSchema.default("block"),
  authType: AuthenticationMethodDataset$outboundSchema.default("manual"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  customUrl: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeDataset$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionDataset$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorDataset$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsDataset$outboundSchema).optional(),
  apiKey: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDatasetToJSON(outputDataset: OutputDataset): string {
  return JSON.stringify(OutputDataset$outboundSchema.parse(outputDataset));
}
export function outputDatasetFromJSON(
  jsonString: string,
): SafeParseResult<OutputDataset, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDataset$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDataset' from JSON`,
  );
}

/** @internal */
export const TypeServiceNow$inboundSchema: z.ZodNativeEnum<
  typeof TypeServiceNow
> = z.nativeEnum(TypeServiceNow);
/** @internal */
export const TypeServiceNow$outboundSchema: z.ZodNativeEnum<
  typeof TypeServiceNow
> = TypeServiceNow$inboundSchema;

/** @internal */
export const OTLPVersionServiceNow$inboundSchema: z.ZodType<
  OTLPVersionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OTLPVersionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OTLPVersionServiceNow$outboundSchema: z.ZodType<
  OTLPVersionServiceNow,
  z.ZodTypeDef,
  OTLPVersionServiceNow
> = z.union([
  z.nativeEnum(OTLPVersionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ProtocolServiceNow$inboundSchema: z.ZodType<
  ProtocolServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ProtocolServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ProtocolServiceNow$outboundSchema: z.ZodType<
  ProtocolServiceNow,
  z.ZodTypeDef,
  ProtocolServiceNow
> = z.union([
  z.nativeEnum(ProtocolServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressCompressionServiceNow$inboundSchema: z.ZodType<
  CompressCompressionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressCompressionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressCompressionServiceNow$outboundSchema: z.ZodType<
  CompressCompressionServiceNow,
  z.ZodTypeDef,
  CompressCompressionServiceNow
> = z.union([
  z.nativeEnum(CompressCompressionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HttpCompressCompressionServiceNow$inboundSchema: z.ZodType<
  HttpCompressCompressionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(HttpCompressCompressionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const HttpCompressCompressionServiceNow$outboundSchema: z.ZodType<
  HttpCompressCompressionServiceNow,
  z.ZodTypeDef,
  HttpCompressCompressionServiceNow
> = z.union([
  z.nativeEnum(HttpCompressCompressionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumServiceNow$inboundSchema: z.ZodType<
  MetadatumServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type MetadatumServiceNow$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const MetadatumServiceNow$outboundSchema: z.ZodType<
  MetadatumServiceNow$Outbound,
  z.ZodTypeDef,
  MetadatumServiceNow
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function metadatumServiceNowToJSON(
  metadatumServiceNow: MetadatumServiceNow,
): string {
  return JSON.stringify(
    MetadatumServiceNow$outboundSchema.parse(metadatumServiceNow),
  );
}
export function metadatumServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumServiceNow' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeServiceNow$inboundSchema: z.ZodType<
  FailedRequestLoggingModeServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeServiceNow$outboundSchema: z.ZodType<
  FailedRequestLoggingModeServiceNow,
  z.ZodTypeDef,
  FailedRequestLoggingModeServiceNow
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorServiceNow$inboundSchema: z.ZodType<
  BackpressureBehaviorServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorServiceNow$outboundSchema: z.ZodType<
  BackpressureBehaviorServiceNow,
  z.ZodTypeDef,
  BackpressureBehaviorServiceNow
> = z.union([
  z.nativeEnum(BackpressureBehaviorServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderServiceNow$inboundSchema: z.ZodType<
  ExtraHttpHeaderServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderServiceNow$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderServiceNow$outboundSchema: z.ZodType<
  ExtraHttpHeaderServiceNow$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderServiceNow
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderServiceNowToJSON(
  extraHttpHeaderServiceNow: ExtraHttpHeaderServiceNow,
): string {
  return JSON.stringify(
    ExtraHttpHeaderServiceNow$outboundSchema.parse(extraHttpHeaderServiceNow),
  );
}
export function extraHttpHeaderServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderServiceNow' from JSON`,
  );
}

/** @internal */
export const ResponseRetrySettingServiceNow$inboundSchema: z.ZodType<
  ResponseRetrySettingServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingServiceNow$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingServiceNow$outboundSchema: z.ZodType<
  ResponseRetrySettingServiceNow$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingServiceNow
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingServiceNowToJSON(
  responseRetrySettingServiceNow: ResponseRetrySettingServiceNow,
): string {
  return JSON.stringify(
    ResponseRetrySettingServiceNow$outboundSchema.parse(
      responseRetrySettingServiceNow,
    ),
  );
}
export function responseRetrySettingServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingServiceNow' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsServiceNow$inboundSchema: z.ZodType<
  TimeoutRetrySettingsServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsServiceNow$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsServiceNow$outboundSchema: z.ZodType<
  TimeoutRetrySettingsServiceNow$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsServiceNow
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsServiceNowToJSON(
  timeoutRetrySettingsServiceNow: TimeoutRetrySettingsServiceNow,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsServiceNow$outboundSchema.parse(
      timeoutRetrySettingsServiceNow,
    ),
  );
}
export function timeoutRetrySettingsServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsServiceNow' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionServiceNow$inboundSchema: z.ZodType<
  MinimumTLSVersionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionServiceNow$outboundSchema: z.ZodType<
  MinimumTLSVersionServiceNow,
  z.ZodTypeDef,
  MinimumTLSVersionServiceNow
> = z.union([
  z.nativeEnum(MinimumTLSVersionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionServiceNow$inboundSchema: z.ZodType<
  MaximumTLSVersionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionServiceNow$outboundSchema: z.ZodType<
  MaximumTLSVersionServiceNow,
  z.ZodTypeDef,
  MaximumTLSVersionServiceNow
> = z.union([
  z.nativeEnum(MaximumTLSVersionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideServiceNow$inboundSchema: z.ZodType<
  TLSSettingsClientSideServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionServiceNow$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionServiceNow$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideServiceNow$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideServiceNow$outboundSchema: z.ZodType<
  TLSSettingsClientSideServiceNow$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideServiceNow
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionServiceNow$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionServiceNow$outboundSchema.optional(),
});

export function tlsSettingsClientSideServiceNowToJSON(
  tlsSettingsClientSideServiceNow: TLSSettingsClientSideServiceNow,
): string {
  return JSON.stringify(
    TLSSettingsClientSideServiceNow$outboundSchema.parse(
      tlsSettingsClientSideServiceNow,
    ),
  );
}
export function tlsSettingsClientSideServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideServiceNow' from JSON`,
  );
}

/** @internal */
export const ModeServiceNow$inboundSchema: z.ZodType<
  ModeServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeServiceNow$outboundSchema: z.ZodType<
  ModeServiceNow,
  z.ZodTypeDef,
  ModeServiceNow
> = z.union([
  z.nativeEnum(ModeServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionServiceNow$inboundSchema: z.ZodType<
  PqCompressCompressionServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionServiceNow$outboundSchema: z.ZodType<
  PqCompressCompressionServiceNow,
  z.ZodTypeDef,
  PqCompressCompressionServiceNow
> = z.union([
  z.nativeEnum(PqCompressCompressionServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorServiceNow$inboundSchema: z.ZodType<
  QueueFullBehaviorServiceNow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorServiceNow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorServiceNow$outboundSchema: z.ZodType<
  QueueFullBehaviorServiceNow,
  z.ZodTypeDef,
  QueueFullBehaviorServiceNow
> = z.union([
  z.nativeEnum(QueueFullBehaviorServiceNow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsServiceNow$inboundSchema: z.ZodType<
  PqControlsServiceNow,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsServiceNow$Outbound = {};

/** @internal */
export const PqControlsServiceNow$outboundSchema: z.ZodType<
  PqControlsServiceNow$Outbound,
  z.ZodTypeDef,
  PqControlsServiceNow
> = z.object({});

export function pqControlsServiceNowToJSON(
  pqControlsServiceNow: PqControlsServiceNow,
): string {
  return JSON.stringify(
    PqControlsServiceNow$outboundSchema.parse(pqControlsServiceNow),
  );
}
export function pqControlsServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsServiceNow' from JSON`,
  );
}

/** @internal */
export const OutputServiceNow$inboundSchema: z.ZodType<
  OutputServiceNow,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeServiceNow$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    endpoint: z.string().default("ingest.lightstep.com:443"),
    tokenSecret: z.string(),
    authTokenName: z.string().default("lightstep-access-token"),
    otlpVersion: OTLPVersionServiceNow$inboundSchema.default("1.3.1"),
    maxPayloadSizeKB: z.number().default(2048),
    protocol: ProtocolServiceNow$inboundSchema.default("grpc"),
    compress: CompressCompressionServiceNow$inboundSchema.default("gzip"),
    httpCompress: HttpCompressCompressionServiceNow$inboundSchema.default(
      "gzip",
    ),
    httpTracesEndpointOverride: z.string().optional(),
    httpMetricsEndpointOverride: z.string().optional(),
    httpLogsEndpointOverride: z.string().optional(),
    metadata: z.array(z.lazy(() => MetadatumServiceNow$inboundSchema))
      .optional(),
    concurrency: z.number().default(5),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    failedRequestLoggingMode: FailedRequestLoggingModeServiceNow$inboundSchema
      .default("none"),
    connectionTimeout: z.number().default(10000),
    keepAliveTime: z.number().default(30),
    keepAlive: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorServiceNow$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    rejectUnauthorized: z.boolean().default(true),
    useRoundRobinDns: z.boolean().default(false),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderServiceNow$inboundSchema),
    ).optional(),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingServiceNow$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsServiceNow$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    tls: z.lazy(() => TLSSettingsClientSideServiceNow$inboundSchema).optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeServiceNow$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionServiceNow$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorServiceNow$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsServiceNow$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputServiceNow$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  endpoint: string;
  tokenSecret: string;
  authTokenName: string;
  otlpVersion: string;
  maxPayloadSizeKB: number;
  protocol: string;
  compress: string;
  httpCompress: string;
  httpTracesEndpointOverride?: string | undefined;
  httpMetricsEndpointOverride?: string | undefined;
  httpLogsEndpointOverride?: string | undefined;
  metadata?: Array<MetadatumServiceNow$Outbound> | undefined;
  concurrency: number;
  timeoutSec: number;
  flushPeriodSec: number;
  failedRequestLoggingMode: string;
  connectionTimeout: number;
  keepAliveTime: number;
  keepAlive: boolean;
  onBackpressure: string;
  description?: string | undefined;
  rejectUnauthorized: boolean;
  useRoundRobinDns: boolean;
  extraHttpHeaders?: Array<ExtraHttpHeaderServiceNow$Outbound> | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingServiceNow$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsServiceNow$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  tls?: TLSSettingsClientSideServiceNow$Outbound | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsServiceNow$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputServiceNow$outboundSchema: z.ZodType<
  OutputServiceNow$Outbound,
  z.ZodTypeDef,
  OutputServiceNow
> = z.object({
  id: z.string().optional(),
  type: TypeServiceNow$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  endpoint: z.string().default("ingest.lightstep.com:443"),
  tokenSecret: z.string(),
  authTokenName: z.string().default("lightstep-access-token"),
  otlpVersion: OTLPVersionServiceNow$outboundSchema.default("1.3.1"),
  maxPayloadSizeKB: z.number().default(2048),
  protocol: ProtocolServiceNow$outboundSchema.default("grpc"),
  compress: CompressCompressionServiceNow$outboundSchema.default("gzip"),
  httpCompress: HttpCompressCompressionServiceNow$outboundSchema.default(
    "gzip",
  ),
  httpTracesEndpointOverride: z.string().optional(),
  httpMetricsEndpointOverride: z.string().optional(),
  httpLogsEndpointOverride: z.string().optional(),
  metadata: z.array(z.lazy(() => MetadatumServiceNow$outboundSchema))
    .optional(),
  concurrency: z.number().default(5),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  failedRequestLoggingMode: FailedRequestLoggingModeServiceNow$outboundSchema
    .default("none"),
  connectionTimeout: z.number().default(10000),
  keepAliveTime: z.number().default(30),
  keepAlive: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorServiceNow$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  rejectUnauthorized: z.boolean().default(true),
  useRoundRobinDns: z.boolean().default(false),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderServiceNow$outboundSchema),
  ).optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingServiceNow$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsServiceNow$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  tls: z.lazy(() => TLSSettingsClientSideServiceNow$outboundSchema).optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeServiceNow$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionServiceNow$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorServiceNow$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsServiceNow$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputServiceNowToJSON(
  outputServiceNow: OutputServiceNow,
): string {
  return JSON.stringify(
    OutputServiceNow$outboundSchema.parse(outputServiceNow),
  );
}
export function outputServiceNowFromJSON(
  jsonString: string,
): SafeParseResult<OutputServiceNow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputServiceNow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputServiceNow' from JSON`,
  );
}

/** @internal */
export const OutputTypeOpenTelemetry$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeOpenTelemetry
> = z.nativeEnum(OutputTypeOpenTelemetry);
/** @internal */
export const OutputTypeOpenTelemetry$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeOpenTelemetry
> = OutputTypeOpenTelemetry$inboundSchema;

/** @internal */
export const OutputProtocolOpenTelemetry$inboundSchema: z.ZodType<
  OutputProtocolOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputProtocolOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputProtocolOpenTelemetry$outboundSchema: z.ZodType<
  OutputProtocolOpenTelemetry,
  z.ZodTypeDef,
  OutputProtocolOpenTelemetry
> = z.union([
  z.nativeEnum(OutputProtocolOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputOTLPVersionOpenTelemetry$inboundSchema: z.ZodType<
  OutputOTLPVersionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputOTLPVersionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputOTLPVersionOpenTelemetry$outboundSchema: z.ZodType<
  OutputOTLPVersionOpenTelemetry,
  z.ZodTypeDef,
  OutputOTLPVersionOpenTelemetry
> = z.union([
  z.nativeEnum(OutputOTLPVersionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressCompressionOpenTelemetry$inboundSchema: z.ZodType<
  OutputCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressCompressionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressCompressionOpenTelemetry$outboundSchema: z.ZodType<
  OutputCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  OutputCompressCompressionOpenTelemetry
> = z.union([
  z.nativeEnum(OutputCompressCompressionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HttpCompressCompressionOpenTelemetry$inboundSchema: z.ZodType<
  HttpCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(HttpCompressCompressionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const HttpCompressCompressionOpenTelemetry$outboundSchema: z.ZodType<
  HttpCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  HttpCompressCompressionOpenTelemetry
> = z.union([
  z.nativeEnum(HttpCompressCompressionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthenticationTypeOpenTelemetry$inboundSchema: z.ZodType<
  OutputAuthenticationTypeOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationTypeOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationTypeOpenTelemetry$outboundSchema: z.ZodType<
  OutputAuthenticationTypeOpenTelemetry,
  z.ZodTypeDef,
  OutputAuthenticationTypeOpenTelemetry
> = z.union([
  z.nativeEnum(OutputAuthenticationTypeOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMetadatumOpenTelemetry$inboundSchema: z.ZodType<
  OutputMetadatumOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type OutputMetadatumOpenTelemetry$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const OutputMetadatumOpenTelemetry$outboundSchema: z.ZodType<
  OutputMetadatumOpenTelemetry$Outbound,
  z.ZodTypeDef,
  OutputMetadatumOpenTelemetry
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function outputMetadatumOpenTelemetryToJSON(
  outputMetadatumOpenTelemetry: OutputMetadatumOpenTelemetry,
): string {
  return JSON.stringify(
    OutputMetadatumOpenTelemetry$outboundSchema.parse(
      outputMetadatumOpenTelemetry,
    ),
  );
}
export function outputMetadatumOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<OutputMetadatumOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputMetadatumOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputMetadatumOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeOpenTelemetry$inboundSchema: z.ZodType<
  FailedRequestLoggingModeOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeOpenTelemetry$outboundSchema: z.ZodType<
  FailedRequestLoggingModeOpenTelemetry,
  z.ZodTypeDef,
  FailedRequestLoggingModeOpenTelemetry
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorOpenTelemetry$inboundSchema: z.ZodType<
  BackpressureBehaviorOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorOpenTelemetry$outboundSchema: z.ZodType<
  BackpressureBehaviorOpenTelemetry,
  z.ZodTypeDef,
  BackpressureBehaviorOpenTelemetry
> = z.union([
  z.nativeEnum(BackpressureBehaviorOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputOauthParamOpenTelemetry$inboundSchema: z.ZodType<
  OutputOauthParamOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputOauthParamOpenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputOauthParamOpenTelemetry$outboundSchema: z.ZodType<
  OutputOauthParamOpenTelemetry$Outbound,
  z.ZodTypeDef,
  OutputOauthParamOpenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputOauthParamOpenTelemetryToJSON(
  outputOauthParamOpenTelemetry: OutputOauthParamOpenTelemetry,
): string {
  return JSON.stringify(
    OutputOauthParamOpenTelemetry$outboundSchema.parse(
      outputOauthParamOpenTelemetry,
    ),
  );
}
export function outputOauthParamOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<OutputOauthParamOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputOauthParamOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputOauthParamOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const OutputOauthHeaderOpenTelemetry$inboundSchema: z.ZodType<
  OutputOauthHeaderOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputOauthHeaderOpenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputOauthHeaderOpenTelemetry$outboundSchema: z.ZodType<
  OutputOauthHeaderOpenTelemetry$Outbound,
  z.ZodTypeDef,
  OutputOauthHeaderOpenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputOauthHeaderOpenTelemetryToJSON(
  outputOauthHeaderOpenTelemetry: OutputOauthHeaderOpenTelemetry,
): string {
  return JSON.stringify(
    OutputOauthHeaderOpenTelemetry$outboundSchema.parse(
      outputOauthHeaderOpenTelemetry,
    ),
  );
}
export function outputOauthHeaderOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<OutputOauthHeaderOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputOauthHeaderOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputOauthHeaderOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const ExtraHttpHeaderOpenTelemetry$inboundSchema: z.ZodType<
  ExtraHttpHeaderOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderOpenTelemetry$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderOpenTelemetry$outboundSchema: z.ZodType<
  ExtraHttpHeaderOpenTelemetry$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderOpenTelemetry
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderOpenTelemetryToJSON(
  extraHttpHeaderOpenTelemetry: ExtraHttpHeaderOpenTelemetry,
): string {
  return JSON.stringify(
    ExtraHttpHeaderOpenTelemetry$outboundSchema.parse(
      extraHttpHeaderOpenTelemetry,
    ),
  );
}
export function extraHttpHeaderOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const ResponseRetrySettingOpenTelemetry$inboundSchema: z.ZodType<
  ResponseRetrySettingOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingOpenTelemetry$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingOpenTelemetry$outboundSchema: z.ZodType<
  ResponseRetrySettingOpenTelemetry$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingOpenTelemetry
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingOpenTelemetryToJSON(
  responseRetrySettingOpenTelemetry: ResponseRetrySettingOpenTelemetry,
): string {
  return JSON.stringify(
    ResponseRetrySettingOpenTelemetry$outboundSchema.parse(
      responseRetrySettingOpenTelemetry,
    ),
  );
}
export function responseRetrySettingOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsOpenTelemetry$inboundSchema: z.ZodType<
  TimeoutRetrySettingsOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsOpenTelemetry$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsOpenTelemetry$outboundSchema: z.ZodType<
  TimeoutRetrySettingsOpenTelemetry$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsOpenTelemetry
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsOpenTelemetryToJSON(
  timeoutRetrySettingsOpenTelemetry: TimeoutRetrySettingsOpenTelemetry,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsOpenTelemetry$outboundSchema.parse(
      timeoutRetrySettingsOpenTelemetry,
    ),
  );
}
export function timeoutRetrySettingsOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const OutputMinimumTLSVersionOpenTelemetry$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionOpenTelemetry$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  OutputMinimumTLSVersionOpenTelemetry
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionOpenTelemetry$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionOpenTelemetry$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  OutputMaximumTLSVersionOpenTelemetry
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideOpenTelemetry$inboundSchema: z.ZodType<
  TLSSettingsClientSideOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionOpenTelemetry$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionOpenTelemetry$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideOpenTelemetry$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideOpenTelemetry$outboundSchema: z.ZodType<
  TLSSettingsClientSideOpenTelemetry$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideOpenTelemetry
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionOpenTelemetry$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionOpenTelemetry$outboundSchema.optional(),
});

export function tlsSettingsClientSideOpenTelemetryToJSON(
  tlsSettingsClientSideOpenTelemetry: TLSSettingsClientSideOpenTelemetry,
): string {
  return JSON.stringify(
    TLSSettingsClientSideOpenTelemetry$outboundSchema.parse(
      tlsSettingsClientSideOpenTelemetry,
    ),
  );
}
export function tlsSettingsClientSideOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsClientSideOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const OutputModeOpenTelemetry$inboundSchema: z.ZodType<
  OutputModeOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeOpenTelemetry$outboundSchema: z.ZodType<
  OutputModeOpenTelemetry,
  z.ZodTypeDef,
  OutputModeOpenTelemetry
> = z.union([
  z.nativeEnum(OutputModeOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionOpenTelemetry$inboundSchema: z.ZodType<
  PqCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionOpenTelemetry$outboundSchema: z.ZodType<
  PqCompressCompressionOpenTelemetry,
  z.ZodTypeDef,
  PqCompressCompressionOpenTelemetry
> = z.union([
  z.nativeEnum(PqCompressCompressionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorOpenTelemetry$inboundSchema: z.ZodType<
  QueueFullBehaviorOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorOpenTelemetry$outboundSchema: z.ZodType<
  QueueFullBehaviorOpenTelemetry,
  z.ZodTypeDef,
  QueueFullBehaviorOpenTelemetry
> = z.union([
  z.nativeEnum(QueueFullBehaviorOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsOpenTelemetry$inboundSchema: z.ZodType<
  OutputPqControlsOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsOpenTelemetry$Outbound = {};

/** @internal */
export const OutputPqControlsOpenTelemetry$outboundSchema: z.ZodType<
  OutputPqControlsOpenTelemetry$Outbound,
  z.ZodTypeDef,
  OutputPqControlsOpenTelemetry
> = z.object({});

export function outputPqControlsOpenTelemetryToJSON(
  outputPqControlsOpenTelemetry: OutputPqControlsOpenTelemetry,
): string {
  return JSON.stringify(
    OutputPqControlsOpenTelemetry$outboundSchema.parse(
      outputPqControlsOpenTelemetry,
    ),
  );
}
export function outputPqControlsOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const OutputOpenTelemetry$inboundSchema: z.ZodType<
  OutputOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeOpenTelemetry$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: OutputProtocolOpenTelemetry$inboundSchema.default("grpc"),
    endpoint: z.string(),
    otlpVersion: OutputOTLPVersionOpenTelemetry$inboundSchema.default("0.10.0"),
    compress: OutputCompressCompressionOpenTelemetry$inboundSchema.default(
      "gzip",
    ),
    httpCompress: HttpCompressCompressionOpenTelemetry$inboundSchema.default(
      "gzip",
    ),
    authType: OutputAuthenticationTypeOpenTelemetry$inboundSchema.default(
      "none",
    ),
    httpTracesEndpointOverride: z.string().optional(),
    httpMetricsEndpointOverride: z.string().optional(),
    httpLogsEndpointOverride: z.string().optional(),
    metadata: z.array(z.lazy(() => OutputMetadatumOpenTelemetry$inboundSchema))
      .optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    failedRequestLoggingMode:
      FailedRequestLoggingModeOpenTelemetry$inboundSchema.default("none"),
    connectionTimeout: z.number().default(10000),
    keepAliveTime: z.number().default(30),
    keepAlive: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorOpenTelemetry$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(
      z.lazy(() => OutputOauthParamOpenTelemetry$inboundSchema),
    ).optional(),
    oauthHeaders: z.array(
      z.lazy(() => OutputOauthHeaderOpenTelemetry$inboundSchema),
    ).optional(),
    rejectUnauthorized: z.boolean().default(true),
    useRoundRobinDns: z.boolean().default(false),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderOpenTelemetry$inboundSchema),
    ).optional(),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingOpenTelemetry$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsOpenTelemetry$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    tls: z.lazy(() => TLSSettingsClientSideOpenTelemetry$inboundSchema)
      .optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeOpenTelemetry$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionOpenTelemetry$inboundSchema.default(
      "none",
    ),
    pqOnBackpressure: QueueFullBehaviorOpenTelemetry$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => OutputPqControlsOpenTelemetry$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputOpenTelemetry$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  endpoint: string;
  otlpVersion: string;
  compress: string;
  httpCompress: string;
  authType: string;
  httpTracesEndpointOverride?: string | undefined;
  httpMetricsEndpointOverride?: string | undefined;
  httpLogsEndpointOverride?: string | undefined;
  metadata?: Array<OutputMetadatumOpenTelemetry$Outbound> | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  timeoutSec: number;
  flushPeriodSec: number;
  failedRequestLoggingMode: string;
  connectionTimeout: number;
  keepAliveTime: number;
  keepAlive: boolean;
  onBackpressure: string;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OutputOauthParamOpenTelemetry$Outbound> | undefined;
  oauthHeaders?: Array<OutputOauthHeaderOpenTelemetry$Outbound> | undefined;
  rejectUnauthorized: boolean;
  useRoundRobinDns: boolean;
  extraHttpHeaders?: Array<ExtraHttpHeaderOpenTelemetry$Outbound> | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingOpenTelemetry$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsOpenTelemetry$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  tls?: TLSSettingsClientSideOpenTelemetry$Outbound | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsOpenTelemetry$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputOpenTelemetry$outboundSchema: z.ZodType<
  OutputOpenTelemetry$Outbound,
  z.ZodTypeDef,
  OutputOpenTelemetry
> = z.object({
  id: z.string().optional(),
  type: OutputTypeOpenTelemetry$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: OutputProtocolOpenTelemetry$outboundSchema.default("grpc"),
  endpoint: z.string(),
  otlpVersion: OutputOTLPVersionOpenTelemetry$outboundSchema.default("0.10.0"),
  compress: OutputCompressCompressionOpenTelemetry$outboundSchema.default(
    "gzip",
  ),
  httpCompress: HttpCompressCompressionOpenTelemetry$outboundSchema.default(
    "gzip",
  ),
  authType: OutputAuthenticationTypeOpenTelemetry$outboundSchema.default(
    "none",
  ),
  httpTracesEndpointOverride: z.string().optional(),
  httpMetricsEndpointOverride: z.string().optional(),
  httpLogsEndpointOverride: z.string().optional(),
  metadata: z.array(z.lazy(() => OutputMetadatumOpenTelemetry$outboundSchema))
    .optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  failedRequestLoggingMode: FailedRequestLoggingModeOpenTelemetry$outboundSchema
    .default("none"),
  connectionTimeout: z.number().default(10000),
  keepAliveTime: z.number().default(30),
  keepAlive: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorOpenTelemetry$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(
    z.lazy(() => OutputOauthParamOpenTelemetry$outboundSchema),
  ).optional(),
  oauthHeaders: z.array(
    z.lazy(() => OutputOauthHeaderOpenTelemetry$outboundSchema),
  ).optional(),
  rejectUnauthorized: z.boolean().default(true),
  useRoundRobinDns: z.boolean().default(false),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderOpenTelemetry$outboundSchema),
  ).optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingOpenTelemetry$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsOpenTelemetry$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  tls: z.lazy(() => TLSSettingsClientSideOpenTelemetry$outboundSchema)
    .optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeOpenTelemetry$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionOpenTelemetry$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorOpenTelemetry$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => OutputPqControlsOpenTelemetry$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputOpenTelemetryToJSON(
  outputOpenTelemetry: OutputOpenTelemetry,
): string {
  return JSON.stringify(
    OutputOpenTelemetry$outboundSchema.parse(outputOpenTelemetry),
  );
}
export function outputOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<OutputOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const TypeRing$inboundSchema: z.ZodNativeEnum<typeof TypeRing> = z
  .nativeEnum(TypeRing);
/** @internal */
export const TypeRing$outboundSchema: z.ZodNativeEnum<typeof TypeRing> =
  TypeRing$inboundSchema;

/** @internal */
export const DataFormatRing$inboundSchema: z.ZodType<
  DataFormatRing,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatRing),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatRing$outboundSchema: z.ZodType<
  DataFormatRing,
  z.ZodTypeDef,
  DataFormatRing
> = z.union([
  z.nativeEnum(DataFormatRing),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputDataCompressionFormat$inboundSchema: z.ZodType<
  OutputDataCompressionFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputDataCompressionFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputDataCompressionFormat$outboundSchema: z.ZodType<
  OutputDataCompressionFormat,
  z.ZodTypeDef,
  OutputDataCompressionFormat
> = z.union([
  z.nativeEnum(OutputDataCompressionFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorRing$inboundSchema: z.ZodType<
  BackpressureBehaviorRing,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorRing),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorRing$outboundSchema: z.ZodType<
  BackpressureBehaviorRing,
  z.ZodTypeDef,
  BackpressureBehaviorRing
> = z.union([
  z.nativeEnum(BackpressureBehaviorRing),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputRing$inboundSchema: z.ZodType<
  OutputRing,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeRing$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    format: DataFormatRing$inboundSchema.default("json"),
    partitionExpr: z.string().optional(),
    maxDataSize: z.string().default("1GB"),
    maxDataTime: z.string().default("24h"),
    compress: OutputDataCompressionFormat$inboundSchema.default("gzip"),
    destPath: z.string().optional(),
    onBackpressure: BackpressureBehaviorRing$inboundSchema.default("block"),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputRing$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  format: string;
  partitionExpr?: string | undefined;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath?: string | undefined;
  onBackpressure: string;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputRing$outboundSchema: z.ZodType<
  OutputRing$Outbound,
  z.ZodTypeDef,
  OutputRing
> = z.object({
  id: z.string().optional(),
  type: TypeRing$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  format: DataFormatRing$outboundSchema.default("json"),
  partitionExpr: z.string().optional(),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: OutputDataCompressionFormat$outboundSchema.default("gzip"),
  destPath: z.string().optional(),
  onBackpressure: BackpressureBehaviorRing$outboundSchema.default("block"),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputRingToJSON(outputRing: OutputRing): string {
  return JSON.stringify(OutputRing$outboundSchema.parse(outputRing));
}
export function outputRingFromJSON(
  jsonString: string,
): SafeParseResult<OutputRing, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputRing$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputRing' from JSON`,
  );
}

/** @internal */
export const OutputTypePrometheus$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypePrometheus
> = z.nativeEnum(OutputTypePrometheus);
/** @internal */
export const OutputTypePrometheus$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypePrometheus
> = OutputTypePrometheus$inboundSchema;

/** @internal */
export const ExtraHttpHeaderPrometheus$inboundSchema: z.ZodType<
  ExtraHttpHeaderPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderPrometheus$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderPrometheus$outboundSchema: z.ZodType<
  ExtraHttpHeaderPrometheus$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderPrometheus
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderPrometheusToJSON(
  extraHttpHeaderPrometheus: ExtraHttpHeaderPrometheus,
): string {
  return JSON.stringify(
    ExtraHttpHeaderPrometheus$outboundSchema.parse(extraHttpHeaderPrometheus),
  );
}
export function extraHttpHeaderPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderPrometheus' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModePrometheus$inboundSchema: z.ZodType<
  FailedRequestLoggingModePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModePrometheus$outboundSchema: z.ZodType<
  FailedRequestLoggingModePrometheus,
  z.ZodTypeDef,
  FailedRequestLoggingModePrometheus
> = z.union([
  z.nativeEnum(FailedRequestLoggingModePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingPrometheus$inboundSchema: z.ZodType<
  ResponseRetrySettingPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingPrometheus$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingPrometheus$outboundSchema: z.ZodType<
  ResponseRetrySettingPrometheus$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingPrometheus
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingPrometheusToJSON(
  responseRetrySettingPrometheus: ResponseRetrySettingPrometheus,
): string {
  return JSON.stringify(
    ResponseRetrySettingPrometheus$outboundSchema.parse(
      responseRetrySettingPrometheus,
    ),
  );
}
export function responseRetrySettingPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingPrometheus' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsPrometheus$inboundSchema: z.ZodType<
  TimeoutRetrySettingsPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsPrometheus$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsPrometheus$outboundSchema: z.ZodType<
  TimeoutRetrySettingsPrometheus$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsPrometheus
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsPrometheusToJSON(
  timeoutRetrySettingsPrometheus: TimeoutRetrySettingsPrometheus,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsPrometheus$outboundSchema.parse(
      timeoutRetrySettingsPrometheus,
    ),
  );
}
export function timeoutRetrySettingsPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsPrometheus' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorPrometheus$inboundSchema: z.ZodType<
  BackpressureBehaviorPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorPrometheus$outboundSchema: z.ZodType<
  BackpressureBehaviorPrometheus,
  z.ZodTypeDef,
  BackpressureBehaviorPrometheus
> = z.union([
  z.nativeEnum(BackpressureBehaviorPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationTypePrometheus$inboundSchema: z.ZodType<
  AuthenticationTypePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypePrometheus$outboundSchema: z.ZodType<
  AuthenticationTypePrometheus,
  z.ZodTypeDef,
  AuthenticationTypePrometheus
> = z.union([
  z.nativeEnum(AuthenticationTypePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModePrometheus$inboundSchema: z.ZodType<
  OutputModePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModePrometheus$outboundSchema: z.ZodType<
  OutputModePrometheus,
  z.ZodTypeDef,
  OutputModePrometheus
> = z.union([
  z.nativeEnum(OutputModePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionPrometheus$inboundSchema: z.ZodType<
  PqCompressCompressionPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionPrometheus$outboundSchema: z.ZodType<
  PqCompressCompressionPrometheus,
  z.ZodTypeDef,
  PqCompressCompressionPrometheus
> = z.union([
  z.nativeEnum(PqCompressCompressionPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorPrometheus$inboundSchema: z.ZodType<
  QueueFullBehaviorPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorPrometheus$outboundSchema: z.ZodType<
  QueueFullBehaviorPrometheus,
  z.ZodTypeDef,
  QueueFullBehaviorPrometheus
> = z.union([
  z.nativeEnum(QueueFullBehaviorPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsPrometheus$inboundSchema: z.ZodType<
  OutputPqControlsPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsPrometheus$Outbound = {};

/** @internal */
export const OutputPqControlsPrometheus$outboundSchema: z.ZodType<
  OutputPqControlsPrometheus$Outbound,
  z.ZodTypeDef,
  OutputPqControlsPrometheus
> = z.object({});

export function outputPqControlsPrometheusToJSON(
  outputPqControlsPrometheus: OutputPqControlsPrometheus,
): string {
  return JSON.stringify(
    OutputPqControlsPrometheus$outboundSchema.parse(outputPqControlsPrometheus),
  );
}
export function outputPqControlsPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsPrometheus' from JSON`,
  );
}

/** @internal */
export const OauthParamPrometheus$inboundSchema: z.ZodType<
  OauthParamPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamPrometheus$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamPrometheus$outboundSchema: z.ZodType<
  OauthParamPrometheus$Outbound,
  z.ZodTypeDef,
  OauthParamPrometheus
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamPrometheusToJSON(
  oauthParamPrometheus: OauthParamPrometheus,
): string {
  return JSON.stringify(
    OauthParamPrometheus$outboundSchema.parse(oauthParamPrometheus),
  );
}
export function oauthParamPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamPrometheus' from JSON`,
  );
}

/** @internal */
export const OauthHeaderPrometheus$inboundSchema: z.ZodType<
  OauthHeaderPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderPrometheus$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderPrometheus$outboundSchema: z.ZodType<
  OauthHeaderPrometheus$Outbound,
  z.ZodTypeDef,
  OauthHeaderPrometheus
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderPrometheusToJSON(
  oauthHeaderPrometheus: OauthHeaderPrometheus,
): string {
  return JSON.stringify(
    OauthHeaderPrometheus$outboundSchema.parse(oauthHeaderPrometheus),
  );
}
export function oauthHeaderPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderPrometheus' from JSON`,
  );
}

/** @internal */
export const OutputPrometheus$inboundSchema: z.ZodType<
  OutputPrometheus,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypePrometheus$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
    sendMetadata: z.boolean().default(true),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderPrometheus$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModePrometheus$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingPrometheus$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsPrometheus$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorPrometheus$inboundSchema.default(
      "block",
    ),
    authType: AuthenticationTypePrometheus$inboundSchema.default("none"),
    description: z.string().optional(),
    metricsFlushPeriodSec: z.number().default(60),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModePrometheus$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionPrometheus$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorPrometheus$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => OutputPqControlsPrometheus$inboundSchema)
      .optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamPrometheus$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderPrometheus$inboundSchema))
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputPrometheus$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  metricRenameExpr: string;
  sendMetadata: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderPrometheus$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingPrometheus$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsPrometheus$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  metricsFlushPeriodSec: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsPrometheus$Outbound | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamPrometheus$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderPrometheus$Outbound> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputPrometheus$outboundSchema: z.ZodType<
  OutputPrometheus$Outbound,
  z.ZodTypeDef,
  OutputPrometheus
> = z.object({
  id: z.string().optional(),
  type: OutputTypePrometheus$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
  sendMetadata: z.boolean().default(true),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderPrometheus$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModePrometheus$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingPrometheus$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsPrometheus$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorPrometheus$outboundSchema.default(
    "block",
  ),
  authType: AuthenticationTypePrometheus$outboundSchema.default("none"),
  description: z.string().optional(),
  metricsFlushPeriodSec: z.number().default(60),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModePrometheus$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionPrometheus$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorPrometheus$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsPrometheus$outboundSchema)
    .optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamPrometheus$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderPrometheus$outboundSchema))
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputPrometheusToJSON(
  outputPrometheus: OutputPrometheus,
): string {
  return JSON.stringify(
    OutputPrometheus$outboundSchema.parse(outputPrometheus),
  );
}
export function outputPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<OutputPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPrometheus' from JSON`,
  );
}

/** @internal */
export const OutputTypeLoki$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeLoki
> = z.nativeEnum(OutputTypeLoki);
/** @internal */
export const OutputTypeLoki$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeLoki
> = OutputTypeLoki$inboundSchema;

/** @internal */
export const MessageFormatLoki$inboundSchema: z.ZodType<
  MessageFormatLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MessageFormatLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MessageFormatLoki$outboundSchema: z.ZodType<
  MessageFormatLoki,
  z.ZodTypeDef,
  MessageFormatLoki
> = z.union([
  z.nativeEnum(MessageFormatLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LabelLoki$inboundSchema: z.ZodType<
  LabelLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type LabelLoki$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const LabelLoki$outboundSchema: z.ZodType<
  LabelLoki$Outbound,
  z.ZodTypeDef,
  LabelLoki
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});

export function labelLokiToJSON(labelLoki: LabelLoki): string {
  return JSON.stringify(LabelLoki$outboundSchema.parse(labelLoki));
}
export function labelLokiFromJSON(
  jsonString: string,
): SafeParseResult<LabelLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LabelLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LabelLoki' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationTypeLoki$inboundSchema: z.ZodType<
  OutputAuthenticationTypeLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationTypeLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationTypeLoki$outboundSchema: z.ZodType<
  OutputAuthenticationTypeLoki,
  z.ZodTypeDef,
  OutputAuthenticationTypeLoki
> = z.union([
  z.nativeEnum(OutputAuthenticationTypeLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderLoki$inboundSchema: z.ZodType<
  ExtraHttpHeaderLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderLoki$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderLoki$outboundSchema: z.ZodType<
  ExtraHttpHeaderLoki$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderLoki
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderLokiToJSON(
  extraHttpHeaderLoki: ExtraHttpHeaderLoki,
): string {
  return JSON.stringify(
    ExtraHttpHeaderLoki$outboundSchema.parse(extraHttpHeaderLoki),
  );
}
export function extraHttpHeaderLokiFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderLoki' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeLoki$inboundSchema: z.ZodType<
  FailedRequestLoggingModeLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeLoki$outboundSchema: z.ZodType<
  FailedRequestLoggingModeLoki,
  z.ZodTypeDef,
  FailedRequestLoggingModeLoki
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingLoki$inboundSchema: z.ZodType<
  ResponseRetrySettingLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingLoki$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingLoki$outboundSchema: z.ZodType<
  ResponseRetrySettingLoki$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingLoki
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingLokiToJSON(
  responseRetrySettingLoki: ResponseRetrySettingLoki,
): string {
  return JSON.stringify(
    ResponseRetrySettingLoki$outboundSchema.parse(responseRetrySettingLoki),
  );
}
export function responseRetrySettingLokiFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingLoki' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsLoki$inboundSchema: z.ZodType<
  TimeoutRetrySettingsLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsLoki$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsLoki$outboundSchema: z.ZodType<
  TimeoutRetrySettingsLoki$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsLoki
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsLokiToJSON(
  timeoutRetrySettingsLoki: TimeoutRetrySettingsLoki,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsLoki$outboundSchema.parse(timeoutRetrySettingsLoki),
  );
}
export function timeoutRetrySettingsLokiFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsLoki' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorLoki$inboundSchema: z.ZodType<
  BackpressureBehaviorLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorLoki$outboundSchema: z.ZodType<
  BackpressureBehaviorLoki,
  z.ZodTypeDef,
  BackpressureBehaviorLoki
> = z.union([
  z.nativeEnum(BackpressureBehaviorLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeLoki$inboundSchema: z.ZodType<
  OutputModeLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeLoki$outboundSchema: z.ZodType<
  OutputModeLoki,
  z.ZodTypeDef,
  OutputModeLoki
> = z.union([
  z.nativeEnum(OutputModeLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionLoki$inboundSchema: z.ZodType<
  PqCompressCompressionLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionLoki$outboundSchema: z.ZodType<
  PqCompressCompressionLoki,
  z.ZodTypeDef,
  PqCompressCompressionLoki
> = z.union([
  z.nativeEnum(PqCompressCompressionLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorLoki$inboundSchema: z.ZodType<
  QueueFullBehaviorLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorLoki$outboundSchema: z.ZodType<
  QueueFullBehaviorLoki,
  z.ZodTypeDef,
  QueueFullBehaviorLoki
> = z.union([
  z.nativeEnum(QueueFullBehaviorLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsLoki$inboundSchema: z.ZodType<
  OutputPqControlsLoki,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsLoki$Outbound = {};

/** @internal */
export const OutputPqControlsLoki$outboundSchema: z.ZodType<
  OutputPqControlsLoki$Outbound,
  z.ZodTypeDef,
  OutputPqControlsLoki
> = z.object({});

export function outputPqControlsLokiToJSON(
  outputPqControlsLoki: OutputPqControlsLoki,
): string {
  return JSON.stringify(
    OutputPqControlsLoki$outboundSchema.parse(outputPqControlsLoki),
  );
}
export function outputPqControlsLokiFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsLoki' from JSON`,
  );
}

/** @internal */
export const OutputLoki$inboundSchema: z.ZodType<
  OutputLoki,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeLoki$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    message: z.string().optional(),
    messageFormat: MessageFormatLoki$inboundSchema.default("protobuf"),
    labels: z.array(z.lazy(() => LabelLoki$inboundSchema)).optional(),
    authType: OutputAuthenticationTypeLoki$inboundSchema.default("none"),
    concurrency: z.number().default(1),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(15),
    extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderLoki$inboundSchema))
      .optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeLoki$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingLoki$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsLoki$inboundSchema)
      .optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    enableDynamicHeaders: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorLoki$inboundSchema.default("block"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    compress: z.boolean().default(true),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    credentialsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeLoki$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionLoki$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorLoki$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsLoki$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputLoki$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  message?: string | undefined;
  messageFormat: string;
  labels?: Array<LabelLoki$Outbound> | undefined;
  authType: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderLoki$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?: Array<ResponseRetrySettingLoki$Outbound> | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsLoki$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  enableDynamicHeaders: boolean;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  compress: boolean;
  token?: string | undefined;
  textSecret?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsLoki$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputLoki$outboundSchema: z.ZodType<
  OutputLoki$Outbound,
  z.ZodTypeDef,
  OutputLoki
> = z.object({
  id: z.string().optional(),
  type: OutputTypeLoki$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  message: z.string().optional(),
  messageFormat: MessageFormatLoki$outboundSchema.default("protobuf"),
  labels: z.array(z.lazy(() => LabelLoki$outboundSchema)).optional(),
  authType: OutputAuthenticationTypeLoki$outboundSchema.default("none"),
  concurrency: z.number().default(1),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(15),
  extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderLoki$outboundSchema))
    .optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeLoki$outboundSchema.default(
    "none",
  ),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingLoki$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsLoki$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  enableDynamicHeaders: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorLoki$outboundSchema.default("block"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  compress: z.boolean().default(true),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeLoki$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionLoki$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorLoki$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsLoki$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputLokiToJSON(outputLoki: OutputLoki): string {
  return JSON.stringify(OutputLoki$outboundSchema.parse(outputLoki));
}
export function outputLokiFromJSON(
  jsonString: string,
): SafeParseResult<OutputLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputLoki' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudType2$inboundSchema: z.ZodNativeEnum<
  typeof OutputGrafanaCloudType2
> = z.nativeEnum(OutputGrafanaCloudType2);
/** @internal */
export const OutputGrafanaCloudType2$outboundSchema: z.ZodNativeEnum<
  typeof OutputGrafanaCloudType2
> = OutputGrafanaCloudType2$inboundSchema;

/** @internal */
export const OutputGrafanaCloudMessageFormat2$inboundSchema: z.ZodType<
  OutputGrafanaCloudMessageFormat2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudMessageFormat2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudMessageFormat2$outboundSchema: z.ZodType<
  OutputGrafanaCloudMessageFormat2,
  z.ZodTypeDef,
  OutputGrafanaCloudMessageFormat2
> = z.union([
  z.nativeEnum(OutputGrafanaCloudMessageFormat2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudLabel2$inboundSchema: z.ZodType<
  OutputGrafanaCloudLabel2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type OutputGrafanaCloudLabel2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputGrafanaCloudLabel2$outboundSchema: z.ZodType<
  OutputGrafanaCloudLabel2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudLabel2
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});

export function outputGrafanaCloudLabel2ToJSON(
  outputGrafanaCloudLabel2: OutputGrafanaCloudLabel2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudLabel2$outboundSchema.parse(outputGrafanaCloudLabel2),
  );
}
export function outputGrafanaCloudLabel2FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudLabel2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudLabel2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudLabel2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudPrometheusAuthAuthenticationType2$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudPrometheusAuthAuthenticationType2,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudPrometheusAuthAuthenticationType2),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudPrometheusAuthAuthenticationType2$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudPrometheusAuthAuthenticationType2,
    z.ZodTypeDef,
    OutputGrafanaCloudPrometheusAuthAuthenticationType2
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudPrometheusAuthAuthenticationType2),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputPrometheusAuth2$inboundSchema: z.ZodType<
  OutputPrometheusAuth2,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: OutputGrafanaCloudPrometheusAuthAuthenticationType2$inboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputPrometheusAuth2$Outbound = {
  authType: string;
  token?: string | undefined;
  textSecret?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputPrometheusAuth2$outboundSchema: z.ZodType<
  OutputPrometheusAuth2$Outbound,
  z.ZodTypeDef,
  OutputPrometheusAuth2
> = z.object({
  authType: OutputGrafanaCloudPrometheusAuthAuthenticationType2$outboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});

export function outputPrometheusAuth2ToJSON(
  outputPrometheusAuth2: OutputPrometheusAuth2,
): string {
  return JSON.stringify(
    OutputPrometheusAuth2$outboundSchema.parse(outputPrometheusAuth2),
  );
}
export function outputPrometheusAuth2FromJSON(
  jsonString: string,
): SafeParseResult<OutputPrometheusAuth2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPrometheusAuth2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPrometheusAuth2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudLokiAuthAuthenticationType2$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudLokiAuthAuthenticationType2,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudLokiAuthAuthenticationType2),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudLokiAuthAuthenticationType2$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudLokiAuthAuthenticationType2,
    z.ZodTypeDef,
    OutputGrafanaCloudLokiAuthAuthenticationType2
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudLokiAuthAuthenticationType2),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputLokiAuth2$inboundSchema: z.ZodType<
  OutputLokiAuth2,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: OutputGrafanaCloudLokiAuthAuthenticationType2$inboundSchema.default(
    "basic",
  ),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputLokiAuth2$Outbound = {
  authType: string;
  token?: string | undefined;
  textSecret?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputLokiAuth2$outboundSchema: z.ZodType<
  OutputLokiAuth2$Outbound,
  z.ZodTypeDef,
  OutputLokiAuth2
> = z.object({
  authType: OutputGrafanaCloudLokiAuthAuthenticationType2$outboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});

export function outputLokiAuth2ToJSON(
  outputLokiAuth2: OutputLokiAuth2,
): string {
  return JSON.stringify(OutputLokiAuth2$outboundSchema.parse(outputLokiAuth2));
}
export function outputLokiAuth2FromJSON(
  jsonString: string,
): SafeParseResult<OutputLokiAuth2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputLokiAuth2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputLokiAuth2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudExtraHttpHeader2$inboundSchema: z.ZodType<
  OutputGrafanaCloudExtraHttpHeader2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type OutputGrafanaCloudExtraHttpHeader2$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const OutputGrafanaCloudExtraHttpHeader2$outboundSchema: z.ZodType<
  OutputGrafanaCloudExtraHttpHeader2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudExtraHttpHeader2
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function outputGrafanaCloudExtraHttpHeader2ToJSON(
  outputGrafanaCloudExtraHttpHeader2: OutputGrafanaCloudExtraHttpHeader2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudExtraHttpHeader2$outboundSchema.parse(
      outputGrafanaCloudExtraHttpHeader2,
    ),
  );
}
export function outputGrafanaCloudExtraHttpHeader2FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudExtraHttpHeader2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudExtraHttpHeader2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudExtraHttpHeader2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudFailedRequestLoggingMode2$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudFailedRequestLoggingMode2,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudFailedRequestLoggingMode2),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudFailedRequestLoggingMode2$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudFailedRequestLoggingMode2,
    z.ZodTypeDef,
    OutputGrafanaCloudFailedRequestLoggingMode2
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudFailedRequestLoggingMode2),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputGrafanaCloudResponseRetrySetting2$inboundSchema: z.ZodType<
  OutputGrafanaCloudResponseRetrySetting2,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type OutputGrafanaCloudResponseRetrySetting2$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const OutputGrafanaCloudResponseRetrySetting2$outboundSchema: z.ZodType<
  OutputGrafanaCloudResponseRetrySetting2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudResponseRetrySetting2
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function outputGrafanaCloudResponseRetrySetting2ToJSON(
  outputGrafanaCloudResponseRetrySetting2:
    OutputGrafanaCloudResponseRetrySetting2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudResponseRetrySetting2$outboundSchema.parse(
      outputGrafanaCloudResponseRetrySetting2,
    ),
  );
}
export function outputGrafanaCloudResponseRetrySetting2FromJSON(
  jsonString: string,
): SafeParseResult<
  OutputGrafanaCloudResponseRetrySetting2,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudResponseRetrySetting2$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputGrafanaCloudResponseRetrySetting2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudTimeoutRetrySettings2$inboundSchema: z.ZodType<
  OutputGrafanaCloudTimeoutRetrySettings2,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type OutputGrafanaCloudTimeoutRetrySettings2$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const OutputGrafanaCloudTimeoutRetrySettings2$outboundSchema: z.ZodType<
  OutputGrafanaCloudTimeoutRetrySettings2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudTimeoutRetrySettings2
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function outputGrafanaCloudTimeoutRetrySettings2ToJSON(
  outputGrafanaCloudTimeoutRetrySettings2:
    OutputGrafanaCloudTimeoutRetrySettings2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudTimeoutRetrySettings2$outboundSchema.parse(
      outputGrafanaCloudTimeoutRetrySettings2,
    ),
  );
}
export function outputGrafanaCloudTimeoutRetrySettings2FromJSON(
  jsonString: string,
): SafeParseResult<
  OutputGrafanaCloudTimeoutRetrySettings2,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudTimeoutRetrySettings2$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputGrafanaCloudTimeoutRetrySettings2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudBackpressureBehavior2$inboundSchema: z.ZodType<
  OutputGrafanaCloudBackpressureBehavior2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudBackpressureBehavior2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudBackpressureBehavior2$outboundSchema: z.ZodType<
  OutputGrafanaCloudBackpressureBehavior2,
  z.ZodTypeDef,
  OutputGrafanaCloudBackpressureBehavior2
> = z.union([
  z.nativeEnum(OutputGrafanaCloudBackpressureBehavior2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudMode2$inboundSchema: z.ZodType<
  OutputGrafanaCloudMode2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudMode2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudMode2$outboundSchema: z.ZodType<
  OutputGrafanaCloudMode2,
  z.ZodTypeDef,
  OutputGrafanaCloudMode2
> = z.union([
  z.nativeEnum(OutputGrafanaCloudMode2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudCompression2$inboundSchema: z.ZodType<
  OutputGrafanaCloudCompression2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudCompression2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudCompression2$outboundSchema: z.ZodType<
  OutputGrafanaCloudCompression2,
  z.ZodTypeDef,
  OutputGrafanaCloudCompression2
> = z.union([
  z.nativeEnum(OutputGrafanaCloudCompression2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudQueueFullBehavior2$inboundSchema: z.ZodType<
  OutputGrafanaCloudQueueFullBehavior2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudQueueFullBehavior2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudQueueFullBehavior2$outboundSchema: z.ZodType<
  OutputGrafanaCloudQueueFullBehavior2,
  z.ZodTypeDef,
  OutputGrafanaCloudQueueFullBehavior2
> = z.union([
  z.nativeEnum(OutputGrafanaCloudQueueFullBehavior2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudPqControls2$inboundSchema: z.ZodType<
  OutputGrafanaCloudPqControls2,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputGrafanaCloudPqControls2$Outbound = {};

/** @internal */
export const OutputGrafanaCloudPqControls2$outboundSchema: z.ZodType<
  OutputGrafanaCloudPqControls2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudPqControls2
> = z.object({});

export function outputGrafanaCloudPqControls2ToJSON(
  outputGrafanaCloudPqControls2: OutputGrafanaCloudPqControls2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudPqControls2$outboundSchema.parse(
      outputGrafanaCloudPqControls2,
    ),
  );
}
export function outputGrafanaCloudPqControls2FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudPqControls2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudPqControls2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudPqControls2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudGrafanaCloud2$inboundSchema: z.ZodType<
  OutputGrafanaCloudGrafanaCloud2,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputGrafanaCloudType2$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    lokiUrl: z.string().optional(),
    prometheusUrl: z.string(),
    message: z.string().optional(),
    messageFormat: OutputGrafanaCloudMessageFormat2$inboundSchema.default(
      "protobuf",
    ),
    labels: z.array(z.lazy(() => OutputGrafanaCloudLabel2$inboundSchema))
      .optional(),
    metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
    prometheusAuth: z.lazy(() => OutputPrometheusAuth2$inboundSchema)
      .optional(),
    lokiAuth: z.lazy(() => OutputLokiAuth2$inboundSchema).optional(),
    concurrency: z.number().default(1),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(15),
    extraHttpHeaders: z.array(
      z.lazy(() => OutputGrafanaCloudExtraHttpHeader2$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode:
      OutputGrafanaCloudFailedRequestLoggingMode2$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => OutputGrafanaCloudResponseRetrySetting2$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      OutputGrafanaCloudTimeoutRetrySettings2$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: OutputGrafanaCloudBackpressureBehavior2$inboundSchema
      .default("block"),
    description: z.string().optional(),
    compress: z.boolean().default(true),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputGrafanaCloudMode2$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: OutputGrafanaCloudCompression2$inboundSchema.default("none"),
    pqOnBackpressure: OutputGrafanaCloudQueueFullBehavior2$inboundSchema
      .default("block"),
    pqControls: z.lazy(() => OutputGrafanaCloudPqControls2$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGrafanaCloudGrafanaCloud2$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  lokiUrl?: string | undefined;
  prometheusUrl: string;
  message?: string | undefined;
  messageFormat: string;
  labels?: Array<OutputGrafanaCloudLabel2$Outbound> | undefined;
  metricRenameExpr: string;
  prometheusAuth?: OutputPrometheusAuth2$Outbound | undefined;
  lokiAuth?: OutputLokiAuth2$Outbound | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?:
    | Array<OutputGrafanaCloudExtraHttpHeader2$Outbound>
    | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<OutputGrafanaCloudResponseRetrySetting2$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | OutputGrafanaCloudTimeoutRetrySettings2$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  compress: boolean;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputGrafanaCloudPqControls2$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGrafanaCloudGrafanaCloud2$outboundSchema: z.ZodType<
  OutputGrafanaCloudGrafanaCloud2$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudGrafanaCloud2
> = z.object({
  id: z.string().optional(),
  type: OutputGrafanaCloudType2$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  lokiUrl: z.string().optional(),
  prometheusUrl: z.string(),
  message: z.string().optional(),
  messageFormat: OutputGrafanaCloudMessageFormat2$outboundSchema.default(
    "protobuf",
  ),
  labels: z.array(z.lazy(() => OutputGrafanaCloudLabel2$outboundSchema))
    .optional(),
  metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
  prometheusAuth: z.lazy(() => OutputPrometheusAuth2$outboundSchema).optional(),
  lokiAuth: z.lazy(() => OutputLokiAuth2$outboundSchema).optional(),
  concurrency: z.number().default(1),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(15),
  extraHttpHeaders: z.array(
    z.lazy(() => OutputGrafanaCloudExtraHttpHeader2$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode:
    OutputGrafanaCloudFailedRequestLoggingMode2$outboundSchema.default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => OutputGrafanaCloudResponseRetrySetting2$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    OutputGrafanaCloudTimeoutRetrySettings2$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: OutputGrafanaCloudBackpressureBehavior2$outboundSchema
    .default("block"),
  description: z.string().optional(),
  compress: z.boolean().default(true),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputGrafanaCloudMode2$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: OutputGrafanaCloudCompression2$outboundSchema.default("none"),
  pqOnBackpressure: OutputGrafanaCloudQueueFullBehavior2$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => OutputGrafanaCloudPqControls2$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGrafanaCloudGrafanaCloud2ToJSON(
  outputGrafanaCloudGrafanaCloud2: OutputGrafanaCloudGrafanaCloud2,
): string {
  return JSON.stringify(
    OutputGrafanaCloudGrafanaCloud2$outboundSchema.parse(
      outputGrafanaCloudGrafanaCloud2,
    ),
  );
}
export function outputGrafanaCloudGrafanaCloud2FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudGrafanaCloud2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudGrafanaCloud2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudGrafanaCloud2' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudType1$inboundSchema: z.ZodNativeEnum<
  typeof OutputGrafanaCloudType1
> = z.nativeEnum(OutputGrafanaCloudType1);
/** @internal */
export const OutputGrafanaCloudType1$outboundSchema: z.ZodNativeEnum<
  typeof OutputGrafanaCloudType1
> = OutputGrafanaCloudType1$inboundSchema;

/** @internal */
export const OutputGrafanaCloudMessageFormat1$inboundSchema: z.ZodType<
  OutputGrafanaCloudMessageFormat1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudMessageFormat1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudMessageFormat1$outboundSchema: z.ZodType<
  OutputGrafanaCloudMessageFormat1,
  z.ZodTypeDef,
  OutputGrafanaCloudMessageFormat1
> = z.union([
  z.nativeEnum(OutputGrafanaCloudMessageFormat1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudLabel1$inboundSchema: z.ZodType<
  OutputGrafanaCloudLabel1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type OutputGrafanaCloudLabel1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputGrafanaCloudLabel1$outboundSchema: z.ZodType<
  OutputGrafanaCloudLabel1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudLabel1
> = z.object({
  name: z.string().default(""),
  value: z.string(),
});

export function outputGrafanaCloudLabel1ToJSON(
  outputGrafanaCloudLabel1: OutputGrafanaCloudLabel1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudLabel1$outboundSchema.parse(outputGrafanaCloudLabel1),
  );
}
export function outputGrafanaCloudLabel1FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudLabel1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudLabel1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudLabel1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudPrometheusAuthAuthenticationType1$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudPrometheusAuthAuthenticationType1,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudPrometheusAuthAuthenticationType1),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudPrometheusAuthAuthenticationType1$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudPrometheusAuthAuthenticationType1,
    z.ZodTypeDef,
    OutputGrafanaCloudPrometheusAuthAuthenticationType1
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudPrometheusAuthAuthenticationType1),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputPrometheusAuth1$inboundSchema: z.ZodType<
  OutputPrometheusAuth1,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: OutputGrafanaCloudPrometheusAuthAuthenticationType1$inboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputPrometheusAuth1$Outbound = {
  authType: string;
  token?: string | undefined;
  textSecret?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputPrometheusAuth1$outboundSchema: z.ZodType<
  OutputPrometheusAuth1$Outbound,
  z.ZodTypeDef,
  OutputPrometheusAuth1
> = z.object({
  authType: OutputGrafanaCloudPrometheusAuthAuthenticationType1$outboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});

export function outputPrometheusAuth1ToJSON(
  outputPrometheusAuth1: OutputPrometheusAuth1,
): string {
  return JSON.stringify(
    OutputPrometheusAuth1$outboundSchema.parse(outputPrometheusAuth1),
  );
}
export function outputPrometheusAuth1FromJSON(
  jsonString: string,
): SafeParseResult<OutputPrometheusAuth1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPrometheusAuth1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPrometheusAuth1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudLokiAuthAuthenticationType1$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudLokiAuthAuthenticationType1,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudLokiAuthAuthenticationType1),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudLokiAuthAuthenticationType1$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudLokiAuthAuthenticationType1,
    z.ZodTypeDef,
    OutputGrafanaCloudLokiAuthAuthenticationType1
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudLokiAuthAuthenticationType1),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputLokiAuth1$inboundSchema: z.ZodType<
  OutputLokiAuth1,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: OutputGrafanaCloudLokiAuthAuthenticationType1$inboundSchema.default(
    "basic",
  ),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputLokiAuth1$Outbound = {
  authType: string;
  token?: string | undefined;
  textSecret?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputLokiAuth1$outboundSchema: z.ZodType<
  OutputLokiAuth1$Outbound,
  z.ZodTypeDef,
  OutputLokiAuth1
> = z.object({
  authType: OutputGrafanaCloudLokiAuthAuthenticationType1$outboundSchema
    .default("basic"),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
});

export function outputLokiAuth1ToJSON(
  outputLokiAuth1: OutputLokiAuth1,
): string {
  return JSON.stringify(OutputLokiAuth1$outboundSchema.parse(outputLokiAuth1));
}
export function outputLokiAuth1FromJSON(
  jsonString: string,
): SafeParseResult<OutputLokiAuth1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputLokiAuth1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputLokiAuth1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudExtraHttpHeader1$inboundSchema: z.ZodType<
  OutputGrafanaCloudExtraHttpHeader1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type OutputGrafanaCloudExtraHttpHeader1$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const OutputGrafanaCloudExtraHttpHeader1$outboundSchema: z.ZodType<
  OutputGrafanaCloudExtraHttpHeader1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudExtraHttpHeader1
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function outputGrafanaCloudExtraHttpHeader1ToJSON(
  outputGrafanaCloudExtraHttpHeader1: OutputGrafanaCloudExtraHttpHeader1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudExtraHttpHeader1$outboundSchema.parse(
      outputGrafanaCloudExtraHttpHeader1,
    ),
  );
}
export function outputGrafanaCloudExtraHttpHeader1FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudExtraHttpHeader1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudExtraHttpHeader1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudExtraHttpHeader1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudFailedRequestLoggingMode1$inboundSchema:
  z.ZodType<
    OutputGrafanaCloudFailedRequestLoggingMode1,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGrafanaCloudFailedRequestLoggingMode1),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGrafanaCloudFailedRequestLoggingMode1$outboundSchema:
  z.ZodType<
    OutputGrafanaCloudFailedRequestLoggingMode1,
    z.ZodTypeDef,
    OutputGrafanaCloudFailedRequestLoggingMode1
  > = z.union([
    z.nativeEnum(OutputGrafanaCloudFailedRequestLoggingMode1),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputGrafanaCloudResponseRetrySetting1$inboundSchema: z.ZodType<
  OutputGrafanaCloudResponseRetrySetting1,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type OutputGrafanaCloudResponseRetrySetting1$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const OutputGrafanaCloudResponseRetrySetting1$outboundSchema: z.ZodType<
  OutputGrafanaCloudResponseRetrySetting1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudResponseRetrySetting1
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function outputGrafanaCloudResponseRetrySetting1ToJSON(
  outputGrafanaCloudResponseRetrySetting1:
    OutputGrafanaCloudResponseRetrySetting1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudResponseRetrySetting1$outboundSchema.parse(
      outputGrafanaCloudResponseRetrySetting1,
    ),
  );
}
export function outputGrafanaCloudResponseRetrySetting1FromJSON(
  jsonString: string,
): SafeParseResult<
  OutputGrafanaCloudResponseRetrySetting1,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudResponseRetrySetting1$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputGrafanaCloudResponseRetrySetting1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudTimeoutRetrySettings1$inboundSchema: z.ZodType<
  OutputGrafanaCloudTimeoutRetrySettings1,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type OutputGrafanaCloudTimeoutRetrySettings1$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const OutputGrafanaCloudTimeoutRetrySettings1$outboundSchema: z.ZodType<
  OutputGrafanaCloudTimeoutRetrySettings1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudTimeoutRetrySettings1
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function outputGrafanaCloudTimeoutRetrySettings1ToJSON(
  outputGrafanaCloudTimeoutRetrySettings1:
    OutputGrafanaCloudTimeoutRetrySettings1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudTimeoutRetrySettings1$outboundSchema.parse(
      outputGrafanaCloudTimeoutRetrySettings1,
    ),
  );
}
export function outputGrafanaCloudTimeoutRetrySettings1FromJSON(
  jsonString: string,
): SafeParseResult<
  OutputGrafanaCloudTimeoutRetrySettings1,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputGrafanaCloudTimeoutRetrySettings1$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputGrafanaCloudTimeoutRetrySettings1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudBackpressureBehavior1$inboundSchema: z.ZodType<
  OutputGrafanaCloudBackpressureBehavior1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudBackpressureBehavior1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudBackpressureBehavior1$outboundSchema: z.ZodType<
  OutputGrafanaCloudBackpressureBehavior1,
  z.ZodTypeDef,
  OutputGrafanaCloudBackpressureBehavior1
> = z.union([
  z.nativeEnum(OutputGrafanaCloudBackpressureBehavior1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudMode1$inboundSchema: z.ZodType<
  OutputGrafanaCloudMode1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudMode1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudMode1$outboundSchema: z.ZodType<
  OutputGrafanaCloudMode1,
  z.ZodTypeDef,
  OutputGrafanaCloudMode1
> = z.union([
  z.nativeEnum(OutputGrafanaCloudMode1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudCompression1$inboundSchema: z.ZodType<
  OutputGrafanaCloudCompression1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudCompression1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudCompression1$outboundSchema: z.ZodType<
  OutputGrafanaCloudCompression1,
  z.ZodTypeDef,
  OutputGrafanaCloudCompression1
> = z.union([
  z.nativeEnum(OutputGrafanaCloudCompression1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudQueueFullBehavior1$inboundSchema: z.ZodType<
  OutputGrafanaCloudQueueFullBehavior1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputGrafanaCloudQueueFullBehavior1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputGrafanaCloudQueueFullBehavior1$outboundSchema: z.ZodType<
  OutputGrafanaCloudQueueFullBehavior1,
  z.ZodTypeDef,
  OutputGrafanaCloudQueueFullBehavior1
> = z.union([
  z.nativeEnum(OutputGrafanaCloudQueueFullBehavior1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputGrafanaCloudPqControls1$inboundSchema: z.ZodType<
  OutputGrafanaCloudPqControls1,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputGrafanaCloudPqControls1$Outbound = {};

/** @internal */
export const OutputGrafanaCloudPqControls1$outboundSchema: z.ZodType<
  OutputGrafanaCloudPqControls1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudPqControls1
> = z.object({});

export function outputGrafanaCloudPqControls1ToJSON(
  outputGrafanaCloudPqControls1: OutputGrafanaCloudPqControls1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudPqControls1$outboundSchema.parse(
      outputGrafanaCloudPqControls1,
    ),
  );
}
export function outputGrafanaCloudPqControls1FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudPqControls1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudPqControls1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudPqControls1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloudGrafanaCloud1$inboundSchema: z.ZodType<
  OutputGrafanaCloudGrafanaCloud1,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputGrafanaCloudType1$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    lokiUrl: z.string(),
    prometheusUrl: z.string().optional(),
    message: z.string().optional(),
    messageFormat: OutputGrafanaCloudMessageFormat1$inboundSchema.default(
      "protobuf",
    ),
    labels: z.array(z.lazy(() => OutputGrafanaCloudLabel1$inboundSchema))
      .optional(),
    metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
    prometheusAuth: z.lazy(() => OutputPrometheusAuth1$inboundSchema)
      .optional(),
    lokiAuth: z.lazy(() => OutputLokiAuth1$inboundSchema).optional(),
    concurrency: z.number().default(1),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(15),
    extraHttpHeaders: z.array(
      z.lazy(() => OutputGrafanaCloudExtraHttpHeader1$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode:
      OutputGrafanaCloudFailedRequestLoggingMode1$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => OutputGrafanaCloudResponseRetrySetting1$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      OutputGrafanaCloudTimeoutRetrySettings1$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: OutputGrafanaCloudBackpressureBehavior1$inboundSchema
      .default("block"),
    description: z.string().optional(),
    compress: z.boolean().default(true),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputGrafanaCloudMode1$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: OutputGrafanaCloudCompression1$inboundSchema.default("none"),
    pqOnBackpressure: OutputGrafanaCloudQueueFullBehavior1$inboundSchema
      .default("block"),
    pqControls: z.lazy(() => OutputGrafanaCloudPqControls1$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGrafanaCloudGrafanaCloud1$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  lokiUrl: string;
  prometheusUrl?: string | undefined;
  message?: string | undefined;
  messageFormat: string;
  labels?: Array<OutputGrafanaCloudLabel1$Outbound> | undefined;
  metricRenameExpr: string;
  prometheusAuth?: OutputPrometheusAuth1$Outbound | undefined;
  lokiAuth?: OutputLokiAuth1$Outbound | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?:
    | Array<OutputGrafanaCloudExtraHttpHeader1$Outbound>
    | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<OutputGrafanaCloudResponseRetrySetting1$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | OutputGrafanaCloudTimeoutRetrySettings1$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  compress: boolean;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputGrafanaCloudPqControls1$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGrafanaCloudGrafanaCloud1$outboundSchema: z.ZodType<
  OutputGrafanaCloudGrafanaCloud1$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloudGrafanaCloud1
> = z.object({
  id: z.string().optional(),
  type: OutputGrafanaCloudType1$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  lokiUrl: z.string(),
  prometheusUrl: z.string().optional(),
  message: z.string().optional(),
  messageFormat: OutputGrafanaCloudMessageFormat1$outboundSchema.default(
    "protobuf",
  ),
  labels: z.array(z.lazy(() => OutputGrafanaCloudLabel1$outboundSchema))
    .optional(),
  metricRenameExpr: z.string().default("name.replace(/[^a-zA-Z0-9_]/g, '_')"),
  prometheusAuth: z.lazy(() => OutputPrometheusAuth1$outboundSchema).optional(),
  lokiAuth: z.lazy(() => OutputLokiAuth1$outboundSchema).optional(),
  concurrency: z.number().default(1),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(15),
  extraHttpHeaders: z.array(
    z.lazy(() => OutputGrafanaCloudExtraHttpHeader1$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode:
    OutputGrafanaCloudFailedRequestLoggingMode1$outboundSchema.default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => OutputGrafanaCloudResponseRetrySetting1$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    OutputGrafanaCloudTimeoutRetrySettings1$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: OutputGrafanaCloudBackpressureBehavior1$outboundSchema
    .default("block"),
  description: z.string().optional(),
  compress: z.boolean().default(true),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputGrafanaCloudMode1$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: OutputGrafanaCloudCompression1$outboundSchema.default("none"),
  pqOnBackpressure: OutputGrafanaCloudQueueFullBehavior1$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => OutputGrafanaCloudPqControls1$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGrafanaCloudGrafanaCloud1ToJSON(
  outputGrafanaCloudGrafanaCloud1: OutputGrafanaCloudGrafanaCloud1,
): string {
  return JSON.stringify(
    OutputGrafanaCloudGrafanaCloud1$outboundSchema.parse(
      outputGrafanaCloudGrafanaCloud1,
    ),
  );
}
export function outputGrafanaCloudGrafanaCloud1FromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloudGrafanaCloud1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloudGrafanaCloud1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloudGrafanaCloud1' from JSON`,
  );
}

/** @internal */
export const OutputGrafanaCloud$inboundSchema: z.ZodType<
  OutputGrafanaCloud,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => OutputGrafanaCloudGrafanaCloud1$inboundSchema),
  z.lazy(() => OutputGrafanaCloudGrafanaCloud2$inboundSchema),
]);
/** @internal */
export type OutputGrafanaCloud$Outbound =
  | OutputGrafanaCloudGrafanaCloud1$Outbound
  | OutputGrafanaCloudGrafanaCloud2$Outbound;

/** @internal */
export const OutputGrafanaCloud$outboundSchema: z.ZodType<
  OutputGrafanaCloud$Outbound,
  z.ZodTypeDef,
  OutputGrafanaCloud
> = z.union([
  z.lazy(() => OutputGrafanaCloudGrafanaCloud1$outboundSchema),
  z.lazy(() => OutputGrafanaCloudGrafanaCloud2$outboundSchema),
]);

export function outputGrafanaCloudToJSON(
  outputGrafanaCloud: OutputGrafanaCloud,
): string {
  return JSON.stringify(
    OutputGrafanaCloud$outboundSchema.parse(outputGrafanaCloud),
  );
}
export function outputGrafanaCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputGrafanaCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGrafanaCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGrafanaCloud' from JSON`,
  );
}

/** @internal */
export const TypeDatadog$inboundSchema: z.ZodNativeEnum<typeof TypeDatadog> = z
  .nativeEnum(TypeDatadog);
/** @internal */
export const TypeDatadog$outboundSchema: z.ZodNativeEnum<typeof TypeDatadog> =
  TypeDatadog$inboundSchema;

/** @internal */
export const SendLogsAs$inboundSchema: z.ZodType<
  SendLogsAs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SendLogsAs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SendLogsAs$outboundSchema: z.ZodType<
  SendLogsAs,
  z.ZodTypeDef,
  SendLogsAs
> = z.union([
  z.nativeEnum(SendLogsAs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SeverityDatadog$inboundSchema: z.ZodType<
  SeverityDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SeverityDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SeverityDatadog$outboundSchema: z.ZodType<
  SeverityDatadog,
  z.ZodTypeDef,
  SeverityDatadog
> = z.union([
  z.nativeEnum(SeverityDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DatadogSite$inboundSchema: z.ZodType<
  DatadogSite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DatadogSite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DatadogSite$outboundSchema: z.ZodType<
  DatadogSite,
  z.ZodTypeDef,
  DatadogSite
> = z.union([
  z.nativeEnum(DatadogSite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderDatadog$inboundSchema: z.ZodType<
  ExtraHttpHeaderDatadog,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderDatadog$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderDatadog$outboundSchema: z.ZodType<
  ExtraHttpHeaderDatadog$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderDatadog
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderDatadogToJSON(
  extraHttpHeaderDatadog: ExtraHttpHeaderDatadog,
): string {
  return JSON.stringify(
    ExtraHttpHeaderDatadog$outboundSchema.parse(extraHttpHeaderDatadog),
  );
}
export function extraHttpHeaderDatadogFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderDatadog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderDatadog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderDatadog' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeDatadog$inboundSchema: z.ZodType<
  FailedRequestLoggingModeDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeDatadog$outboundSchema: z.ZodType<
  FailedRequestLoggingModeDatadog,
  z.ZodTypeDef,
  FailedRequestLoggingModeDatadog
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingDatadog$inboundSchema: z.ZodType<
  ResponseRetrySettingDatadog,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingDatadog$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingDatadog$outboundSchema: z.ZodType<
  ResponseRetrySettingDatadog$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingDatadog
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingDatadogToJSON(
  responseRetrySettingDatadog: ResponseRetrySettingDatadog,
): string {
  return JSON.stringify(
    ResponseRetrySettingDatadog$outboundSchema.parse(
      responseRetrySettingDatadog,
    ),
  );
}
export function responseRetrySettingDatadogFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingDatadog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingDatadog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingDatadog' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsDatadog$inboundSchema: z.ZodType<
  TimeoutRetrySettingsDatadog,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsDatadog$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsDatadog$outboundSchema: z.ZodType<
  TimeoutRetrySettingsDatadog$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsDatadog
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsDatadogToJSON(
  timeoutRetrySettingsDatadog: TimeoutRetrySettingsDatadog,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsDatadog$outboundSchema.parse(
      timeoutRetrySettingsDatadog,
    ),
  );
}
export function timeoutRetrySettingsDatadogFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsDatadog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsDatadog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsDatadog' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorDatadog$inboundSchema: z.ZodType<
  BackpressureBehaviorDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorDatadog$outboundSchema: z.ZodType<
  BackpressureBehaviorDatadog,
  z.ZodTypeDef,
  BackpressureBehaviorDatadog
> = z.union([
  z.nativeEnum(BackpressureBehaviorDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodDatadog$inboundSchema: z.ZodType<
  AuthenticationMethodDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodDatadog$outboundSchema: z.ZodType<
  AuthenticationMethodDatadog,
  z.ZodTypeDef,
  AuthenticationMethodDatadog
> = z.union([
  z.nativeEnum(AuthenticationMethodDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeDatadog$inboundSchema: z.ZodType<
  ModeDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDatadog$outboundSchema: z.ZodType<
  ModeDatadog,
  z.ZodTypeDef,
  ModeDatadog
> = z.union([
  z.nativeEnum(ModeDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDatadog$inboundSchema: z.ZodType<
  CompressionDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDatadog$outboundSchema: z.ZodType<
  CompressionDatadog,
  z.ZodTypeDef,
  CompressionDatadog
> = z.union([
  z.nativeEnum(CompressionDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorDatadog$inboundSchema: z.ZodType<
  QueueFullBehaviorDatadog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorDatadog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorDatadog$outboundSchema: z.ZodType<
  QueueFullBehaviorDatadog,
  z.ZodTypeDef,
  QueueFullBehaviorDatadog
> = z.union([
  z.nativeEnum(QueueFullBehaviorDatadog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDatadog$inboundSchema: z.ZodType<
  PqControlsDatadog,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDatadog$Outbound = {};

/** @internal */
export const PqControlsDatadog$outboundSchema: z.ZodType<
  PqControlsDatadog$Outbound,
  z.ZodTypeDef,
  PqControlsDatadog
> = z.object({});

export function pqControlsDatadogToJSON(
  pqControlsDatadog: PqControlsDatadog,
): string {
  return JSON.stringify(
    PqControlsDatadog$outboundSchema.parse(pqControlsDatadog),
  );
}
export function pqControlsDatadogFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDatadog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDatadog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDatadog' from JSON`,
  );
}

/** @internal */
export const OutputDatadog$inboundSchema: z.ZodType<
  OutputDatadog,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDatadog$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    contentType: SendLogsAs$inboundSchema.default("json"),
    message: z.string().optional(),
    source: z.string().optional(),
    host: z.string().optional(),
    service: z.string().optional(),
    tags: z.array(z.string()).optional(),
    batchByTags: z.boolean().default(true),
    allowApiKeyFromEvents: z.boolean().default(false),
    severity: SeverityDatadog$inboundSchema.optional(),
    site: DatadogSite$inboundSchema.default("us"),
    sendCountersAsCount: z.boolean().default(false),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderDatadog$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeDatadog$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingDatadog$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsDatadog$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorDatadog$inboundSchema.default("block"),
    authType: AuthenticationMethodDatadog$inboundSchema.default("manual"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    customUrl: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeDatadog$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionDatadog$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorDatadog$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsDatadog$inboundSchema).optional(),
    apiKey: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDatadog$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  contentType: string;
  message?: string | undefined;
  source?: string | undefined;
  host?: string | undefined;
  service?: string | undefined;
  tags?: Array<string> | undefined;
  batchByTags: boolean;
  allowApiKeyFromEvents: boolean;
  severity?: string | undefined;
  site: string;
  sendCountersAsCount: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderDatadog$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingDatadog$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsDatadog$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsDatadog$Outbound | undefined;
  apiKey?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDatadog$outboundSchema: z.ZodType<
  OutputDatadog$Outbound,
  z.ZodTypeDef,
  OutputDatadog
> = z.object({
  id: z.string().optional(),
  type: TypeDatadog$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  contentType: SendLogsAs$outboundSchema.default("json"),
  message: z.string().optional(),
  source: z.string().optional(),
  host: z.string().optional(),
  service: z.string().optional(),
  tags: z.array(z.string()).optional(),
  batchByTags: z.boolean().default(true),
  allowApiKeyFromEvents: z.boolean().default(false),
  severity: SeverityDatadog$outboundSchema.optional(),
  site: DatadogSite$outboundSchema.default("us"),
  sendCountersAsCount: z.boolean().default(false),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderDatadog$outboundSchema))
    .optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeDatadog$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingDatadog$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsDatadog$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorDatadog$outboundSchema.default("block"),
  authType: AuthenticationMethodDatadog$outboundSchema.default("manual"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  customUrl: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeDatadog$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionDatadog$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorDatadog$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsDatadog$outboundSchema).optional(),
  apiKey: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDatadogToJSON(outputDatadog: OutputDatadog): string {
  return JSON.stringify(OutputDatadog$outboundSchema.parse(outputDatadog));
}
export function outputDatadogFromJSON(
  jsonString: string,
): SafeParseResult<OutputDatadog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDatadog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDatadog' from JSON`,
  );
}

/** @internal */
export const TypeSumoLogic$inboundSchema: z.ZodNativeEnum<
  typeof TypeSumoLogic
> = z.nativeEnum(TypeSumoLogic);
/** @internal */
export const TypeSumoLogic$outboundSchema: z.ZodNativeEnum<
  typeof TypeSumoLogic
> = TypeSumoLogic$inboundSchema;

/** @internal */
export const DataFormatSumoLogic$inboundSchema: z.ZodType<
  DataFormatSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatSumoLogic$outboundSchema: z.ZodType<
  DataFormatSumoLogic,
  z.ZodTypeDef,
  DataFormatSumoLogic
> = z.union([
  z.nativeEnum(DataFormatSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderSumoLogic$inboundSchema: z.ZodType<
  ExtraHttpHeaderSumoLogic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderSumoLogic$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderSumoLogic$outboundSchema: z.ZodType<
  ExtraHttpHeaderSumoLogic$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderSumoLogic
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderSumoLogicToJSON(
  extraHttpHeaderSumoLogic: ExtraHttpHeaderSumoLogic,
): string {
  return JSON.stringify(
    ExtraHttpHeaderSumoLogic$outboundSchema.parse(extraHttpHeaderSumoLogic),
  );
}
export function extraHttpHeaderSumoLogicFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderSumoLogic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderSumoLogic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderSumoLogic' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeSumoLogic$inboundSchema: z.ZodType<
  FailedRequestLoggingModeSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeSumoLogic$outboundSchema: z.ZodType<
  FailedRequestLoggingModeSumoLogic,
  z.ZodTypeDef,
  FailedRequestLoggingModeSumoLogic
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingSumoLogic$inboundSchema: z.ZodType<
  ResponseRetrySettingSumoLogic,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingSumoLogic$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingSumoLogic$outboundSchema: z.ZodType<
  ResponseRetrySettingSumoLogic$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingSumoLogic
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingSumoLogicToJSON(
  responseRetrySettingSumoLogic: ResponseRetrySettingSumoLogic,
): string {
  return JSON.stringify(
    ResponseRetrySettingSumoLogic$outboundSchema.parse(
      responseRetrySettingSumoLogic,
    ),
  );
}
export function responseRetrySettingSumoLogicFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingSumoLogic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingSumoLogic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingSumoLogic' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsSumoLogic$inboundSchema: z.ZodType<
  TimeoutRetrySettingsSumoLogic,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsSumoLogic$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsSumoLogic$outboundSchema: z.ZodType<
  TimeoutRetrySettingsSumoLogic$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsSumoLogic
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsSumoLogicToJSON(
  timeoutRetrySettingsSumoLogic: TimeoutRetrySettingsSumoLogic,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsSumoLogic$outboundSchema.parse(
      timeoutRetrySettingsSumoLogic,
    ),
  );
}
export function timeoutRetrySettingsSumoLogicFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsSumoLogic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsSumoLogic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsSumoLogic' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSumoLogic$inboundSchema: z.ZodType<
  BackpressureBehaviorSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSumoLogic$outboundSchema: z.ZodType<
  BackpressureBehaviorSumoLogic,
  z.ZodTypeDef,
  BackpressureBehaviorSumoLogic
> = z.union([
  z.nativeEnum(BackpressureBehaviorSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSumoLogic$inboundSchema: z.ZodType<
  ModeSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSumoLogic$outboundSchema: z.ZodType<
  ModeSumoLogic,
  z.ZodTypeDef,
  ModeSumoLogic
> = z.union([
  z.nativeEnum(ModeSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSumoLogic$inboundSchema: z.ZodType<
  CompressionSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSumoLogic$outboundSchema: z.ZodType<
  CompressionSumoLogic,
  z.ZodTypeDef,
  CompressionSumoLogic
> = z.union([
  z.nativeEnum(CompressionSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSumoLogic$inboundSchema: z.ZodType<
  QueueFullBehaviorSumoLogic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSumoLogic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSumoLogic$outboundSchema: z.ZodType<
  QueueFullBehaviorSumoLogic,
  z.ZodTypeDef,
  QueueFullBehaviorSumoLogic
> = z.union([
  z.nativeEnum(QueueFullBehaviorSumoLogic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSumoLogic$inboundSchema: z.ZodType<
  PqControlsSumoLogic,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSumoLogic$Outbound = {};

/** @internal */
export const PqControlsSumoLogic$outboundSchema: z.ZodType<
  PqControlsSumoLogic$Outbound,
  z.ZodTypeDef,
  PqControlsSumoLogic
> = z.object({});

export function pqControlsSumoLogicToJSON(
  pqControlsSumoLogic: PqControlsSumoLogic,
): string {
  return JSON.stringify(
    PqControlsSumoLogic$outboundSchema.parse(pqControlsSumoLogic),
  );
}
export function pqControlsSumoLogicFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSumoLogic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSumoLogic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSumoLogic' from JSON`,
  );
}

/** @internal */
export const OutputSumoLogic$inboundSchema: z.ZodType<
  OutputSumoLogic,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSumoLogic$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    customSource: z.string().optional(),
    customCategory: z.string().optional(),
    format: DataFormatSumoLogic$inboundSchema.default("json"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderSumoLogic$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeSumoLogic$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingSumoLogic$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsSumoLogic$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorSumoLogic$inboundSchema.default(
      "block",
    ),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSumoLogic$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSumoLogic$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSumoLogic$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSumoLogic$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSumoLogic$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  customSource?: string | undefined;
  customCategory?: string | undefined;
  format: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderSumoLogic$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingSumoLogic$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSumoLogic$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSumoLogic$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSumoLogic$outboundSchema: z.ZodType<
  OutputSumoLogic$Outbound,
  z.ZodTypeDef,
  OutputSumoLogic
> = z.object({
  id: z.string().optional(),
  type: TypeSumoLogic$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  customSource: z.string().optional(),
  customCategory: z.string().optional(),
  format: DataFormatSumoLogic$outboundSchema.default("json"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderSumoLogic$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeSumoLogic$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingSumoLogic$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsSumoLogic$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorSumoLogic$outboundSchema.default("block"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSumoLogic$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSumoLogic$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSumoLogic$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSumoLogic$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSumoLogicToJSON(
  outputSumoLogic: OutputSumoLogic,
): string {
  return JSON.stringify(OutputSumoLogic$outboundSchema.parse(outputSumoLogic));
}
export function outputSumoLogicFromJSON(
  jsonString: string,
): SafeParseResult<OutputSumoLogic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSumoLogic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSumoLogic' from JSON`,
  );
}

/** @internal */
export const OutputTypeSnmp$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSnmp
> = z.nativeEnum(OutputTypeSnmp);
/** @internal */
export const OutputTypeSnmp$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSnmp
> = OutputTypeSnmp$inboundSchema;

/** @internal */
export const HostSnmp$inboundSchema: z.ZodType<
  HostSnmp,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number().default(162),
});
/** @internal */
export type HostSnmp$Outbound = {
  host: string;
  port: number;
};

/** @internal */
export const HostSnmp$outboundSchema: z.ZodType<
  HostSnmp$Outbound,
  z.ZodTypeDef,
  HostSnmp
> = z.object({
  host: z.string(),
  port: z.number().default(162),
});

export function hostSnmpToJSON(hostSnmp: HostSnmp): string {
  return JSON.stringify(HostSnmp$outboundSchema.parse(hostSnmp));
}
export function hostSnmpFromJSON(
  jsonString: string,
): SafeParseResult<HostSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostSnmp' from JSON`,
  );
}

/** @internal */
export const OutputSnmp$inboundSchema: z.ZodType<
  OutputSnmp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSnmp$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    hosts: z.array(z.lazy(() => HostSnmp$inboundSchema)),
    dnsResolvePeriodSec: z.number().default(0),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSnmp$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  hosts: Array<HostSnmp$Outbound>;
  dnsResolvePeriodSec: number;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSnmp$outboundSchema: z.ZodType<
  OutputSnmp$Outbound,
  z.ZodTypeDef,
  OutputSnmp
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSnmp$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  hosts: z.array(z.lazy(() => HostSnmp$outboundSchema)),
  dnsResolvePeriodSec: z.number().default(0),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSnmpToJSON(outputSnmp: OutputSnmp): string {
  return JSON.stringify(OutputSnmp$outboundSchema.parse(outputSnmp));
}
export function outputSnmpFromJSON(
  jsonString: string,
): SafeParseResult<OutputSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSnmp' from JSON`,
  );
}

/** @internal */
export const OutputTypeSqs$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSqs
> = z.nativeEnum(OutputTypeSqs);
/** @internal */
export const OutputTypeSqs$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSqs
> = OutputTypeSqs$inboundSchema;

/** @internal */
export const OutputQueueType$inboundSchema: z.ZodType<
  OutputQueueType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputQueueType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputQueueType$outboundSchema: z.ZodType<
  OutputQueueType,
  z.ZodTypeDef,
  OutputQueueType
> = z.union([
  z.nativeEnum(OutputQueueType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthenticationMethodSqs$inboundSchema: z.ZodType<
  OutputAuthenticationMethodSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodSqs$outboundSchema: z.ZodType<
  OutputAuthenticationMethodSqs,
  z.ZodTypeDef,
  OutputAuthenticationMethodSqs
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSignatureVersionSqs$inboundSchema: z.ZodType<
  OutputSignatureVersionSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSignatureVersionSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSignatureVersionSqs$outboundSchema: z.ZodType<
  OutputSignatureVersionSqs,
  z.ZodTypeDef,
  OutputSignatureVersionSqs
> = z.union([
  z.nativeEnum(OutputSignatureVersionSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorSqs$inboundSchema: z.ZodType<
  BackpressureBehaviorSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSqs$outboundSchema: z.ZodType<
  BackpressureBehaviorSqs,
  z.ZodTypeDef,
  BackpressureBehaviorSqs
> = z.union([
  z.nativeEnum(BackpressureBehaviorSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeSqs$inboundSchema: z.ZodType<
  OutputModeSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeSqs$outboundSchema: z.ZodType<
  OutputModeSqs,
  z.ZodTypeDef,
  OutputModeSqs
> = z.union([
  z.nativeEnum(OutputModeSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionSqs$inboundSchema: z.ZodType<
  PqCompressCompressionSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionSqs$outboundSchema: z.ZodType<
  PqCompressCompressionSqs,
  z.ZodTypeDef,
  PqCompressCompressionSqs
> = z.union([
  z.nativeEnum(PqCompressCompressionSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSqs$inboundSchema: z.ZodType<
  QueueFullBehaviorSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSqs$outboundSchema: z.ZodType<
  QueueFullBehaviorSqs,
  z.ZodTypeDef,
  QueueFullBehaviorSqs
> = z.union([
  z.nativeEnum(QueueFullBehaviorSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsSqs$inboundSchema: z.ZodType<
  OutputPqControlsSqs,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsSqs$Outbound = {};

/** @internal */
export const OutputPqControlsSqs$outboundSchema: z.ZodType<
  OutputPqControlsSqs$Outbound,
  z.ZodTypeDef,
  OutputPqControlsSqs
> = z.object({});

export function outputPqControlsSqsToJSON(
  outputPqControlsSqs: OutputPqControlsSqs,
): string {
  return JSON.stringify(
    OutputPqControlsSqs$outboundSchema.parse(outputPqControlsSqs),
  );
}
export function outputPqControlsSqsFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsSqs' from JSON`,
  );
}

/** @internal */
export const OutputSqs$inboundSchema: z.ZodType<
  OutputSqs,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSqs$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    queueName: z.string(),
    queueType: OutputQueueType$inboundSchema,
    awsAccountId: z.string().optional(),
    messageGroupId: z.string().default("cribl"),
    createQueue: z.boolean().default(true),
    awsAuthenticationMethod: OutputAuthenticationMethodSqs$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: OutputSignatureVersionSqs$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    maxQueueSize: z.number().default(100),
    maxRecordSizeKB: z.number().default(256),
    flushPeriodSec: z.number().default(1),
    maxInProgress: z.number().default(10),
    onBackpressure: BackpressureBehaviorSqs$inboundSchema.default("block"),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeSqs$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionSqs$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSqs$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsSqs$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSqs$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  queueName: string;
  queueType: string;
  awsAccountId?: string | undefined;
  messageGroupId: string;
  createQueue: boolean;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriodSec: number;
  maxInProgress: number;
  onBackpressure: string;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsSqs$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSqs$outboundSchema: z.ZodType<
  OutputSqs$Outbound,
  z.ZodTypeDef,
  OutputSqs
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSqs$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  queueName: z.string(),
  queueType: OutputQueueType$outboundSchema,
  awsAccountId: z.string().optional(),
  messageGroupId: z.string().default("cribl"),
  createQueue: z.boolean().default(true),
  awsAuthenticationMethod: OutputAuthenticationMethodSqs$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: OutputSignatureVersionSqs$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriodSec: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: BackpressureBehaviorSqs$outboundSchema.default("block"),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeSqs$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionSqs$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSqs$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsSqs$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSqsToJSON(outputSqs: OutputSqs): string {
  return JSON.stringify(OutputSqs$outboundSchema.parse(outputSqs));
}
export function outputSqsFromJSON(
  jsonString: string,
): SafeParseResult<OutputSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSqs' from JSON`,
  );
}

/** @internal */
export const TypeSns$inboundSchema: z.ZodNativeEnum<typeof TypeSns> = z
  .nativeEnum(TypeSns);
/** @internal */
export const TypeSns$outboundSchema: z.ZodNativeEnum<typeof TypeSns> =
  TypeSns$inboundSchema;

/** @internal */
export const AuthenticationMethodSns$inboundSchema: z.ZodType<
  AuthenticationMethodSns,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodSns),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodSns$outboundSchema: z.ZodType<
  AuthenticationMethodSns,
  z.ZodTypeDef,
  AuthenticationMethodSns
> = z.union([
  z.nativeEnum(AuthenticationMethodSns),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionSns$inboundSchema: z.ZodType<
  SignatureVersionSns,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionSns),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionSns$outboundSchema: z.ZodType<
  SignatureVersionSns,
  z.ZodTypeDef,
  SignatureVersionSns
> = z.union([
  z.nativeEnum(SignatureVersionSns),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorSns$inboundSchema: z.ZodType<
  BackpressureBehaviorSns,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSns),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSns$outboundSchema: z.ZodType<
  BackpressureBehaviorSns,
  z.ZodTypeDef,
  BackpressureBehaviorSns
> = z.union([
  z.nativeEnum(BackpressureBehaviorSns),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSns$inboundSchema: z.ZodType<ModeSns, z.ZodTypeDef, unknown> =
  z
    .union([
      z.nativeEnum(ModeSns),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ModeSns$outboundSchema: z.ZodType<ModeSns, z.ZodTypeDef, ModeSns> =
  z.union([
    z.nativeEnum(ModeSns),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const CompressionSns$inboundSchema: z.ZodType<
  CompressionSns,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSns),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSns$outboundSchema: z.ZodType<
  CompressionSns,
  z.ZodTypeDef,
  CompressionSns
> = z.union([
  z.nativeEnum(CompressionSns),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSns$inboundSchema: z.ZodType<
  QueueFullBehaviorSns,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSns),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSns$outboundSchema: z.ZodType<
  QueueFullBehaviorSns,
  z.ZodTypeDef,
  QueueFullBehaviorSns
> = z.union([
  z.nativeEnum(QueueFullBehaviorSns),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSns$inboundSchema: z.ZodType<
  PqControlsSns,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSns$Outbound = {};

/** @internal */
export const PqControlsSns$outboundSchema: z.ZodType<
  PqControlsSns$Outbound,
  z.ZodTypeDef,
  PqControlsSns
> = z.object({});

export function pqControlsSnsToJSON(pqControlsSns: PqControlsSns): string {
  return JSON.stringify(PqControlsSns$outboundSchema.parse(pqControlsSns));
}
export function pqControlsSnsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSns, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSns$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSns' from JSON`,
  );
}

/** @internal */
export const OutputSns$inboundSchema: z.ZodType<
  OutputSns,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSns$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    topicArn: z.string(),
    messageGroupId: z.string(),
    maxRetries: z.number().optional(),
    awsAuthenticationMethod: AuthenticationMethodSns$inboundSchema.default(
      "auto",
    ),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionSns$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    onBackpressure: BackpressureBehaviorSns$inboundSchema.default("block"),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSns$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSns$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSns$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSns$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSns$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicArn: string;
  messageGroupId: string;
  maxRetries?: number | undefined;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  onBackpressure: string;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSns$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSns$outboundSchema: z.ZodType<
  OutputSns$Outbound,
  z.ZodTypeDef,
  OutputSns
> = z.object({
  id: z.string().optional(),
  type: TypeSns$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicArn: z.string(),
  messageGroupId: z.string(),
  maxRetries: z.number().optional(),
  awsAuthenticationMethod: AuthenticationMethodSns$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionSns$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  onBackpressure: BackpressureBehaviorSns$outboundSchema.default("block"),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSns$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSns$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSns$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSns$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSnsToJSON(outputSns: OutputSns): string {
  return JSON.stringify(OutputSns$outboundSchema.parse(outputSns));
}
export function outputSnsFromJSON(
  jsonString: string,
): SafeParseResult<OutputSns, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSns$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSns' from JSON`,
  );
}

/** @internal */
export const TypeRouter$inboundSchema: z.ZodNativeEnum<typeof TypeRouter> = z
  .nativeEnum(TypeRouter);
/** @internal */
export const TypeRouter$outboundSchema: z.ZodNativeEnum<typeof TypeRouter> =
  TypeRouter$inboundSchema;

/** @internal */
export const OutputRule$inboundSchema: z.ZodType<
  OutputRule,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  output: z.string(),
  description: z.string().optional(),
  final: z.boolean().default(true),
});
/** @internal */
export type OutputRule$Outbound = {
  filter: string;
  output: string;
  description?: string | undefined;
  final: boolean;
};

/** @internal */
export const OutputRule$outboundSchema: z.ZodType<
  OutputRule$Outbound,
  z.ZodTypeDef,
  OutputRule
> = z.object({
  filter: z.string(),
  output: z.string(),
  description: z.string().optional(),
  final: z.boolean().default(true),
});

export function outputRuleToJSON(outputRule: OutputRule): string {
  return JSON.stringify(OutputRule$outboundSchema.parse(outputRule));
}
export function outputRuleFromJSON(
  jsonString: string,
): SafeParseResult<OutputRule, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputRule$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputRule' from JSON`,
  );
}

/** @internal */
export const OutputRouter$inboundSchema: z.ZodType<
  OutputRouter,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeRouter$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    rules: z.array(z.lazy(() => OutputRule$inboundSchema)),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputRouter$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  rules: Array<OutputRule$Outbound>;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputRouter$outboundSchema: z.ZodType<
  OutputRouter$Outbound,
  z.ZodTypeDef,
  OutputRouter
> = z.object({
  id: z.string().optional(),
  type: TypeRouter$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  rules: z.array(z.lazy(() => OutputRule$outboundSchema)),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputRouterToJSON(outputRouter: OutputRouter): string {
  return JSON.stringify(OutputRouter$outboundSchema.parse(outputRouter));
}
export function outputRouterFromJSON(
  jsonString: string,
): SafeParseResult<OutputRouter, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputRouter$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputRouter' from JSON`,
  );
}

/** @internal */
export const TypeGraphite$inboundSchema: z.ZodNativeEnum<typeof TypeGraphite> =
  z.nativeEnum(TypeGraphite);
/** @internal */
export const TypeGraphite$outboundSchema: z.ZodNativeEnum<typeof TypeGraphite> =
  TypeGraphite$inboundSchema;

/** @internal */
export const DestinationProtocolGraphite$inboundSchema: z.ZodType<
  DestinationProtocolGraphite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DestinationProtocolGraphite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DestinationProtocolGraphite$outboundSchema: z.ZodType<
  DestinationProtocolGraphite,
  z.ZodTypeDef,
  DestinationProtocolGraphite
> = z.union([
  z.nativeEnum(DestinationProtocolGraphite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorGraphite$inboundSchema: z.ZodType<
  BackpressureBehaviorGraphite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorGraphite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorGraphite$outboundSchema: z.ZodType<
  BackpressureBehaviorGraphite,
  z.ZodTypeDef,
  BackpressureBehaviorGraphite
> = z.union([
  z.nativeEnum(BackpressureBehaviorGraphite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeGraphite$inboundSchema: z.ZodType<
  ModeGraphite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeGraphite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeGraphite$outboundSchema: z.ZodType<
  ModeGraphite,
  z.ZodTypeDef,
  ModeGraphite
> = z.union([
  z.nativeEnum(ModeGraphite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionGraphite$inboundSchema: z.ZodType<
  CompressionGraphite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionGraphite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionGraphite$outboundSchema: z.ZodType<
  CompressionGraphite,
  z.ZodTypeDef,
  CompressionGraphite
> = z.union([
  z.nativeEnum(CompressionGraphite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorGraphite$inboundSchema: z.ZodType<
  QueueFullBehaviorGraphite,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorGraphite),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorGraphite$outboundSchema: z.ZodType<
  QueueFullBehaviorGraphite,
  z.ZodTypeDef,
  QueueFullBehaviorGraphite
> = z.union([
  z.nativeEnum(QueueFullBehaviorGraphite),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsGraphite$inboundSchema: z.ZodType<
  PqControlsGraphite,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsGraphite$Outbound = {};

/** @internal */
export const PqControlsGraphite$outboundSchema: z.ZodType<
  PqControlsGraphite$Outbound,
  z.ZodTypeDef,
  PqControlsGraphite
> = z.object({});

export function pqControlsGraphiteToJSON(
  pqControlsGraphite: PqControlsGraphite,
): string {
  return JSON.stringify(
    PqControlsGraphite$outboundSchema.parse(pqControlsGraphite),
  );
}
export function pqControlsGraphiteFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsGraphite, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsGraphite$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsGraphite' from JSON`,
  );
}

/** @internal */
export const OutputGraphite$inboundSchema: z.ZodType<
  OutputGraphite,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeGraphite$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: DestinationProtocolGraphite$inboundSchema.default("udp"),
    host: z.string(),
    port: z.number().default(8125),
    mtu: z.number().default(512),
    flushPeriodSec: z.number().default(1),
    dnsResolvePeriodSec: z.number().default(0),
    description: z.string().optional(),
    throttleRatePerSec: z.string().default("0"),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    onBackpressure: BackpressureBehaviorGraphite$inboundSchema.default("block"),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeGraphite$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionGraphite$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorGraphite$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsGraphite$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGraphite$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  host: string;
  port: number;
  mtu: number;
  flushPeriodSec: number;
  dnsResolvePeriodSec: number;
  description?: string | undefined;
  throttleRatePerSec: string;
  connectionTimeout: number;
  writeTimeout: number;
  onBackpressure: string;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsGraphite$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGraphite$outboundSchema: z.ZodType<
  OutputGraphite$Outbound,
  z.ZodTypeDef,
  OutputGraphite
> = z.object({
  id: z.string().optional(),
  type: TypeGraphite$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: DestinationProtocolGraphite$outboundSchema.default("udp"),
  host: z.string(),
  port: z.number().default(8125),
  mtu: z.number().default(512),
  flushPeriodSec: z.number().default(1),
  dnsResolvePeriodSec: z.number().default(0),
  description: z.string().optional(),
  throttleRatePerSec: z.string().default("0"),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  onBackpressure: BackpressureBehaviorGraphite$outboundSchema.default("block"),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeGraphite$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionGraphite$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorGraphite$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsGraphite$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGraphiteToJSON(outputGraphite: OutputGraphite): string {
  return JSON.stringify(OutputGraphite$outboundSchema.parse(outputGraphite));
}
export function outputGraphiteFromJSON(
  jsonString: string,
): SafeParseResult<OutputGraphite, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGraphite$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGraphite' from JSON`,
  );
}

/** @internal */
export const TypeStatsdExt$inboundSchema: z.ZodNativeEnum<
  typeof TypeStatsdExt
> = z.nativeEnum(TypeStatsdExt);
/** @internal */
export const TypeStatsdExt$outboundSchema: z.ZodNativeEnum<
  typeof TypeStatsdExt
> = TypeStatsdExt$inboundSchema;

/** @internal */
export const DestinationProtocolStatsdExt$inboundSchema: z.ZodType<
  DestinationProtocolStatsdExt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DestinationProtocolStatsdExt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DestinationProtocolStatsdExt$outboundSchema: z.ZodType<
  DestinationProtocolStatsdExt,
  z.ZodTypeDef,
  DestinationProtocolStatsdExt
> = z.union([
  z.nativeEnum(DestinationProtocolStatsdExt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorStatsdExt$inboundSchema: z.ZodType<
  BackpressureBehaviorStatsdExt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorStatsdExt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorStatsdExt$outboundSchema: z.ZodType<
  BackpressureBehaviorStatsdExt,
  z.ZodTypeDef,
  BackpressureBehaviorStatsdExt
> = z.union([
  z.nativeEnum(BackpressureBehaviorStatsdExt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeStatsdExt$inboundSchema: z.ZodType<
  ModeStatsdExt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeStatsdExt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeStatsdExt$outboundSchema: z.ZodType<
  ModeStatsdExt,
  z.ZodTypeDef,
  ModeStatsdExt
> = z.union([
  z.nativeEnum(ModeStatsdExt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionStatsdExt$inboundSchema: z.ZodType<
  CompressionStatsdExt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionStatsdExt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionStatsdExt$outboundSchema: z.ZodType<
  CompressionStatsdExt,
  z.ZodTypeDef,
  CompressionStatsdExt
> = z.union([
  z.nativeEnum(CompressionStatsdExt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorStatsdExt$inboundSchema: z.ZodType<
  QueueFullBehaviorStatsdExt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorStatsdExt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorStatsdExt$outboundSchema: z.ZodType<
  QueueFullBehaviorStatsdExt,
  z.ZodTypeDef,
  QueueFullBehaviorStatsdExt
> = z.union([
  z.nativeEnum(QueueFullBehaviorStatsdExt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsStatsdExt$inboundSchema: z.ZodType<
  PqControlsStatsdExt,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsStatsdExt$Outbound = {};

/** @internal */
export const PqControlsStatsdExt$outboundSchema: z.ZodType<
  PqControlsStatsdExt$Outbound,
  z.ZodTypeDef,
  PqControlsStatsdExt
> = z.object({});

export function pqControlsStatsdExtToJSON(
  pqControlsStatsdExt: PqControlsStatsdExt,
): string {
  return JSON.stringify(
    PqControlsStatsdExt$outboundSchema.parse(pqControlsStatsdExt),
  );
}
export function pqControlsStatsdExtFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsStatsdExt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsStatsdExt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsStatsdExt' from JSON`,
  );
}

/** @internal */
export const OutputStatsdExt$inboundSchema: z.ZodType<
  OutputStatsdExt,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeStatsdExt$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: DestinationProtocolStatsdExt$inboundSchema.default("udp"),
    host: z.string(),
    port: z.number().default(8125),
    mtu: z.number().default(512),
    flushPeriodSec: z.number().default(1),
    dnsResolvePeriodSec: z.number().default(0),
    description: z.string().optional(),
    throttleRatePerSec: z.string().default("0"),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    onBackpressure: BackpressureBehaviorStatsdExt$inboundSchema.default(
      "block",
    ),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeStatsdExt$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionStatsdExt$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorStatsdExt$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsStatsdExt$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputStatsdExt$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  host: string;
  port: number;
  mtu: number;
  flushPeriodSec: number;
  dnsResolvePeriodSec: number;
  description?: string | undefined;
  throttleRatePerSec: string;
  connectionTimeout: number;
  writeTimeout: number;
  onBackpressure: string;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsStatsdExt$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputStatsdExt$outboundSchema: z.ZodType<
  OutputStatsdExt$Outbound,
  z.ZodTypeDef,
  OutputStatsdExt
> = z.object({
  id: z.string().optional(),
  type: TypeStatsdExt$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: DestinationProtocolStatsdExt$outboundSchema.default("udp"),
  host: z.string(),
  port: z.number().default(8125),
  mtu: z.number().default(512),
  flushPeriodSec: z.number().default(1),
  dnsResolvePeriodSec: z.number().default(0),
  description: z.string().optional(),
  throttleRatePerSec: z.string().default("0"),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  onBackpressure: BackpressureBehaviorStatsdExt$outboundSchema.default("block"),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeStatsdExt$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionStatsdExt$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorStatsdExt$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsStatsdExt$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputStatsdExtToJSON(
  outputStatsdExt: OutputStatsdExt,
): string {
  return JSON.stringify(OutputStatsdExt$outboundSchema.parse(outputStatsdExt));
}
export function outputStatsdExtFromJSON(
  jsonString: string,
): SafeParseResult<OutputStatsdExt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputStatsdExt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputStatsdExt' from JSON`,
  );
}

/** @internal */
export const TypeStatsd$inboundSchema: z.ZodNativeEnum<typeof TypeStatsd> = z
  .nativeEnum(TypeStatsd);
/** @internal */
export const TypeStatsd$outboundSchema: z.ZodNativeEnum<typeof TypeStatsd> =
  TypeStatsd$inboundSchema;

/** @internal */
export const DestinationProtocolStatsd$inboundSchema: z.ZodType<
  DestinationProtocolStatsd,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DestinationProtocolStatsd),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DestinationProtocolStatsd$outboundSchema: z.ZodType<
  DestinationProtocolStatsd,
  z.ZodTypeDef,
  DestinationProtocolStatsd
> = z.union([
  z.nativeEnum(DestinationProtocolStatsd),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorStatsd$inboundSchema: z.ZodType<
  BackpressureBehaviorStatsd,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorStatsd),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorStatsd$outboundSchema: z.ZodType<
  BackpressureBehaviorStatsd,
  z.ZodTypeDef,
  BackpressureBehaviorStatsd
> = z.union([
  z.nativeEnum(BackpressureBehaviorStatsd),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeStatsd$inboundSchema: z.ZodType<
  ModeStatsd,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeStatsd),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeStatsd$outboundSchema: z.ZodType<
  ModeStatsd,
  z.ZodTypeDef,
  ModeStatsd
> = z.union([
  z.nativeEnum(ModeStatsd),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionStatsd$inboundSchema: z.ZodType<
  CompressionStatsd,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionStatsd),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionStatsd$outboundSchema: z.ZodType<
  CompressionStatsd,
  z.ZodTypeDef,
  CompressionStatsd
> = z.union([
  z.nativeEnum(CompressionStatsd),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorStatsd$inboundSchema: z.ZodType<
  QueueFullBehaviorStatsd,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorStatsd),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorStatsd$outboundSchema: z.ZodType<
  QueueFullBehaviorStatsd,
  z.ZodTypeDef,
  QueueFullBehaviorStatsd
> = z.union([
  z.nativeEnum(QueueFullBehaviorStatsd),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsStatsd$inboundSchema: z.ZodType<
  PqControlsStatsd,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsStatsd$Outbound = {};

/** @internal */
export const PqControlsStatsd$outboundSchema: z.ZodType<
  PqControlsStatsd$Outbound,
  z.ZodTypeDef,
  PqControlsStatsd
> = z.object({});

export function pqControlsStatsdToJSON(
  pqControlsStatsd: PqControlsStatsd,
): string {
  return JSON.stringify(
    PqControlsStatsd$outboundSchema.parse(pqControlsStatsd),
  );
}
export function pqControlsStatsdFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsStatsd, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsStatsd$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsStatsd' from JSON`,
  );
}

/** @internal */
export const OutputStatsd$inboundSchema: z.ZodType<
  OutputStatsd,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeStatsd$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: DestinationProtocolStatsd$inboundSchema.default("udp"),
    host: z.string(),
    port: z.number().default(8125),
    mtu: z.number().default(512),
    flushPeriodSec: z.number().default(1),
    dnsResolvePeriodSec: z.number().default(0),
    description: z.string().optional(),
    throttleRatePerSec: z.string().default("0"),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    onBackpressure: BackpressureBehaviorStatsd$inboundSchema.default("block"),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeStatsd$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionStatsd$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorStatsd$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsStatsd$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputStatsd$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  host: string;
  port: number;
  mtu: number;
  flushPeriodSec: number;
  dnsResolvePeriodSec: number;
  description?: string | undefined;
  throttleRatePerSec: string;
  connectionTimeout: number;
  writeTimeout: number;
  onBackpressure: string;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsStatsd$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputStatsd$outboundSchema: z.ZodType<
  OutputStatsd$Outbound,
  z.ZodTypeDef,
  OutputStatsd
> = z.object({
  id: z.string().optional(),
  type: TypeStatsd$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: DestinationProtocolStatsd$outboundSchema.default("udp"),
  host: z.string(),
  port: z.number().default(8125),
  mtu: z.number().default(512),
  flushPeriodSec: z.number().default(1),
  dnsResolvePeriodSec: z.number().default(0),
  description: z.string().optional(),
  throttleRatePerSec: z.string().default("0"),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  onBackpressure: BackpressureBehaviorStatsd$outboundSchema.default("block"),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeStatsd$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionStatsd$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorStatsd$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsStatsd$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputStatsdToJSON(outputStatsd: OutputStatsd): string {
  return JSON.stringify(OutputStatsd$outboundSchema.parse(outputStatsd));
}
export function outputStatsdFromJSON(
  jsonString: string,
): SafeParseResult<OutputStatsd, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputStatsd$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputStatsd' from JSON`,
  );
}

/** @internal */
export const TypeMinio$inboundSchema: z.ZodNativeEnum<typeof TypeMinio> = z
  .nativeEnum(TypeMinio);
/** @internal */
export const TypeMinio$outboundSchema: z.ZodNativeEnum<typeof TypeMinio> =
  TypeMinio$inboundSchema;

/** @internal */
export const AuthenticationMethodMinio$inboundSchema: z.ZodType<
  AuthenticationMethodMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodMinio$outboundSchema: z.ZodType<
  AuthenticationMethodMinio,
  z.ZodTypeDef,
  AuthenticationMethodMinio
> = z.union([
  z.nativeEnum(AuthenticationMethodMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionMinio$inboundSchema: z.ZodType<
  SignatureVersionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionMinio$outboundSchema: z.ZodType<
  SignatureVersionMinio,
  z.ZodTypeDef,
  SignatureVersionMinio
> = z.union([
  z.nativeEnum(SignatureVersionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLMinio$inboundSchema: z.ZodType<
  ObjectACLMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLMinio$outboundSchema: z.ZodType<
  ObjectACLMinio,
  z.ZodTypeDef,
  ObjectACLMinio
> = z.union([
  z.nativeEnum(ObjectACLMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassMinio$inboundSchema: z.ZodType<
  StorageClassMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassMinio$outboundSchema: z.ZodType<
  StorageClassMinio,
  z.ZodTypeDef,
  StorageClassMinio
> = z.union([
  z.nativeEnum(StorageClassMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionMinio$inboundSchema: z.ZodType<
  ServerSideEncryptionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ServerSideEncryptionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ServerSideEncryptionMinio$outboundSchema: z.ZodType<
  ServerSideEncryptionMinio,
  z.ZodTypeDef,
  ServerSideEncryptionMinio
> = z.union([
  z.nativeEnum(ServerSideEncryptionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataFormatMinio$inboundSchema: z.ZodType<
  DataFormatMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatMinio$outboundSchema: z.ZodType<
  DataFormatMinio,
  z.ZodTypeDef,
  DataFormatMinio
> = z.union([
  z.nativeEnum(DataFormatMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorMinio$inboundSchema: z.ZodType<
  BackpressureBehaviorMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorMinio$outboundSchema: z.ZodType<
  BackpressureBehaviorMinio,
  z.ZodTypeDef,
  BackpressureBehaviorMinio
> = z.union([
  z.nativeEnum(BackpressureBehaviorMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionMinio$inboundSchema: z.ZodType<
  DiskSpaceProtectionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionMinio$outboundSchema: z.ZodType<
  DiskSpaceProtectionMinio,
  z.ZodTypeDef,
  DiskSpaceProtectionMinio
> = z.union([
  z.nativeEnum(DiskSpaceProtectionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionMinio$inboundSchema: z.ZodType<
  CompressionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionMinio$outboundSchema: z.ZodType<
  CompressionMinio,
  z.ZodTypeDef,
  CompressionMinio
> = z.union([
  z.nativeEnum(CompressionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelMinio$inboundSchema: z.ZodType<
  CompressionLevelMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelMinio$outboundSchema: z.ZodType<
  CompressionLevelMinio,
  z.ZodTypeDef,
  CompressionLevelMinio
> = z.union([
  z.nativeEnum(CompressionLevelMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionMinio$inboundSchema: z.ZodType<
  ParquetVersionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionMinio$outboundSchema: z.ZodType<
  ParquetVersionMinio,
  z.ZodTypeDef,
  ParquetVersionMinio
> = z.union([
  z.nativeEnum(ParquetVersionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionMinio$inboundSchema: z.ZodType<
  DataPageVersionMinio,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionMinio),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionMinio$outboundSchema: z.ZodType<
  DataPageVersionMinio,
  z.ZodTypeDef,
  DataPageVersionMinio
> = z.union([
  z.nativeEnum(DataPageVersionMinio),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumMinio$inboundSchema: z.ZodType<
  KeyValueMetadatumMinio,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumMinio$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumMinio$outboundSchema: z.ZodType<
  KeyValueMetadatumMinio$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumMinio
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumMinioToJSON(
  keyValueMetadatumMinio: KeyValueMetadatumMinio,
): string {
  return JSON.stringify(
    KeyValueMetadatumMinio$outboundSchema.parse(keyValueMetadatumMinio),
  );
}
export function keyValueMetadatumMinioFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumMinio, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumMinio$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumMinio' from JSON`,
  );
}

/** @internal */
export const OutputMinio$inboundSchema: z.ZodType<
  OutputMinio,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeMinio$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    endpoint: z.string(),
    bucket: z.string(),
    awsAuthenticationMethod: AuthenticationMethodMinio$inboundSchema.default(
      "auto",
    ),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    destPath: z.string().optional(),
    signatureVersion: SignatureVersionMinio$inboundSchema.default("v4"),
    objectACL: ObjectACLMinio$inboundSchema.default("private"),
    storageClass: StorageClassMinio$inboundSchema.optional(),
    serverSideEncryption: ServerSideEncryptionMinio$inboundSchema.optional(),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    verifyPermissions: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatMinio$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorMinio$inboundSchema.default("block"),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionMinio$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxConcurrentFileParts: z.number().default(4),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    compress: CompressionMinio$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelMinio$inboundSchema.default("best_speed"),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionMinio$inboundSchema.default("PARQUET_2_6"),
    parquetDataPageVersion: DataPageVersionMinio$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumMinio$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputMinio$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  endpoint: string;
  bucket: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath?: string | undefined;
  signatureVersion: string;
  objectACL: string;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  verifyPermissions: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumMinio$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputMinio$outboundSchema: z.ZodType<
  OutputMinio$Outbound,
  z.ZodTypeDef,
  OutputMinio
> = z.object({
  id: z.string().optional(),
  type: TypeMinio$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  endpoint: z.string(),
  bucket: z.string(),
  awsAuthenticationMethod: AuthenticationMethodMinio$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().optional(),
  signatureVersion: SignatureVersionMinio$outboundSchema.default("v4"),
  objectACL: ObjectACLMinio$outboundSchema.default("private"),
  storageClass: StorageClassMinio$outboundSchema.optional(),
  serverSideEncryption: ServerSideEncryptionMinio$outboundSchema.optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  verifyPermissions: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatMinio$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorMinio$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionMinio$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: CompressionMinio$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelMinio$outboundSchema.default("best_speed"),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionMinio$outboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionMinio$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(z.lazy(() => KeyValueMetadatumMinio$outboundSchema))
    .optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputMinioToJSON(outputMinio: OutputMinio): string {
  return JSON.stringify(OutputMinio$outboundSchema.parse(outputMinio));
}
export function outputMinioFromJSON(
  jsonString: string,
): SafeParseResult<OutputMinio, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputMinio$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputMinio' from JSON`,
  );
}

/** @internal */
export const TypeCloudwatch$inboundSchema: z.ZodNativeEnum<
  typeof TypeCloudwatch
> = z.nativeEnum(TypeCloudwatch);
/** @internal */
export const TypeCloudwatch$outboundSchema: z.ZodNativeEnum<
  typeof TypeCloudwatch
> = TypeCloudwatch$inboundSchema;

/** @internal */
export const AuthenticationMethodCloudwatch$inboundSchema: z.ZodType<
  AuthenticationMethodCloudwatch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodCloudwatch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodCloudwatch$outboundSchema: z.ZodType<
  AuthenticationMethodCloudwatch,
  z.ZodTypeDef,
  AuthenticationMethodCloudwatch
> = z.union([
  z.nativeEnum(AuthenticationMethodCloudwatch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorCloudwatch$inboundSchema: z.ZodType<
  BackpressureBehaviorCloudwatch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorCloudwatch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorCloudwatch$outboundSchema: z.ZodType<
  BackpressureBehaviorCloudwatch,
  z.ZodTypeDef,
  BackpressureBehaviorCloudwatch
> = z.union([
  z.nativeEnum(BackpressureBehaviorCloudwatch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeCloudwatch$inboundSchema: z.ZodType<
  ModeCloudwatch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCloudwatch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCloudwatch$outboundSchema: z.ZodType<
  ModeCloudwatch,
  z.ZodTypeDef,
  ModeCloudwatch
> = z.union([
  z.nativeEnum(ModeCloudwatch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCloudwatch$inboundSchema: z.ZodType<
  CompressionCloudwatch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCloudwatch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCloudwatch$outboundSchema: z.ZodType<
  CompressionCloudwatch,
  z.ZodTypeDef,
  CompressionCloudwatch
> = z.union([
  z.nativeEnum(CompressionCloudwatch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorCloudwatch$inboundSchema: z.ZodType<
  QueueFullBehaviorCloudwatch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorCloudwatch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorCloudwatch$outboundSchema: z.ZodType<
  QueueFullBehaviorCloudwatch,
  z.ZodTypeDef,
  QueueFullBehaviorCloudwatch
> = z.union([
  z.nativeEnum(QueueFullBehaviorCloudwatch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCloudwatch$inboundSchema: z.ZodType<
  PqControlsCloudwatch,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCloudwatch$Outbound = {};

/** @internal */
export const PqControlsCloudwatch$outboundSchema: z.ZodType<
  PqControlsCloudwatch$Outbound,
  z.ZodTypeDef,
  PqControlsCloudwatch
> = z.object({});

export function pqControlsCloudwatchToJSON(
  pqControlsCloudwatch: PqControlsCloudwatch,
): string {
  return JSON.stringify(
    PqControlsCloudwatch$outboundSchema.parse(pqControlsCloudwatch),
  );
}
export function pqControlsCloudwatchFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCloudwatch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCloudwatch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCloudwatch' from JSON`,
  );
}

/** @internal */
export const OutputCloudwatch$inboundSchema: z.ZodType<
  OutputCloudwatch,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCloudwatch$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    logGroupName: z.string(),
    logStreamName: z.string(),
    awsAuthenticationMethod: AuthenticationMethodCloudwatch$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string(),
    endpoint: z.string().optional(),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    maxQueueSize: z.number().default(5),
    maxRecordSizeKB: z.number().default(1024),
    flushPeriodSec: z.number().default(1),
    onBackpressure: BackpressureBehaviorCloudwatch$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeCloudwatch$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionCloudwatch$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorCloudwatch$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsCloudwatch$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputCloudwatch$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  logGroupName: string;
  logStreamName: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region: string;
  endpoint?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriodSec: number;
  onBackpressure: string;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsCloudwatch$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputCloudwatch$outboundSchema: z.ZodType<
  OutputCloudwatch$Outbound,
  z.ZodTypeDef,
  OutputCloudwatch
> = z.object({
  id: z.string().optional(),
  type: TypeCloudwatch$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  logGroupName: z.string(),
  logStreamName: z.string(),
  awsAuthenticationMethod: AuthenticationMethodCloudwatch$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string(),
  endpoint: z.string().optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  maxQueueSize: z.number().default(5),
  maxRecordSizeKB: z.number().default(1024),
  flushPeriodSec: z.number().default(1),
  onBackpressure: BackpressureBehaviorCloudwatch$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeCloudwatch$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionCloudwatch$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorCloudwatch$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsCloudwatch$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputCloudwatchToJSON(
  outputCloudwatch: OutputCloudwatch,
): string {
  return JSON.stringify(
    OutputCloudwatch$outboundSchema.parse(outputCloudwatch),
  );
}
export function outputCloudwatchFromJSON(
  jsonString: string,
): SafeParseResult<OutputCloudwatch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCloudwatch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCloudwatch' from JSON`,
  );
}

/** @internal */
export const TypeInfluxdb$inboundSchema: z.ZodNativeEnum<typeof TypeInfluxdb> =
  z.nativeEnum(TypeInfluxdb);
/** @internal */
export const TypeInfluxdb$outboundSchema: z.ZodNativeEnum<typeof TypeInfluxdb> =
  TypeInfluxdb$inboundSchema;

/** @internal */
export const TimestampPrecision$inboundSchema: z.ZodType<
  TimestampPrecision,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TimestampPrecision),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TimestampPrecision$outboundSchema: z.ZodType<
  TimestampPrecision,
  z.ZodTypeDef,
  TimestampPrecision
> = z.union([
  z.nativeEnum(TimestampPrecision),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderInfluxdb$inboundSchema: z.ZodType<
  ExtraHttpHeaderInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderInfluxdb$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderInfluxdb$outboundSchema: z.ZodType<
  ExtraHttpHeaderInfluxdb$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderInfluxdb
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderInfluxdbToJSON(
  extraHttpHeaderInfluxdb: ExtraHttpHeaderInfluxdb,
): string {
  return JSON.stringify(
    ExtraHttpHeaderInfluxdb$outboundSchema.parse(extraHttpHeaderInfluxdb),
  );
}
export function extraHttpHeaderInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderInfluxdb' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeInfluxdb$inboundSchema: z.ZodType<
  FailedRequestLoggingModeInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeInfluxdb$outboundSchema: z.ZodType<
  FailedRequestLoggingModeInfluxdb,
  z.ZodTypeDef,
  FailedRequestLoggingModeInfluxdb
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingInfluxdb$inboundSchema: z.ZodType<
  ResponseRetrySettingInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingInfluxdb$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingInfluxdb$outboundSchema: z.ZodType<
  ResponseRetrySettingInfluxdb$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingInfluxdb
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingInfluxdbToJSON(
  responseRetrySettingInfluxdb: ResponseRetrySettingInfluxdb,
): string {
  return JSON.stringify(
    ResponseRetrySettingInfluxdb$outboundSchema.parse(
      responseRetrySettingInfluxdb,
    ),
  );
}
export function responseRetrySettingInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingInfluxdb' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsInfluxdb$inboundSchema: z.ZodType<
  TimeoutRetrySettingsInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsInfluxdb$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsInfluxdb$outboundSchema: z.ZodType<
  TimeoutRetrySettingsInfluxdb$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsInfluxdb
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsInfluxdbToJSON(
  timeoutRetrySettingsInfluxdb: TimeoutRetrySettingsInfluxdb,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsInfluxdb$outboundSchema.parse(
      timeoutRetrySettingsInfluxdb,
    ),
  );
}
export function timeoutRetrySettingsInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsInfluxdb' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorInfluxdb$inboundSchema: z.ZodType<
  BackpressureBehaviorInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorInfluxdb$outboundSchema: z.ZodType<
  BackpressureBehaviorInfluxdb,
  z.ZodTypeDef,
  BackpressureBehaviorInfluxdb
> = z.union([
  z.nativeEnum(BackpressureBehaviorInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationTypeInfluxdb$inboundSchema: z.ZodType<
  AuthenticationTypeInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeInfluxdb$outboundSchema: z.ZodType<
  AuthenticationTypeInfluxdb,
  z.ZodTypeDef,
  AuthenticationTypeInfluxdb
> = z.union([
  z.nativeEnum(AuthenticationTypeInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeInfluxdb$inboundSchema: z.ZodType<
  ModeInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeInfluxdb$outboundSchema: z.ZodType<
  ModeInfluxdb,
  z.ZodTypeDef,
  ModeInfluxdb
> = z.union([
  z.nativeEnum(ModeInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionInfluxdb$inboundSchema: z.ZodType<
  CompressionInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionInfluxdb$outboundSchema: z.ZodType<
  CompressionInfluxdb,
  z.ZodTypeDef,
  CompressionInfluxdb
> = z.union([
  z.nativeEnum(CompressionInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorInfluxdb$inboundSchema: z.ZodType<
  QueueFullBehaviorInfluxdb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorInfluxdb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorInfluxdb$outboundSchema: z.ZodType<
  QueueFullBehaviorInfluxdb,
  z.ZodTypeDef,
  QueueFullBehaviorInfluxdb
> = z.union([
  z.nativeEnum(QueueFullBehaviorInfluxdb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsInfluxdb$inboundSchema: z.ZodType<
  PqControlsInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsInfluxdb$Outbound = {};

/** @internal */
export const PqControlsInfluxdb$outboundSchema: z.ZodType<
  PqControlsInfluxdb$Outbound,
  z.ZodTypeDef,
  PqControlsInfluxdb
> = z.object({});

export function pqControlsInfluxdbToJSON(
  pqControlsInfluxdb: PqControlsInfluxdb,
): string {
  return JSON.stringify(
    PqControlsInfluxdb$outboundSchema.parse(pqControlsInfluxdb),
  );
}
export function pqControlsInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsInfluxdb' from JSON`,
  );
}

/** @internal */
export const OauthParamInfluxdb$inboundSchema: z.ZodType<
  OauthParamInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamInfluxdb$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamInfluxdb$outboundSchema: z.ZodType<
  OauthParamInfluxdb$Outbound,
  z.ZodTypeDef,
  OauthParamInfluxdb
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamInfluxdbToJSON(
  oauthParamInfluxdb: OauthParamInfluxdb,
): string {
  return JSON.stringify(
    OauthParamInfluxdb$outboundSchema.parse(oauthParamInfluxdb),
  );
}
export function oauthParamInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamInfluxdb' from JSON`,
  );
}

/** @internal */
export const OauthHeaderInfluxdb$inboundSchema: z.ZodType<
  OauthHeaderInfluxdb,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderInfluxdb$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderInfluxdb$outboundSchema: z.ZodType<
  OauthHeaderInfluxdb$Outbound,
  z.ZodTypeDef,
  OauthHeaderInfluxdb
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderInfluxdbToJSON(
  oauthHeaderInfluxdb: OauthHeaderInfluxdb,
): string {
  return JSON.stringify(
    OauthHeaderInfluxdb$outboundSchema.parse(oauthHeaderInfluxdb),
  );
}
export function oauthHeaderInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderInfluxdb' from JSON`,
  );
}

/** @internal */
export const OutputInfluxdb$inboundSchema: z.ZodType<
  OutputInfluxdb,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeInfluxdb$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    useV2API: z.boolean().default(false),
    timestampPrecision: TimestampPrecision$inboundSchema.default("ms"),
    dynamicValueFieldName: z.boolean().default(true),
    valueFieldName: z.string().default("value"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderInfluxdb$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeInfluxdb$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingInfluxdb$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsInfluxdb$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorInfluxdb$inboundSchema.default("block"),
    authType: AuthenticationTypeInfluxdb$inboundSchema.default("none"),
    description: z.string().optional(),
    database: z.string().optional(),
    bucket: z.string().optional(),
    org: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeInfluxdb$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionInfluxdb$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorInfluxdb$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsInfluxdb$inboundSchema).optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamInfluxdb$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderInfluxdb$inboundSchema))
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputInfluxdb$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  useV2API: boolean;
  timestampPrecision: string;
  dynamicValueFieldName: boolean;
  valueFieldName: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderInfluxdb$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingInfluxdb$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsInfluxdb$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  database?: string | undefined;
  bucket?: string | undefined;
  org?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsInfluxdb$Outbound | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamInfluxdb$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderInfluxdb$Outbound> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputInfluxdb$outboundSchema: z.ZodType<
  OutputInfluxdb$Outbound,
  z.ZodTypeDef,
  OutputInfluxdb
> = z.object({
  id: z.string().optional(),
  type: TypeInfluxdb$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  useV2API: z.boolean().default(false),
  timestampPrecision: TimestampPrecision$outboundSchema.default("ms"),
  dynamicValueFieldName: z.boolean().default(true),
  valueFieldName: z.string().default("value"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderInfluxdb$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeInfluxdb$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingInfluxdb$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsInfluxdb$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorInfluxdb$outboundSchema.default("block"),
  authType: AuthenticationTypeInfluxdb$outboundSchema.default("none"),
  description: z.string().optional(),
  database: z.string().optional(),
  bucket: z.string().optional(),
  org: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeInfluxdb$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionInfluxdb$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorInfluxdb$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsInfluxdb$outboundSchema).optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamInfluxdb$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderInfluxdb$outboundSchema))
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputInfluxdbToJSON(outputInfluxdb: OutputInfluxdb): string {
  return JSON.stringify(OutputInfluxdb$outboundSchema.parse(outputInfluxdb));
}
export function outputInfluxdbFromJSON(
  jsonString: string,
): SafeParseResult<OutputInfluxdb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputInfluxdb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputInfluxdb' from JSON`,
  );
}

/** @internal */
export const TypeNewrelicEvents$inboundSchema: z.ZodNativeEnum<
  typeof TypeNewrelicEvents
> = z.nativeEnum(TypeNewrelicEvents);
/** @internal */
export const TypeNewrelicEvents$outboundSchema: z.ZodNativeEnum<
  typeof TypeNewrelicEvents
> = TypeNewrelicEvents$inboundSchema;

/** @internal */
export const RegionNewrelicEvents$inboundSchema: z.ZodType<
  RegionNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RegionNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RegionNewrelicEvents$outboundSchema: z.ZodType<
  RegionNewrelicEvents,
  z.ZodTypeDef,
  RegionNewrelicEvents
> = z.union([
  z.nativeEnum(RegionNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderNewrelicEvents$inboundSchema: z.ZodType<
  ExtraHttpHeaderNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderNewrelicEvents$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderNewrelicEvents$outboundSchema: z.ZodType<
  ExtraHttpHeaderNewrelicEvents$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderNewrelicEvents
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderNewrelicEventsToJSON(
  extraHttpHeaderNewrelicEvents: ExtraHttpHeaderNewrelicEvents,
): string {
  return JSON.stringify(
    ExtraHttpHeaderNewrelicEvents$outboundSchema.parse(
      extraHttpHeaderNewrelicEvents,
    ),
  );
}
export function extraHttpHeaderNewrelicEventsFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderNewrelicEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderNewrelicEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderNewrelicEvents' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeNewrelicEvents$inboundSchema: z.ZodType<
  FailedRequestLoggingModeNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeNewrelicEvents$outboundSchema: z.ZodType<
  FailedRequestLoggingModeNewrelicEvents,
  z.ZodTypeDef,
  FailedRequestLoggingModeNewrelicEvents
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingNewrelicEvents$inboundSchema: z.ZodType<
  ResponseRetrySettingNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingNewrelicEvents$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingNewrelicEvents$outboundSchema: z.ZodType<
  ResponseRetrySettingNewrelicEvents$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingNewrelicEvents
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingNewrelicEventsToJSON(
  responseRetrySettingNewrelicEvents: ResponseRetrySettingNewrelicEvents,
): string {
  return JSON.stringify(
    ResponseRetrySettingNewrelicEvents$outboundSchema.parse(
      responseRetrySettingNewrelicEvents,
    ),
  );
}
export function responseRetrySettingNewrelicEventsFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingNewrelicEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      ResponseRetrySettingNewrelicEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingNewrelicEvents' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsNewrelicEvents$inboundSchema: z.ZodType<
  TimeoutRetrySettingsNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsNewrelicEvents$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsNewrelicEvents$outboundSchema: z.ZodType<
  TimeoutRetrySettingsNewrelicEvents$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsNewrelicEvents
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsNewrelicEventsToJSON(
  timeoutRetrySettingsNewrelicEvents: TimeoutRetrySettingsNewrelicEvents,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsNewrelicEvents$outboundSchema.parse(
      timeoutRetrySettingsNewrelicEvents,
    ),
  );
}
export function timeoutRetrySettingsNewrelicEventsFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsNewrelicEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TimeoutRetrySettingsNewrelicEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsNewrelicEvents' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorNewrelicEvents$inboundSchema: z.ZodType<
  BackpressureBehaviorNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorNewrelicEvents$outboundSchema: z.ZodType<
  BackpressureBehaviorNewrelicEvents,
  z.ZodTypeDef,
  BackpressureBehaviorNewrelicEvents
> = z.union([
  z.nativeEnum(BackpressureBehaviorNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodNewrelicEvents$inboundSchema: z.ZodType<
  AuthenticationMethodNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodNewrelicEvents$outboundSchema: z.ZodType<
  AuthenticationMethodNewrelicEvents,
  z.ZodTypeDef,
  AuthenticationMethodNewrelicEvents
> = z.union([
  z.nativeEnum(AuthenticationMethodNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeNewrelicEvents$inboundSchema: z.ZodType<
  ModeNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeNewrelicEvents$outboundSchema: z.ZodType<
  ModeNewrelicEvents,
  z.ZodTypeDef,
  ModeNewrelicEvents
> = z.union([
  z.nativeEnum(ModeNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionNewrelicEvents$inboundSchema: z.ZodType<
  CompressionNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionNewrelicEvents$outboundSchema: z.ZodType<
  CompressionNewrelicEvents,
  z.ZodTypeDef,
  CompressionNewrelicEvents
> = z.union([
  z.nativeEnum(CompressionNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorNewrelicEvents$inboundSchema: z.ZodType<
  QueueFullBehaviorNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorNewrelicEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorNewrelicEvents$outboundSchema: z.ZodType<
  QueueFullBehaviorNewrelicEvents,
  z.ZodTypeDef,
  QueueFullBehaviorNewrelicEvents
> = z.union([
  z.nativeEnum(QueueFullBehaviorNewrelicEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsNewrelicEvents$inboundSchema: z.ZodType<
  PqControlsNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsNewrelicEvents$Outbound = {};

/** @internal */
export const PqControlsNewrelicEvents$outboundSchema: z.ZodType<
  PqControlsNewrelicEvents$Outbound,
  z.ZodTypeDef,
  PqControlsNewrelicEvents
> = z.object({});

export function pqControlsNewrelicEventsToJSON(
  pqControlsNewrelicEvents: PqControlsNewrelicEvents,
): string {
  return JSON.stringify(
    PqControlsNewrelicEvents$outboundSchema.parse(pqControlsNewrelicEvents),
  );
}
export function pqControlsNewrelicEventsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsNewrelicEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsNewrelicEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsNewrelicEvents' from JSON`,
  );
}

/** @internal */
export const OutputNewrelicEvents$inboundSchema: z.ZodType<
  OutputNewrelicEvents,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeNewrelicEvents$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    region: RegionNewrelicEvents$inboundSchema.default("US"),
    accountId: z.string(),
    eventType: z.string(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderNewrelicEvents$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode:
      FailedRequestLoggingModeNewrelicEvents$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingNewrelicEvents$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsNewrelicEvents$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorNewrelicEvents$inboundSchema.default(
      "block",
    ),
    authType: AuthenticationMethodNewrelicEvents$inboundSchema.default(
      "manual",
    ),
    description: z.string().optional(),
    customUrl: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeNewrelicEvents$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionNewrelicEvents$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorNewrelicEvents$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsNewrelicEvents$inboundSchema).optional(),
    apiKey: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputNewrelicEvents$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  region: string;
  accountId: string;
  eventType: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderNewrelicEvents$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingNewrelicEvents$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | TimeoutRetrySettingsNewrelicEvents$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  customUrl?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsNewrelicEvents$Outbound | undefined;
  apiKey?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputNewrelicEvents$outboundSchema: z.ZodType<
  OutputNewrelicEvents$Outbound,
  z.ZodTypeDef,
  OutputNewrelicEvents
> = z.object({
  id: z.string().optional(),
  type: TypeNewrelicEvents$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  region: RegionNewrelicEvents$outboundSchema.default("US"),
  accountId: z.string(),
  eventType: z.string(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderNewrelicEvents$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode:
    FailedRequestLoggingModeNewrelicEvents$outboundSchema.default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingNewrelicEvents$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsNewrelicEvents$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorNewrelicEvents$outboundSchema.default(
    "block",
  ),
  authType: AuthenticationMethodNewrelicEvents$outboundSchema.default("manual"),
  description: z.string().optional(),
  customUrl: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeNewrelicEvents$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionNewrelicEvents$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorNewrelicEvents$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsNewrelicEvents$outboundSchema).optional(),
  apiKey: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputNewrelicEventsToJSON(
  outputNewrelicEvents: OutputNewrelicEvents,
): string {
  return JSON.stringify(
    OutputNewrelicEvents$outboundSchema.parse(outputNewrelicEvents),
  );
}
export function outputNewrelicEventsFromJSON(
  jsonString: string,
): SafeParseResult<OutputNewrelicEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputNewrelicEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputNewrelicEvents' from JSON`,
  );
}

/** @internal */
export const TypeNewrelic$inboundSchema: z.ZodNativeEnum<typeof TypeNewrelic> =
  z.nativeEnum(TypeNewrelic);
/** @internal */
export const TypeNewrelic$outboundSchema: z.ZodNativeEnum<typeof TypeNewrelic> =
  TypeNewrelic$inboundSchema;

/** @internal */
export const RegionNewrelic$inboundSchema: z.ZodType<
  RegionNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RegionNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RegionNewrelic$outboundSchema: z.ZodType<
  RegionNewrelic,
  z.ZodTypeDef,
  RegionNewrelic
> = z.union([
  z.nativeEnum(RegionNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FieldName$inboundSchema: z.ZodType<
  FieldName,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FieldName),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FieldName$outboundSchema: z.ZodType<
  FieldName,
  z.ZodTypeDef,
  FieldName
> = z.union([
  z.nativeEnum(FieldName),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumNewrelic$inboundSchema: z.ZodType<
  MetadatumNewrelic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: FieldName$inboundSchema,
  value: z.string(),
});
/** @internal */
export type MetadatumNewrelic$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumNewrelic$outboundSchema: z.ZodType<
  MetadatumNewrelic$Outbound,
  z.ZodTypeDef,
  MetadatumNewrelic
> = z.object({
  name: FieldName$outboundSchema,
  value: z.string(),
});

export function metadatumNewrelicToJSON(
  metadatumNewrelic: MetadatumNewrelic,
): string {
  return JSON.stringify(
    MetadatumNewrelic$outboundSchema.parse(metadatumNewrelic),
  );
}
export function metadatumNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumNewrelic' from JSON`,
  );
}

/** @internal */
export const ExtraHttpHeaderNewrelic$inboundSchema: z.ZodType<
  ExtraHttpHeaderNewrelic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderNewrelic$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderNewrelic$outboundSchema: z.ZodType<
  ExtraHttpHeaderNewrelic$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderNewrelic
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderNewrelicToJSON(
  extraHttpHeaderNewrelic: ExtraHttpHeaderNewrelic,
): string {
  return JSON.stringify(
    ExtraHttpHeaderNewrelic$outboundSchema.parse(extraHttpHeaderNewrelic),
  );
}
export function extraHttpHeaderNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderNewrelic' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeNewrelic$inboundSchema: z.ZodType<
  FailedRequestLoggingModeNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeNewrelic$outboundSchema: z.ZodType<
  FailedRequestLoggingModeNewrelic,
  z.ZodTypeDef,
  FailedRequestLoggingModeNewrelic
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingNewrelic$inboundSchema: z.ZodType<
  ResponseRetrySettingNewrelic,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingNewrelic$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingNewrelic$outboundSchema: z.ZodType<
  ResponseRetrySettingNewrelic$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingNewrelic
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingNewrelicToJSON(
  responseRetrySettingNewrelic: ResponseRetrySettingNewrelic,
): string {
  return JSON.stringify(
    ResponseRetrySettingNewrelic$outboundSchema.parse(
      responseRetrySettingNewrelic,
    ),
  );
}
export function responseRetrySettingNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingNewrelic' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsNewrelic$inboundSchema: z.ZodType<
  TimeoutRetrySettingsNewrelic,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsNewrelic$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsNewrelic$outboundSchema: z.ZodType<
  TimeoutRetrySettingsNewrelic$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsNewrelic
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsNewrelicToJSON(
  timeoutRetrySettingsNewrelic: TimeoutRetrySettingsNewrelic,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsNewrelic$outboundSchema.parse(
      timeoutRetrySettingsNewrelic,
    ),
  );
}
export function timeoutRetrySettingsNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsNewrelic' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorNewrelic$inboundSchema: z.ZodType<
  BackpressureBehaviorNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorNewrelic$outboundSchema: z.ZodType<
  BackpressureBehaviorNewrelic,
  z.ZodTypeDef,
  BackpressureBehaviorNewrelic
> = z.union([
  z.nativeEnum(BackpressureBehaviorNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodNewrelic$inboundSchema: z.ZodType<
  AuthenticationMethodNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodNewrelic$outboundSchema: z.ZodType<
  AuthenticationMethodNewrelic,
  z.ZodTypeDef,
  AuthenticationMethodNewrelic
> = z.union([
  z.nativeEnum(AuthenticationMethodNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeNewrelic$inboundSchema: z.ZodType<
  ModeNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeNewrelic$outboundSchema: z.ZodType<
  ModeNewrelic,
  z.ZodTypeDef,
  ModeNewrelic
> = z.union([
  z.nativeEnum(ModeNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionNewrelic$inboundSchema: z.ZodType<
  CompressionNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionNewrelic$outboundSchema: z.ZodType<
  CompressionNewrelic,
  z.ZodTypeDef,
  CompressionNewrelic
> = z.union([
  z.nativeEnum(CompressionNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorNewrelic$inboundSchema: z.ZodType<
  QueueFullBehaviorNewrelic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorNewrelic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorNewrelic$outboundSchema: z.ZodType<
  QueueFullBehaviorNewrelic,
  z.ZodTypeDef,
  QueueFullBehaviorNewrelic
> = z.union([
  z.nativeEnum(QueueFullBehaviorNewrelic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsNewrelic$inboundSchema: z.ZodType<
  PqControlsNewrelic,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsNewrelic$Outbound = {};

/** @internal */
export const PqControlsNewrelic$outboundSchema: z.ZodType<
  PqControlsNewrelic$Outbound,
  z.ZodTypeDef,
  PqControlsNewrelic
> = z.object({});

export function pqControlsNewrelicToJSON(
  pqControlsNewrelic: PqControlsNewrelic,
): string {
  return JSON.stringify(
    PqControlsNewrelic$outboundSchema.parse(pqControlsNewrelic),
  );
}
export function pqControlsNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsNewrelic' from JSON`,
  );
}

/** @internal */
export const OutputNewrelic$inboundSchema: z.ZodType<
  OutputNewrelic,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeNewrelic$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    region: RegionNewrelic$inboundSchema.default("US"),
    logType: z.string().default(""),
    messageField: z.string().default(""),
    metadata: z.array(z.lazy(() => MetadatumNewrelic$inboundSchema)).optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderNewrelic$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeNewrelic$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingNewrelic$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsNewrelic$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorNewrelic$inboundSchema.default("block"),
    authType: AuthenticationMethodNewrelic$inboundSchema.default("manual"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    customUrl: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeNewrelic$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionNewrelic$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorNewrelic$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsNewrelic$inboundSchema).optional(),
    apiKey: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputNewrelic$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  region: string;
  logType: string;
  messageField: string;
  metadata?: Array<MetadatumNewrelic$Outbound> | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderNewrelic$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingNewrelic$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsNewrelic$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  customUrl?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsNewrelic$Outbound | undefined;
  apiKey?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputNewrelic$outboundSchema: z.ZodType<
  OutputNewrelic$Outbound,
  z.ZodTypeDef,
  OutputNewrelic
> = z.object({
  id: z.string().optional(),
  type: TypeNewrelic$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  region: RegionNewrelic$outboundSchema.default("US"),
  logType: z.string().default(""),
  messageField: z.string().default(""),
  metadata: z.array(z.lazy(() => MetadatumNewrelic$outboundSchema)).optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderNewrelic$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeNewrelic$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingNewrelic$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsNewrelic$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorNewrelic$outboundSchema.default("block"),
  authType: AuthenticationMethodNewrelic$outboundSchema.default("manual"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  customUrl: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeNewrelic$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionNewrelic$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorNewrelic$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsNewrelic$outboundSchema).optional(),
  apiKey: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputNewrelicToJSON(outputNewrelic: OutputNewrelic): string {
  return JSON.stringify(OutputNewrelic$outboundSchema.parse(outputNewrelic));
}
export function outputNewrelicFromJSON(
  jsonString: string,
): SafeParseResult<OutputNewrelic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputNewrelic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputNewrelic' from JSON`,
  );
}

/** @internal */
export const TypeElasticCloud$inboundSchema: z.ZodNativeEnum<
  typeof TypeElasticCloud
> = z.nativeEnum(TypeElasticCloud);
/** @internal */
export const TypeElasticCloud$outboundSchema: z.ZodNativeEnum<
  typeof TypeElasticCloud
> = TypeElasticCloud$inboundSchema;

/** @internal */
export const ExtraHttpHeaderElasticCloud$inboundSchema: z.ZodType<
  ExtraHttpHeaderElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderElasticCloud$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderElasticCloud$outboundSchema: z.ZodType<
  ExtraHttpHeaderElasticCloud$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderElasticCloud
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderElasticCloudToJSON(
  extraHttpHeaderElasticCloud: ExtraHttpHeaderElasticCloud,
): string {
  return JSON.stringify(
    ExtraHttpHeaderElasticCloud$outboundSchema.parse(
      extraHttpHeaderElasticCloud,
    ),
  );
}
export function extraHttpHeaderElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderElasticCloud' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeElasticCloud$inboundSchema: z.ZodType<
  FailedRequestLoggingModeElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeElasticCloud$outboundSchema: z.ZodType<
  FailedRequestLoggingModeElasticCloud,
  z.ZodTypeDef,
  FailedRequestLoggingModeElasticCloud
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraParamElasticCloud$inboundSchema: z.ZodType<
  ExtraParamElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type ExtraParamElasticCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const ExtraParamElasticCloud$outboundSchema: z.ZodType<
  ExtraParamElasticCloud$Outbound,
  z.ZodTypeDef,
  ExtraParamElasticCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function extraParamElasticCloudToJSON(
  extraParamElasticCloud: ExtraParamElasticCloud,
): string {
  return JSON.stringify(
    ExtraParamElasticCloud$outboundSchema.parse(extraParamElasticCloud),
  );
}
export function extraParamElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<ExtraParamElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraParamElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraParamElasticCloud' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodElasticCloud$inboundSchema: z.ZodType<
  AuthenticationMethodElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodElasticCloud$outboundSchema: z.ZodType<
  AuthenticationMethodElasticCloud,
  z.ZodTypeDef,
  AuthenticationMethodElasticCloud
> = z.union([
  z.nativeEnum(AuthenticationMethodElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthElasticCloud$inboundSchema: z.ZodType<
  AuthElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: AuthenticationMethodElasticCloud$inboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  manualAPIKey: z.string().optional(),
  textSecret: z.string().optional(),
});
/** @internal */
export type AuthElasticCloud$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  manualAPIKey?: string | undefined;
  textSecret?: string | undefined;
};

/** @internal */
export const AuthElasticCloud$outboundSchema: z.ZodType<
  AuthElasticCloud$Outbound,
  z.ZodTypeDef,
  AuthElasticCloud
> = z.object({
  disabled: z.boolean().default(false),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: AuthenticationMethodElasticCloud$outboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  manualAPIKey: z.string().optional(),
  textSecret: z.string().optional(),
});

export function authElasticCloudToJSON(
  authElasticCloud: AuthElasticCloud,
): string {
  return JSON.stringify(
    AuthElasticCloud$outboundSchema.parse(authElasticCloud),
  );
}
export function authElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<AuthElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthElasticCloud' from JSON`,
  );
}

/** @internal */
export const ResponseRetrySettingElasticCloud$inboundSchema: z.ZodType<
  ResponseRetrySettingElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingElasticCloud$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingElasticCloud$outboundSchema: z.ZodType<
  ResponseRetrySettingElasticCloud$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingElasticCloud
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingElasticCloudToJSON(
  responseRetrySettingElasticCloud: ResponseRetrySettingElasticCloud,
): string {
  return JSON.stringify(
    ResponseRetrySettingElasticCloud$outboundSchema.parse(
      responseRetrySettingElasticCloud,
    ),
  );
}
export function responseRetrySettingElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingElasticCloud' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsElasticCloud$inboundSchema: z.ZodType<
  TimeoutRetrySettingsElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsElasticCloud$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsElasticCloud$outboundSchema: z.ZodType<
  TimeoutRetrySettingsElasticCloud$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsElasticCloud
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsElasticCloudToJSON(
  timeoutRetrySettingsElasticCloud: TimeoutRetrySettingsElasticCloud,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsElasticCloud$outboundSchema.parse(
      timeoutRetrySettingsElasticCloud,
    ),
  );
}
export function timeoutRetrySettingsElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsElasticCloud' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorElasticCloud$inboundSchema: z.ZodType<
  BackpressureBehaviorElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorElasticCloud$outboundSchema: z.ZodType<
  BackpressureBehaviorElasticCloud,
  z.ZodTypeDef,
  BackpressureBehaviorElasticCloud
> = z.union([
  z.nativeEnum(BackpressureBehaviorElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeElasticCloud$inboundSchema: z.ZodType<
  ModeElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeElasticCloud$outboundSchema: z.ZodType<
  ModeElasticCloud,
  z.ZodTypeDef,
  ModeElasticCloud
> = z.union([
  z.nativeEnum(ModeElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionElasticCloud$inboundSchema: z.ZodType<
  CompressionElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionElasticCloud$outboundSchema: z.ZodType<
  CompressionElasticCloud,
  z.ZodTypeDef,
  CompressionElasticCloud
> = z.union([
  z.nativeEnum(CompressionElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorElasticCloud$inboundSchema: z.ZodType<
  QueueFullBehaviorElasticCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorElasticCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorElasticCloud$outboundSchema: z.ZodType<
  QueueFullBehaviorElasticCloud,
  z.ZodTypeDef,
  QueueFullBehaviorElasticCloud
> = z.union([
  z.nativeEnum(QueueFullBehaviorElasticCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsElasticCloud$inboundSchema: z.ZodType<
  PqControlsElasticCloud,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsElasticCloud$Outbound = {};

/** @internal */
export const PqControlsElasticCloud$outboundSchema: z.ZodType<
  PqControlsElasticCloud$Outbound,
  z.ZodTypeDef,
  PqControlsElasticCloud
> = z.object({});

export function pqControlsElasticCloudToJSON(
  pqControlsElasticCloud: PqControlsElasticCloud,
): string {
  return JSON.stringify(
    PqControlsElasticCloud$outboundSchema.parse(pqControlsElasticCloud),
  );
}
export function pqControlsElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsElasticCloud' from JSON`,
  );
}

/** @internal */
export const OutputElasticCloud$inboundSchema: z.ZodType<
  OutputElasticCloud,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeElasticCloud$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    url: z.string(),
    index: z.string(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderElasticCloud$inboundSchema),
    ).optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeElasticCloud$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    extraParams: z.array(z.lazy(() => ExtraParamElasticCloud$inboundSchema))
      .optional(),
    auth: z.lazy(() => AuthElasticCloud$inboundSchema).optional(),
    elasticPipeline: z.string().optional(),
    includeDocId: z.boolean().default(true),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingElasticCloud$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsElasticCloud$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorElasticCloud$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeElasticCloud$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionElasticCloud$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorElasticCloud$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsElasticCloud$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputElasticCloud$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  url: string;
  index: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderElasticCloud$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  extraParams?: Array<ExtraParamElasticCloud$Outbound> | undefined;
  auth?: AuthElasticCloud$Outbound | undefined;
  elasticPipeline?: string | undefined;
  includeDocId: boolean;
  responseRetrySettings?:
    | Array<ResponseRetrySettingElasticCloud$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsElasticCloud$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsElasticCloud$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputElasticCloud$outboundSchema: z.ZodType<
  OutputElasticCloud$Outbound,
  z.ZodTypeDef,
  OutputElasticCloud
> = z.object({
  id: z.string().optional(),
  type: TypeElasticCloud$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  url: z.string(),
  index: z.string(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderElasticCloud$outboundSchema),
  ).optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeElasticCloud$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  extraParams: z.array(z.lazy(() => ExtraParamElasticCloud$outboundSchema))
    .optional(),
  auth: z.lazy(() => AuthElasticCloud$outboundSchema).optional(),
  elasticPipeline: z.string().optional(),
  includeDocId: z.boolean().default(true),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingElasticCloud$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsElasticCloud$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorElasticCloud$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeElasticCloud$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionElasticCloud$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorElasticCloud$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsElasticCloud$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputElasticCloudToJSON(
  outputElasticCloud: OutputElasticCloud,
): string {
  return JSON.stringify(
    OutputElasticCloud$outboundSchema.parse(outputElasticCloud),
  );
}
export function outputElasticCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputElasticCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputElasticCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputElasticCloud' from JSON`,
  );
}

/** @internal */
export const OutputTypeElastic$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeElastic
> = z.nativeEnum(OutputTypeElastic);
/** @internal */
export const OutputTypeElastic$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeElastic
> = OutputTypeElastic$inboundSchema;

/** @internal */
export const OutputExtraHttpHeaderElastic$inboundSchema: z.ZodType<
  OutputExtraHttpHeaderElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type OutputExtraHttpHeaderElastic$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const OutputExtraHttpHeaderElastic$outboundSchema: z.ZodType<
  OutputExtraHttpHeaderElastic$Outbound,
  z.ZodTypeDef,
  OutputExtraHttpHeaderElastic
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function outputExtraHttpHeaderElasticToJSON(
  outputExtraHttpHeaderElastic: OutputExtraHttpHeaderElastic,
): string {
  return JSON.stringify(
    OutputExtraHttpHeaderElastic$outboundSchema.parse(
      outputExtraHttpHeaderElastic,
    ),
  );
}
export function outputExtraHttpHeaderElasticFromJSON(
  jsonString: string,
): SafeParseResult<OutputExtraHttpHeaderElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputExtraHttpHeaderElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputExtraHttpHeaderElastic' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeElastic$inboundSchema: z.ZodType<
  FailedRequestLoggingModeElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeElastic$outboundSchema: z.ZodType<
  FailedRequestLoggingModeElastic,
  z.ZodTypeDef,
  FailedRequestLoggingModeElastic
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingElastic$inboundSchema: z.ZodType<
  ResponseRetrySettingElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingElastic$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingElastic$outboundSchema: z.ZodType<
  ResponseRetrySettingElastic$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingElastic
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingElasticToJSON(
  responseRetrySettingElastic: ResponseRetrySettingElastic,
): string {
  return JSON.stringify(
    ResponseRetrySettingElastic$outboundSchema.parse(
      responseRetrySettingElastic,
    ),
  );
}
export function responseRetrySettingElasticFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingElastic' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsElastic$inboundSchema: z.ZodType<
  TimeoutRetrySettingsElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsElastic$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsElastic$outboundSchema: z.ZodType<
  TimeoutRetrySettingsElastic$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsElastic
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsElasticToJSON(
  timeoutRetrySettingsElastic: TimeoutRetrySettingsElastic,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsElastic$outboundSchema.parse(
      timeoutRetrySettingsElastic,
    ),
  );
}
export function timeoutRetrySettingsElasticFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsElastic' from JSON`,
  );
}

/** @internal */
export const ExtraParamElastic$inboundSchema: z.ZodType<
  ExtraParamElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type ExtraParamElastic$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const ExtraParamElastic$outboundSchema: z.ZodType<
  ExtraParamElastic$Outbound,
  z.ZodTypeDef,
  ExtraParamElastic
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function extraParamElasticToJSON(
  extraParamElastic: ExtraParamElastic,
): string {
  return JSON.stringify(
    ExtraParamElastic$outboundSchema.parse(extraParamElastic),
  );
}
export function extraParamElasticFromJSON(
  jsonString: string,
): SafeParseResult<ExtraParamElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraParamElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraParamElastic' from JSON`,
  );
}

/** @internal */
export const AuthAuthenticationMethodElastic$inboundSchema: z.ZodType<
  AuthAuthenticationMethodElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthAuthenticationMethodElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthAuthenticationMethodElastic$outboundSchema: z.ZodType<
  AuthAuthenticationMethodElastic,
  z.ZodTypeDef,
  AuthAuthenticationMethodElastic
> = z.union([
  z.nativeEnum(AuthAuthenticationMethodElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthElastic$inboundSchema: z.ZodType<
  AuthElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: AuthAuthenticationMethodElastic$inboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  manualAPIKey: z.string().optional(),
  textSecret: z.string().optional(),
});
/** @internal */
export type AuthElastic$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  manualAPIKey?: string | undefined;
  textSecret?: string | undefined;
};

/** @internal */
export const AuthElastic$outboundSchema: z.ZodType<
  AuthElastic$Outbound,
  z.ZodTypeDef,
  AuthElastic
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: AuthAuthenticationMethodElastic$outboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  manualAPIKey: z.string().optional(),
  textSecret: z.string().optional(),
});

export function authElasticToJSON(authElastic: AuthElastic): string {
  return JSON.stringify(AuthElastic$outboundSchema.parse(authElastic));
}
export function authElasticFromJSON(
  jsonString: string,
): SafeParseResult<AuthElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthElastic' from JSON`,
  );
}

/** @internal */
export const ElasticVersion$inboundSchema: z.ZodType<
  ElasticVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ElasticVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ElasticVersion$outboundSchema: z.ZodType<
  ElasticVersion,
  z.ZodTypeDef,
  ElasticVersion
> = z.union([
  z.nativeEnum(ElasticVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const WriteAction$inboundSchema: z.ZodType<
  WriteAction,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(WriteAction),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const WriteAction$outboundSchema: z.ZodType<
  WriteAction,
  z.ZodTypeDef,
  WriteAction
> = z.union([
  z.nativeEnum(WriteAction),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorElastic$inboundSchema: z.ZodType<
  BackpressureBehaviorElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorElastic$outboundSchema: z.ZodType<
  BackpressureBehaviorElastic,
  z.ZodTypeDef,
  BackpressureBehaviorElastic
> = z.union([
  z.nativeEnum(BackpressureBehaviorElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const UrlElastic$inboundSchema: z.ZodType<
  UrlElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});
/** @internal */
export type UrlElastic$Outbound = {
  url: string;
  weight: number;
};

/** @internal */
export const UrlElastic$outboundSchema: z.ZodType<
  UrlElastic$Outbound,
  z.ZodTypeDef,
  UrlElastic
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});

export function urlElasticToJSON(urlElastic: UrlElastic): string {
  return JSON.stringify(UrlElastic$outboundSchema.parse(urlElastic));
}
export function urlElasticFromJSON(
  jsonString: string,
): SafeParseResult<UrlElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UrlElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UrlElastic' from JSON`,
  );
}

/** @internal */
export const OutputModeElastic$inboundSchema: z.ZodType<
  OutputModeElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeElastic$outboundSchema: z.ZodType<
  OutputModeElastic,
  z.ZodTypeDef,
  OutputModeElastic
> = z.union([
  z.nativeEnum(OutputModeElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionElastic$inboundSchema: z.ZodType<
  PqCompressCompressionElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionElastic$outboundSchema: z.ZodType<
  PqCompressCompressionElastic,
  z.ZodTypeDef,
  PqCompressCompressionElastic
> = z.union([
  z.nativeEnum(PqCompressCompressionElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorElastic$inboundSchema: z.ZodType<
  QueueFullBehaviorElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorElastic$outboundSchema: z.ZodType<
  QueueFullBehaviorElastic,
  z.ZodTypeDef,
  QueueFullBehaviorElastic
> = z.union([
  z.nativeEnum(QueueFullBehaviorElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsElastic$inboundSchema: z.ZodType<
  OutputPqControlsElastic,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsElastic$Outbound = {};

/** @internal */
export const OutputPqControlsElastic$outboundSchema: z.ZodType<
  OutputPqControlsElastic$Outbound,
  z.ZodTypeDef,
  OutputPqControlsElastic
> = z.object({});

export function outputPqControlsElasticToJSON(
  outputPqControlsElastic: OutputPqControlsElastic,
): string {
  return JSON.stringify(
    OutputPqControlsElastic$outboundSchema.parse(outputPqControlsElastic),
  );
}
export function outputPqControlsElasticFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsElastic' from JSON`,
  );
}

/** @internal */
export const OutputElastic$inboundSchema: z.ZodType<
  OutputElastic,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeElastic$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(true),
    index: z.string(),
    docType: z.string().optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => OutputExtraHttpHeaderElastic$inboundSchema),
    ).optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeElastic$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingElastic$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsElastic$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    extraParams: z.array(z.lazy(() => ExtraParamElastic$inboundSchema))
      .optional(),
    auth: z.lazy(() => AuthElastic$inboundSchema).optional(),
    elasticVersion: ElasticVersion$inboundSchema.default("auto"),
    elasticPipeline: z.string().optional(),
    includeDocId: z.boolean().default(false),
    writeAction: WriteAction$inboundSchema.default("create"),
    retryPartialErrors: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorElastic$inboundSchema.default("block"),
    description: z.string().optional(),
    url: z.string().optional(),
    useRoundRobinDns: z.boolean().default(false),
    excludeSelf: z.boolean().default(false),
    urls: z.array(z.lazy(() => UrlElastic$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeElastic$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionElastic$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorElastic$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsElastic$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputElastic$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  index: string;
  docType?: string | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<OutputExtraHttpHeaderElastic$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingElastic$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsElastic$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  extraParams?: Array<ExtraParamElastic$Outbound> | undefined;
  auth?: AuthElastic$Outbound | undefined;
  elasticVersion: string;
  elasticPipeline?: string | undefined;
  includeDocId: boolean;
  writeAction: string;
  retryPartialErrors: boolean;
  onBackpressure: string;
  description?: string | undefined;
  url?: string | undefined;
  useRoundRobinDns: boolean;
  excludeSelf: boolean;
  urls?: Array<UrlElastic$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsElastic$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputElastic$outboundSchema: z.ZodType<
  OutputElastic$Outbound,
  z.ZodTypeDef,
  OutputElastic
> = z.object({
  id: z.string().optional(),
  type: OutputTypeElastic$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(true),
  index: z.string(),
  docType: z.string().optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => OutputExtraHttpHeaderElastic$outboundSchema),
  ).optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeElastic$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingElastic$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsElastic$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  extraParams: z.array(z.lazy(() => ExtraParamElastic$outboundSchema))
    .optional(),
  auth: z.lazy(() => AuthElastic$outboundSchema).optional(),
  elasticVersion: ElasticVersion$outboundSchema.default("auto"),
  elasticPipeline: z.string().optional(),
  includeDocId: z.boolean().default(false),
  writeAction: WriteAction$outboundSchema.default("create"),
  retryPartialErrors: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorElastic$outboundSchema.default("block"),
  description: z.string().optional(),
  url: z.string().optional(),
  useRoundRobinDns: z.boolean().default(false),
  excludeSelf: z.boolean().default(false),
  urls: z.array(z.lazy(() => UrlElastic$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeElastic$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionElastic$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorElastic$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsElastic$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputElasticToJSON(outputElastic: OutputElastic): string {
  return JSON.stringify(OutputElastic$outboundSchema.parse(outputElastic));
}
export function outputElasticFromJSON(
  jsonString: string,
): SafeParseResult<OutputElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputElastic' from JSON`,
  );
}

/** @internal */
export const OutputTypeMsk$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeMsk
> = z.nativeEnum(OutputTypeMsk);
/** @internal */
export const OutputTypeMsk$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeMsk
> = OutputTypeMsk$inboundSchema;

/** @internal */
export const AcknowledgmentsMsk$inboundSchema: z.ZodType<
  AcknowledgmentsMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AcknowledgmentsMsk),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AcknowledgmentsMsk$outboundSchema: z.ZodType<
  AcknowledgmentsMsk,
  z.ZodTypeDef,
  AcknowledgmentsMsk
> = z.union([
  z.nativeEnum(AcknowledgmentsMsk),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const RecordDataFormatMsk$inboundSchema: z.ZodType<
  RecordDataFormatMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordDataFormatMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordDataFormatMsk$outboundSchema: z.ZodType<
  RecordDataFormatMsk,
  z.ZodTypeDef,
  RecordDataFormatMsk
> = z.union([
  z.nativeEnum(RecordDataFormatMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionMsk$inboundSchema: z.ZodType<
  OutputCompressionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionMsk$outboundSchema: z.ZodType<
  OutputCompressionMsk,
  z.ZodTypeDef,
  OutputCompressionMsk
> = z.union([
  z.nativeEnum(OutputCompressionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthMsk$inboundSchema: z.ZodType<
  OutputAuthMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputAuthMsk$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputAuthMsk$outboundSchema: z.ZodType<
  OutputAuthMsk$Outbound,
  z.ZodTypeDef,
  OutputAuthMsk
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function outputAuthMskToJSON(outputAuthMsk: OutputAuthMsk): string {
  return JSON.stringify(OutputAuthMsk$outboundSchema.parse(outputAuthMsk));
}
export function outputAuthMskFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthMsk' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionMsk$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionMsk,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionMsk),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionMsk$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionMsk,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMinimumTLSVersionMsk
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionMsk),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionMsk$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionMsk,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionMsk),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionMsk$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionMsk,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMaximumTLSVersionMsk
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionMsk),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideMsk,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: OutputKafkaSchemaRegistryMinimumTLSVersionMsk$inboundSchema
      .optional(),
    maxVersion: OutputKafkaSchemaRegistryMaximumTLSVersionMsk$inboundSchema
      .optional(),
  });
/** @internal */
export type OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryTLSSettingsClientSideMsk
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: OutputKafkaSchemaRegistryMinimumTLSVersionMsk$outboundSchema
      .optional(),
    maxVersion: OutputKafkaSchemaRegistryMaximumTLSVersionMsk$outboundSchema
      .optional(),
  });

export function outputKafkaSchemaRegistryTLSSettingsClientSideMskToJSON(
  outputKafkaSchemaRegistryTLSSettingsClientSideMsk:
    OutputKafkaSchemaRegistryTLSSettingsClientSideMsk,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema.parse(
      outputKafkaSchemaRegistryTLSSettingsClientSideMsk,
    ),
  );
}
export function outputKafkaSchemaRegistryTLSSettingsClientSideMskFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryTLSSettingsClientSideMsk,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputKafkaSchemaRegistryTLSSettingsClientSideMsk' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationMsk$inboundSchema:
  z.ZodType<OutputKafkaSchemaRegistryAuthenticationMsk, z.ZodTypeDef, unknown> =
    z.object({
      disabled: z.boolean().default(true),
      schemaRegistryURL: z.string().default("http://localhost:8081"),
      connectionTimeout: z.number().default(30000),
      requestTimeout: z.number().default(30000),
      maxRetries: z.number().default(1),
      auth: z.lazy(() => OutputAuthMsk$inboundSchema).optional(),
      tls: z.lazy(() =>
        OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema
      ).optional(),
      defaultKeySchemaId: z.number().optional(),
      defaultValueSchemaId: z.number().optional(),
    });
/** @internal */
export type OutputKafkaSchemaRegistryAuthenticationMsk$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: OutputAuthMsk$Outbound | undefined;
  tls?: OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound | undefined;
  defaultKeySchemaId?: number | undefined;
  defaultValueSchemaId?: number | undefined;
};

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationMsk$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryAuthenticationMsk$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryAuthenticationMsk
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => OutputAuthMsk$outboundSchema).optional(),
    tls: z.lazy(() =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema
    ).optional(),
    defaultKeySchemaId: z.number().optional(),
    defaultValueSchemaId: z.number().optional(),
  });

export function outputKafkaSchemaRegistryAuthenticationMskToJSON(
  outputKafkaSchemaRegistryAuthenticationMsk:
    OutputKafkaSchemaRegistryAuthenticationMsk,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryAuthenticationMsk$outboundSchema.parse(
      outputKafkaSchemaRegistryAuthenticationMsk,
    ),
  );
}
export function outputKafkaSchemaRegistryAuthenticationMskFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryAuthenticationMsk,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryAuthenticationMsk$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputKafkaSchemaRegistryAuthenticationMsk' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationMethodMsk$inboundSchema: z.ZodType<
  OutputAuthenticationMethodMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodMsk$outboundSchema: z.ZodType<
  OutputAuthenticationMethodMsk,
  z.ZodTypeDef,
  OutputAuthenticationMethodMsk
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSignatureVersionMsk$inboundSchema: z.ZodType<
  OutputSignatureVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSignatureVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSignatureVersionMsk$outboundSchema: z.ZodType<
  OutputSignatureVersionMsk,
  z.ZodTypeDef,
  OutputSignatureVersionMsk
> = z.union([
  z.nativeEnum(OutputSignatureVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMinimumTLSVersionMsk$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionMsk$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionMsk,
  z.ZodTypeDef,
  OutputMinimumTLSVersionMsk
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionMsk$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionMsk$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionMsk,
  z.ZodTypeDef,
  OutputMaximumTLSVersionMsk
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputTLSSettingsClientSideMsk$inboundSchema: z.ZodType<
  OutputTLSSettingsClientSideMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionMsk$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionMsk$inboundSchema.optional(),
});
/** @internal */
export type OutputTLSSettingsClientSideMsk$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const OutputTLSSettingsClientSideMsk$outboundSchema: z.ZodType<
  OutputTLSSettingsClientSideMsk$Outbound,
  z.ZodTypeDef,
  OutputTLSSettingsClientSideMsk
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionMsk$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionMsk$outboundSchema.optional(),
});

export function outputTLSSettingsClientSideMskToJSON(
  outputTLSSettingsClientSideMsk: OutputTLSSettingsClientSideMsk,
): string {
  return JSON.stringify(
    OutputTLSSettingsClientSideMsk$outboundSchema.parse(
      outputTLSSettingsClientSideMsk,
    ),
  );
}
export function outputTLSSettingsClientSideMskFromJSON(
  jsonString: string,
): SafeParseResult<OutputTLSSettingsClientSideMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputTLSSettingsClientSideMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputTLSSettingsClientSideMsk' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorMsk$inboundSchema: z.ZodType<
  BackpressureBehaviorMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorMsk$outboundSchema: z.ZodType<
  BackpressureBehaviorMsk,
  z.ZodTypeDef,
  BackpressureBehaviorMsk
> = z.union([
  z.nativeEnum(BackpressureBehaviorMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeMsk$inboundSchema: z.ZodType<
  OutputModeMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeMsk$outboundSchema: z.ZodType<
  OutputModeMsk,
  z.ZodTypeDef,
  OutputModeMsk
> = z.union([
  z.nativeEnum(OutputModeMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionMsk$inboundSchema: z.ZodType<
  PqCompressCompressionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionMsk$outboundSchema: z.ZodType<
  PqCompressCompressionMsk,
  z.ZodTypeDef,
  PqCompressCompressionMsk
> = z.union([
  z.nativeEnum(PqCompressCompressionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorMsk$inboundSchema: z.ZodType<
  QueueFullBehaviorMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorMsk$outboundSchema: z.ZodType<
  QueueFullBehaviorMsk,
  z.ZodTypeDef,
  QueueFullBehaviorMsk
> = z.union([
  z.nativeEnum(QueueFullBehaviorMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsMsk$inboundSchema: z.ZodType<
  OutputPqControlsMsk,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsMsk$Outbound = {};

/** @internal */
export const OutputPqControlsMsk$outboundSchema: z.ZodType<
  OutputPqControlsMsk$Outbound,
  z.ZodTypeDef,
  OutputPqControlsMsk
> = z.object({});

export function outputPqControlsMskToJSON(
  outputPqControlsMsk: OutputPqControlsMsk,
): string {
  return JSON.stringify(
    OutputPqControlsMsk$outboundSchema.parse(outputPqControlsMsk),
  );
}
export function outputPqControlsMskFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsMsk' from JSON`,
  );
}

/** @internal */
export const OutputMsk$inboundSchema: z.ZodType<
  OutputMsk,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeMsk$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    brokers: z.array(z.string()),
    topic: z.string(),
    ack: AcknowledgmentsMsk$inboundSchema.default(1),
    format: RecordDataFormatMsk$inboundSchema.default("json"),
    compression: OutputCompressionMsk$inboundSchema.default("gzip"),
    maxRecordSizeKB: z.number().default(768),
    flushEventCount: z.number().default(1000),
    flushPeriodSec: z.number().default(1),
    kafkaSchemaRegistry: z.lazy(() =>
      OutputKafkaSchemaRegistryAuthenticationMsk$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    awsAuthenticationMethod: OutputAuthenticationMethodMsk$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string(),
    endpoint: z.string().optional(),
    signatureVersion: OutputSignatureVersionMsk$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    tls: z.lazy(() => OutputTLSSettingsClientSideMsk$inboundSchema).optional(),
    onBackpressure: BackpressureBehaviorMsk$inboundSchema.default("block"),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    protobufLibraryId: z.string().optional(),
    protobufEncodingId: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeMsk$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionMsk$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorMsk$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsMsk$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputMsk$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  brokers: Array<string>;
  topic: string;
  ack: number;
  format: string;
  compression: string;
  maxRecordSizeKB: number;
  flushEventCount: number;
  flushPeriodSec: number;
  kafkaSchemaRegistry?:
    | OutputKafkaSchemaRegistryAuthenticationMsk$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  tls?: OutputTLSSettingsClientSideMsk$Outbound | undefined;
  onBackpressure: string;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  protobufLibraryId?: string | undefined;
  protobufEncodingId?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsMsk$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputMsk$outboundSchema: z.ZodType<
  OutputMsk$Outbound,
  z.ZodTypeDef,
  OutputMsk
> = z.object({
  id: z.string().optional(),
  type: OutputTypeMsk$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  brokers: z.array(z.string()),
  topic: z.string(),
  ack: AcknowledgmentsMsk$outboundSchema.default(1),
  format: RecordDataFormatMsk$outboundSchema.default("json"),
  compression: OutputCompressionMsk$outboundSchema.default("gzip"),
  maxRecordSizeKB: z.number().default(768),
  flushEventCount: z.number().default(1000),
  flushPeriodSec: z.number().default(1),
  kafkaSchemaRegistry: z.lazy(() =>
    OutputKafkaSchemaRegistryAuthenticationMsk$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  awsAuthenticationMethod: OutputAuthenticationMethodMsk$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string(),
  endpoint: z.string().optional(),
  signatureVersion: OutputSignatureVersionMsk$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  tls: z.lazy(() => OutputTLSSettingsClientSideMsk$outboundSchema).optional(),
  onBackpressure: BackpressureBehaviorMsk$outboundSchema.default("block"),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  protobufLibraryId: z.string().optional(),
  protobufEncodingId: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeMsk$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionMsk$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorMsk$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsMsk$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputMskToJSON(outputMsk: OutputMsk): string {
  return JSON.stringify(OutputMsk$outboundSchema.parse(outputMsk));
}
export function outputMskFromJSON(
  jsonString: string,
): SafeParseResult<OutputMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputMsk' from JSON`,
  );
}

/** @internal */
export const OutputTypeConfluentCloud$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeConfluentCloud
> = z.nativeEnum(OutputTypeConfluentCloud);
/** @internal */
export const OutputTypeConfluentCloud$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeConfluentCloud
> = OutputTypeConfluentCloud$inboundSchema;

/** @internal */
export const OutputMinimumTLSVersionConfluentCloud$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionConfluentCloud$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  OutputMinimumTLSVersionConfluentCloud
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionConfluentCloud$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionConfluentCloud$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  OutputMaximumTLSVersionConfluentCloud
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputTLSSettingsClientSideConfluentCloud$inboundSchema: z.ZodType<
  OutputTLSSettingsClientSideConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionConfluentCloud$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionConfluentCloud$inboundSchema.optional(),
});
/** @internal */
export type OutputTLSSettingsClientSideConfluentCloud$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const OutputTLSSettingsClientSideConfluentCloud$outboundSchema:
  z.ZodType<
    OutputTLSSettingsClientSideConfluentCloud$Outbound,
    z.ZodTypeDef,
    OutputTLSSettingsClientSideConfluentCloud
  > = z.object({
    disabled: z.boolean().default(false),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: OutputMinimumTLSVersionConfluentCloud$outboundSchema.optional(),
    maxVersion: OutputMaximumTLSVersionConfluentCloud$outboundSchema.optional(),
  });

export function outputTLSSettingsClientSideConfluentCloudToJSON(
  outputTLSSettingsClientSideConfluentCloud:
    OutputTLSSettingsClientSideConfluentCloud,
): string {
  return JSON.stringify(
    OutputTLSSettingsClientSideConfluentCloud$outboundSchema.parse(
      outputTLSSettingsClientSideConfluentCloud,
    ),
  );
}
export function outputTLSSettingsClientSideConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputTLSSettingsClientSideConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputTLSSettingsClientSideConfluentCloud$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputTLSSettingsClientSideConfluentCloud' from JSON`,
  );
}

/** @internal */
export const AcknowledgmentsConfluentCloud$inboundSchema: z.ZodType<
  AcknowledgmentsConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AcknowledgmentsConfluentCloud),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AcknowledgmentsConfluentCloud$outboundSchema: z.ZodType<
  AcknowledgmentsConfluentCloud,
  z.ZodTypeDef,
  AcknowledgmentsConfluentCloud
> = z.union([
  z.nativeEnum(AcknowledgmentsConfluentCloud),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const RecordDataFormatConfluentCloud$inboundSchema: z.ZodType<
  RecordDataFormatConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordDataFormatConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordDataFormatConfluentCloud$outboundSchema: z.ZodType<
  RecordDataFormatConfluentCloud,
  z.ZodTypeDef,
  RecordDataFormatConfluentCloud
> = z.union([
  z.nativeEnum(RecordDataFormatConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionConfluentCloud$inboundSchema: z.ZodType<
  OutputCompressionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionConfluentCloud$outboundSchema: z.ZodType<
  OutputCompressionConfluentCloud,
  z.ZodTypeDef,
  OutputCompressionConfluentCloud
> = z.union([
  z.nativeEnum(OutputCompressionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthConfluentCloud$inboundSchema: z.ZodType<
  OutputAuthConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputAuthConfluentCloud$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputAuthConfluentCloud$outboundSchema: z.ZodType<
  OutputAuthConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputAuthConfluentCloud
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function outputAuthConfluentCloudToJSON(
  outputAuthConfluentCloud: OutputAuthConfluentCloud,
): string {
  return JSON.stringify(
    OutputAuthConfluentCloud$outboundSchema.parse(outputAuthConfluentCloud),
  );
}
export function outputAuthConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion:
      OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$inboundSchema
        .optional(),
    maxVersion:
      OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$inboundSchema
        .optional(),
  });
/** @internal */
export type OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound =
  {
    disabled: boolean;
    rejectUnauthorized: boolean;
    servername?: string | undefined;
    certificateName?: string | undefined;
    caPath?: string | undefined;
    privKeyPath?: string | undefined;
    certPath?: string | undefined;
    passphrase?: string | undefined;
    minVersion?: string | undefined;
    maxVersion?: string | undefined;
  };

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion:
      OutputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$outboundSchema
        .optional(),
    maxVersion:
      OutputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$outboundSchema
        .optional(),
  });

export function outputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloudToJSON(
  outputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud:
    OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema
      .parse(outputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud),
  );
}
export function outputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => OutputAuthConfluentCloud$inboundSchema).optional(),
    tls: z.lazy(() =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema
    ).optional(),
    defaultKeySchemaId: z.number().optional(),
    defaultValueSchemaId: z.number().optional(),
  });
/** @internal */
export type OutputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: OutputAuthConfluentCloud$Outbound | undefined;
  tls?:
    | OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound
    | undefined;
  defaultKeySchemaId?: number | undefined;
  defaultValueSchemaId?: number | undefined;
};

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => OutputAuthConfluentCloud$outboundSchema).optional(),
    tls: z.lazy(() =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema
    ).optional(),
    defaultKeySchemaId: z.number().optional(),
    defaultValueSchemaId: z.number().optional(),
  });

export function outputKafkaSchemaRegistryAuthenticationConfluentCloudToJSON(
  outputKafkaSchemaRegistryAuthenticationConfluentCloud:
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema.parse(
      outputKafkaSchemaRegistryAuthenticationConfluentCloud,
    ),
  );
}
export function outputKafkaSchemaRegistryAuthenticationConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryAuthenticationConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputKafkaSchemaRegistryAuthenticationConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationMethodConfluentCloud$inboundSchema: z.ZodType<
  OutputAuthenticationMethodConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodConfluentCloud$outboundSchema: z.ZodType<
  OutputAuthenticationMethodConfluentCloud,
  z.ZodTypeDef,
  OutputAuthenticationMethodConfluentCloud
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSASLMechanismConfluentCloud$inboundSchema: z.ZodType<
  OutputSASLMechanismConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSASLMechanismConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSASLMechanismConfluentCloud$outboundSchema: z.ZodType<
  OutputSASLMechanismConfluentCloud,
  z.ZodTypeDef,
  OutputSASLMechanismConfluentCloud
> = z.union([
  z.nativeEnum(OutputSASLMechanismConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputOauthParamConfluentCloud$inboundSchema: z.ZodType<
  OutputOauthParamConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputOauthParamConfluentCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputOauthParamConfluentCloud$outboundSchema: z.ZodType<
  OutputOauthParamConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputOauthParamConfluentCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputOauthParamConfluentCloudToJSON(
  outputOauthParamConfluentCloud: OutputOauthParamConfluentCloud,
): string {
  return JSON.stringify(
    OutputOauthParamConfluentCloud$outboundSchema.parse(
      outputOauthParamConfluentCloud,
    ),
  );
}
export function outputOauthParamConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputOauthParamConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputOauthParamConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputOauthParamConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputSaslExtensionConfluentCloud$inboundSchema: z.ZodType<
  OutputSaslExtensionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputSaslExtensionConfluentCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputSaslExtensionConfluentCloud$outboundSchema: z.ZodType<
  OutputSaslExtensionConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputSaslExtensionConfluentCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputSaslExtensionConfluentCloudToJSON(
  outputSaslExtensionConfluentCloud: OutputSaslExtensionConfluentCloud,
): string {
  return JSON.stringify(
    OutputSaslExtensionConfluentCloud$outboundSchema.parse(
      outputSaslExtensionConfluentCloud,
    ),
  );
}
export function outputSaslExtensionConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputSaslExtensionConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSaslExtensionConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSaslExtensionConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationConfluentCloud$inboundSchema: z.ZodType<
  OutputAuthenticationConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: OutputAuthenticationMethodConfluentCloud$inboundSchema.default(
    "manual",
  ),
  credentialsSecret: z.string().optional(),
  mechanism: OutputSASLMechanismConfluentCloud$inboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(
    z.lazy(() => OutputOauthParamConfluentCloud$inboundSchema),
  ).optional(),
  saslExtensions: z.array(
    z.lazy(() => OutputSaslExtensionConfluentCloud$inboundSchema),
  ).optional(),
});
/** @internal */
export type OutputAuthenticationConfluentCloud$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  mechanism: string;
  keytabLocation?: string | undefined;
  principal?: string | undefined;
  brokerServiceClass?: string | undefined;
  oauthEnabled: boolean;
  tokenUrl?: string | undefined;
  clientId?: string | undefined;
  oauthSecretType: string;
  clientTextSecret?: string | undefined;
  oauthParams?: Array<OutputOauthParamConfluentCloud$Outbound> | undefined;
  saslExtensions?:
    | Array<OutputSaslExtensionConfluentCloud$Outbound>
    | undefined;
};

/** @internal */
export const OutputAuthenticationConfluentCloud$outboundSchema: z.ZodType<
  OutputAuthenticationConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputAuthenticationConfluentCloud
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: OutputAuthenticationMethodConfluentCloud$outboundSchema.default(
    "manual",
  ),
  credentialsSecret: z.string().optional(),
  mechanism: OutputSASLMechanismConfluentCloud$outboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(
    z.lazy(() => OutputOauthParamConfluentCloud$outboundSchema),
  ).optional(),
  saslExtensions: z.array(
    z.lazy(() => OutputSaslExtensionConfluentCloud$outboundSchema),
  ).optional(),
});

export function outputAuthenticationConfluentCloudToJSON(
  outputAuthenticationConfluentCloud: OutputAuthenticationConfluentCloud,
): string {
  return JSON.stringify(
    OutputAuthenticationConfluentCloud$outboundSchema.parse(
      outputAuthenticationConfluentCloud,
    ),
  );
}
export function outputAuthenticationConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthenticationConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      OutputAuthenticationConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthenticationConfluentCloud' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorConfluentCloud$inboundSchema: z.ZodType<
  BackpressureBehaviorConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorConfluentCloud$outboundSchema: z.ZodType<
  BackpressureBehaviorConfluentCloud,
  z.ZodTypeDef,
  BackpressureBehaviorConfluentCloud
> = z.union([
  z.nativeEnum(BackpressureBehaviorConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeConfluentCloud$inboundSchema: z.ZodType<
  OutputModeConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeConfluentCloud$outboundSchema: z.ZodType<
  OutputModeConfluentCloud,
  z.ZodTypeDef,
  OutputModeConfluentCloud
> = z.union([
  z.nativeEnum(OutputModeConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionConfluentCloud$inboundSchema: z.ZodType<
  PqCompressCompressionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionConfluentCloud$outboundSchema: z.ZodType<
  PqCompressCompressionConfluentCloud,
  z.ZodTypeDef,
  PqCompressCompressionConfluentCloud
> = z.union([
  z.nativeEnum(PqCompressCompressionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorConfluentCloud$inboundSchema: z.ZodType<
  QueueFullBehaviorConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorConfluentCloud$outboundSchema: z.ZodType<
  QueueFullBehaviorConfluentCloud,
  z.ZodTypeDef,
  QueueFullBehaviorConfluentCloud
> = z.union([
  z.nativeEnum(QueueFullBehaviorConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsConfluentCloud$inboundSchema: z.ZodType<
  OutputPqControlsConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsConfluentCloud$Outbound = {};

/** @internal */
export const OutputPqControlsConfluentCloud$outboundSchema: z.ZodType<
  OutputPqControlsConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputPqControlsConfluentCloud
> = z.object({});

export function outputPqControlsConfluentCloudToJSON(
  outputPqControlsConfluentCloud: OutputPqControlsConfluentCloud,
): string {
  return JSON.stringify(
    OutputPqControlsConfluentCloud$outboundSchema.parse(
      outputPqControlsConfluentCloud,
    ),
  );
}
export function outputPqControlsConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputConfluentCloud$inboundSchema: z.ZodType<
  OutputConfluentCloud,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeConfluentCloud$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    brokers: z.array(z.string()),
    tls: z.lazy(() => OutputTLSSettingsClientSideConfluentCloud$inboundSchema)
      .optional(),
    topic: z.string(),
    ack: AcknowledgmentsConfluentCloud$inboundSchema.default(1),
    format: RecordDataFormatConfluentCloud$inboundSchema.default("json"),
    compression: OutputCompressionConfluentCloud$inboundSchema.default("gzip"),
    maxRecordSizeKB: z.number().default(768),
    flushEventCount: z.number().default(1000),
    flushPeriodSec: z.number().default(1),
    kafkaSchemaRegistry: z.lazy(() =>
      OutputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => OutputAuthenticationConfluentCloud$inboundSchema)
      .optional(),
    onBackpressure: BackpressureBehaviorConfluentCloud$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    protobufLibraryId: z.string().optional(),
    protobufEncodingId: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeConfluentCloud$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionConfluentCloud$inboundSchema.default(
      "none",
    ),
    pqOnBackpressure: QueueFullBehaviorConfluentCloud$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => OutputPqControlsConfluentCloud$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputConfluentCloud$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  brokers: Array<string>;
  tls?: OutputTLSSettingsClientSideConfluentCloud$Outbound | undefined;
  topic: string;
  ack: number;
  format: string;
  compression: string;
  maxRecordSizeKB: number;
  flushEventCount: number;
  flushPeriodSec: number;
  kafkaSchemaRegistry?:
    | OutputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: OutputAuthenticationConfluentCloud$Outbound | undefined;
  onBackpressure: string;
  description?: string | undefined;
  protobufLibraryId?: string | undefined;
  protobufEncodingId?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsConfluentCloud$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputConfluentCloud$outboundSchema: z.ZodType<
  OutputConfluentCloud$Outbound,
  z.ZodTypeDef,
  OutputConfluentCloud
> = z.object({
  id: z.string().optional(),
  type: OutputTypeConfluentCloud$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  brokers: z.array(z.string()),
  tls: z.lazy(() => OutputTLSSettingsClientSideConfluentCloud$outboundSchema)
    .optional(),
  topic: z.string(),
  ack: AcknowledgmentsConfluentCloud$outboundSchema.default(1),
  format: RecordDataFormatConfluentCloud$outboundSchema.default("json"),
  compression: OutputCompressionConfluentCloud$outboundSchema.default("gzip"),
  maxRecordSizeKB: z.number().default(768),
  flushEventCount: z.number().default(1000),
  flushPeriodSec: z.number().default(1),
  kafkaSchemaRegistry: z.lazy(() =>
    OutputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => OutputAuthenticationConfluentCloud$outboundSchema)
    .optional(),
  onBackpressure: BackpressureBehaviorConfluentCloud$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  protobufLibraryId: z.string().optional(),
  protobufEncodingId: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeConfluentCloud$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionConfluentCloud$outboundSchema.default(
    "none",
  ),
  pqOnBackpressure: QueueFullBehaviorConfluentCloud$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => OutputPqControlsConfluentCloud$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputConfluentCloudToJSON(
  outputConfluentCloud: OutputConfluentCloud,
): string {
  return JSON.stringify(
    OutputConfluentCloud$outboundSchema.parse(outputConfluentCloud),
  );
}
export function outputConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<OutputConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputConfluentCloud' from JSON`,
  );
}

/** @internal */
export const OutputTypeKafka$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeKafka
> = z.nativeEnum(OutputTypeKafka);
/** @internal */
export const OutputTypeKafka$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeKafka
> = OutputTypeKafka$inboundSchema;

/** @internal */
export const AcknowledgmentsKafka$inboundSchema: z.ZodType<
  AcknowledgmentsKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AcknowledgmentsKafka),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AcknowledgmentsKafka$outboundSchema: z.ZodType<
  AcknowledgmentsKafka,
  z.ZodTypeDef,
  AcknowledgmentsKafka
> = z.union([
  z.nativeEnum(AcknowledgmentsKafka),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const RecordDataFormatKafka$inboundSchema: z.ZodType<
  RecordDataFormatKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordDataFormatKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordDataFormatKafka$outboundSchema: z.ZodType<
  RecordDataFormatKafka,
  z.ZodTypeDef,
  RecordDataFormatKafka
> = z.union([
  z.nativeEnum(RecordDataFormatKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionKafka$inboundSchema: z.ZodType<
  OutputCompressionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionKafka$outboundSchema: z.ZodType<
  OutputCompressionKafka,
  z.ZodTypeDef,
  OutputCompressionKafka
> = z.union([
  z.nativeEnum(OutputCompressionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthKafka$inboundSchema: z.ZodType<
  OutputAuthKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type OutputAuthKafka$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const OutputAuthKafka$outboundSchema: z.ZodType<
  OutputAuthKafka$Outbound,
  z.ZodTypeDef,
  OutputAuthKafka
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function outputAuthKafkaToJSON(
  outputAuthKafka: OutputAuthKafka,
): string {
  return JSON.stringify(OutputAuthKafka$outboundSchema.parse(outputAuthKafka));
}
export function outputAuthKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthKafka' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionKafka$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionKafka,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionKafka),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMinimumTLSVersionKafka$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMinimumTLSVersionKafka,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMinimumTLSVersionKafka
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMinimumTLSVersionKafka),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionKafka$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionKafka,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionKafka),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputKafkaSchemaRegistryMaximumTLSVersionKafka$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryMaximumTLSVersionKafka,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryMaximumTLSVersionKafka
  > = z.union([
    z.nativeEnum(OutputKafkaSchemaRegistryMaximumTLSVersionKafka),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideKafka,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: OutputKafkaSchemaRegistryMinimumTLSVersionKafka$inboundSchema
      .optional(),
    maxVersion: OutputKafkaSchemaRegistryMaximumTLSVersionKafka$inboundSchema
      .optional(),
  });
/** @internal */
export type OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryTLSSettingsClientSideKafka
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: OutputKafkaSchemaRegistryMinimumTLSVersionKafka$outboundSchema
      .optional(),
    maxVersion: OutputKafkaSchemaRegistryMaximumTLSVersionKafka$outboundSchema
      .optional(),
  });

export function outputKafkaSchemaRegistryTLSSettingsClientSideKafkaToJSON(
  outputKafkaSchemaRegistryTLSSettingsClientSideKafka:
    OutputKafkaSchemaRegistryTLSSettingsClientSideKafka,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema.parse(
      outputKafkaSchemaRegistryTLSSettingsClientSideKafka,
    ),
  );
}
export function outputKafkaSchemaRegistryTLSSettingsClientSideKafkaFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryTLSSettingsClientSideKafka,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputKafkaSchemaRegistryTLSSettingsClientSideKafka' from JSON`,
  );
}

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationKafka$inboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryAuthenticationKafka,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => OutputAuthKafka$inboundSchema).optional(),
    tls: z.lazy(() =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema
    ).optional(),
    defaultKeySchemaId: z.number().optional(),
    defaultValueSchemaId: z.number().optional(),
  });
/** @internal */
export type OutputKafkaSchemaRegistryAuthenticationKafka$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: OutputAuthKafka$Outbound | undefined;
  tls?:
    | OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound
    | undefined;
  defaultKeySchemaId?: number | undefined;
  defaultValueSchemaId?: number | undefined;
};

/** @internal */
export const OutputKafkaSchemaRegistryAuthenticationKafka$outboundSchema:
  z.ZodType<
    OutputKafkaSchemaRegistryAuthenticationKafka$Outbound,
    z.ZodTypeDef,
    OutputKafkaSchemaRegistryAuthenticationKafka
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => OutputAuthKafka$outboundSchema).optional(),
    tls: z.lazy(() =>
      OutputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema
    ).optional(),
    defaultKeySchemaId: z.number().optional(),
    defaultValueSchemaId: z.number().optional(),
  });

export function outputKafkaSchemaRegistryAuthenticationKafkaToJSON(
  outputKafkaSchemaRegistryAuthenticationKafka:
    OutputKafkaSchemaRegistryAuthenticationKafka,
): string {
  return JSON.stringify(
    OutputKafkaSchemaRegistryAuthenticationKafka$outboundSchema.parse(
      outputKafkaSchemaRegistryAuthenticationKafka,
    ),
  );
}
export function outputKafkaSchemaRegistryAuthenticationKafkaFromJSON(
  jsonString: string,
): SafeParseResult<
  OutputKafkaSchemaRegistryAuthenticationKafka,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      OutputKafkaSchemaRegistryAuthenticationKafka$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'OutputKafkaSchemaRegistryAuthenticationKafka' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationMethodKafka$inboundSchema: z.ZodType<
  OutputAuthenticationMethodKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodKafka$outboundSchema: z.ZodType<
  OutputAuthenticationMethodKafka,
  z.ZodTypeDef,
  OutputAuthenticationMethodKafka
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSASLMechanismKafka$inboundSchema: z.ZodType<
  OutputSASLMechanismKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSASLMechanismKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSASLMechanismKafka$outboundSchema: z.ZodType<
  OutputSASLMechanismKafka,
  z.ZodTypeDef,
  OutputSASLMechanismKafka
> = z.union([
  z.nativeEnum(OutputSASLMechanismKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputOauthParamKafka$inboundSchema: z.ZodType<
  OutputOauthParamKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputOauthParamKafka$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputOauthParamKafka$outboundSchema: z.ZodType<
  OutputOauthParamKafka$Outbound,
  z.ZodTypeDef,
  OutputOauthParamKafka
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputOauthParamKafkaToJSON(
  outputOauthParamKafka: OutputOauthParamKafka,
): string {
  return JSON.stringify(
    OutputOauthParamKafka$outboundSchema.parse(outputOauthParamKafka),
  );
}
export function outputOauthParamKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputOauthParamKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputOauthParamKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputOauthParamKafka' from JSON`,
  );
}

/** @internal */
export const OutputSaslExtensionKafka$inboundSchema: z.ZodType<
  OutputSaslExtensionKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OutputSaslExtensionKafka$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OutputSaslExtensionKafka$outboundSchema: z.ZodType<
  OutputSaslExtensionKafka$Outbound,
  z.ZodTypeDef,
  OutputSaslExtensionKafka
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function outputSaslExtensionKafkaToJSON(
  outputSaslExtensionKafka: OutputSaslExtensionKafka,
): string {
  return JSON.stringify(
    OutputSaslExtensionKafka$outboundSchema.parse(outputSaslExtensionKafka),
  );
}
export function outputSaslExtensionKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputSaslExtensionKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSaslExtensionKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSaslExtensionKafka' from JSON`,
  );
}

/** @internal */
export const OutputAuthenticationKafka$inboundSchema: z.ZodType<
  OutputAuthenticationKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: OutputAuthenticationMethodKafka$inboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  mechanism: OutputSASLMechanismKafka$inboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(z.lazy(() => OutputOauthParamKafka$inboundSchema))
    .optional(),
  saslExtensions: z.array(z.lazy(() => OutputSaslExtensionKafka$inboundSchema))
    .optional(),
});
/** @internal */
export type OutputAuthenticationKafka$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  mechanism: string;
  keytabLocation?: string | undefined;
  principal?: string | undefined;
  brokerServiceClass?: string | undefined;
  oauthEnabled: boolean;
  tokenUrl?: string | undefined;
  clientId?: string | undefined;
  oauthSecretType: string;
  clientTextSecret?: string | undefined;
  oauthParams?: Array<OutputOauthParamKafka$Outbound> | undefined;
  saslExtensions?: Array<OutputSaslExtensionKafka$Outbound> | undefined;
};

/** @internal */
export const OutputAuthenticationKafka$outboundSchema: z.ZodType<
  OutputAuthenticationKafka$Outbound,
  z.ZodTypeDef,
  OutputAuthenticationKafka
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: OutputAuthenticationMethodKafka$outboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  mechanism: OutputSASLMechanismKafka$outboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(z.lazy(() => OutputOauthParamKafka$outboundSchema))
    .optional(),
  saslExtensions: z.array(z.lazy(() => OutputSaslExtensionKafka$outboundSchema))
    .optional(),
});

export function outputAuthenticationKafkaToJSON(
  outputAuthenticationKafka: OutputAuthenticationKafka,
): string {
  return JSON.stringify(
    OutputAuthenticationKafka$outboundSchema.parse(outputAuthenticationKafka),
  );
}
export function outputAuthenticationKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputAuthenticationKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAuthenticationKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAuthenticationKafka' from JSON`,
  );
}

/** @internal */
export const OutputMinimumTLSVersionKafka$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionKafka$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionKafka,
  z.ZodTypeDef,
  OutputMinimumTLSVersionKafka
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionKafka$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionKafka$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionKafka,
  z.ZodTypeDef,
  OutputMaximumTLSVersionKafka
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputTLSSettingsClientSideKafka$inboundSchema: z.ZodType<
  OutputTLSSettingsClientSideKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionKafka$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionKafka$inboundSchema.optional(),
});
/** @internal */
export type OutputTLSSettingsClientSideKafka$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const OutputTLSSettingsClientSideKafka$outboundSchema: z.ZodType<
  OutputTLSSettingsClientSideKafka$Outbound,
  z.ZodTypeDef,
  OutputTLSSettingsClientSideKafka
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionKafka$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionKafka$outboundSchema.optional(),
});

export function outputTLSSettingsClientSideKafkaToJSON(
  outputTLSSettingsClientSideKafka: OutputTLSSettingsClientSideKafka,
): string {
  return JSON.stringify(
    OutputTLSSettingsClientSideKafka$outboundSchema.parse(
      outputTLSSettingsClientSideKafka,
    ),
  );
}
export function outputTLSSettingsClientSideKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputTLSSettingsClientSideKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputTLSSettingsClientSideKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputTLSSettingsClientSideKafka' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorKafka$inboundSchema: z.ZodType<
  BackpressureBehaviorKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorKafka$outboundSchema: z.ZodType<
  BackpressureBehaviorKafka,
  z.ZodTypeDef,
  BackpressureBehaviorKafka
> = z.union([
  z.nativeEnum(BackpressureBehaviorKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeKafka$inboundSchema: z.ZodType<
  OutputModeKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeKafka$outboundSchema: z.ZodType<
  OutputModeKafka,
  z.ZodTypeDef,
  OutputModeKafka
> = z.union([
  z.nativeEnum(OutputModeKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionKafka$inboundSchema: z.ZodType<
  PqCompressCompressionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionKafka$outboundSchema: z.ZodType<
  PqCompressCompressionKafka,
  z.ZodTypeDef,
  PqCompressCompressionKafka
> = z.union([
  z.nativeEnum(PqCompressCompressionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorKafka$inboundSchema: z.ZodType<
  QueueFullBehaviorKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorKafka$outboundSchema: z.ZodType<
  QueueFullBehaviorKafka,
  z.ZodTypeDef,
  QueueFullBehaviorKafka
> = z.union([
  z.nativeEnum(QueueFullBehaviorKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsKafka$inboundSchema: z.ZodType<
  OutputPqControlsKafka,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsKafka$Outbound = {};

/** @internal */
export const OutputPqControlsKafka$outboundSchema: z.ZodType<
  OutputPqControlsKafka$Outbound,
  z.ZodTypeDef,
  OutputPqControlsKafka
> = z.object({});

export function outputPqControlsKafkaToJSON(
  outputPqControlsKafka: OutputPqControlsKafka,
): string {
  return JSON.stringify(
    OutputPqControlsKafka$outboundSchema.parse(outputPqControlsKafka),
  );
}
export function outputPqControlsKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsKafka' from JSON`,
  );
}

/** @internal */
export const OutputKafka$inboundSchema: z.ZodType<
  OutputKafka,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeKafka$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    brokers: z.array(z.string()),
    topic: z.string(),
    ack: AcknowledgmentsKafka$inboundSchema.default(1),
    format: RecordDataFormatKafka$inboundSchema.default("json"),
    compression: OutputCompressionKafka$inboundSchema.default("gzip"),
    maxRecordSizeKB: z.number().default(768),
    flushEventCount: z.number().default(1000),
    flushPeriodSec: z.number().default(1),
    kafkaSchemaRegistry: z.lazy(() =>
      OutputKafkaSchemaRegistryAuthenticationKafka$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => OutputAuthenticationKafka$inboundSchema).optional(),
    tls: z.lazy(() => OutputTLSSettingsClientSideKafka$inboundSchema)
      .optional(),
    onBackpressure: BackpressureBehaviorKafka$inboundSchema.default("block"),
    description: z.string().optional(),
    protobufLibraryId: z.string().optional(),
    protobufEncodingId: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeKafka$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionKafka$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorKafka$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsKafka$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputKafka$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  brokers: Array<string>;
  topic: string;
  ack: number;
  format: string;
  compression: string;
  maxRecordSizeKB: number;
  flushEventCount: number;
  flushPeriodSec: number;
  kafkaSchemaRegistry?:
    | OutputKafkaSchemaRegistryAuthenticationKafka$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: OutputAuthenticationKafka$Outbound | undefined;
  tls?: OutputTLSSettingsClientSideKafka$Outbound | undefined;
  onBackpressure: string;
  description?: string | undefined;
  protobufLibraryId?: string | undefined;
  protobufEncodingId?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsKafka$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputKafka$outboundSchema: z.ZodType<
  OutputKafka$Outbound,
  z.ZodTypeDef,
  OutputKafka
> = z.object({
  id: z.string().optional(),
  type: OutputTypeKafka$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  brokers: z.array(z.string()),
  topic: z.string(),
  ack: AcknowledgmentsKafka$outboundSchema.default(1),
  format: RecordDataFormatKafka$outboundSchema.default("json"),
  compression: OutputCompressionKafka$outboundSchema.default("gzip"),
  maxRecordSizeKB: z.number().default(768),
  flushEventCount: z.number().default(1000),
  flushPeriodSec: z.number().default(1),
  kafkaSchemaRegistry: z.lazy(() =>
    OutputKafkaSchemaRegistryAuthenticationKafka$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => OutputAuthenticationKafka$outboundSchema).optional(),
  tls: z.lazy(() => OutputTLSSettingsClientSideKafka$outboundSchema).optional(),
  onBackpressure: BackpressureBehaviorKafka$outboundSchema.default("block"),
  description: z.string().optional(),
  protobufLibraryId: z.string().optional(),
  protobufEncodingId: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeKafka$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionKafka$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorKafka$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsKafka$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputKafkaToJSON(outputKafka: OutputKafka): string {
  return JSON.stringify(OutputKafka$outboundSchema.parse(outputKafka));
}
export function outputKafkaFromJSON(
  jsonString: string,
): SafeParseResult<OutputKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputKafka' from JSON`,
  );
}

/** @internal */
export const TypeExabeam$inboundSchema: z.ZodNativeEnum<typeof TypeExabeam> = z
  .nativeEnum(TypeExabeam);
/** @internal */
export const TypeExabeam$outboundSchema: z.ZodNativeEnum<typeof TypeExabeam> =
  TypeExabeam$inboundSchema;

/** @internal */
export const SignatureVersionExabeam$inboundSchema: z.ZodType<
  SignatureVersionExabeam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionExabeam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionExabeam$outboundSchema: z.ZodType<
  SignatureVersionExabeam,
  z.ZodTypeDef,
  SignatureVersionExabeam
> = z.union([
  z.nativeEnum(SignatureVersionExabeam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLExabeam$inboundSchema: z.ZodType<
  ObjectACLExabeam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLExabeam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLExabeam$outboundSchema: z.ZodType<
  ObjectACLExabeam,
  z.ZodTypeDef,
  ObjectACLExabeam
> = z.union([
  z.nativeEnum(ObjectACLExabeam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassExabeam$inboundSchema: z.ZodType<
  StorageClassExabeam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassExabeam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassExabeam$outboundSchema: z.ZodType<
  StorageClassExabeam,
  z.ZodTypeDef,
  StorageClassExabeam
> = z.union([
  z.nativeEnum(StorageClassExabeam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorExabeam$inboundSchema: z.ZodType<
  BackpressureBehaviorExabeam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorExabeam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorExabeam$outboundSchema: z.ZodType<
  BackpressureBehaviorExabeam,
  z.ZodTypeDef,
  BackpressureBehaviorExabeam
> = z.union([
  z.nativeEnum(BackpressureBehaviorExabeam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionExabeam$inboundSchema: z.ZodType<
  DiskSpaceProtectionExabeam,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionExabeam),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionExabeam$outboundSchema: z.ZodType<
  DiskSpaceProtectionExabeam,
  z.ZodTypeDef,
  DiskSpaceProtectionExabeam
> = z.union([
  z.nativeEnum(DiskSpaceProtectionExabeam),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputExabeam$inboundSchema: z.ZodType<
  OutputExabeam,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeExabeam$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string(),
    region: z.string(),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    endpoint: z.string().default("https://storage.googleapis.com"),
    signatureVersion: SignatureVersionExabeam$inboundSchema.default("v4"),
    objectACL: ObjectACLExabeam$inboundSchema.default("private"),
    storageClass: StorageClassExabeam$inboundSchema.optional(),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    addIdToStagePath: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    onBackpressure: BackpressureBehaviorExabeam$inboundSchema.default("block"),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionExabeam$inboundSchema.default(
      "block",
    ),
    maxFileSizeMB: z.number().default(10),
    encodedConfiguration: z.string().optional(),
    collectorInstanceId: z.string(),
    siteName: z.string().optional(),
    siteId: z.string().optional(),
    timezoneOffset: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecretKey: z.string().optional(),
    description: z.string().optional(),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputExabeam$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region: string;
  stagePath: string;
  endpoint: string;
  signatureVersion: string;
  objectACL: string;
  storageClass?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  addIdToStagePath: boolean;
  removeEmptyDirs: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  maxFileSizeMB: number;
  encodedConfiguration?: string | undefined;
  collectorInstanceId: string;
  siteName?: string | undefined;
  siteId?: string | undefined;
  timezoneOffset?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecretKey?: string | undefined;
  description?: string | undefined;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputExabeam$outboundSchema: z.ZodType<
  OutputExabeam$Outbound,
  z.ZodTypeDef,
  OutputExabeam
> = z.object({
  id: z.string().optional(),
  type: TypeExabeam$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  endpoint: z.string().default("https://storage.googleapis.com"),
  signatureVersion: SignatureVersionExabeam$outboundSchema.default("v4"),
  objectACL: ObjectACLExabeam$outboundSchema.default("private"),
  storageClass: StorageClassExabeam$outboundSchema.optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  onBackpressure: BackpressureBehaviorExabeam$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionExabeam$outboundSchema.default(
    "block",
  ),
  maxFileSizeMB: z.number().default(10),
  encodedConfiguration: z.string().optional(),
  collectorInstanceId: z.string(),
  siteName: z.string().optional(),
  siteId: z.string().optional(),
  timezoneOffset: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecretKey: z.string().optional(),
  description: z.string().optional(),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputExabeamToJSON(outputExabeam: OutputExabeam): string {
  return JSON.stringify(OutputExabeam$outboundSchema.parse(outputExabeam));
}
export function outputExabeamFromJSON(
  jsonString: string,
): SafeParseResult<OutputExabeam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputExabeam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputExabeam' from JSON`,
  );
}

/** @internal */
export const OutputTypeGooglePubsub$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeGooglePubsub
> = z.nativeEnum(OutputTypeGooglePubsub);
/** @internal */
export const OutputTypeGooglePubsub$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeGooglePubsub
> = OutputTypeGooglePubsub$inboundSchema;

/** @internal */
export const OutputGoogleAuthenticationMethodGooglePubsub$inboundSchema:
  z.ZodType<
    OutputGoogleAuthenticationMethodGooglePubsub,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(OutputGoogleAuthenticationMethodGooglePubsub),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const OutputGoogleAuthenticationMethodGooglePubsub$outboundSchema:
  z.ZodType<
    OutputGoogleAuthenticationMethodGooglePubsub,
    z.ZodTypeDef,
    OutputGoogleAuthenticationMethodGooglePubsub
  > = z.union([
    z.nativeEnum(OutputGoogleAuthenticationMethodGooglePubsub),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const BackpressureBehaviorGooglePubsub$inboundSchema: z.ZodType<
  BackpressureBehaviorGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorGooglePubsub$outboundSchema: z.ZodType<
  BackpressureBehaviorGooglePubsub,
  z.ZodTypeDef,
  BackpressureBehaviorGooglePubsub
> = z.union([
  z.nativeEnum(BackpressureBehaviorGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeGooglePubsub$inboundSchema: z.ZodType<
  OutputModeGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeGooglePubsub$outboundSchema: z.ZodType<
  OutputModeGooglePubsub,
  z.ZodTypeDef,
  OutputModeGooglePubsub
> = z.union([
  z.nativeEnum(OutputModeGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionGooglePubsub$inboundSchema: z.ZodType<
  PqCompressCompressionGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionGooglePubsub$outboundSchema: z.ZodType<
  PqCompressCompressionGooglePubsub,
  z.ZodTypeDef,
  PqCompressCompressionGooglePubsub
> = z.union([
  z.nativeEnum(PqCompressCompressionGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorGooglePubsub$inboundSchema: z.ZodType<
  QueueFullBehaviorGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorGooglePubsub$outboundSchema: z.ZodType<
  QueueFullBehaviorGooglePubsub,
  z.ZodTypeDef,
  QueueFullBehaviorGooglePubsub
> = z.union([
  z.nativeEnum(QueueFullBehaviorGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsGooglePubsub$inboundSchema: z.ZodType<
  OutputPqControlsGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsGooglePubsub$Outbound = {};

/** @internal */
export const OutputPqControlsGooglePubsub$outboundSchema: z.ZodType<
  OutputPqControlsGooglePubsub$Outbound,
  z.ZodTypeDef,
  OutputPqControlsGooglePubsub
> = z.object({});

export function outputPqControlsGooglePubsubToJSON(
  outputPqControlsGooglePubsub: OutputPqControlsGooglePubsub,
): string {
  return JSON.stringify(
    OutputPqControlsGooglePubsub$outboundSchema.parse(
      outputPqControlsGooglePubsub,
    ),
  );
}
export function outputPqControlsGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsGooglePubsub' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsub$inboundSchema: z.ZodType<
  OutputGooglePubsub,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeGooglePubsub$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    topicName: z.string(),
    createTopic: z.boolean().default(false),
    orderedDelivery: z.boolean().default(false),
    region: z.string().optional(),
    googleAuthMethod: OutputGoogleAuthenticationMethodGooglePubsub$inboundSchema
      .default("manual"),
    serviceAccountCredentials: z.string().optional(),
    secret: z.string().optional(),
    batchSize: z.number().default(1000),
    batchTimeout: z.number().default(100),
    maxQueueSize: z.number().default(100),
    maxRecordSizeKB: z.number().default(256),
    flushPeriod: z.number().default(1),
    maxInProgress: z.number().default(10),
    onBackpressure: BackpressureBehaviorGooglePubsub$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeGooglePubsub$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionGooglePubsub$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorGooglePubsub$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => OutputPqControlsGooglePubsub$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGooglePubsub$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  googleAuthMethod: string;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsGooglePubsub$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGooglePubsub$outboundSchema: z.ZodType<
  OutputGooglePubsub$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsub
> = z.object({
  id: z.string().optional(),
  type: OutputTypeGooglePubsub$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  googleAuthMethod: OutputGoogleAuthenticationMethodGooglePubsub$outboundSchema
    .default("manual"),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: BackpressureBehaviorGooglePubsub$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeGooglePubsub$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionGooglePubsub$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorGooglePubsub$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => OutputPqControlsGooglePubsub$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGooglePubsubToJSON(
  outputGooglePubsub: OutputGooglePubsub,
): string {
  return JSON.stringify(
    OutputGooglePubsub$outboundSchema.parse(outputGooglePubsub),
  );
}
export function outputGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsub' from JSON`,
  );
}

/** @internal */
export const TypeGoogleCloudLogging$inboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleCloudLogging
> = z.nativeEnum(TypeGoogleCloudLogging);
/** @internal */
export const TypeGoogleCloudLogging$outboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleCloudLogging
> = TypeGoogleCloudLogging$inboundSchema;

/** @internal */
export const LogLocationType$inboundSchema: z.ZodType<
  LogLocationType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLocationType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLocationType$outboundSchema: z.ZodType<
  LogLocationType,
  z.ZodTypeDef,
  LogLocationType
> = z.union([
  z.nativeEnum(LogLocationType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PayloadFormat$inboundSchema: z.ZodType<
  PayloadFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PayloadFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PayloadFormat$outboundSchema: z.ZodType<
  PayloadFormat,
  z.ZodTypeDef,
  PayloadFormat
> = z.union([
  z.nativeEnum(PayloadFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LogLabel$inboundSchema: z.ZodType<
  LogLabel,
  z.ZodTypeDef,
  unknown
> = z.object({
  label: z.string(),
  valueExpression: z.string(),
});
/** @internal */
export type LogLabel$Outbound = {
  label: string;
  valueExpression: string;
};

/** @internal */
export const LogLabel$outboundSchema: z.ZodType<
  LogLabel$Outbound,
  z.ZodTypeDef,
  LogLabel
> = z.object({
  label: z.string(),
  valueExpression: z.string(),
});

export function logLabelToJSON(logLabel: LogLabel): string {
  return JSON.stringify(LogLabel$outboundSchema.parse(logLabel));
}
export function logLabelFromJSON(
  jsonString: string,
): SafeParseResult<LogLabel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LogLabel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LogLabel' from JSON`,
  );
}

/** @internal */
export const ResourceTypeLabel$inboundSchema: z.ZodType<
  ResourceTypeLabel,
  z.ZodTypeDef,
  unknown
> = z.object({
  label: z.string(),
  valueExpression: z.string(),
});
/** @internal */
export type ResourceTypeLabel$Outbound = {
  label: string;
  valueExpression: string;
};

/** @internal */
export const ResourceTypeLabel$outboundSchema: z.ZodType<
  ResourceTypeLabel$Outbound,
  z.ZodTypeDef,
  ResourceTypeLabel
> = z.object({
  label: z.string(),
  valueExpression: z.string(),
});

export function resourceTypeLabelToJSON(
  resourceTypeLabel: ResourceTypeLabel,
): string {
  return JSON.stringify(
    ResourceTypeLabel$outboundSchema.parse(resourceTypeLabel),
  );
}
export function resourceTypeLabelFromJSON(
  jsonString: string,
): SafeParseResult<ResourceTypeLabel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResourceTypeLabel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResourceTypeLabel' from JSON`,
  );
}

/** @internal */
export const GoogleAuthenticationMethodGoogleCloudLogging$inboundSchema:
  z.ZodType<
    GoogleAuthenticationMethodGoogleCloudLogging,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(GoogleAuthenticationMethodGoogleCloudLogging),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const GoogleAuthenticationMethodGoogleCloudLogging$outboundSchema:
  z.ZodType<
    GoogleAuthenticationMethodGoogleCloudLogging,
    z.ZodTypeDef,
    GoogleAuthenticationMethodGoogleCloudLogging
  > = z.union([
    z.nativeEnum(GoogleAuthenticationMethodGoogleCloudLogging),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const BackpressureBehaviorGoogleCloudLogging$inboundSchema: z.ZodType<
  BackpressureBehaviorGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorGoogleCloudLogging),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorGoogleCloudLogging$outboundSchema: z.ZodType<
  BackpressureBehaviorGoogleCloudLogging,
  z.ZodTypeDef,
  BackpressureBehaviorGoogleCloudLogging
> = z.union([
  z.nativeEnum(BackpressureBehaviorGoogleCloudLogging),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeGoogleCloudLogging$inboundSchema: z.ZodType<
  ModeGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeGoogleCloudLogging),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeGoogleCloudLogging$outboundSchema: z.ZodType<
  ModeGoogleCloudLogging,
  z.ZodTypeDef,
  ModeGoogleCloudLogging
> = z.union([
  z.nativeEnum(ModeGoogleCloudLogging),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionGoogleCloudLogging$inboundSchema: z.ZodType<
  CompressionGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionGoogleCloudLogging),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionGoogleCloudLogging$outboundSchema: z.ZodType<
  CompressionGoogleCloudLogging,
  z.ZodTypeDef,
  CompressionGoogleCloudLogging
> = z.union([
  z.nativeEnum(CompressionGoogleCloudLogging),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorGoogleCloudLogging$inboundSchema: z.ZodType<
  QueueFullBehaviorGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorGoogleCloudLogging),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorGoogleCloudLogging$outboundSchema: z.ZodType<
  QueueFullBehaviorGoogleCloudLogging,
  z.ZodTypeDef,
  QueueFullBehaviorGoogleCloudLogging
> = z.union([
  z.nativeEnum(QueueFullBehaviorGoogleCloudLogging),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsGoogleCloudLogging$inboundSchema: z.ZodType<
  PqControlsGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsGoogleCloudLogging$Outbound = {};

/** @internal */
export const PqControlsGoogleCloudLogging$outboundSchema: z.ZodType<
  PqControlsGoogleCloudLogging$Outbound,
  z.ZodTypeDef,
  PqControlsGoogleCloudLogging
> = z.object({});

export function pqControlsGoogleCloudLoggingToJSON(
  pqControlsGoogleCloudLogging: PqControlsGoogleCloudLogging,
): string {
  return JSON.stringify(
    PqControlsGoogleCloudLogging$outboundSchema.parse(
      pqControlsGoogleCloudLogging,
    ),
  );
}
export function pqControlsGoogleCloudLoggingFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsGoogleCloudLogging, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsGoogleCloudLogging$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsGoogleCloudLogging' from JSON`,
  );
}

/** @internal */
export const OutputGoogleCloudLogging$inboundSchema: z.ZodType<
  OutputGoogleCloudLogging,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeGoogleCloudLogging$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    logLocationType: LogLocationType$inboundSchema,
    logNameExpression: z.string(),
    sanitizeLogNames: z.boolean().default(false),
    payloadFormat: PayloadFormat$inboundSchema.default("text"),
    logLabels: z.array(z.lazy(() => LogLabel$inboundSchema)).optional(),
    resourceTypeExpression: z.string().optional(),
    resourceTypeLabels: z.array(z.lazy(() => ResourceTypeLabel$inboundSchema))
      .optional(),
    severityExpression: z.string().optional(),
    insertIdExpression: z.string().optional(),
    googleAuthMethod: GoogleAuthenticationMethodGoogleCloudLogging$inboundSchema
      .default("manual"),
    serviceAccountCredentials: z.string().optional(),
    secret: z.string().optional(),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    flushPeriodSec: z.number().default(1),
    concurrency: z.number().default(5),
    connectionTimeout: z.number().default(10000),
    timeoutSec: z.number().default(30),
    throttleRateReqPerSec: z.number().int().optional(),
    requestMethodExpression: z.string().optional(),
    requestUrlExpression: z.string().optional(),
    requestSizeExpression: z.string().optional(),
    statusExpression: z.string().optional(),
    responseSizeExpression: z.string().optional(),
    userAgentExpression: z.string().optional(),
    remoteIpExpression: z.string().optional(),
    serverIpExpression: z.string().optional(),
    refererExpression: z.string().optional(),
    latencyExpression: z.string().optional(),
    cacheLookupExpression: z.string().optional(),
    cacheHitExpression: z.string().optional(),
    cacheValidatedExpression: z.string().optional(),
    cacheFillBytesExpression: z.string().optional(),
    protocolExpression: z.string().optional(),
    idExpression: z.string().optional(),
    producerExpression: z.string().optional(),
    firstExpression: z.string().optional(),
    lastExpression: z.string().optional(),
    fileExpression: z.string().optional(),
    lineExpression: z.string().optional(),
    functionExpression: z.string().optional(),
    uidExpression: z.string().optional(),
    indexExpression: z.string().optional(),
    totalSplitsExpression: z.string().optional(),
    traceExpression: z.string().optional(),
    spanIdExpression: z.string().optional(),
    traceSampledExpression: z.string().optional(),
    onBackpressure: BackpressureBehaviorGoogleCloudLogging$inboundSchema
      .default("block"),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    logLocationExpression: z.string(),
    payloadExpression: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeGoogleCloudLogging$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionGoogleCloudLogging$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorGoogleCloudLogging$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsGoogleCloudLogging$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGoogleCloudLogging$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  logLocationType: string;
  logNameExpression: string;
  sanitizeLogNames: boolean;
  payloadFormat: string;
  logLabels?: Array<LogLabel$Outbound> | undefined;
  resourceTypeExpression?: string | undefined;
  resourceTypeLabels?: Array<ResourceTypeLabel$Outbound> | undefined;
  severityExpression?: string | undefined;
  insertIdExpression?: string | undefined;
  googleAuthMethod: string;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  flushPeriodSec: number;
  concurrency: number;
  connectionTimeout: number;
  timeoutSec: number;
  throttleRateReqPerSec?: number | undefined;
  requestMethodExpression?: string | undefined;
  requestUrlExpression?: string | undefined;
  requestSizeExpression?: string | undefined;
  statusExpression?: string | undefined;
  responseSizeExpression?: string | undefined;
  userAgentExpression?: string | undefined;
  remoteIpExpression?: string | undefined;
  serverIpExpression?: string | undefined;
  refererExpression?: string | undefined;
  latencyExpression?: string | undefined;
  cacheLookupExpression?: string | undefined;
  cacheHitExpression?: string | undefined;
  cacheValidatedExpression?: string | undefined;
  cacheFillBytesExpression?: string | undefined;
  protocolExpression?: string | undefined;
  idExpression?: string | undefined;
  producerExpression?: string | undefined;
  firstExpression?: string | undefined;
  lastExpression?: string | undefined;
  fileExpression?: string | undefined;
  lineExpression?: string | undefined;
  functionExpression?: string | undefined;
  uidExpression?: string | undefined;
  indexExpression?: string | undefined;
  totalSplitsExpression?: string | undefined;
  traceExpression?: string | undefined;
  spanIdExpression?: string | undefined;
  traceSampledExpression?: string | undefined;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  logLocationExpression: string;
  payloadExpression?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsGoogleCloudLogging$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGoogleCloudLogging$outboundSchema: z.ZodType<
  OutputGoogleCloudLogging$Outbound,
  z.ZodTypeDef,
  OutputGoogleCloudLogging
> = z.object({
  id: z.string().optional(),
  type: TypeGoogleCloudLogging$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  logLocationType: LogLocationType$outboundSchema,
  logNameExpression: z.string(),
  sanitizeLogNames: z.boolean().default(false),
  payloadFormat: PayloadFormat$outboundSchema.default("text"),
  logLabels: z.array(z.lazy(() => LogLabel$outboundSchema)).optional(),
  resourceTypeExpression: z.string().optional(),
  resourceTypeLabels: z.array(z.lazy(() => ResourceTypeLabel$outboundSchema))
    .optional(),
  severityExpression: z.string().optional(),
  insertIdExpression: z.string().optional(),
  googleAuthMethod: GoogleAuthenticationMethodGoogleCloudLogging$outboundSchema
    .default("manual"),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  flushPeriodSec: z.number().default(1),
  concurrency: z.number().default(5),
  connectionTimeout: z.number().default(10000),
  timeoutSec: z.number().default(30),
  throttleRateReqPerSec: z.number().int().optional(),
  requestMethodExpression: z.string().optional(),
  requestUrlExpression: z.string().optional(),
  requestSizeExpression: z.string().optional(),
  statusExpression: z.string().optional(),
  responseSizeExpression: z.string().optional(),
  userAgentExpression: z.string().optional(),
  remoteIpExpression: z.string().optional(),
  serverIpExpression: z.string().optional(),
  refererExpression: z.string().optional(),
  latencyExpression: z.string().optional(),
  cacheLookupExpression: z.string().optional(),
  cacheHitExpression: z.string().optional(),
  cacheValidatedExpression: z.string().optional(),
  cacheFillBytesExpression: z.string().optional(),
  protocolExpression: z.string().optional(),
  idExpression: z.string().optional(),
  producerExpression: z.string().optional(),
  firstExpression: z.string().optional(),
  lastExpression: z.string().optional(),
  fileExpression: z.string().optional(),
  lineExpression: z.string().optional(),
  functionExpression: z.string().optional(),
  uidExpression: z.string().optional(),
  indexExpression: z.string().optional(),
  totalSplitsExpression: z.string().optional(),
  traceExpression: z.string().optional(),
  spanIdExpression: z.string().optional(),
  traceSampledExpression: z.string().optional(),
  onBackpressure: BackpressureBehaviorGoogleCloudLogging$outboundSchema.default(
    "block",
  ),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  logLocationExpression: z.string(),
  payloadExpression: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeGoogleCloudLogging$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionGoogleCloudLogging$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorGoogleCloudLogging$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsGoogleCloudLogging$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGoogleCloudLoggingToJSON(
  outputGoogleCloudLogging: OutputGoogleCloudLogging,
): string {
  return JSON.stringify(
    OutputGoogleCloudLogging$outboundSchema.parse(outputGoogleCloudLogging),
  );
}
export function outputGoogleCloudLoggingFromJSON(
  jsonString: string,
): SafeParseResult<OutputGoogleCloudLogging, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGoogleCloudLogging$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGoogleCloudLogging' from JSON`,
  );
}

/** @internal */
export const TypeGoogleCloudStorage$inboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleCloudStorage
> = z.nativeEnum(TypeGoogleCloudStorage);
/** @internal */
export const TypeGoogleCloudStorage$outboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleCloudStorage
> = TypeGoogleCloudStorage$inboundSchema;

/** @internal */
export const SignatureVersionGoogleCloudStorage$inboundSchema: z.ZodType<
  SignatureVersionGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionGoogleCloudStorage$outboundSchema: z.ZodType<
  SignatureVersionGoogleCloudStorage,
  z.ZodTypeDef,
  SignatureVersionGoogleCloudStorage
> = z.union([
  z.nativeEnum(SignatureVersionGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodGoogleCloudStorage$inboundSchema: z.ZodType<
  AuthenticationMethodGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodGoogleCloudStorage$outboundSchema: z.ZodType<
  AuthenticationMethodGoogleCloudStorage,
  z.ZodTypeDef,
  AuthenticationMethodGoogleCloudStorage
> = z.union([
  z.nativeEnum(AuthenticationMethodGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectACLGoogleCloudStorage$inboundSchema: z.ZodType<
  ObjectACLGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectACLGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectACLGoogleCloudStorage$outboundSchema: z.ZodType<
  ObjectACLGoogleCloudStorage,
  z.ZodTypeDef,
  ObjectACLGoogleCloudStorage
> = z.union([
  z.nativeEnum(ObjectACLGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassGoogleCloudStorage$inboundSchema: z.ZodType<
  StorageClassGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassGoogleCloudStorage$outboundSchema: z.ZodType<
  StorageClassGoogleCloudStorage,
  z.ZodTypeDef,
  StorageClassGoogleCloudStorage
> = z.union([
  z.nativeEnum(StorageClassGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataFormatGoogleCloudStorage$inboundSchema: z.ZodType<
  DataFormatGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatGoogleCloudStorage$outboundSchema: z.ZodType<
  DataFormatGoogleCloudStorage,
  z.ZodTypeDef,
  DataFormatGoogleCloudStorage
> = z.union([
  z.nativeEnum(DataFormatGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorGoogleCloudStorage$inboundSchema: z.ZodType<
  BackpressureBehaviorGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorGoogleCloudStorage$outboundSchema: z.ZodType<
  BackpressureBehaviorGoogleCloudStorage,
  z.ZodTypeDef,
  BackpressureBehaviorGoogleCloudStorage
> = z.union([
  z.nativeEnum(BackpressureBehaviorGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionGoogleCloudStorage$inboundSchema: z.ZodType<
  DiskSpaceProtectionGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionGoogleCloudStorage$outboundSchema: z.ZodType<
  DiskSpaceProtectionGoogleCloudStorage,
  z.ZodTypeDef,
  DiskSpaceProtectionGoogleCloudStorage
> = z.union([
  z.nativeEnum(DiskSpaceProtectionGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionGoogleCloudStorage$inboundSchema: z.ZodType<
  CompressionGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionGoogleCloudStorage$outboundSchema: z.ZodType<
  CompressionGoogleCloudStorage,
  z.ZodTypeDef,
  CompressionGoogleCloudStorage
> = z.union([
  z.nativeEnum(CompressionGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelGoogleCloudStorage$inboundSchema: z.ZodType<
  CompressionLevelGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelGoogleCloudStorage$outboundSchema: z.ZodType<
  CompressionLevelGoogleCloudStorage,
  z.ZodTypeDef,
  CompressionLevelGoogleCloudStorage
> = z.union([
  z.nativeEnum(CompressionLevelGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionGoogleCloudStorage$inboundSchema: z.ZodType<
  ParquetVersionGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionGoogleCloudStorage$outboundSchema: z.ZodType<
  ParquetVersionGoogleCloudStorage,
  z.ZodTypeDef,
  ParquetVersionGoogleCloudStorage
> = z.union([
  z.nativeEnum(ParquetVersionGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionGoogleCloudStorage$inboundSchema: z.ZodType<
  DataPageVersionGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionGoogleCloudStorage),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionGoogleCloudStorage$outboundSchema: z.ZodType<
  DataPageVersionGoogleCloudStorage,
  z.ZodTypeDef,
  DataPageVersionGoogleCloudStorage
> = z.union([
  z.nativeEnum(DataPageVersionGoogleCloudStorage),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumGoogleCloudStorage$inboundSchema: z.ZodType<
  KeyValueMetadatumGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumGoogleCloudStorage$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumGoogleCloudStorage$outboundSchema: z.ZodType<
  KeyValueMetadatumGoogleCloudStorage$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumGoogleCloudStorage
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumGoogleCloudStorageToJSON(
  keyValueMetadatumGoogleCloudStorage: KeyValueMetadatumGoogleCloudStorage,
): string {
  return JSON.stringify(
    KeyValueMetadatumGoogleCloudStorage$outboundSchema.parse(
      keyValueMetadatumGoogleCloudStorage,
    ),
  );
}
export function keyValueMetadatumGoogleCloudStorageFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumGoogleCloudStorage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      KeyValueMetadatumGoogleCloudStorage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumGoogleCloudStorage' from JSON`,
  );
}

/** @internal */
export const OutputGoogleCloudStorage$inboundSchema: z.ZodType<
  OutputGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeGoogleCloudStorage$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string(),
    region: z.string(),
    endpoint: z.string().default("https://storage.googleapis.com"),
    signatureVersion: SignatureVersionGoogleCloudStorage$inboundSchema.default(
      "v4",
    ),
    awsAuthenticationMethod:
      AuthenticationMethodGoogleCloudStorage$inboundSchema.default("manual"),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    destPath: z.string().default(""),
    verifyPermissions: z.boolean().default(true),
    objectACL: ObjectACLGoogleCloudStorage$inboundSchema.default("private"),
    storageClass: StorageClassGoogleCloudStorage$inboundSchema.optional(),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    addIdToStagePath: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatGoogleCloudStorage$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorGoogleCloudStorage$inboundSchema
      .default("block"),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionGoogleCloudStorage$inboundSchema
      .default("block"),
    forceCloseOnShutdown: z.boolean().default(false),
    description: z.string().optional(),
    compress: CompressionGoogleCloudStorage$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelGoogleCloudStorage$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionGoogleCloudStorage$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionGoogleCloudStorage$inboundSchema
      .default("DATA_PAGE_V2"),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumGoogleCloudStorage$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
    awsApiKey: z.string().optional(),
    awsSecretKey: z.string().optional(),
    awsSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGoogleCloudStorage$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region: string;
  endpoint: string;
  signatureVersion: string;
  awsAuthenticationMethod: string;
  stagePath: string;
  destPath: string;
  verifyPermissions: boolean;
  objectACL: string;
  storageClass?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  addIdToStagePath: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  description?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<KeyValueMetadatumGoogleCloudStorage$Outbound>
    | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  awsApiKey?: string | undefined;
  awsSecretKey?: string | undefined;
  awsSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGoogleCloudStorage$outboundSchema: z.ZodType<
  OutputGoogleCloudStorage$Outbound,
  z.ZodTypeDef,
  OutputGoogleCloudStorage
> = z.object({
  id: z.string().optional(),
  type: TypeGoogleCloudStorage$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string(),
  endpoint: z.string().default("https://storage.googleapis.com"),
  signatureVersion: SignatureVersionGoogleCloudStorage$outboundSchema.default(
    "v4",
  ),
  awsAuthenticationMethod: AuthenticationMethodGoogleCloudStorage$outboundSchema
    .default("manual"),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  destPath: z.string().default(""),
  verifyPermissions: z.boolean().default(true),
  objectACL: ObjectACLGoogleCloudStorage$outboundSchema.default("private"),
  storageClass: StorageClassGoogleCloudStorage$outboundSchema.optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatGoogleCloudStorage$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorGoogleCloudStorage$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionGoogleCloudStorage$outboundSchema
    .default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  description: z.string().optional(),
  compress: CompressionGoogleCloudStorage$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelGoogleCloudStorage$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionGoogleCloudStorage$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionGoogleCloudStorage$outboundSchema
    .default("DATA_PAGE_V2"),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumGoogleCloudStorage$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  awsApiKey: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGoogleCloudStorageToJSON(
  outputGoogleCloudStorage: OutputGoogleCloudStorage,
): string {
  return JSON.stringify(
    OutputGoogleCloudStorage$outboundSchema.parse(outputGoogleCloudStorage),
  );
}
export function outputGoogleCloudStorageFromJSON(
  jsonString: string,
): SafeParseResult<OutputGoogleCloudStorage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGoogleCloudStorage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGoogleCloudStorage' from JSON`,
  );
}

/** @internal */
export const TypeGoogleChronicle$inboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleChronicle
> = z.nativeEnum(TypeGoogleChronicle);
/** @internal */
export const TypeGoogleChronicle$outboundSchema: z.ZodNativeEnum<
  typeof TypeGoogleChronicle
> = TypeGoogleChronicle$inboundSchema;

/** @internal */
export const OutputAPIVersion$inboundSchema: z.ZodType<
  OutputAPIVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAPIVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAPIVersion$outboundSchema: z.ZodType<
  OutputAPIVersion,
  z.ZodTypeDef,
  OutputAPIVersion
> = z.union([
  z.nativeEnum(OutputAPIVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodGoogleChronicle$inboundSchema: z.ZodType<
  AuthenticationMethodGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodGoogleChronicle$outboundSchema: z.ZodType<
  AuthenticationMethodGoogleChronicle,
  z.ZodTypeDef,
  AuthenticationMethodGoogleChronicle
> = z.union([
  z.nativeEnum(AuthenticationMethodGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingGoogleChronicle$inboundSchema: z.ZodType<
  ResponseRetrySettingGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingGoogleChronicle$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingGoogleChronicle$outboundSchema: z.ZodType<
  ResponseRetrySettingGoogleChronicle$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingGoogleChronicle
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingGoogleChronicleToJSON(
  responseRetrySettingGoogleChronicle: ResponseRetrySettingGoogleChronicle,
): string {
  return JSON.stringify(
    ResponseRetrySettingGoogleChronicle$outboundSchema.parse(
      responseRetrySettingGoogleChronicle,
    ),
  );
}
export function responseRetrySettingGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      ResponseRetrySettingGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsGoogleChronicle$inboundSchema: z.ZodType<
  TimeoutRetrySettingsGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsGoogleChronicle$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsGoogleChronicle$outboundSchema: z.ZodType<
  TimeoutRetrySettingsGoogleChronicle$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsGoogleChronicle
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsGoogleChronicleToJSON(
  timeoutRetrySettingsGoogleChronicle: TimeoutRetrySettingsGoogleChronicle,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsGoogleChronicle$outboundSchema.parse(
      timeoutRetrySettingsGoogleChronicle,
    ),
  );
}
export function timeoutRetrySettingsGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TimeoutRetrySettingsGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const SendEventsAs$inboundSchema: z.ZodType<
  SendEventsAs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SendEventsAs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SendEventsAs$outboundSchema: z.ZodType<
  SendEventsAs,
  z.ZodTypeDef,
  SendEventsAs
> = z.union([
  z.nativeEnum(SendEventsAs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderGoogleChronicle$inboundSchema: z.ZodType<
  ExtraHttpHeaderGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderGoogleChronicle$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderGoogleChronicle$outboundSchema: z.ZodType<
  ExtraHttpHeaderGoogleChronicle$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderGoogleChronicle
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderGoogleChronicleToJSON(
  extraHttpHeaderGoogleChronicle: ExtraHttpHeaderGoogleChronicle,
): string {
  return JSON.stringify(
    ExtraHttpHeaderGoogleChronicle$outboundSchema.parse(
      extraHttpHeaderGoogleChronicle,
    ),
  );
}
export function extraHttpHeaderGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeGoogleChronicle$inboundSchema: z.ZodType<
  FailedRequestLoggingModeGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeGoogleChronicle$outboundSchema: z.ZodType<
  FailedRequestLoggingModeGoogleChronicle,
  z.ZodTypeDef,
  FailedRequestLoggingModeGoogleChronicle
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorGoogleChronicle$inboundSchema: z.ZodType<
  BackpressureBehaviorGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorGoogleChronicle$outboundSchema: z.ZodType<
  BackpressureBehaviorGoogleChronicle,
  z.ZodTypeDef,
  BackpressureBehaviorGoogleChronicle
> = z.union([
  z.nativeEnum(BackpressureBehaviorGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraLogType$inboundSchema: z.ZodType<
  ExtraLogType,
  z.ZodTypeDef,
  unknown
> = z.object({
  logType: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type ExtraLogType$Outbound = {
  logType: string;
  description?: string | undefined;
};

/** @internal */
export const ExtraLogType$outboundSchema: z.ZodType<
  ExtraLogType$Outbound,
  z.ZodTypeDef,
  ExtraLogType
> = z.object({
  logType: z.string(),
  description: z.string().optional(),
});

export function extraLogTypeToJSON(extraLogType: ExtraLogType): string {
  return JSON.stringify(ExtraLogType$outboundSchema.parse(extraLogType));
}
export function extraLogTypeFromJSON(
  jsonString: string,
): SafeParseResult<ExtraLogType, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraLogType$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraLogType' from JSON`,
  );
}

/** @internal */
export const CustomLabelGoogleChronicle$inboundSchema: z.ZodType<
  CustomLabelGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string(),
  value: z.string(),
});
/** @internal */
export type CustomLabelGoogleChronicle$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const CustomLabelGoogleChronicle$outboundSchema: z.ZodType<
  CustomLabelGoogleChronicle$Outbound,
  z.ZodTypeDef,
  CustomLabelGoogleChronicle
> = z.object({
  key: z.string(),
  value: z.string(),
});

export function customLabelGoogleChronicleToJSON(
  customLabelGoogleChronicle: CustomLabelGoogleChronicle,
): string {
  return JSON.stringify(
    CustomLabelGoogleChronicle$outboundSchema.parse(customLabelGoogleChronicle),
  );
}
export function customLabelGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<CustomLabelGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CustomLabelGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CustomLabelGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const UDMType$inboundSchema: z.ZodType<UDMType, z.ZodTypeDef, unknown> =
  z
    .union([
      z.nativeEnum(UDMType),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const UDMType$outboundSchema: z.ZodType<UDMType, z.ZodTypeDef, UDMType> =
  z.union([
    z.nativeEnum(UDMType),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const ModeGoogleChronicle$inboundSchema: z.ZodType<
  ModeGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeGoogleChronicle$outboundSchema: z.ZodType<
  ModeGoogleChronicle,
  z.ZodTypeDef,
  ModeGoogleChronicle
> = z.union([
  z.nativeEnum(ModeGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionGoogleChronicle$inboundSchema: z.ZodType<
  CompressionGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionGoogleChronicle$outboundSchema: z.ZodType<
  CompressionGoogleChronicle,
  z.ZodTypeDef,
  CompressionGoogleChronicle
> = z.union([
  z.nativeEnum(CompressionGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorGoogleChronicle$inboundSchema: z.ZodType<
  QueueFullBehaviorGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorGoogleChronicle),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorGoogleChronicle$outboundSchema: z.ZodType<
  QueueFullBehaviorGoogleChronicle,
  z.ZodTypeDef,
  QueueFullBehaviorGoogleChronicle
> = z.union([
  z.nativeEnum(QueueFullBehaviorGoogleChronicle),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsGoogleChronicle$inboundSchema: z.ZodType<
  PqControlsGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsGoogleChronicle$Outbound = {};

/** @internal */
export const PqControlsGoogleChronicle$outboundSchema: z.ZodType<
  PqControlsGoogleChronicle$Outbound,
  z.ZodTypeDef,
  PqControlsGoogleChronicle
> = z.object({});

export function pqControlsGoogleChronicleToJSON(
  pqControlsGoogleChronicle: PqControlsGoogleChronicle,
): string {
  return JSON.stringify(
    PqControlsGoogleChronicle$outboundSchema.parse(pqControlsGoogleChronicle),
  );
}
export function pqControlsGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const OutputGoogleChronicle$inboundSchema: z.ZodType<
  OutputGoogleChronicle,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeGoogleChronicle$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    apiVersion: OutputAPIVersion$inboundSchema.default("v1"),
    authenticationMethod: AuthenticationMethodGoogleChronicle$inboundSchema
      .default("serviceAccount"),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingGoogleChronicle$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsGoogleChronicle$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    logFormatType: SendEventsAs$inboundSchema.default("unstructured"),
    region: z.string().optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(90),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderGoogleChronicle$inboundSchema),
    ).optional(),
    failedRequestLoggingMode:
      FailedRequestLoggingModeGoogleChronicle$inboundSchema.default("none"),
    safeHeaders: z.array(z.string()).optional(),
    useRoundRobinDns: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorGoogleChronicle$inboundSchema.default(
      "block",
    ),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    extraLogTypes: z.array(z.lazy(() => ExtraLogType$inboundSchema)).optional(),
    logType: z.string().optional(),
    logTextField: z.string().optional(),
    customerId: z.string().optional(),
    namespace: z.string().optional(),
    customLabels: z.array(
      z.lazy(() => CustomLabelGoogleChronicle$inboundSchema),
    ).optional(),
    udmType: UDMType$inboundSchema.default("logs"),
    apiKey: z.string().optional(),
    apiKeySecret: z.string().optional(),
    serviceAccountCredentials: z.string().optional(),
    serviceAccountCredentialsSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeGoogleChronicle$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionGoogleChronicle$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorGoogleChronicle$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsGoogleChronicle$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputGoogleChronicle$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  apiVersion: string;
  authenticationMethod: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingGoogleChronicle$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | TimeoutRetrySettingsGoogleChronicle$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  logFormatType: string;
  region?: string | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderGoogleChronicle$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  useRoundRobinDns: boolean;
  onBackpressure: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  extraLogTypes?: Array<ExtraLogType$Outbound> | undefined;
  logType?: string | undefined;
  logTextField?: string | undefined;
  customerId?: string | undefined;
  namespace?: string | undefined;
  customLabels?: Array<CustomLabelGoogleChronicle$Outbound> | undefined;
  udmType: string;
  apiKey?: string | undefined;
  apiKeySecret?: string | undefined;
  serviceAccountCredentials?: string | undefined;
  serviceAccountCredentialsSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsGoogleChronicle$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputGoogleChronicle$outboundSchema: z.ZodType<
  OutputGoogleChronicle$Outbound,
  z.ZodTypeDef,
  OutputGoogleChronicle
> = z.object({
  id: z.string().optional(),
  type: TypeGoogleChronicle$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  apiVersion: OutputAPIVersion$outboundSchema.default("v1"),
  authenticationMethod: AuthenticationMethodGoogleChronicle$outboundSchema
    .default("serviceAccount"),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingGoogleChronicle$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsGoogleChronicle$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  logFormatType: SendEventsAs$outboundSchema.default("unstructured"),
  region: z.string().optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(90),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderGoogleChronicle$outboundSchema),
  ).optional(),
  failedRequestLoggingMode:
    FailedRequestLoggingModeGoogleChronicle$outboundSchema.default("none"),
  safeHeaders: z.array(z.string()).optional(),
  useRoundRobinDns: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorGoogleChronicle$outboundSchema.default(
    "block",
  ),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  extraLogTypes: z.array(z.lazy(() => ExtraLogType$outboundSchema)).optional(),
  logType: z.string().optional(),
  logTextField: z.string().optional(),
  customerId: z.string().optional(),
  namespace: z.string().optional(),
  customLabels: z.array(z.lazy(() => CustomLabelGoogleChronicle$outboundSchema))
    .optional(),
  udmType: UDMType$outboundSchema.default("logs"),
  apiKey: z.string().optional(),
  apiKeySecret: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  serviceAccountCredentialsSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeGoogleChronicle$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionGoogleChronicle$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorGoogleChronicle$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsGoogleChronicle$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputGoogleChronicleToJSON(
  outputGoogleChronicle: OutputGoogleChronicle,
): string {
  return JSON.stringify(
    OutputGoogleChronicle$outboundSchema.parse(outputGoogleChronicle),
  );
}
export function outputGoogleChronicleFromJSON(
  jsonString: string,
): SafeParseResult<OutputGoogleChronicle, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGoogleChronicle$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGoogleChronicle' from JSON`,
  );
}

/** @internal */
export const TypeAzureEventhub$inboundSchema: z.ZodNativeEnum<
  typeof TypeAzureEventhub
> = z.nativeEnum(TypeAzureEventhub);
/** @internal */
export const TypeAzureEventhub$outboundSchema: z.ZodNativeEnum<
  typeof TypeAzureEventhub
> = TypeAzureEventhub$inboundSchema;

/** @internal */
export const AcknowledgmentsAzureEventhub$inboundSchema: z.ZodType<
  AcknowledgmentsAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AcknowledgmentsAzureEventhub),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AcknowledgmentsAzureEventhub$outboundSchema: z.ZodType<
  AcknowledgmentsAzureEventhub,
  z.ZodTypeDef,
  AcknowledgmentsAzureEventhub
> = z.union([
  z.nativeEnum(AcknowledgmentsAzureEventhub),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const RecordDataFormatAzureEventhub$inboundSchema: z.ZodType<
  RecordDataFormatAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordDataFormatAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordDataFormatAzureEventhub$outboundSchema: z.ZodType<
  RecordDataFormatAzureEventhub,
  z.ZodTypeDef,
  RecordDataFormatAzureEventhub
> = z.union([
  z.nativeEnum(RecordDataFormatAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthTypeAuthenticationMethodAzureEventhub$inboundSchema: z.ZodType<
  AuthTypeAuthenticationMethodAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthTypeAuthenticationMethodAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthTypeAuthenticationMethodAzureEventhub$outboundSchema:
  z.ZodType<
    AuthTypeAuthenticationMethodAzureEventhub,
    z.ZodTypeDef,
    AuthTypeAuthenticationMethodAzureEventhub
  > = z.union([
    z.nativeEnum(AuthTypeAuthenticationMethodAzureEventhub),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const SASLMechanismAzureEventhub$inboundSchema: z.ZodType<
  SASLMechanismAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SASLMechanismAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SASLMechanismAzureEventhub$outboundSchema: z.ZodType<
  SASLMechanismAzureEventhub,
  z.ZodTypeDef,
  SASLMechanismAzureEventhub
> = z.union([
  z.nativeEnum(SASLMechanismAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ClientSecretAuthTypeAuthenticationMethodAzureEventhub$inboundSchema:
  z.ZodType<
    ClientSecretAuthTypeAuthenticationMethodAzureEventhub,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(ClientSecretAuthTypeAuthenticationMethodAzureEventhub),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ClientSecretAuthTypeAuthenticationMethodAzureEventhub$outboundSchema:
  z.ZodType<
    ClientSecretAuthTypeAuthenticationMethodAzureEventhub,
    z.ZodTypeDef,
    ClientSecretAuthTypeAuthenticationMethodAzureEventhub
  > = z.union([
    z.nativeEnum(ClientSecretAuthTypeAuthenticationMethodAzureEventhub),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointAzureEventhub$inboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointAzureEventhub,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointAzureEventhub),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointAzureEventhub$outboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointAzureEventhub,
    z.ZodTypeDef,
    MicrosoftEntraIDAuthenticationEndpointAzureEventhub
  > = z.union([
    z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointAzureEventhub),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const AuthenticationAzureEventhub$inboundSchema: z.ZodType<
  AuthenticationAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  authType: AuthTypeAuthenticationMethodAzureEventhub$inboundSchema.default(
    "manual",
  ),
  password: z.string().optional(),
  textSecret: z.string().optional(),
  mechanism: SASLMechanismAzureEventhub$inboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  clientSecretAuthType:
    ClientSecretAuthTypeAuthenticationMethodAzureEventhub$inboundSchema.default(
      "manual",
    ),
  clientSecret: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint:
    MicrosoftEntraIDAuthenticationEndpointAzureEventhub$inboundSchema.default(
      "https://login.microsoftonline.com",
    ),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});
/** @internal */
export type AuthenticationAzureEventhub$Outbound = {
  disabled: boolean;
  authType: string;
  password?: string | undefined;
  textSecret?: string | undefined;
  mechanism: string;
  username: string;
  clientSecretAuthType: string;
  clientSecret?: string | undefined;
  clientTextSecret?: string | undefined;
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  oauthEndpoint: string;
  clientId?: string | undefined;
  tenantId?: string | undefined;
  scope?: string | undefined;
};

/** @internal */
export const AuthenticationAzureEventhub$outboundSchema: z.ZodType<
  AuthenticationAzureEventhub$Outbound,
  z.ZodTypeDef,
  AuthenticationAzureEventhub
> = z.object({
  disabled: z.boolean().default(false),
  authType: AuthTypeAuthenticationMethodAzureEventhub$outboundSchema.default(
    "manual",
  ),
  password: z.string().optional(),
  textSecret: z.string().optional(),
  mechanism: SASLMechanismAzureEventhub$outboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  clientSecretAuthType:
    ClientSecretAuthTypeAuthenticationMethodAzureEventhub$outboundSchema
      .default("manual"),
  clientSecret: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint:
    MicrosoftEntraIDAuthenticationEndpointAzureEventhub$outboundSchema.default(
      "https://login.microsoftonline.com",
    ),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});

export function authenticationAzureEventhubToJSON(
  authenticationAzureEventhub: AuthenticationAzureEventhub,
): string {
  return JSON.stringify(
    AuthenticationAzureEventhub$outboundSchema.parse(
      authenticationAzureEventhub,
    ),
  );
}
export function authenticationAzureEventhubFromJSON(
  jsonString: string,
): SafeParseResult<AuthenticationAzureEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthenticationAzureEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthenticationAzureEventhub' from JSON`,
  );
}

/** @internal */
export const TLSSettingsClientSideAzureEventhub$inboundSchema: z.ZodType<
  TLSSettingsClientSideAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});
/** @internal */
export type TLSSettingsClientSideAzureEventhub$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
};

/** @internal */
export const TLSSettingsClientSideAzureEventhub$outboundSchema: z.ZodType<
  TLSSettingsClientSideAzureEventhub$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideAzureEventhub
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});

export function tlsSettingsClientSideAzureEventhubToJSON(
  tlsSettingsClientSideAzureEventhub: TLSSettingsClientSideAzureEventhub,
): string {
  return JSON.stringify(
    TLSSettingsClientSideAzureEventhub$outboundSchema.parse(
      tlsSettingsClientSideAzureEventhub,
    ),
  );
}
export function tlsSettingsClientSideAzureEventhubFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideAzureEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsClientSideAzureEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideAzureEventhub' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorAzureEventhub$inboundSchema: z.ZodType<
  BackpressureBehaviorAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorAzureEventhub$outboundSchema: z.ZodType<
  BackpressureBehaviorAzureEventhub,
  z.ZodTypeDef,
  BackpressureBehaviorAzureEventhub
> = z.union([
  z.nativeEnum(BackpressureBehaviorAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeAzureEventhub$inboundSchema: z.ZodType<
  ModeAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeAzureEventhub$outboundSchema: z.ZodType<
  ModeAzureEventhub,
  z.ZodTypeDef,
  ModeAzureEventhub
> = z.union([
  z.nativeEnum(ModeAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionAzureEventhub$inboundSchema: z.ZodType<
  CompressionAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionAzureEventhub$outboundSchema: z.ZodType<
  CompressionAzureEventhub,
  z.ZodTypeDef,
  CompressionAzureEventhub
> = z.union([
  z.nativeEnum(CompressionAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorAzureEventhub$inboundSchema: z.ZodType<
  QueueFullBehaviorAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorAzureEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorAzureEventhub$outboundSchema: z.ZodType<
  QueueFullBehaviorAzureEventhub,
  z.ZodTypeDef,
  QueueFullBehaviorAzureEventhub
> = z.union([
  z.nativeEnum(QueueFullBehaviorAzureEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsAzureEventhub$inboundSchema: z.ZodType<
  PqControlsAzureEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsAzureEventhub$Outbound = {};

/** @internal */
export const PqControlsAzureEventhub$outboundSchema: z.ZodType<
  PqControlsAzureEventhub$Outbound,
  z.ZodTypeDef,
  PqControlsAzureEventhub
> = z.object({});

export function pqControlsAzureEventhubToJSON(
  pqControlsAzureEventhub: PqControlsAzureEventhub,
): string {
  return JSON.stringify(
    PqControlsAzureEventhub$outboundSchema.parse(pqControlsAzureEventhub),
  );
}
export function pqControlsAzureEventhubFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsAzureEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsAzureEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsAzureEventhub' from JSON`,
  );
}

/** @internal */
export const OutputAzureEventhub$inboundSchema: z.ZodType<
  OutputAzureEventhub,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeAzureEventhub$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    brokers: z.array(z.string()),
    topic: z.string(),
    ack: AcknowledgmentsAzureEventhub$inboundSchema.default(1),
    format: RecordDataFormatAzureEventhub$inboundSchema.default("json"),
    maxRecordSizeKB: z.number().default(768),
    flushEventCount: z.number().default(1000),
    flushPeriodSec: z.number().default(1),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => AuthenticationAzureEventhub$inboundSchema).optional(),
    tls: z.lazy(() => TLSSettingsClientSideAzureEventhub$inboundSchema)
      .optional(),
    onBackpressure: BackpressureBehaviorAzureEventhub$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeAzureEventhub$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionAzureEventhub$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorAzureEventhub$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsAzureEventhub$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputAzureEventhub$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  brokers: Array<string>;
  topic: string;
  ack: number;
  format: string;
  maxRecordSizeKB: number;
  flushEventCount: number;
  flushPeriodSec: number;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: AuthenticationAzureEventhub$Outbound | undefined;
  tls?: TLSSettingsClientSideAzureEventhub$Outbound | undefined;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsAzureEventhub$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputAzureEventhub$outboundSchema: z.ZodType<
  OutputAzureEventhub$Outbound,
  z.ZodTypeDef,
  OutputAzureEventhub
> = z.object({
  id: z.string().optional(),
  type: TypeAzureEventhub$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  brokers: z.array(z.string()),
  topic: z.string(),
  ack: AcknowledgmentsAzureEventhub$outboundSchema.default(1),
  format: RecordDataFormatAzureEventhub$outboundSchema.default("json"),
  maxRecordSizeKB: z.number().default(768),
  flushEventCount: z.number().default(1000),
  flushPeriodSec: z.number().default(1),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => AuthenticationAzureEventhub$outboundSchema).optional(),
  tls: z.lazy(() => TLSSettingsClientSideAzureEventhub$outboundSchema)
    .optional(),
  onBackpressure: BackpressureBehaviorAzureEventhub$outboundSchema.default(
    "block",
  ),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeAzureEventhub$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionAzureEventhub$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorAzureEventhub$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsAzureEventhub$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputAzureEventhubToJSON(
  outputAzureEventhub: OutputAzureEventhub,
): string {
  return JSON.stringify(
    OutputAzureEventhub$outboundSchema.parse(outputAzureEventhub),
  );
}
export function outputAzureEventhubFromJSON(
  jsonString: string,
): SafeParseResult<OutputAzureEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAzureEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAzureEventhub' from JSON`,
  );
}

/** @internal */
export const TypeHoneycomb$inboundSchema: z.ZodNativeEnum<
  typeof TypeHoneycomb
> = z.nativeEnum(TypeHoneycomb);
/** @internal */
export const TypeHoneycomb$outboundSchema: z.ZodNativeEnum<
  typeof TypeHoneycomb
> = TypeHoneycomb$inboundSchema;

/** @internal */
export const ExtraHttpHeaderHoneycomb$inboundSchema: z.ZodType<
  ExtraHttpHeaderHoneycomb,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderHoneycomb$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderHoneycomb$outboundSchema: z.ZodType<
  ExtraHttpHeaderHoneycomb$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderHoneycomb
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderHoneycombToJSON(
  extraHttpHeaderHoneycomb: ExtraHttpHeaderHoneycomb,
): string {
  return JSON.stringify(
    ExtraHttpHeaderHoneycomb$outboundSchema.parse(extraHttpHeaderHoneycomb),
  );
}
export function extraHttpHeaderHoneycombFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderHoneycomb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderHoneycomb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderHoneycomb' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeHoneycomb$inboundSchema: z.ZodType<
  FailedRequestLoggingModeHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeHoneycomb$outboundSchema: z.ZodType<
  FailedRequestLoggingModeHoneycomb,
  z.ZodTypeDef,
  FailedRequestLoggingModeHoneycomb
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingHoneycomb$inboundSchema: z.ZodType<
  ResponseRetrySettingHoneycomb,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingHoneycomb$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingHoneycomb$outboundSchema: z.ZodType<
  ResponseRetrySettingHoneycomb$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingHoneycomb
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingHoneycombToJSON(
  responseRetrySettingHoneycomb: ResponseRetrySettingHoneycomb,
): string {
  return JSON.stringify(
    ResponseRetrySettingHoneycomb$outboundSchema.parse(
      responseRetrySettingHoneycomb,
    ),
  );
}
export function responseRetrySettingHoneycombFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingHoneycomb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingHoneycomb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingHoneycomb' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsHoneycomb$inboundSchema: z.ZodType<
  TimeoutRetrySettingsHoneycomb,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsHoneycomb$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsHoneycomb$outboundSchema: z.ZodType<
  TimeoutRetrySettingsHoneycomb$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsHoneycomb
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsHoneycombToJSON(
  timeoutRetrySettingsHoneycomb: TimeoutRetrySettingsHoneycomb,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsHoneycomb$outboundSchema.parse(
      timeoutRetrySettingsHoneycomb,
    ),
  );
}
export function timeoutRetrySettingsHoneycombFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsHoneycomb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsHoneycomb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsHoneycomb' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorHoneycomb$inboundSchema: z.ZodType<
  BackpressureBehaviorHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorHoneycomb$outboundSchema: z.ZodType<
  BackpressureBehaviorHoneycomb,
  z.ZodTypeDef,
  BackpressureBehaviorHoneycomb
> = z.union([
  z.nativeEnum(BackpressureBehaviorHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodHoneycomb$inboundSchema: z.ZodType<
  AuthenticationMethodHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodHoneycomb$outboundSchema: z.ZodType<
  AuthenticationMethodHoneycomb,
  z.ZodTypeDef,
  AuthenticationMethodHoneycomb
> = z.union([
  z.nativeEnum(AuthenticationMethodHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeHoneycomb$inboundSchema: z.ZodType<
  ModeHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeHoneycomb$outboundSchema: z.ZodType<
  ModeHoneycomb,
  z.ZodTypeDef,
  ModeHoneycomb
> = z.union([
  z.nativeEnum(ModeHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionHoneycomb$inboundSchema: z.ZodType<
  CompressionHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionHoneycomb$outboundSchema: z.ZodType<
  CompressionHoneycomb,
  z.ZodTypeDef,
  CompressionHoneycomb
> = z.union([
  z.nativeEnum(CompressionHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorHoneycomb$inboundSchema: z.ZodType<
  QueueFullBehaviorHoneycomb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorHoneycomb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorHoneycomb$outboundSchema: z.ZodType<
  QueueFullBehaviorHoneycomb,
  z.ZodTypeDef,
  QueueFullBehaviorHoneycomb
> = z.union([
  z.nativeEnum(QueueFullBehaviorHoneycomb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsHoneycomb$inboundSchema: z.ZodType<
  PqControlsHoneycomb,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsHoneycomb$Outbound = {};

/** @internal */
export const PqControlsHoneycomb$outboundSchema: z.ZodType<
  PqControlsHoneycomb$Outbound,
  z.ZodTypeDef,
  PqControlsHoneycomb
> = z.object({});

export function pqControlsHoneycombToJSON(
  pqControlsHoneycomb: PqControlsHoneycomb,
): string {
  return JSON.stringify(
    PqControlsHoneycomb$outboundSchema.parse(pqControlsHoneycomb),
  );
}
export function pqControlsHoneycombFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsHoneycomb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsHoneycomb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsHoneycomb' from JSON`,
  );
}

/** @internal */
export const OutputHoneycomb$inboundSchema: z.ZodType<
  OutputHoneycomb,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeHoneycomb$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    dataset: z.string(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderHoneycomb$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeHoneycomb$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingHoneycomb$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsHoneycomb$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorHoneycomb$inboundSchema.default(
      "block",
    ),
    authType: AuthenticationMethodHoneycomb$inboundSchema.default("manual"),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeHoneycomb$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionHoneycomb$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorHoneycomb$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsHoneycomb$inboundSchema).optional(),
    team: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputHoneycomb$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  dataset: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderHoneycomb$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingHoneycomb$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsHoneycomb$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsHoneycomb$Outbound | undefined;
  team?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputHoneycomb$outboundSchema: z.ZodType<
  OutputHoneycomb$Outbound,
  z.ZodTypeDef,
  OutputHoneycomb
> = z.object({
  id: z.string().optional(),
  type: TypeHoneycomb$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  dataset: z.string(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderHoneycomb$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeHoneycomb$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingHoneycomb$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsHoneycomb$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorHoneycomb$outboundSchema.default("block"),
  authType: AuthenticationMethodHoneycomb$outboundSchema.default("manual"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeHoneycomb$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionHoneycomb$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorHoneycomb$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsHoneycomb$outboundSchema).optional(),
  team: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputHoneycombToJSON(
  outputHoneycomb: OutputHoneycomb,
): string {
  return JSON.stringify(OutputHoneycomb$outboundSchema.parse(outputHoneycomb));
}
export function outputHoneycombFromJSON(
  jsonString: string,
): SafeParseResult<OutputHoneycomb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputHoneycomb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputHoneycomb' from JSON`,
  );
}

/** @internal */
export const OutputTypeKinesis$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeKinesis
> = z.nativeEnum(OutputTypeKinesis);
/** @internal */
export const OutputTypeKinesis$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeKinesis
> = OutputTypeKinesis$inboundSchema;

/** @internal */
export const OutputAuthenticationMethodKinesis$inboundSchema: z.ZodType<
  OutputAuthenticationMethodKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodKinesis$outboundSchema: z.ZodType<
  OutputAuthenticationMethodKinesis,
  z.ZodTypeDef,
  OutputAuthenticationMethodKinesis
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSignatureVersionKinesis$inboundSchema: z.ZodType<
  OutputSignatureVersionKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSignatureVersionKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSignatureVersionKinesis$outboundSchema: z.ZodType<
  OutputSignatureVersionKinesis,
  z.ZodTypeDef,
  OutputSignatureVersionKinesis
> = z.union([
  z.nativeEnum(OutputSignatureVersionKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionKinesis$inboundSchema: z.ZodType<
  OutputCompressionKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionKinesis$outboundSchema: z.ZodType<
  OutputCompressionKinesis,
  z.ZodTypeDef,
  OutputCompressionKinesis
> = z.union([
  z.nativeEnum(OutputCompressionKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorKinesis$inboundSchema: z.ZodType<
  BackpressureBehaviorKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorKinesis$outboundSchema: z.ZodType<
  BackpressureBehaviorKinesis,
  z.ZodTypeDef,
  BackpressureBehaviorKinesis
> = z.union([
  z.nativeEnum(BackpressureBehaviorKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeKinesis$inboundSchema: z.ZodType<
  OutputModeKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeKinesis$outboundSchema: z.ZodType<
  OutputModeKinesis,
  z.ZodTypeDef,
  OutputModeKinesis
> = z.union([
  z.nativeEnum(OutputModeKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionKinesis$inboundSchema: z.ZodType<
  PqCompressCompressionKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionKinesis$outboundSchema: z.ZodType<
  PqCompressCompressionKinesis,
  z.ZodTypeDef,
  PqCompressCompressionKinesis
> = z.union([
  z.nativeEnum(PqCompressCompressionKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorKinesis$inboundSchema: z.ZodType<
  QueueFullBehaviorKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorKinesis$outboundSchema: z.ZodType<
  QueueFullBehaviorKinesis,
  z.ZodTypeDef,
  QueueFullBehaviorKinesis
> = z.union([
  z.nativeEnum(QueueFullBehaviorKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsKinesis$inboundSchema: z.ZodType<
  OutputPqControlsKinesis,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsKinesis$Outbound = {};

/** @internal */
export const OutputPqControlsKinesis$outboundSchema: z.ZodType<
  OutputPqControlsKinesis$Outbound,
  z.ZodTypeDef,
  OutputPqControlsKinesis
> = z.object({});

export function outputPqControlsKinesisToJSON(
  outputPqControlsKinesis: OutputPqControlsKinesis,
): string {
  return JSON.stringify(
    OutputPqControlsKinesis$outboundSchema.parse(outputPqControlsKinesis),
  );
}
export function outputPqControlsKinesisFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsKinesis' from JSON`,
  );
}

/** @internal */
export const OutputKinesis$inboundSchema: z.ZodType<
  OutputKinesis,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeKinesis$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    streamName: z.string(),
    awsAuthenticationMethod: OutputAuthenticationMethodKinesis$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string(),
    endpoint: z.string().optional(),
    signatureVersion: OutputSignatureVersionKinesis$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    concurrency: z.number().default(5),
    maxRecordSizeKB: z.number().default(1024),
    flushPeriodSec: z.number().default(1),
    compression: OutputCompressionKinesis$inboundSchema.default("gzip"),
    useListShards: z.boolean().default(false),
    asNdjson: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorKinesis$inboundSchema.default("block"),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    maxEventsPerFlush: z.number().default(500),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeKinesis$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionKinesis$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorKinesis$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsKinesis$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputKinesis$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  streamName: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  concurrency: number;
  maxRecordSizeKB: number;
  flushPeriodSec: number;
  compression: string;
  useListShards: boolean;
  asNdjson: boolean;
  onBackpressure: string;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  maxEventsPerFlush: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsKinesis$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputKinesis$outboundSchema: z.ZodType<
  OutputKinesis$Outbound,
  z.ZodTypeDef,
  OutputKinesis
> = z.object({
  id: z.string().optional(),
  type: OutputTypeKinesis$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  streamName: z.string(),
  awsAuthenticationMethod: OutputAuthenticationMethodKinesis$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string(),
  endpoint: z.string().optional(),
  signatureVersion: OutputSignatureVersionKinesis$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  concurrency: z.number().default(5),
  maxRecordSizeKB: z.number().default(1024),
  flushPeriodSec: z.number().default(1),
  compression: OutputCompressionKinesis$outboundSchema.default("gzip"),
  useListShards: z.boolean().default(false),
  asNdjson: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorKinesis$outboundSchema.default("block"),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  maxEventsPerFlush: z.number().default(500),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeKinesis$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionKinesis$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorKinesis$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsKinesis$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputKinesisToJSON(outputKinesis: OutputKinesis): string {
  return JSON.stringify(OutputKinesis$outboundSchema.parse(outputKinesis));
}
export function outputKinesisFromJSON(
  jsonString: string,
): SafeParseResult<OutputKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputKinesis' from JSON`,
  );
}

/** @internal */
export const TypeAzureLogs$inboundSchema: z.ZodNativeEnum<
  typeof TypeAzureLogs
> = z.nativeEnum(TypeAzureLogs);
/** @internal */
export const TypeAzureLogs$outboundSchema: z.ZodNativeEnum<
  typeof TypeAzureLogs
> = TypeAzureLogs$inboundSchema;

/** @internal */
export const ExtraHttpHeaderAzureLogs$inboundSchema: z.ZodType<
  ExtraHttpHeaderAzureLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderAzureLogs$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderAzureLogs$outboundSchema: z.ZodType<
  ExtraHttpHeaderAzureLogs$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderAzureLogs
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderAzureLogsToJSON(
  extraHttpHeaderAzureLogs: ExtraHttpHeaderAzureLogs,
): string {
  return JSON.stringify(
    ExtraHttpHeaderAzureLogs$outboundSchema.parse(extraHttpHeaderAzureLogs),
  );
}
export function extraHttpHeaderAzureLogsFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderAzureLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderAzureLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderAzureLogs' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeAzureLogs$inboundSchema: z.ZodType<
  FailedRequestLoggingModeAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeAzureLogs$outboundSchema: z.ZodType<
  FailedRequestLoggingModeAzureLogs,
  z.ZodTypeDef,
  FailedRequestLoggingModeAzureLogs
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingAzureLogs$inboundSchema: z.ZodType<
  ResponseRetrySettingAzureLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingAzureLogs$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingAzureLogs$outboundSchema: z.ZodType<
  ResponseRetrySettingAzureLogs$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingAzureLogs
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingAzureLogsToJSON(
  responseRetrySettingAzureLogs: ResponseRetrySettingAzureLogs,
): string {
  return JSON.stringify(
    ResponseRetrySettingAzureLogs$outboundSchema.parse(
      responseRetrySettingAzureLogs,
    ),
  );
}
export function responseRetrySettingAzureLogsFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingAzureLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingAzureLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingAzureLogs' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsAzureLogs$inboundSchema: z.ZodType<
  TimeoutRetrySettingsAzureLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsAzureLogs$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsAzureLogs$outboundSchema: z.ZodType<
  TimeoutRetrySettingsAzureLogs$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsAzureLogs
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsAzureLogsToJSON(
  timeoutRetrySettingsAzureLogs: TimeoutRetrySettingsAzureLogs,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsAzureLogs$outboundSchema.parse(
      timeoutRetrySettingsAzureLogs,
    ),
  );
}
export function timeoutRetrySettingsAzureLogsFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsAzureLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsAzureLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsAzureLogs' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorAzureLogs$inboundSchema: z.ZodType<
  BackpressureBehaviorAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorAzureLogs$outboundSchema: z.ZodType<
  BackpressureBehaviorAzureLogs,
  z.ZodTypeDef,
  BackpressureBehaviorAzureLogs
> = z.union([
  z.nativeEnum(BackpressureBehaviorAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodAzureLogs$inboundSchema: z.ZodType<
  AuthenticationMethodAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodAzureLogs$outboundSchema: z.ZodType<
  AuthenticationMethodAzureLogs,
  z.ZodTypeDef,
  AuthenticationMethodAzureLogs
> = z.union([
  z.nativeEnum(AuthenticationMethodAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeAzureLogs$inboundSchema: z.ZodType<
  ModeAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeAzureLogs$outboundSchema: z.ZodType<
  ModeAzureLogs,
  z.ZodTypeDef,
  ModeAzureLogs
> = z.union([
  z.nativeEnum(ModeAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionAzureLogs$inboundSchema: z.ZodType<
  CompressionAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionAzureLogs$outboundSchema: z.ZodType<
  CompressionAzureLogs,
  z.ZodTypeDef,
  CompressionAzureLogs
> = z.union([
  z.nativeEnum(CompressionAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorAzureLogs$inboundSchema: z.ZodType<
  QueueFullBehaviorAzureLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorAzureLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorAzureLogs$outboundSchema: z.ZodType<
  QueueFullBehaviorAzureLogs,
  z.ZodTypeDef,
  QueueFullBehaviorAzureLogs
> = z.union([
  z.nativeEnum(QueueFullBehaviorAzureLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsAzureLogs$inboundSchema: z.ZodType<
  PqControlsAzureLogs,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsAzureLogs$Outbound = {};

/** @internal */
export const PqControlsAzureLogs$outboundSchema: z.ZodType<
  PqControlsAzureLogs$Outbound,
  z.ZodTypeDef,
  PqControlsAzureLogs
> = z.object({});

export function pqControlsAzureLogsToJSON(
  pqControlsAzureLogs: PqControlsAzureLogs,
): string {
  return JSON.stringify(
    PqControlsAzureLogs$outboundSchema.parse(pqControlsAzureLogs),
  );
}
export function pqControlsAzureLogsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsAzureLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsAzureLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsAzureLogs' from JSON`,
  );
}

/** @internal */
export const OutputAzureLogs$inboundSchema: z.ZodType<
  OutputAzureLogs,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeAzureLogs$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    logType: z.string().default("Cribl"),
    resourceId: z.string().optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1024),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().optional(),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderAzureLogs$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeAzureLogs$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    apiUrl: z.string().default(".ods.opinsights.azure.com"),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingAzureLogs$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsAzureLogs$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorAzureLogs$inboundSchema.default(
      "block",
    ),
    authType: AuthenticationMethodAzureLogs$inboundSchema.default("manual"),
    description: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeAzureLogs$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionAzureLogs$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorAzureLogs$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsAzureLogs$inboundSchema).optional(),
    workspaceId: z.string().optional(),
    workspaceKey: z.string().optional(),
    keypairSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputAzureLogs$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  logType: string;
  resourceId?: string | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress?: boolean | undefined;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderAzureLogs$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  apiUrl: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingAzureLogs$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsAzureLogs$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsAzureLogs$Outbound | undefined;
  workspaceId?: string | undefined;
  workspaceKey?: string | undefined;
  keypairSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputAzureLogs$outboundSchema: z.ZodType<
  OutputAzureLogs$Outbound,
  z.ZodTypeDef,
  OutputAzureLogs
> = z.object({
  id: z.string().optional(),
  type: TypeAzureLogs$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  logType: z.string().default("Cribl"),
  resourceId: z.string().optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1024),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderAzureLogs$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeAzureLogs$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  apiUrl: z.string().default(".ods.opinsights.azure.com"),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingAzureLogs$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsAzureLogs$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorAzureLogs$outboundSchema.default("block"),
  authType: AuthenticationMethodAzureLogs$outboundSchema.default("manual"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeAzureLogs$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionAzureLogs$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorAzureLogs$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsAzureLogs$outboundSchema).optional(),
  workspaceId: z.string().optional(),
  workspaceKey: z.string().optional(),
  keypairSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputAzureLogsToJSON(
  outputAzureLogs: OutputAzureLogs,
): string {
  return JSON.stringify(OutputAzureLogs$outboundSchema.parse(outputAzureLogs));
}
export function outputAzureLogsFromJSON(
  jsonString: string,
): SafeParseResult<OutputAzureLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAzureLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAzureLogs' from JSON`,
  );
}

/** @internal */
export const TypeAzureDataExplorer$inboundSchema: z.ZodNativeEnum<
  typeof TypeAzureDataExplorer
> = z.nativeEnum(TypeAzureDataExplorer);
/** @internal */
export const TypeAzureDataExplorer$outboundSchema: z.ZodNativeEnum<
  typeof TypeAzureDataExplorer
> = TypeAzureDataExplorer$inboundSchema;

/** @internal */
export const IngestionMode$inboundSchema: z.ZodType<
  IngestionMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(IngestionMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const IngestionMode$outboundSchema: z.ZodType<
  IngestionMode,
  z.ZodTypeDef,
  IngestionMode
> = z.union([
  z.nativeEnum(IngestionMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer$inboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer$outboundSchema:
  z.ZodType<
    MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer,
    z.ZodTypeDef,
    MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer
  > = z.union([
    z.nativeEnum(MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const OauthTypeAuthenticationMethod$inboundSchema: z.ZodType<
  OauthTypeAuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OauthTypeAuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OauthTypeAuthenticationMethod$outboundSchema: z.ZodType<
  OauthTypeAuthenticationMethod,
  z.ZodTypeDef,
  OauthTypeAuthenticationMethod
> = z.union([
  z.nativeEnum(OauthTypeAuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CertificateAzureDataExplorer$inboundSchema: z.ZodType<
  CertificateAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z.object({
  certificateName: z.string().optional(),
});
/** @internal */
export type CertificateAzureDataExplorer$Outbound = {
  certificateName?: string | undefined;
};

/** @internal */
export const CertificateAzureDataExplorer$outboundSchema: z.ZodType<
  CertificateAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  CertificateAzureDataExplorer
> = z.object({
  certificateName: z.string().optional(),
});

export function certificateAzureDataExplorerToJSON(
  certificateAzureDataExplorer: CertificateAzureDataExplorer,
): string {
  return JSON.stringify(
    CertificateAzureDataExplorer$outboundSchema.parse(
      certificateAzureDataExplorer,
    ),
  );
}
export function certificateAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<CertificateAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CertificateAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CertificateAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const DataFormatAzureDataExplorer$inboundSchema: z.ZodType<
  DataFormatAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatAzureDataExplorer$outboundSchema: z.ZodType<
  DataFormatAzureDataExplorer,
  z.ZodTypeDef,
  DataFormatAzureDataExplorer
> = z.union([
  z.nativeEnum(DataFormatAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressCompressionAzureDataExplorer$inboundSchema: z.ZodType<
  CompressCompressionAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressCompressionAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressCompressionAzureDataExplorer$outboundSchema: z.ZodType<
  CompressCompressionAzureDataExplorer,
  z.ZodTypeDef,
  CompressCompressionAzureDataExplorer
> = z.union([
  z.nativeEnum(CompressCompressionAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelAzureDataExplorer$inboundSchema: z.ZodType<
  CompressionLevelAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelAzureDataExplorer$outboundSchema: z.ZodType<
  CompressionLevelAzureDataExplorer,
  z.ZodTypeDef,
  CompressionLevelAzureDataExplorer
> = z.union([
  z.nativeEnum(CompressionLevelAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionAzureDataExplorer$inboundSchema: z.ZodType<
  ParquetVersionAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionAzureDataExplorer$outboundSchema: z.ZodType<
  ParquetVersionAzureDataExplorer,
  z.ZodTypeDef,
  ParquetVersionAzureDataExplorer
> = z.union([
  z.nativeEnum(ParquetVersionAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionAzureDataExplorer$inboundSchema: z.ZodType<
  DataPageVersionAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionAzureDataExplorer$outboundSchema: z.ZodType<
  DataPageVersionAzureDataExplorer,
  z.ZodTypeDef,
  DataPageVersionAzureDataExplorer
> = z.union([
  z.nativeEnum(DataPageVersionAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumAzureDataExplorer$inboundSchema: z.ZodType<
  KeyValueMetadatumAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumAzureDataExplorer$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumAzureDataExplorer$outboundSchema: z.ZodType<
  KeyValueMetadatumAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumAzureDataExplorer
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumAzureDataExplorerToJSON(
  keyValueMetadatumAzureDataExplorer: KeyValueMetadatumAzureDataExplorer,
): string {
  return JSON.stringify(
    KeyValueMetadatumAzureDataExplorer$outboundSchema.parse(
      keyValueMetadatumAzureDataExplorer,
    ),
  );
}
export function keyValueMetadatumAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      KeyValueMetadatumAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorAzureDataExplorer$inboundSchema: z.ZodType<
  BackpressureBehaviorAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorAzureDataExplorer$outboundSchema: z.ZodType<
  BackpressureBehaviorAzureDataExplorer,
  z.ZodTypeDef,
  BackpressureBehaviorAzureDataExplorer
> = z.union([
  z.nativeEnum(BackpressureBehaviorAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionAzureDataExplorer$inboundSchema: z.ZodType<
  DiskSpaceProtectionAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionAzureDataExplorer$outboundSchema: z.ZodType<
  DiskSpaceProtectionAzureDataExplorer,
  z.ZodTypeDef,
  DiskSpaceProtectionAzureDataExplorer
> = z.union([
  z.nativeEnum(DiskSpaceProtectionAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PrefixOptional$inboundSchema: z.ZodType<
  PrefixOptional,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PrefixOptional),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PrefixOptional$outboundSchema: z.ZodType<
  PrefixOptional,
  z.ZodTypeDef,
  PrefixOptional
> = z.union([
  z.nativeEnum(PrefixOptional),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtentTag$inboundSchema: z.ZodType<
  ExtentTag,
  z.ZodTypeDef,
  unknown
> = z.object({
  prefix: PrefixOptional$inboundSchema.optional(),
  value: z.string(),
});
/** @internal */
export type ExtentTag$Outbound = {
  prefix?: string | undefined;
  value: string;
};

/** @internal */
export const ExtentTag$outboundSchema: z.ZodType<
  ExtentTag$Outbound,
  z.ZodTypeDef,
  ExtentTag
> = z.object({
  prefix: PrefixOptional$outboundSchema.optional(),
  value: z.string(),
});

export function extentTagToJSON(extentTag: ExtentTag): string {
  return JSON.stringify(ExtentTag$outboundSchema.parse(extentTag));
}
export function extentTagFromJSON(
  jsonString: string,
): SafeParseResult<ExtentTag, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtentTag$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtentTag' from JSON`,
  );
}

/** @internal */
export const IngestIfNotExist$inboundSchema: z.ZodType<
  IngestIfNotExist,
  z.ZodTypeDef,
  unknown
> = z.object({
  value: z.string(),
});
/** @internal */
export type IngestIfNotExist$Outbound = {
  value: string;
};

/** @internal */
export const IngestIfNotExist$outboundSchema: z.ZodType<
  IngestIfNotExist$Outbound,
  z.ZodTypeDef,
  IngestIfNotExist
> = z.object({
  value: z.string(),
});

export function ingestIfNotExistToJSON(
  ingestIfNotExist: IngestIfNotExist,
): string {
  return JSON.stringify(
    IngestIfNotExist$outboundSchema.parse(ingestIfNotExist),
  );
}
export function ingestIfNotExistFromJSON(
  jsonString: string,
): SafeParseResult<IngestIfNotExist, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => IngestIfNotExist$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'IngestIfNotExist' from JSON`,
  );
}

/** @internal */
export const ReportLevel$inboundSchema: z.ZodType<
  ReportLevel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ReportLevel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ReportLevel$outboundSchema: z.ZodType<
  ReportLevel,
  z.ZodTypeDef,
  ReportLevel
> = z.union([
  z.nativeEnum(ReportLevel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ReportMethod$inboundSchema: z.ZodType<
  ReportMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ReportMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ReportMethod$outboundSchema: z.ZodType<
  ReportMethod,
  z.ZodTypeDef,
  ReportMethod
> = z.union([
  z.nativeEnum(ReportMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AdditionalProperty$inboundSchema: z.ZodType<
  AdditionalProperty,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string(),
  value: z.string(),
});
/** @internal */
export type AdditionalProperty$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const AdditionalProperty$outboundSchema: z.ZodType<
  AdditionalProperty$Outbound,
  z.ZodTypeDef,
  AdditionalProperty
> = z.object({
  key: z.string(),
  value: z.string(),
});

export function additionalPropertyToJSON(
  additionalProperty: AdditionalProperty,
): string {
  return JSON.stringify(
    AdditionalProperty$outboundSchema.parse(additionalProperty),
  );
}
export function additionalPropertyFromJSON(
  jsonString: string,
): SafeParseResult<AdditionalProperty, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AdditionalProperty$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AdditionalProperty' from JSON`,
  );
}

/** @internal */
export const ResponseRetrySettingAzureDataExplorer$inboundSchema: z.ZodType<
  ResponseRetrySettingAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingAzureDataExplorer$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingAzureDataExplorer$outboundSchema: z.ZodType<
  ResponseRetrySettingAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingAzureDataExplorer
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingAzureDataExplorerToJSON(
  responseRetrySettingAzureDataExplorer: ResponseRetrySettingAzureDataExplorer,
): string {
  return JSON.stringify(
    ResponseRetrySettingAzureDataExplorer$outboundSchema.parse(
      responseRetrySettingAzureDataExplorer,
    ),
  );
}
export function responseRetrySettingAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      ResponseRetrySettingAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsAzureDataExplorer$inboundSchema: z.ZodType<
  TimeoutRetrySettingsAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsAzureDataExplorer$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsAzureDataExplorer$outboundSchema: z.ZodType<
  TimeoutRetrySettingsAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsAzureDataExplorer
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsAzureDataExplorerToJSON(
  timeoutRetrySettingsAzureDataExplorer: TimeoutRetrySettingsAzureDataExplorer,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsAzureDataExplorer$outboundSchema.parse(
      timeoutRetrySettingsAzureDataExplorer,
    ),
  );
}
export function timeoutRetrySettingsAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TimeoutRetrySettingsAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const ModeAzureDataExplorer$inboundSchema: z.ZodType<
  ModeAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeAzureDataExplorer$outboundSchema: z.ZodType<
  ModeAzureDataExplorer,
  z.ZodTypeDef,
  ModeAzureDataExplorer
> = z.union([
  z.nativeEnum(ModeAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionAzureDataExplorer$inboundSchema: z.ZodType<
  PqCompressCompressionAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionAzureDataExplorer$outboundSchema: z.ZodType<
  PqCompressCompressionAzureDataExplorer,
  z.ZodTypeDef,
  PqCompressCompressionAzureDataExplorer
> = z.union([
  z.nativeEnum(PqCompressCompressionAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorAzureDataExplorer$inboundSchema: z.ZodType<
  QueueFullBehaviorAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorAzureDataExplorer),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorAzureDataExplorer$outboundSchema: z.ZodType<
  QueueFullBehaviorAzureDataExplorer,
  z.ZodTypeDef,
  QueueFullBehaviorAzureDataExplorer
> = z.union([
  z.nativeEnum(QueueFullBehaviorAzureDataExplorer),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsAzureDataExplorer$inboundSchema: z.ZodType<
  PqControlsAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsAzureDataExplorer$Outbound = {};

/** @internal */
export const PqControlsAzureDataExplorer$outboundSchema: z.ZodType<
  PqControlsAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  PqControlsAzureDataExplorer
> = z.object({});

export function pqControlsAzureDataExplorerToJSON(
  pqControlsAzureDataExplorer: PqControlsAzureDataExplorer,
): string {
  return JSON.stringify(
    PqControlsAzureDataExplorer$outboundSchema.parse(
      pqControlsAzureDataExplorer,
    ),
  );
}
export function pqControlsAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const OutputAzureDataExplorer$inboundSchema: z.ZodType<
  OutputAzureDataExplorer,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeAzureDataExplorer$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    clusterUrl: z.string(),
    database: z.string(),
    table: z.string(),
    validateDatabaseSettings: z.boolean().default(true),
    ingestMode: IngestionMode$inboundSchema.default("batching"),
    oauthEndpoint:
      MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer$inboundSchema
        .default("https://login.microsoftonline.com"),
    tenantId: z.string(),
    clientId: z.string(),
    scope: z.string(),
    oauthType: OauthTypeAuthenticationMethod$inboundSchema.default(
      "clientSecret",
    ),
    description: z.string().optional(),
    clientSecret: z.string().optional(),
    textSecret: z.string().optional(),
    certificate: z.lazy(() => CertificateAzureDataExplorer$inboundSchema)
      .optional(),
    format: DataFormatAzureDataExplorer$inboundSchema.default("json"),
    compress: CompressCompressionAzureDataExplorer$inboundSchema.default(
      "gzip",
    ),
    compressionLevel: CompressionLevelAzureDataExplorer$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionAzureDataExplorer$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionAzureDataExplorer$inboundSchema
      .default("DATA_PAGE_V2"),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumAzureDataExplorer$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    removeEmptyDirs: z.boolean().default(true),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterEnabled: z.boolean().default(false),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
    isMappingObj: z.boolean().default(false),
    mappingObj: z.string().optional(),
    mappingRef: z.string().optional(),
    ingestUrl: z.string().optional(),
    onBackpressure: BackpressureBehaviorAzureDataExplorer$inboundSchema.default(
      "block",
    ),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    maxConcurrentFileParts: z.number().default(1),
    onDiskFullBackpressure: DiskSpaceProtectionAzureDataExplorer$inboundSchema
      .default("block"),
    addIdToStagePath: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushImmediately: z.boolean().default(false),
    retainBlobOnSuccess: z.boolean().default(false),
    extentTags: z.array(z.lazy(() => ExtentTag$inboundSchema)).optional(),
    ingestIfNotExists: z.array(z.lazy(() => IngestIfNotExist$inboundSchema))
      .optional(),
    reportLevel: ReportLevel$inboundSchema.default("failuresOnly"),
    reportMethod: ReportMethod$inboundSchema.default("queue"),
    additionalProperties: z.array(
      z.lazy(() => AdditionalProperty$inboundSchema),
    ).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingAzureDataExplorer$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsAzureDataExplorer$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    flushPeriodSec: z.number().default(1),
    rejectUnauthorized: z.boolean().default(true),
    useRoundRobinDns: z.boolean().default(false),
    keepAlive: z.boolean().default(true),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeAzureDataExplorer$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionAzureDataExplorer$inboundSchema.default(
      "none",
    ),
    pqOnBackpressure: QueueFullBehaviorAzureDataExplorer$inboundSchema.default(
      "block",
    ),
    pqControls: z.lazy(() => PqControlsAzureDataExplorer$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties1",
  true,
);
/** @internal */
export type OutputAzureDataExplorer$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  clusterUrl: string;
  database: string;
  table: string;
  validateDatabaseSettings: boolean;
  ingestMode: string;
  oauthEndpoint: string;
  tenantId: string;
  clientId: string;
  scope: string;
  oauthType: string;
  description?: string | undefined;
  clientSecret?: string | undefined;
  textSecret?: string | undefined;
  certificate?: CertificateAzureDataExplorer$Outbound | undefined;
  format: string;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<KeyValueMetadatumAzureDataExplorer$Outbound>
    | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  removeEmptyDirs: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterEnabled: boolean;
  deadletterPath: string;
  maxRetryNum: number;
  isMappingObj: boolean;
  mappingObj?: string | undefined;
  mappingRef?: string | undefined;
  ingestUrl?: string | undefined;
  onBackpressure: string;
  stagePath: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  maxConcurrentFileParts: number;
  onDiskFullBackpressure: string;
  addIdToStagePath: boolean;
  timeoutSec: number;
  flushImmediately: boolean;
  retainBlobOnSuccess: boolean;
  extentTags?: Array<ExtentTag$Outbound> | undefined;
  ingestIfNotExists?: Array<IngestIfNotExist$Outbound> | undefined;
  reportLevel: string;
  reportMethod: string;
  additionalProperties?: Array<AdditionalProperty$Outbound> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingAzureDataExplorer$Outbound>
    | undefined;
  timeoutRetrySettings?:
    | TimeoutRetrySettingsAzureDataExplorer$Outbound
    | undefined;
  responseHonorRetryAfterHeader: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  flushPeriodSec: number;
  rejectUnauthorized: boolean;
  useRoundRobinDns: boolean;
  keepAlive: boolean;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsAzureDataExplorer$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputAzureDataExplorer$outboundSchema: z.ZodType<
  OutputAzureDataExplorer$Outbound,
  z.ZodTypeDef,
  OutputAzureDataExplorer
> = z.object({
  id: z.string().optional(),
  type: TypeAzureDataExplorer$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  clusterUrl: z.string(),
  database: z.string(),
  table: z.string(),
  validateDatabaseSettings: z.boolean().default(true),
  ingestMode: IngestionMode$outboundSchema.default("batching"),
  oauthEndpoint:
    MicrosoftEntraIDAuthenticationEndpointAzureDataExplorer$outboundSchema
      .default("https://login.microsoftonline.com"),
  tenantId: z.string(),
  clientId: z.string(),
  scope: z.string(),
  oauthType: OauthTypeAuthenticationMethod$outboundSchema.default(
    "clientSecret",
  ),
  description: z.string().optional(),
  clientSecret: z.string().optional(),
  textSecret: z.string().optional(),
  certificate: z.lazy(() => CertificateAzureDataExplorer$outboundSchema)
    .optional(),
  format: DataFormatAzureDataExplorer$outboundSchema.default("json"),
  compress: CompressCompressionAzureDataExplorer$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelAzureDataExplorer$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionAzureDataExplorer$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionAzureDataExplorer$outboundSchema
    .default("DATA_PAGE_V2"),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumAzureDataExplorer$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  removeEmptyDirs: z.boolean().default(true),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterEnabled: z.boolean().default(false),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  isMappingObj: z.boolean().default(false),
  mappingObj: z.string().optional(),
  mappingRef: z.string().optional(),
  ingestUrl: z.string().optional(),
  onBackpressure: BackpressureBehaviorAzureDataExplorer$outboundSchema.default(
    "block",
  ),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  maxConcurrentFileParts: z.number().default(1),
  onDiskFullBackpressure: DiskSpaceProtectionAzureDataExplorer$outboundSchema
    .default("block"),
  addIdToStagePath: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushImmediately: z.boolean().default(false),
  retainBlobOnSuccess: z.boolean().default(false),
  extentTags: z.array(z.lazy(() => ExtentTag$outboundSchema)).optional(),
  ingestIfNotExists: z.array(z.lazy(() => IngestIfNotExist$outboundSchema))
    .optional(),
  reportLevel: ReportLevel$outboundSchema.default("failuresOnly"),
  reportMethod: ReportMethod$outboundSchema.default("queue"),
  additionalProperties: z.array(z.lazy(() => AdditionalProperty$outboundSchema))
    .optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingAzureDataExplorer$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsAzureDataExplorer$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  flushPeriodSec: z.number().default(1),
  rejectUnauthorized: z.boolean().default(true),
  useRoundRobinDns: z.boolean().default(false),
  keepAlive: z.boolean().default(true),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeAzureDataExplorer$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionAzureDataExplorer$outboundSchema.default(
    "none",
  ),
  pqOnBackpressure: QueueFullBehaviorAzureDataExplorer$outboundSchema.default(
    "block",
  ),
  pqControls: z.lazy(() => PqControlsAzureDataExplorer$outboundSchema)
    .optional(),
  additionalProperties1: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties1,
    ...remap$(v, {
      additionalProperties1: null,
    }),
  };
});

export function outputAzureDataExplorerToJSON(
  outputAzureDataExplorer: OutputAzureDataExplorer,
): string {
  return JSON.stringify(
    OutputAzureDataExplorer$outboundSchema.parse(outputAzureDataExplorer),
  );
}
export function outputAzureDataExplorerFromJSON(
  jsonString: string,
): SafeParseResult<OutputAzureDataExplorer, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAzureDataExplorer$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAzureDataExplorer' from JSON`,
  );
}

/** @internal */
export const OutputTypeAzureBlob$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeAzureBlob
> = z.nativeEnum(OutputTypeAzureBlob);
/** @internal */
export const OutputTypeAzureBlob$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeAzureBlob
> = OutputTypeAzureBlob$inboundSchema;

/** @internal */
export const DataFormatAzureBlob$inboundSchema: z.ZodType<
  DataFormatAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatAzureBlob$outboundSchema: z.ZodType<
  DataFormatAzureBlob,
  z.ZodTypeDef,
  DataFormatAzureBlob
> = z.union([
  z.nativeEnum(DataFormatAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorAzureBlob$inboundSchema: z.ZodType<
  BackpressureBehaviorAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorAzureBlob$outboundSchema: z.ZodType<
  BackpressureBehaviorAzureBlob,
  z.ZodTypeDef,
  BackpressureBehaviorAzureBlob
> = z.union([
  z.nativeEnum(BackpressureBehaviorAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionAzureBlob$inboundSchema: z.ZodType<
  DiskSpaceProtectionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionAzureBlob$outboundSchema: z.ZodType<
  DiskSpaceProtectionAzureBlob,
  z.ZodTypeDef,
  DiskSpaceProtectionAzureBlob
> = z.union([
  z.nativeEnum(DiskSpaceProtectionAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthenticationMethodAzureBlob$inboundSchema: z.ZodType<
  OutputAuthenticationMethodAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodAzureBlob$outboundSchema: z.ZodType<
  OutputAuthenticationMethodAzureBlob,
  z.ZodTypeDef,
  OutputAuthenticationMethodAzureBlob
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BlobAccessTier$inboundSchema: z.ZodType<
  BlobAccessTier,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BlobAccessTier),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BlobAccessTier$outboundSchema: z.ZodType<
  BlobAccessTier,
  z.ZodTypeDef,
  BlobAccessTier
> = z.union([
  z.nativeEnum(BlobAccessTier),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionAzureBlob$inboundSchema: z.ZodType<
  OutputCompressionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionAzureBlob$outboundSchema: z.ZodType<
  OutputCompressionAzureBlob,
  z.ZodTypeDef,
  OutputCompressionAzureBlob
> = z.union([
  z.nativeEnum(OutputCompressionAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelAzureBlob$inboundSchema: z.ZodType<
  CompressionLevelAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelAzureBlob$outboundSchema: z.ZodType<
  CompressionLevelAzureBlob,
  z.ZodTypeDef,
  CompressionLevelAzureBlob
> = z.union([
  z.nativeEnum(CompressionLevelAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionAzureBlob$inboundSchema: z.ZodType<
  ParquetVersionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionAzureBlob$outboundSchema: z.ZodType<
  ParquetVersionAzureBlob,
  z.ZodTypeDef,
  ParquetVersionAzureBlob
> = z.union([
  z.nativeEnum(ParquetVersionAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionAzureBlob$inboundSchema: z.ZodType<
  DataPageVersionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionAzureBlob$outboundSchema: z.ZodType<
  DataPageVersionAzureBlob,
  z.ZodTypeDef,
  DataPageVersionAzureBlob
> = z.union([
  z.nativeEnum(DataPageVersionAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumAzureBlob$inboundSchema: z.ZodType<
  KeyValueMetadatumAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumAzureBlob$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumAzureBlob$outboundSchema: z.ZodType<
  KeyValueMetadatumAzureBlob$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumAzureBlob
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumAzureBlobToJSON(
  keyValueMetadatumAzureBlob: KeyValueMetadatumAzureBlob,
): string {
  return JSON.stringify(
    KeyValueMetadatumAzureBlob$outboundSchema.parse(keyValueMetadatumAzureBlob),
  );
}
export function keyValueMetadatumAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumAzureBlob' from JSON`,
  );
}

/** @internal */
export const OutputCertificateAzureBlob$inboundSchema: z.ZodType<
  OutputCertificateAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({
  certificateName: z.string(),
});
/** @internal */
export type OutputCertificateAzureBlob$Outbound = {
  certificateName: string;
};

/** @internal */
export const OutputCertificateAzureBlob$outboundSchema: z.ZodType<
  OutputCertificateAzureBlob$Outbound,
  z.ZodTypeDef,
  OutputCertificateAzureBlob
> = z.object({
  certificateName: z.string(),
});

export function outputCertificateAzureBlobToJSON(
  outputCertificateAzureBlob: OutputCertificateAzureBlob,
): string {
  return JSON.stringify(
    OutputCertificateAzureBlob$outboundSchema.parse(outputCertificateAzureBlob),
  );
}
export function outputCertificateAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<OutputCertificateAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCertificateAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCertificateAzureBlob' from JSON`,
  );
}

/** @internal */
export const OutputAzureBlob$inboundSchema: z.ZodType<
  OutputAzureBlob,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeAzureBlob$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    containerName: z.string(),
    createContainer: z.boolean().default(false),
    destPath: z.string().optional(),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    maxConcurrentFileParts: z.number().default(1),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatAzureBlob$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorAzureBlob$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionAzureBlob$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    authType: OutputAuthenticationMethodAzureBlob$inboundSchema.default(
      "manual",
    ),
    storageClass: BlobAccessTier$inboundSchema.default("Inferred"),
    description: z.string().optional(),
    compress: OutputCompressionAzureBlob$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelAzureBlob$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionAzureBlob$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionAzureBlob$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumAzureBlob$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: z.lazy(() => OutputCertificateAzureBlob$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputAzureBlob$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  containerName: string;
  createContainer: boolean;
  destPath?: string | undefined;
  stagePath: string;
  addIdToStagePath: boolean;
  maxConcurrentFileParts: number;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  authType: string;
  storageClass: string;
  description?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumAzureBlob$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?: OutputCertificateAzureBlob$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputAzureBlob$outboundSchema: z.ZodType<
  OutputAzureBlob$Outbound,
  z.ZodTypeDef,
  OutputAzureBlob
> = z.object({
  id: z.string().optional(),
  type: OutputTypeAzureBlob$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  containerName: z.string(),
  createContainer: z.boolean().default(false),
  destPath: z.string().optional(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  maxConcurrentFileParts: z.number().default(1),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatAzureBlob$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorAzureBlob$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionAzureBlob$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  authType: OutputAuthenticationMethodAzureBlob$outboundSchema.default(
    "manual",
  ),
  storageClass: BlobAccessTier$outboundSchema.default("Inferred"),
  description: z.string().optional(),
  compress: OutputCompressionAzureBlob$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelAzureBlob$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionAzureBlob$outboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionAzureBlob$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumAzureBlob$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  connectionString: z.string().optional(),
  textSecret: z.string().optional(),
  storageAccountName: z.string().optional(),
  tenantId: z.string().optional(),
  clientId: z.string().optional(),
  azureCloud: z.string().optional(),
  endpointSuffix: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificate: z.lazy(() => OutputCertificateAzureBlob$outboundSchema)
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputAzureBlobToJSON(
  outputAzureBlob: OutputAzureBlob,
): string {
  return JSON.stringify(OutputAzureBlob$outboundSchema.parse(outputAzureBlob));
}
export function outputAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<OutputAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputAzureBlob' from JSON`,
  );
}

/** @internal */
export const OutputTypeS3$inboundSchema: z.ZodNativeEnum<typeof OutputTypeS3> =
  z.nativeEnum(OutputTypeS3);
/** @internal */
export const OutputTypeS3$outboundSchema: z.ZodNativeEnum<typeof OutputTypeS3> =
  OutputTypeS3$inboundSchema;

/** @internal */
export const OutputAuthenticationMethodS3$inboundSchema: z.ZodType<
  OutputAuthenticationMethodS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodS3$outboundSchema: z.ZodType<
  OutputAuthenticationMethodS3,
  z.ZodTypeDef,
  OutputAuthenticationMethodS3
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputSignatureVersionS3$inboundSchema: z.ZodType<
  OutputSignatureVersionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputSignatureVersionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputSignatureVersionS3$outboundSchema: z.ZodType<
  OutputSignatureVersionS3,
  z.ZodTypeDef,
  OutputSignatureVersionS3
> = z.union([
  z.nativeEnum(OutputSignatureVersionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ObjectAcls3$inboundSchema: z.ZodType<
  ObjectAcls3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ObjectAcls3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ObjectAcls3$outboundSchema: z.ZodType<
  ObjectAcls3,
  z.ZodTypeDef,
  ObjectAcls3
> = z.union([
  z.nativeEnum(ObjectAcls3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const StorageClassS3$inboundSchema: z.ZodType<
  StorageClassS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(StorageClassS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const StorageClassS3$outboundSchema: z.ZodType<
  StorageClassS3,
  z.ZodTypeDef,
  StorageClassS3
> = z.union([
  z.nativeEnum(StorageClassS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ServerSideEncryptionForUploadedObjectsS3$inboundSchema: z.ZodType<
  ServerSideEncryptionForUploadedObjectsS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ServerSideEncryptionForUploadedObjectsS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ServerSideEncryptionForUploadedObjectsS3$outboundSchema: z.ZodType<
  ServerSideEncryptionForUploadedObjectsS3,
  z.ZodTypeDef,
  ServerSideEncryptionForUploadedObjectsS3
> = z.union([
  z.nativeEnum(ServerSideEncryptionForUploadedObjectsS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataFormatS3$inboundSchema: z.ZodType<
  DataFormatS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatS3$outboundSchema: z.ZodType<
  DataFormatS3,
  z.ZodTypeDef,
  DataFormatS3
> = z.union([
  z.nativeEnum(DataFormatS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorS3$inboundSchema: z.ZodType<
  BackpressureBehaviorS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorS3$outboundSchema: z.ZodType<
  BackpressureBehaviorS3,
  z.ZodTypeDef,
  BackpressureBehaviorS3
> = z.union([
  z.nativeEnum(BackpressureBehaviorS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionS3$inboundSchema: z.ZodType<
  DiskSpaceProtectionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionS3$outboundSchema: z.ZodType<
  DiskSpaceProtectionS3,
  z.ZodTypeDef,
  DiskSpaceProtectionS3
> = z.union([
  z.nativeEnum(DiskSpaceProtectionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressionS3$inboundSchema: z.ZodType<
  OutputCompressionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionS3$outboundSchema: z.ZodType<
  OutputCompressionS3,
  z.ZodTypeDef,
  OutputCompressionS3
> = z.union([
  z.nativeEnum(OutputCompressionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelS3$inboundSchema: z.ZodType<
  CompressionLevelS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelS3$outboundSchema: z.ZodType<
  CompressionLevelS3,
  z.ZodTypeDef,
  CompressionLevelS3
> = z.union([
  z.nativeEnum(CompressionLevelS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionS3$inboundSchema: z.ZodType<
  ParquetVersionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionS3$outboundSchema: z.ZodType<
  ParquetVersionS3,
  z.ZodTypeDef,
  ParquetVersionS3
> = z.union([
  z.nativeEnum(ParquetVersionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionS3$inboundSchema: z.ZodType<
  DataPageVersionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionS3$outboundSchema: z.ZodType<
  DataPageVersionS3,
  z.ZodTypeDef,
  DataPageVersionS3
> = z.union([
  z.nativeEnum(DataPageVersionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumS3$inboundSchema: z.ZodType<
  KeyValueMetadatumS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumS3$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumS3$outboundSchema: z.ZodType<
  KeyValueMetadatumS3$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumS3
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumS3ToJSON(
  keyValueMetadatumS3: KeyValueMetadatumS3,
): string {
  return JSON.stringify(
    KeyValueMetadatumS3$outboundSchema.parse(keyValueMetadatumS3),
  );
}
export function keyValueMetadatumS3FromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumS3' from JSON`,
  );
}

/** @internal */
export const OutputS3$inboundSchema: z.ZodType<
  OutputS3,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeS3$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    bucket: z.string(),
    region: z.string().optional(),
    awsSecretKey: z.string().optional(),
    awsAuthenticationMethod: OutputAuthenticationMethodS3$inboundSchema.default(
      "auto",
    ),
    endpoint: z.string().optional(),
    signatureVersion: OutputSignatureVersionS3$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
    addIdToStagePath: z.boolean().default(true),
    destPath: z.string().default(""),
    objectACL: ObjectAcls3$inboundSchema.default("private"),
    storageClass: StorageClassS3$inboundSchema.optional(),
    serverSideEncryption: ServerSideEncryptionForUploadedObjectsS3$inboundSchema
      .optional(),
    kmsKeyId: z.string().optional(),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatS3$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorS3$inboundSchema.default("block"),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionS3$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxConcurrentFileParts: z.number().default(4),
    verifyPermissions: z.boolean().default(true),
    maxClosingFilesToBackpressure: z.number().default(100),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    compress: OutputCompressionS3$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelS3$inboundSchema.default("best_speed"),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionS3$inboundSchema.default("PARQUET_2_6"),
    parquetDataPageVersion: DataPageVersionS3$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(z.lazy(() => KeyValueMetadatumS3$inboundSchema))
      .optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputS3$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region?: string | undefined;
  awsSecretKey?: string | undefined;
  awsAuthenticationMethod: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath: string;
  objectACL: string;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  kmsKeyId?: string | undefined;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  verifyPermissions: boolean;
  maxClosingFilesToBackpressure: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumS3$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputS3$outboundSchema: z.ZodType<
  OutputS3$Outbound,
  z.ZodTypeDef,
  OutputS3
> = z.object({
  id: z.string().optional(),
  type: OutputTypeS3$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsAuthenticationMethod: OutputAuthenticationMethodS3$outboundSchema.default(
    "auto",
  ),
  endpoint: z.string().optional(),
  signatureVersion: OutputSignatureVersionS3$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().default(""),
  objectACL: ObjectAcls3$outboundSchema.default("private"),
  storageClass: StorageClassS3$outboundSchema.optional(),
  serverSideEncryption: ServerSideEncryptionForUploadedObjectsS3$outboundSchema
    .optional(),
  kmsKeyId: z.string().optional(),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatS3$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorS3$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionS3$outboundSchema.default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  verifyPermissions: z.boolean().default(true),
  maxClosingFilesToBackpressure: z.number().default(100),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: OutputCompressionS3$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelS3$outboundSchema.default("best_speed"),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionS3$outboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionS3$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(z.lazy(() => KeyValueMetadatumS3$outboundSchema))
    .optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputS3ToJSON(outputS3: OutputS3): string {
  return JSON.stringify(OutputS3$outboundSchema.parse(outputS3));
}
export function outputS3FromJSON(
  jsonString: string,
): SafeParseResult<OutputS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputS3' from JSON`,
  );
}

/** @internal */
export const TypeFilesystem$inboundSchema: z.ZodNativeEnum<
  typeof TypeFilesystem
> = z.nativeEnum(TypeFilesystem);
/** @internal */
export const TypeFilesystem$outboundSchema: z.ZodNativeEnum<
  typeof TypeFilesystem
> = TypeFilesystem$inboundSchema;

/** @internal */
export const DataFormatFilesystem$inboundSchema: z.ZodType<
  DataFormatFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataFormatFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataFormatFilesystem$outboundSchema: z.ZodType<
  DataFormatFilesystem,
  z.ZodTypeDef,
  DataFormatFilesystem
> = z.union([
  z.nativeEnum(DataFormatFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorFilesystem$inboundSchema: z.ZodType<
  BackpressureBehaviorFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorFilesystem$outboundSchema: z.ZodType<
  BackpressureBehaviorFilesystem,
  z.ZodTypeDef,
  BackpressureBehaviorFilesystem
> = z.union([
  z.nativeEnum(BackpressureBehaviorFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpaceProtectionFilesystem$inboundSchema: z.ZodType<
  DiskSpaceProtectionFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskSpaceProtectionFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskSpaceProtectionFilesystem$outboundSchema: z.ZodType<
  DiskSpaceProtectionFilesystem,
  z.ZodTypeDef,
  DiskSpaceProtectionFilesystem
> = z.union([
  z.nativeEnum(DiskSpaceProtectionFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionFilesystem$inboundSchema: z.ZodType<
  CompressionFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionFilesystem$outboundSchema: z.ZodType<
  CompressionFilesystem,
  z.ZodTypeDef,
  CompressionFilesystem
> = z.union([
  z.nativeEnum(CompressionFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionLevelFilesystem$inboundSchema: z.ZodType<
  CompressionLevelFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionLevelFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionLevelFilesystem$outboundSchema: z.ZodType<
  CompressionLevelFilesystem,
  z.ZodTypeDef,
  CompressionLevelFilesystem
> = z.union([
  z.nativeEnum(CompressionLevelFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ParquetVersionFilesystem$inboundSchema: z.ZodType<
  ParquetVersionFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ParquetVersionFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ParquetVersionFilesystem$outboundSchema: z.ZodType<
  ParquetVersionFilesystem,
  z.ZodTypeDef,
  ParquetVersionFilesystem
> = z.union([
  z.nativeEnum(ParquetVersionFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DataPageVersionFilesystem$inboundSchema: z.ZodType<
  DataPageVersionFilesystem,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataPageVersionFilesystem),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataPageVersionFilesystem$outboundSchema: z.ZodType<
  DataPageVersionFilesystem,
  z.ZodTypeDef,
  DataPageVersionFilesystem
> = z.union([
  z.nativeEnum(DataPageVersionFilesystem),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const KeyValueMetadatumFilesystem$inboundSchema: z.ZodType<
  KeyValueMetadatumFilesystem,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type KeyValueMetadatumFilesystem$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const KeyValueMetadatumFilesystem$outboundSchema: z.ZodType<
  KeyValueMetadatumFilesystem$Outbound,
  z.ZodTypeDef,
  KeyValueMetadatumFilesystem
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function keyValueMetadatumFilesystemToJSON(
  keyValueMetadatumFilesystem: KeyValueMetadatumFilesystem,
): string {
  return JSON.stringify(
    KeyValueMetadatumFilesystem$outboundSchema.parse(
      keyValueMetadatumFilesystem,
    ),
  );
}
export function keyValueMetadatumFilesystemFromJSON(
  jsonString: string,
): SafeParseResult<KeyValueMetadatumFilesystem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => KeyValueMetadatumFilesystem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'KeyValueMetadatumFilesystem' from JSON`,
  );
}

/** @internal */
export const OutputFilesystem$inboundSchema: z.ZodType<
  OutputFilesystem,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeFilesystem$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    destPath: z.string(),
    stagePath: z.string().optional(),
    addIdToStagePath: z.boolean().default(true),
    removeEmptyDirs: z.boolean().default(true),
    partitionExpr: z.string().default(
      "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
    ),
    format: DataFormatFilesystem$inboundSchema.default("json"),
    baseFileName: z.string().default("`CriblOut`"),
    fileNameSuffix: z.string().default(
      "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
    ),
    maxFileSizeMB: z.number().default(32),
    maxFileOpenTimeSec: z.number().default(300),
    maxFileIdleTimeSec: z.number().default(30),
    maxOpenFiles: z.number().default(100),
    headerLine: z.string().default(""),
    writeHighWaterMark: z.number().default(64),
    onBackpressure: BackpressureBehaviorFilesystem$inboundSchema.default(
      "block",
    ),
    deadletterEnabled: z.boolean().default(false),
    onDiskFullBackpressure: DiskSpaceProtectionFilesystem$inboundSchema.default(
      "block",
    ),
    forceCloseOnShutdown: z.boolean().default(false),
    description: z.string().optional(),
    compress: CompressionFilesystem$inboundSchema.default("gzip"),
    compressionLevel: CompressionLevelFilesystem$inboundSchema.default(
      "best_speed",
    ),
    automaticSchema: z.boolean().default(false),
    parquetSchema: z.string().optional(),
    parquetVersion: ParquetVersionFilesystem$inboundSchema.default(
      "PARQUET_2_6",
    ),
    parquetDataPageVersion: DataPageVersionFilesystem$inboundSchema.default(
      "DATA_PAGE_V2",
    ),
    parquetRowGroupLength: z.number().default(10000),
    parquetPageSize: z.string().default("1MB"),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(
      z.lazy(() => KeyValueMetadatumFilesystem$inboundSchema),
    ).optional(),
    enableStatistics: z.boolean().default(true),
    enableWritePageIndex: z.boolean().default(true),
    enablePageChecksum: z.boolean().default(false),
    emptyDirCleanupSec: z.number().default(300),
    directoryBatchSize: z.number().default(1000),
    deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
    maxRetryNum: z.number().default(20),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputFilesystem$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  destPath: string;
  stagePath?: string | undefined;
  addIdToStagePath: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  description?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<KeyValueMetadatumFilesystem$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputFilesystem$outboundSchema: z.ZodType<
  OutputFilesystem$Outbound,
  z.ZodTypeDef,
  OutputFilesystem
> = z.object({
  id: z.string().optional(),
  type: TypeFilesystem$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  destPath: z.string(),
  stagePath: z.string().optional(),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatFilesystem$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorFilesystem$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionFilesystem$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  description: z.string().optional(),
  compress: CompressionFilesystem$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelFilesystem$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionFilesystem$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: DataPageVersionFilesystem$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => KeyValueMetadatumFilesystem$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputFilesystemToJSON(
  outputFilesystem: OutputFilesystem,
): string {
  return JSON.stringify(
    OutputFilesystem$outboundSchema.parse(outputFilesystem),
  );
}
export function outputFilesystemFromJSON(
  jsonString: string,
): SafeParseResult<OutputFilesystem, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputFilesystem$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputFilesystem' from JSON`,
  );
}

/** @internal */
export const TypeSignalfx$inboundSchema: z.ZodNativeEnum<typeof TypeSignalfx> =
  z.nativeEnum(TypeSignalfx);
/** @internal */
export const TypeSignalfx$outboundSchema: z.ZodNativeEnum<typeof TypeSignalfx> =
  TypeSignalfx$inboundSchema;

/** @internal */
export const AuthenticationMethodSignalfx$inboundSchema: z.ZodType<
  AuthenticationMethodSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodSignalfx$outboundSchema: z.ZodType<
  AuthenticationMethodSignalfx,
  z.ZodTypeDef,
  AuthenticationMethodSignalfx
> = z.union([
  z.nativeEnum(AuthenticationMethodSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderSignalfx$inboundSchema: z.ZodType<
  ExtraHttpHeaderSignalfx,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderSignalfx$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderSignalfx$outboundSchema: z.ZodType<
  ExtraHttpHeaderSignalfx$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderSignalfx
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderSignalfxToJSON(
  extraHttpHeaderSignalfx: ExtraHttpHeaderSignalfx,
): string {
  return JSON.stringify(
    ExtraHttpHeaderSignalfx$outboundSchema.parse(extraHttpHeaderSignalfx),
  );
}
export function extraHttpHeaderSignalfxFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderSignalfx, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderSignalfx$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderSignalfx' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeSignalfx$inboundSchema: z.ZodType<
  FailedRequestLoggingModeSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeSignalfx$outboundSchema: z.ZodType<
  FailedRequestLoggingModeSignalfx,
  z.ZodTypeDef,
  FailedRequestLoggingModeSignalfx
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingSignalfx$inboundSchema: z.ZodType<
  ResponseRetrySettingSignalfx,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingSignalfx$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingSignalfx$outboundSchema: z.ZodType<
  ResponseRetrySettingSignalfx$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingSignalfx
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingSignalfxToJSON(
  responseRetrySettingSignalfx: ResponseRetrySettingSignalfx,
): string {
  return JSON.stringify(
    ResponseRetrySettingSignalfx$outboundSchema.parse(
      responseRetrySettingSignalfx,
    ),
  );
}
export function responseRetrySettingSignalfxFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingSignalfx, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingSignalfx$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingSignalfx' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsSignalfx$inboundSchema: z.ZodType<
  TimeoutRetrySettingsSignalfx,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsSignalfx$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsSignalfx$outboundSchema: z.ZodType<
  TimeoutRetrySettingsSignalfx$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsSignalfx
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsSignalfxToJSON(
  timeoutRetrySettingsSignalfx: TimeoutRetrySettingsSignalfx,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsSignalfx$outboundSchema.parse(
      timeoutRetrySettingsSignalfx,
    ),
  );
}
export function timeoutRetrySettingsSignalfxFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsSignalfx, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsSignalfx$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsSignalfx' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSignalfx$inboundSchema: z.ZodType<
  BackpressureBehaviorSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSignalfx$outboundSchema: z.ZodType<
  BackpressureBehaviorSignalfx,
  z.ZodTypeDef,
  BackpressureBehaviorSignalfx
> = z.union([
  z.nativeEnum(BackpressureBehaviorSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSignalfx$inboundSchema: z.ZodType<
  ModeSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSignalfx$outboundSchema: z.ZodType<
  ModeSignalfx,
  z.ZodTypeDef,
  ModeSignalfx
> = z.union([
  z.nativeEnum(ModeSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSignalfx$inboundSchema: z.ZodType<
  CompressionSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSignalfx$outboundSchema: z.ZodType<
  CompressionSignalfx,
  z.ZodTypeDef,
  CompressionSignalfx
> = z.union([
  z.nativeEnum(CompressionSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSignalfx$inboundSchema: z.ZodType<
  QueueFullBehaviorSignalfx,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSignalfx),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSignalfx$outboundSchema: z.ZodType<
  QueueFullBehaviorSignalfx,
  z.ZodTypeDef,
  QueueFullBehaviorSignalfx
> = z.union([
  z.nativeEnum(QueueFullBehaviorSignalfx),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSignalfx$inboundSchema: z.ZodType<
  PqControlsSignalfx,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSignalfx$Outbound = {};

/** @internal */
export const PqControlsSignalfx$outboundSchema: z.ZodType<
  PqControlsSignalfx$Outbound,
  z.ZodTypeDef,
  PqControlsSignalfx
> = z.object({});

export function pqControlsSignalfxToJSON(
  pqControlsSignalfx: PqControlsSignalfx,
): string {
  return JSON.stringify(
    PqControlsSignalfx$outboundSchema.parse(pqControlsSignalfx),
  );
}
export function pqControlsSignalfxFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSignalfx, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSignalfx$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSignalfx' from JSON`,
  );
}

/** @internal */
export const OutputSignalfx$inboundSchema: z.ZodType<
  OutputSignalfx,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSignalfx$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    authType: AuthenticationMethodSignalfx$inboundSchema.default("manual"),
    realm: z.string().default("us0"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderSignalfx$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeSignalfx$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingSignalfx$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsSignalfx$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorSignalfx$inboundSchema.default("block"),
    description: z.string().optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSignalfx$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSignalfx$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSignalfx$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSignalfx$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSignalfx$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  authType: string;
  realm: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderSignalfx$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingSignalfx$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSignalfx$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSignalfx$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSignalfx$outboundSchema: z.ZodType<
  OutputSignalfx$Outbound,
  z.ZodTypeDef,
  OutputSignalfx
> = z.object({
  id: z.string().optional(),
  type: TypeSignalfx$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  authType: AuthenticationMethodSignalfx$outboundSchema.default("manual"),
  realm: z.string().default("us0"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderSignalfx$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeSignalfx$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingSignalfx$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsSignalfx$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorSignalfx$outboundSchema.default("block"),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSignalfx$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSignalfx$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSignalfx$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSignalfx$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSignalfxToJSON(outputSignalfx: OutputSignalfx): string {
  return JSON.stringify(OutputSignalfx$outboundSchema.parse(outputSignalfx));
}
export function outputSignalfxFromJSON(
  jsonString: string,
): SafeParseResult<OutputSignalfx, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSignalfx$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSignalfx' from JSON`,
  );
}

/** @internal */
export const TypeWavefront$inboundSchema: z.ZodNativeEnum<
  typeof TypeWavefront
> = z.nativeEnum(TypeWavefront);
/** @internal */
export const TypeWavefront$outboundSchema: z.ZodNativeEnum<
  typeof TypeWavefront
> = TypeWavefront$inboundSchema;

/** @internal */
export const AuthenticationMethodWavefront$inboundSchema: z.ZodType<
  AuthenticationMethodWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodWavefront$outboundSchema: z.ZodType<
  AuthenticationMethodWavefront,
  z.ZodTypeDef,
  AuthenticationMethodWavefront
> = z.union([
  z.nativeEnum(AuthenticationMethodWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderWavefront$inboundSchema: z.ZodType<
  ExtraHttpHeaderWavefront,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderWavefront$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderWavefront$outboundSchema: z.ZodType<
  ExtraHttpHeaderWavefront$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderWavefront
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderWavefrontToJSON(
  extraHttpHeaderWavefront: ExtraHttpHeaderWavefront,
): string {
  return JSON.stringify(
    ExtraHttpHeaderWavefront$outboundSchema.parse(extraHttpHeaderWavefront),
  );
}
export function extraHttpHeaderWavefrontFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderWavefront, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderWavefront$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderWavefront' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeWavefront$inboundSchema: z.ZodType<
  FailedRequestLoggingModeWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeWavefront$outboundSchema: z.ZodType<
  FailedRequestLoggingModeWavefront,
  z.ZodTypeDef,
  FailedRequestLoggingModeWavefront
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingWavefront$inboundSchema: z.ZodType<
  ResponseRetrySettingWavefront,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingWavefront$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingWavefront$outboundSchema: z.ZodType<
  ResponseRetrySettingWavefront$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingWavefront
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingWavefrontToJSON(
  responseRetrySettingWavefront: ResponseRetrySettingWavefront,
): string {
  return JSON.stringify(
    ResponseRetrySettingWavefront$outboundSchema.parse(
      responseRetrySettingWavefront,
    ),
  );
}
export function responseRetrySettingWavefrontFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingWavefront, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingWavefront$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingWavefront' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsWavefront$inboundSchema: z.ZodType<
  TimeoutRetrySettingsWavefront,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsWavefront$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsWavefront$outboundSchema: z.ZodType<
  TimeoutRetrySettingsWavefront$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsWavefront
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsWavefrontToJSON(
  timeoutRetrySettingsWavefront: TimeoutRetrySettingsWavefront,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsWavefront$outboundSchema.parse(
      timeoutRetrySettingsWavefront,
    ),
  );
}
export function timeoutRetrySettingsWavefrontFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsWavefront, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsWavefront$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsWavefront' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorWavefront$inboundSchema: z.ZodType<
  BackpressureBehaviorWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorWavefront$outboundSchema: z.ZodType<
  BackpressureBehaviorWavefront,
  z.ZodTypeDef,
  BackpressureBehaviorWavefront
> = z.union([
  z.nativeEnum(BackpressureBehaviorWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeWavefront$inboundSchema: z.ZodType<
  ModeWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeWavefront$outboundSchema: z.ZodType<
  ModeWavefront,
  z.ZodTypeDef,
  ModeWavefront
> = z.union([
  z.nativeEnum(ModeWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionWavefront$inboundSchema: z.ZodType<
  CompressionWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWavefront$outboundSchema: z.ZodType<
  CompressionWavefront,
  z.ZodTypeDef,
  CompressionWavefront
> = z.union([
  z.nativeEnum(CompressionWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorWavefront$inboundSchema: z.ZodType<
  QueueFullBehaviorWavefront,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorWavefront),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorWavefront$outboundSchema: z.ZodType<
  QueueFullBehaviorWavefront,
  z.ZodTypeDef,
  QueueFullBehaviorWavefront
> = z.union([
  z.nativeEnum(QueueFullBehaviorWavefront),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWavefront$inboundSchema: z.ZodType<
  PqControlsWavefront,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWavefront$Outbound = {};

/** @internal */
export const PqControlsWavefront$outboundSchema: z.ZodType<
  PqControlsWavefront$Outbound,
  z.ZodTypeDef,
  PqControlsWavefront
> = z.object({});

export function pqControlsWavefrontToJSON(
  pqControlsWavefront: PqControlsWavefront,
): string {
  return JSON.stringify(
    PqControlsWavefront$outboundSchema.parse(pqControlsWavefront),
  );
}
export function pqControlsWavefrontFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWavefront, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWavefront$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWavefront' from JSON`,
  );
}

/** @internal */
export const OutputWavefront$inboundSchema: z.ZodType<
  OutputWavefront,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWavefront$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    authType: AuthenticationMethodWavefront$inboundSchema.default("manual"),
    domain: z.string().default("longboard"),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderWavefront$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeWavefront$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingWavefront$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsWavefront$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorWavefront$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeWavefront$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionWavefront$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorWavefront$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsWavefront$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputWavefront$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  authType: string;
  domain: string;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderWavefront$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingWavefront$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsWavefront$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsWavefront$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputWavefront$outboundSchema: z.ZodType<
  OutputWavefront$Outbound,
  z.ZodTypeDef,
  OutputWavefront
> = z.object({
  id: z.string().optional(),
  type: TypeWavefront$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  authType: AuthenticationMethodWavefront$outboundSchema.default("manual"),
  domain: z.string().default("longboard"),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderWavefront$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeWavefront$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingWavefront$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsWavefront$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorWavefront$outboundSchema.default("block"),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeWavefront$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionWavefront$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorWavefront$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsWavefront$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputWavefrontToJSON(
  outputWavefront: OutputWavefront,
): string {
  return JSON.stringify(OutputWavefront$outboundSchema.parse(outputWavefront));
}
export function outputWavefrontFromJSON(
  jsonString: string,
): SafeParseResult<OutputWavefront, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputWavefront$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputWavefront' from JSON`,
  );
}

/** @internal */
export const OutputTypeTcpjson$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeTcpjson
> = z.nativeEnum(OutputTypeTcpjson);
/** @internal */
export const OutputTypeTcpjson$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeTcpjson
> = OutputTypeTcpjson$inboundSchema;

/** @internal */
export const OutputCompressionTcpjson$inboundSchema: z.ZodType<
  OutputCompressionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressionTcpjson$outboundSchema: z.ZodType<
  OutputCompressionTcpjson,
  z.ZodTypeDef,
  OutputCompressionTcpjson
> = z.union([
  z.nativeEnum(OutputCompressionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMinimumTLSVersionTcpjson$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionTcpjson$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionTcpjson,
  z.ZodTypeDef,
  OutputMinimumTLSVersionTcpjson
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionTcpjson$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionTcpjson$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionTcpjson,
  z.ZodTypeDef,
  OutputMaximumTLSVersionTcpjson
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideTcpjson$inboundSchema: z.ZodType<
  TLSSettingsClientSideTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionTcpjson$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionTcpjson$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideTcpjson$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideTcpjson$outboundSchema: z.ZodType<
  TLSSettingsClientSideTcpjson$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideTcpjson
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionTcpjson$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionTcpjson$outboundSchema.optional(),
});

export function tlsSettingsClientSideTcpjsonToJSON(
  tlsSettingsClientSideTcpjson: TLSSettingsClientSideTcpjson,
): string {
  return JSON.stringify(
    TLSSettingsClientSideTcpjson$outboundSchema.parse(
      tlsSettingsClientSideTcpjson,
    ),
  );
}
export function tlsSettingsClientSideTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideTcpjson' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorTcpjson$inboundSchema: z.ZodType<
  BackpressureBehaviorTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorTcpjson$outboundSchema: z.ZodType<
  BackpressureBehaviorTcpjson,
  z.ZodTypeDef,
  BackpressureBehaviorTcpjson
> = z.union([
  z.nativeEnum(BackpressureBehaviorTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthenticationMethodTcpjson$inboundSchema: z.ZodType<
  OutputAuthenticationMethodTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodTcpjson$outboundSchema: z.ZodType<
  OutputAuthenticationMethodTcpjson,
  z.ZodTypeDef,
  OutputAuthenticationMethodTcpjson
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSTcpjson$inboundSchema: z.ZodType<
  TLSTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TLSTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TLSTcpjson$outboundSchema: z.ZodType<
  TLSTcpjson,
  z.ZodTypeDef,
  TLSTcpjson
> = z.union([
  z.nativeEnum(TLSTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HostTcpjson$inboundSchema: z.ZodType<
  HostTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number(),
  tls: TLSTcpjson$inboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});
/** @internal */
export type HostTcpjson$Outbound = {
  host: string;
  port: number;
  tls: string;
  servername?: string | undefined;
  weight: number;
};

/** @internal */
export const HostTcpjson$outboundSchema: z.ZodType<
  HostTcpjson$Outbound,
  z.ZodTypeDef,
  HostTcpjson
> = z.object({
  host: z.string(),
  port: z.number(),
  tls: TLSTcpjson$outboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});

export function hostTcpjsonToJSON(hostTcpjson: HostTcpjson): string {
  return JSON.stringify(HostTcpjson$outboundSchema.parse(hostTcpjson));
}
export function hostTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<HostTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostTcpjson' from JSON`,
  );
}

/** @internal */
export const OutputModeTcpjson$inboundSchema: z.ZodType<
  OutputModeTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeTcpjson$outboundSchema: z.ZodType<
  OutputModeTcpjson,
  z.ZodTypeDef,
  OutputModeTcpjson
> = z.union([
  z.nativeEnum(OutputModeTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionTcpjson$inboundSchema: z.ZodType<
  PqCompressCompressionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionTcpjson$outboundSchema: z.ZodType<
  PqCompressCompressionTcpjson,
  z.ZodTypeDef,
  PqCompressCompressionTcpjson
> = z.union([
  z.nativeEnum(PqCompressCompressionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorTcpjson$inboundSchema: z.ZodType<
  QueueFullBehaviorTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorTcpjson$outboundSchema: z.ZodType<
  QueueFullBehaviorTcpjson,
  z.ZodTypeDef,
  QueueFullBehaviorTcpjson
> = z.union([
  z.nativeEnum(QueueFullBehaviorTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsTcpjson$inboundSchema: z.ZodType<
  OutputPqControlsTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsTcpjson$Outbound = {};

/** @internal */
export const OutputPqControlsTcpjson$outboundSchema: z.ZodType<
  OutputPqControlsTcpjson$Outbound,
  z.ZodTypeDef,
  OutputPqControlsTcpjson
> = z.object({});

export function outputPqControlsTcpjsonToJSON(
  outputPqControlsTcpjson: OutputPqControlsTcpjson,
): string {
  return JSON.stringify(
    OutputPqControlsTcpjson$outboundSchema.parse(outputPqControlsTcpjson),
  );
}
export function outputPqControlsTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsTcpjson' from JSON`,
  );
}

/** @internal */
export const OutputTcpjson$inboundSchema: z.ZodType<
  OutputTcpjson,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeTcpjson$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(true),
    compression: OutputCompressionTcpjson$inboundSchema.default("gzip"),
    logFailedRequests: z.boolean().default(false),
    throttleRatePerSec: z.string().default("0"),
    tls: z.lazy(() => TLSSettingsClientSideTcpjson$inboundSchema).optional(),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    tokenTTLMinutes: z.number().default(60),
    sendHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorTcpjson$inboundSchema.default("block"),
    authType: OutputAuthenticationMethodTcpjson$inboundSchema.default("manual"),
    description: z.string().optional(),
    host: z.string().optional(),
    port: z.number().optional(),
    excludeSelf: z.boolean().default(false),
    hosts: z.array(z.lazy(() => HostTcpjson$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    maxConcurrentSenders: z.number().default(0),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeTcpjson$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionTcpjson$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorTcpjson$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsTcpjson$inboundSchema).optional(),
    authToken: z.string().default(""),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputTcpjson$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  compression: string;
  logFailedRequests: boolean;
  throttleRatePerSec: string;
  tls?: TLSSettingsClientSideTcpjson$Outbound | undefined;
  connectionTimeout: number;
  writeTimeout: number;
  tokenTTLMinutes: number;
  sendHeader: boolean;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  host?: string | undefined;
  port?: number | undefined;
  excludeSelf: boolean;
  hosts?: Array<HostTcpjson$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  maxConcurrentSenders: number;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsTcpjson$Outbound | undefined;
  authToken: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputTcpjson$outboundSchema: z.ZodType<
  OutputTcpjson$Outbound,
  z.ZodTypeDef,
  OutputTcpjson
> = z.object({
  id: z.string().optional(),
  type: OutputTypeTcpjson$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(true),
  compression: OutputCompressionTcpjson$outboundSchema.default("gzip"),
  logFailedRequests: z.boolean().default(false),
  throttleRatePerSec: z.string().default("0"),
  tls: z.lazy(() => TLSSettingsClientSideTcpjson$outboundSchema).optional(),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  tokenTTLMinutes: z.number().default(60),
  sendHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorTcpjson$outboundSchema.default("block"),
  authType: OutputAuthenticationMethodTcpjson$outboundSchema.default("manual"),
  description: z.string().optional(),
  host: z.string().optional(),
  port: z.number().optional(),
  excludeSelf: z.boolean().default(false),
  hosts: z.array(z.lazy(() => HostTcpjson$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  maxConcurrentSenders: z.number().default(0),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeTcpjson$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionTcpjson$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorTcpjson$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsTcpjson$outboundSchema).optional(),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputTcpjsonToJSON(outputTcpjson: OutputTcpjson): string {
  return JSON.stringify(OutputTcpjson$outboundSchema.parse(outputTcpjson));
}
export function outputTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<OutputTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputTcpjson' from JSON`,
  );
}

/** @internal */
export const OutputTypeSplunkHec$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSplunkHec
> = z.nativeEnum(OutputTypeSplunkHec);
/** @internal */
export const OutputTypeSplunkHec$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSplunkHec
> = OutputTypeSplunkHec$inboundSchema;

/** @internal */
export const OutputMinimumTLSVersionSplunkHec$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionSplunkHec$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionSplunkHec,
  z.ZodTypeDef,
  OutputMinimumTLSVersionSplunkHec
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionSplunkHec$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionSplunkHec$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionSplunkHec,
  z.ZodTypeDef,
  OutputMaximumTLSVersionSplunkHec
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideSplunkHec$inboundSchema: z.ZodType<
  TLSSettingsClientSideSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionSplunkHec$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionSplunkHec$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideSplunkHec$Outbound = {
  disabled: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideSplunkHec$outboundSchema: z.ZodType<
  TLSSettingsClientSideSplunkHec$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideSplunkHec
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionSplunkHec$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionSplunkHec$outboundSchema.optional(),
});

export function tlsSettingsClientSideSplunkHecToJSON(
  tlsSettingsClientSideSplunkHec: TLSSettingsClientSideSplunkHec,
): string {
  return JSON.stringify(
    TLSSettingsClientSideSplunkHec$outboundSchema.parse(
      tlsSettingsClientSideSplunkHec,
    ),
  );
}
export function tlsSettingsClientSideSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideSplunkHec' from JSON`,
  );
}

/** @internal */
export const ExtraHttpHeaderSplunkHec$inboundSchema: z.ZodType<
  ExtraHttpHeaderSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderSplunkHec$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderSplunkHec$outboundSchema: z.ZodType<
  ExtraHttpHeaderSplunkHec$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderSplunkHec
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderSplunkHecToJSON(
  extraHttpHeaderSplunkHec: ExtraHttpHeaderSplunkHec,
): string {
  return JSON.stringify(
    ExtraHttpHeaderSplunkHec$outboundSchema.parse(extraHttpHeaderSplunkHec),
  );
}
export function extraHttpHeaderSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderSplunkHec' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeSplunkHec$inboundSchema: z.ZodType<
  FailedRequestLoggingModeSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeSplunkHec$outboundSchema: z.ZodType<
  FailedRequestLoggingModeSplunkHec,
  z.ZodTypeDef,
  FailedRequestLoggingModeSplunkHec
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputAuthenticationMethodSplunkHec$inboundSchema: z.ZodType<
  OutputAuthenticationMethodSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputAuthenticationMethodSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputAuthenticationMethodSplunkHec$outboundSchema: z.ZodType<
  OutputAuthenticationMethodSplunkHec,
  z.ZodTypeDef,
  OutputAuthenticationMethodSplunkHec
> = z.union([
  z.nativeEnum(OutputAuthenticationMethodSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingSplunkHec$inboundSchema: z.ZodType<
  ResponseRetrySettingSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingSplunkHec$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingSplunkHec$outboundSchema: z.ZodType<
  ResponseRetrySettingSplunkHec$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingSplunkHec
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingSplunkHecToJSON(
  responseRetrySettingSplunkHec: ResponseRetrySettingSplunkHec,
): string {
  return JSON.stringify(
    ResponseRetrySettingSplunkHec$outboundSchema.parse(
      responseRetrySettingSplunkHec,
    ),
  );
}
export function responseRetrySettingSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingSplunkHec' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsSplunkHec$inboundSchema: z.ZodType<
  TimeoutRetrySettingsSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsSplunkHec$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsSplunkHec$outboundSchema: z.ZodType<
  TimeoutRetrySettingsSplunkHec$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsSplunkHec
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsSplunkHecToJSON(
  timeoutRetrySettingsSplunkHec: TimeoutRetrySettingsSplunkHec,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsSplunkHec$outboundSchema.parse(
      timeoutRetrySettingsSplunkHec,
    ),
  );
}
export function timeoutRetrySettingsSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsSplunkHec' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSplunkHec$inboundSchema: z.ZodType<
  BackpressureBehaviorSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSplunkHec$outboundSchema: z.ZodType<
  BackpressureBehaviorSplunkHec,
  z.ZodTypeDef,
  BackpressureBehaviorSplunkHec
> = z.union([
  z.nativeEnum(BackpressureBehaviorSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const UrlSplunkHec$inboundSchema: z.ZodType<
  UrlSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  url: z.string().default("http://localhost:8088/services/collector/event"),
  weight: z.number().default(1),
});
/** @internal */
export type UrlSplunkHec$Outbound = {
  url: string;
  weight: number;
};

/** @internal */
export const UrlSplunkHec$outboundSchema: z.ZodType<
  UrlSplunkHec$Outbound,
  z.ZodTypeDef,
  UrlSplunkHec
> = z.object({
  url: z.string().default("http://localhost:8088/services/collector/event"),
  weight: z.number().default(1),
});

export function urlSplunkHecToJSON(urlSplunkHec: UrlSplunkHec): string {
  return JSON.stringify(UrlSplunkHec$outboundSchema.parse(urlSplunkHec));
}
export function urlSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<UrlSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UrlSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UrlSplunkHec' from JSON`,
  );
}

/** @internal */
export const OutputModeSplunkHec$inboundSchema: z.ZodType<
  OutputModeSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeSplunkHec$outboundSchema: z.ZodType<
  OutputModeSplunkHec,
  z.ZodTypeDef,
  OutputModeSplunkHec
> = z.union([
  z.nativeEnum(OutputModeSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionSplunkHec$inboundSchema: z.ZodType<
  PqCompressCompressionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionSplunkHec$outboundSchema: z.ZodType<
  PqCompressCompressionSplunkHec,
  z.ZodTypeDef,
  PqCompressCompressionSplunkHec
> = z.union([
  z.nativeEnum(PqCompressCompressionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSplunkHec$inboundSchema: z.ZodType<
  QueueFullBehaviorSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSplunkHec$outboundSchema: z.ZodType<
  QueueFullBehaviorSplunkHec,
  z.ZodTypeDef,
  QueueFullBehaviorSplunkHec
> = z.union([
  z.nativeEnum(QueueFullBehaviorSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsSplunkHec$inboundSchema: z.ZodType<
  OutputPqControlsSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsSplunkHec$Outbound = {};

/** @internal */
export const OutputPqControlsSplunkHec$outboundSchema: z.ZodType<
  OutputPqControlsSplunkHec$Outbound,
  z.ZodTypeDef,
  OutputPqControlsSplunkHec
> = z.object({});

export function outputPqControlsSplunkHecToJSON(
  outputPqControlsSplunkHec: OutputPqControlsSplunkHec,
): string {
  return JSON.stringify(
    OutputPqControlsSplunkHec$outboundSchema.parse(outputPqControlsSplunkHec),
  );
}
export function outputPqControlsSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsSplunkHec' from JSON`,
  );
}

/** @internal */
export const OutputSplunkHec$inboundSchema: z.ZodType<
  OutputSplunkHec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSplunkHec$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    loadBalanced: z.boolean().default(true),
    nextQueue: z.string().default("indexQueue"),
    tcpRouting: z.string().default("nowhere"),
    tls: z.lazy(() => TLSSettingsClientSideSplunkHec$inboundSchema).optional(),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderSplunkHec$inboundSchema),
    ).optional(),
    failedRequestLoggingMode: FailedRequestLoggingModeSplunkHec$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    enableMultiMetrics: z.boolean().default(false),
    authType: OutputAuthenticationMethodSplunkHec$inboundSchema.default(
      "manual",
    ),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingSplunkHec$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsSplunkHec$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(true),
    onBackpressure: BackpressureBehaviorSplunkHec$inboundSchema.default(
      "block",
    ),
    description: z.string().optional(),
    url: z.string().default("http://localhost:8088/services/collector/event"),
    useRoundRobinDns: z.boolean().default(false),
    excludeSelf: z.boolean().default(false),
    urls: z.array(z.lazy(() => UrlSplunkHec$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    token: z.string().optional(),
    textSecret: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeSplunkHec$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionSplunkHec$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSplunkHec$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsSplunkHec$inboundSchema)
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSplunkHec$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced: boolean;
  nextQueue: string;
  tcpRouting: string;
  tls?: TLSSettingsClientSideSplunkHec$Outbound | undefined;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderSplunkHec$Outbound> | undefined;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  enableMultiMetrics: boolean;
  authType: string;
  responseRetrySettings?:
    | Array<ResponseRetrySettingSplunkHec$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSplunkHec$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  description?: string | undefined;
  url: string;
  useRoundRobinDns: boolean;
  excludeSelf: boolean;
  urls?: Array<UrlSplunkHec$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsSplunkHec$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSplunkHec$outboundSchema: z.ZodType<
  OutputSplunkHec$Outbound,
  z.ZodTypeDef,
  OutputSplunkHec
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSplunkHec$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().default(true),
  nextQueue: z.string().default("indexQueue"),
  tcpRouting: z.string().default("nowhere"),
  tls: z.lazy(() => TLSSettingsClientSideSplunkHec$outboundSchema).optional(),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderSplunkHec$outboundSchema),
  ).optional(),
  failedRequestLoggingMode: FailedRequestLoggingModeSplunkHec$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  enableMultiMetrics: z.boolean().default(false),
  authType: OutputAuthenticationMethodSplunkHec$outboundSchema.default(
    "manual",
  ),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingSplunkHec$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsSplunkHec$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(true),
  onBackpressure: BackpressureBehaviorSplunkHec$outboundSchema.default("block"),
  description: z.string().optional(),
  url: z.string().default("http://localhost:8088/services/collector/event"),
  useRoundRobinDns: z.boolean().default(false),
  excludeSelf: z.boolean().default(false),
  urls: z.array(z.lazy(() => UrlSplunkHec$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeSplunkHec$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionSplunkHec$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSplunkHec$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsSplunkHec$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSplunkHecToJSON(
  outputSplunkHec: OutputSplunkHec,
): string {
  return JSON.stringify(OutputSplunkHec$outboundSchema.parse(outputSplunkHec));
}
export function outputSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<OutputSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSplunkHec' from JSON`,
  );
}

/** @internal */
export const TypeSplunkLb$inboundSchema: z.ZodNativeEnum<typeof TypeSplunkLb> =
  z.nativeEnum(TypeSplunkLb);
/** @internal */
export const TypeSplunkLb$outboundSchema: z.ZodNativeEnum<typeof TypeSplunkLb> =
  TypeSplunkLb$inboundSchema;

/** @internal */
export const NestedFieldSerializationSplunkLb$inboundSchema: z.ZodType<
  NestedFieldSerializationSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(NestedFieldSerializationSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const NestedFieldSerializationSplunkLb$outboundSchema: z.ZodType<
  NestedFieldSerializationSplunkLb,
  z.ZodTypeDef,
  NestedFieldSerializationSplunkLb
> = z.union([
  z.nativeEnum(NestedFieldSerializationSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MinimumTLSVersionSplunkLb$inboundSchema: z.ZodType<
  MinimumTLSVersionSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionSplunkLb$outboundSchema: z.ZodType<
  MinimumTLSVersionSplunkLb,
  z.ZodTypeDef,
  MinimumTLSVersionSplunkLb
> = z.union([
  z.nativeEnum(MinimumTLSVersionSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionSplunkLb$inboundSchema: z.ZodType<
  MaximumTLSVersionSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionSplunkLb$outboundSchema: z.ZodType<
  MaximumTLSVersionSplunkLb,
  z.ZodTypeDef,
  MaximumTLSVersionSplunkLb
> = z.union([
  z.nativeEnum(MaximumTLSVersionSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideSplunkLb$inboundSchema: z.ZodType<
  TLSSettingsClientSideSplunkLb,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionSplunkLb$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionSplunkLb$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideSplunkLb$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideSplunkLb$outboundSchema: z.ZodType<
  TLSSettingsClientSideSplunkLb$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideSplunkLb
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionSplunkLb$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionSplunkLb$outboundSchema.optional(),
});

export function tlsSettingsClientSideSplunkLbToJSON(
  tlsSettingsClientSideSplunkLb: TLSSettingsClientSideSplunkLb,
): string {
  return JSON.stringify(
    TLSSettingsClientSideSplunkLb$outboundSchema.parse(
      tlsSettingsClientSideSplunkLb,
    ),
  );
}
export function tlsSettingsClientSideSplunkLbFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideSplunkLb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideSplunkLb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideSplunkLb' from JSON`,
  );
}

/** @internal */
export const MaxS2SVersionSplunkLb$inboundSchema: z.ZodType<
  MaxS2SVersionSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaxS2SVersionSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaxS2SVersionSplunkLb$outboundSchema: z.ZodType<
  MaxS2SVersionSplunkLb,
  z.ZodTypeDef,
  MaxS2SVersionSplunkLb
> = z.union([
  z.nativeEnum(MaxS2SVersionSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorSplunkLb$inboundSchema: z.ZodType<
  BackpressureBehaviorSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSplunkLb$outboundSchema: z.ZodType<
  BackpressureBehaviorSplunkLb,
  z.ZodTypeDef,
  BackpressureBehaviorSplunkLb
> = z.union([
  z.nativeEnum(BackpressureBehaviorSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodSplunkLb$inboundSchema: z.ZodType<
  AuthenticationMethodSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodSplunkLb$outboundSchema: z.ZodType<
  AuthenticationMethodSplunkLb,
  z.ZodTypeDef,
  AuthenticationMethodSplunkLb
> = z.union([
  z.nativeEnum(AuthenticationMethodSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressCompressionSplunkLb$inboundSchema: z.ZodType<
  CompressCompressionSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressCompressionSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressCompressionSplunkLb$outboundSchema: z.ZodType<
  CompressCompressionSplunkLb,
  z.ZodTypeDef,
  CompressCompressionSplunkLb
> = z.union([
  z.nativeEnum(CompressCompressionSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const IndexerDiscoveryConfigsAuthTokenAuthenticationMethod$inboundSchema:
  z.ZodType<
    IndexerDiscoveryConfigsAuthTokenAuthenticationMethod,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(IndexerDiscoveryConfigsAuthTokenAuthenticationMethod),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const IndexerDiscoveryConfigsAuthTokenAuthenticationMethod$outboundSchema:
  z.ZodType<
    IndexerDiscoveryConfigsAuthTokenAuthenticationMethod,
    z.ZodTypeDef,
    IndexerDiscoveryConfigsAuthTokenAuthenticationMethod
  > = z.union([
    z.nativeEnum(IndexerDiscoveryConfigsAuthTokenAuthenticationMethod),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const IndexerDiscoveryConfigsAuthToken$inboundSchema: z.ZodType<
  IndexerDiscoveryConfigsAuthToken,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: IndexerDiscoveryConfigsAuthTokenAuthenticationMethod$inboundSchema
    .default("manual"),
});
/** @internal */
export type IndexerDiscoveryConfigsAuthToken$Outbound = {
  authType: string;
};

/** @internal */
export const IndexerDiscoveryConfigsAuthToken$outboundSchema: z.ZodType<
  IndexerDiscoveryConfigsAuthToken$Outbound,
  z.ZodTypeDef,
  IndexerDiscoveryConfigsAuthToken
> = z.object({
  authType: IndexerDiscoveryConfigsAuthTokenAuthenticationMethod$outboundSchema
    .default("manual"),
});

export function indexerDiscoveryConfigsAuthTokenToJSON(
  indexerDiscoveryConfigsAuthToken: IndexerDiscoveryConfigsAuthToken,
): string {
  return JSON.stringify(
    IndexerDiscoveryConfigsAuthToken$outboundSchema.parse(
      indexerDiscoveryConfigsAuthToken,
    ),
  );
}
export function indexerDiscoveryConfigsAuthTokenFromJSON(
  jsonString: string,
): SafeParseResult<IndexerDiscoveryConfigsAuthToken, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => IndexerDiscoveryConfigsAuthToken$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'IndexerDiscoveryConfigsAuthToken' from JSON`,
  );
}

/** @internal */
export const IndexerDiscoveryConfigsAuthenticationMethod$inboundSchema:
  z.ZodType<
    IndexerDiscoveryConfigsAuthenticationMethod,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(IndexerDiscoveryConfigsAuthenticationMethod),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const IndexerDiscoveryConfigsAuthenticationMethod$outboundSchema:
  z.ZodType<
    IndexerDiscoveryConfigsAuthenticationMethod,
    z.ZodTypeDef,
    IndexerDiscoveryConfigsAuthenticationMethod
  > = z.union([
    z.nativeEnum(IndexerDiscoveryConfigsAuthenticationMethod),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const IndexerDiscoveryConfigs$inboundSchema: z.ZodType<
  IndexerDiscoveryConfigs,
  z.ZodTypeDef,
  unknown
> = z.object({
  site: z.string().default("default"),
  masterUri: z.string(),
  refreshIntervalSec: z.number().default(300),
  rejectUnauthorized: z.boolean().default(false),
  authTokens: z.array(
    z.lazy(() => IndexerDiscoveryConfigsAuthToken$inboundSchema),
  ).optional(),
  authType: IndexerDiscoveryConfigsAuthenticationMethod$inboundSchema.default(
    "manual",
  ),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
});
/** @internal */
export type IndexerDiscoveryConfigs$Outbound = {
  site: string;
  masterUri: string;
  refreshIntervalSec: number;
  rejectUnauthorized: boolean;
  authTokens?: Array<IndexerDiscoveryConfigsAuthToken$Outbound> | undefined;
  authType: string;
  authToken: string;
  textSecret?: string | undefined;
};

/** @internal */
export const IndexerDiscoveryConfigs$outboundSchema: z.ZodType<
  IndexerDiscoveryConfigs$Outbound,
  z.ZodTypeDef,
  IndexerDiscoveryConfigs
> = z.object({
  site: z.string().default("default"),
  masterUri: z.string(),
  refreshIntervalSec: z.number().default(300),
  rejectUnauthorized: z.boolean().default(false),
  authTokens: z.array(
    z.lazy(() => IndexerDiscoveryConfigsAuthToken$outboundSchema),
  ).optional(),
  authType: IndexerDiscoveryConfigsAuthenticationMethod$outboundSchema.default(
    "manual",
  ),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
});

export function indexerDiscoveryConfigsToJSON(
  indexerDiscoveryConfigs: IndexerDiscoveryConfigs,
): string {
  return JSON.stringify(
    IndexerDiscoveryConfigs$outboundSchema.parse(indexerDiscoveryConfigs),
  );
}
export function indexerDiscoveryConfigsFromJSON(
  jsonString: string,
): SafeParseResult<IndexerDiscoveryConfigs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => IndexerDiscoveryConfigs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'IndexerDiscoveryConfigs' from JSON`,
  );
}

/** @internal */
export const TLSSplunkLb$inboundSchema: z.ZodType<
  TLSSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TLSSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TLSSplunkLb$outboundSchema: z.ZodType<
  TLSSplunkLb,
  z.ZodTypeDef,
  TLSSplunkLb
> = z.union([
  z.nativeEnum(TLSSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HostSplunkLb$inboundSchema: z.ZodType<
  HostSplunkLb,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number().default(9997),
  tls: TLSSplunkLb$inboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});
/** @internal */
export type HostSplunkLb$Outbound = {
  host: string;
  port: number;
  tls: string;
  servername?: string | undefined;
  weight: number;
};

/** @internal */
export const HostSplunkLb$outboundSchema: z.ZodType<
  HostSplunkLb$Outbound,
  z.ZodTypeDef,
  HostSplunkLb
> = z.object({
  host: z.string(),
  port: z.number().default(9997),
  tls: TLSSplunkLb$outboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});

export function hostSplunkLbToJSON(hostSplunkLb: HostSplunkLb): string {
  return JSON.stringify(HostSplunkLb$outboundSchema.parse(hostSplunkLb));
}
export function hostSplunkLbFromJSON(
  jsonString: string,
): SafeParseResult<HostSplunkLb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostSplunkLb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostSplunkLb' from JSON`,
  );
}

/** @internal */
export const ModeSplunkLb$inboundSchema: z.ZodType<
  ModeSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSplunkLb$outboundSchema: z.ZodType<
  ModeSplunkLb,
  z.ZodTypeDef,
  ModeSplunkLb
> = z.union([
  z.nativeEnum(ModeSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionSplunkLb$inboundSchema: z.ZodType<
  PqCompressCompressionSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionSplunkLb$outboundSchema: z.ZodType<
  PqCompressCompressionSplunkLb,
  z.ZodTypeDef,
  PqCompressCompressionSplunkLb
> = z.union([
  z.nativeEnum(PqCompressCompressionSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSplunkLb$inboundSchema: z.ZodType<
  QueueFullBehaviorSplunkLb,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSplunkLb),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSplunkLb$outboundSchema: z.ZodType<
  QueueFullBehaviorSplunkLb,
  z.ZodTypeDef,
  QueueFullBehaviorSplunkLb
> = z.union([
  z.nativeEnum(QueueFullBehaviorSplunkLb),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSplunkLb$inboundSchema: z.ZodType<
  PqControlsSplunkLb,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSplunkLb$Outbound = {};

/** @internal */
export const PqControlsSplunkLb$outboundSchema: z.ZodType<
  PqControlsSplunkLb$Outbound,
  z.ZodTypeDef,
  PqControlsSplunkLb
> = z.object({});

export function pqControlsSplunkLbToJSON(
  pqControlsSplunkLb: PqControlsSplunkLb,
): string {
  return JSON.stringify(
    PqControlsSplunkLb$outboundSchema.parse(pqControlsSplunkLb),
  );
}
export function pqControlsSplunkLbFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSplunkLb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSplunkLb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSplunkLb' from JSON`,
  );
}

/** @internal */
export const OutputSplunkLb$inboundSchema: z.ZodType<
  OutputSplunkLb,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSplunkLb$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    maxConcurrentSenders: z.number().default(0),
    nestedFields: NestedFieldSerializationSplunkLb$inboundSchema.default(
      "none",
    ),
    throttleRatePerSec: z.string().default("0"),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    tls: z.lazy(() => TLSSettingsClientSideSplunkLb$inboundSchema).optional(),
    enableMultiMetrics: z.boolean().default(false),
    enableACK: z.boolean().default(true),
    logFailedRequests: z.boolean().default(false),
    maxS2Sversion: MaxS2SVersionSplunkLb$inboundSchema.default("v3"),
    onBackpressure: BackpressureBehaviorSplunkLb$inboundSchema.default("block"),
    indexerDiscovery: z.boolean().default(false),
    senderUnhealthyTimeAllowance: z.number().default(100),
    authType: AuthenticationMethodSplunkLb$inboundSchema.default("manual"),
    description: z.string().optional(),
    maxFailedHealthChecks: z.number().default(1),
    compress: CompressCompressionSplunkLb$inboundSchema.default("disabled"),
    indexerDiscoveryConfigs: z.lazy(() => IndexerDiscoveryConfigs$inboundSchema)
      .optional(),
    excludeSelf: z.boolean().default(false),
    hosts: z.array(z.lazy(() => HostSplunkLb$inboundSchema)),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSplunkLb$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionSplunkLb$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSplunkLb$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSplunkLb$inboundSchema).optional(),
    authToken: z.string().default(""),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSplunkLb$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  maxConcurrentSenders: number;
  nestedFields: string;
  throttleRatePerSec: string;
  connectionTimeout: number;
  writeTimeout: number;
  tls?: TLSSettingsClientSideSplunkLb$Outbound | undefined;
  enableMultiMetrics: boolean;
  enableACK: boolean;
  logFailedRequests: boolean;
  maxS2Sversion: string;
  onBackpressure: string;
  indexerDiscovery: boolean;
  senderUnhealthyTimeAllowance: number;
  authType: string;
  description?: string | undefined;
  maxFailedHealthChecks: number;
  compress: string;
  indexerDiscoveryConfigs?: IndexerDiscoveryConfigs$Outbound | undefined;
  excludeSelf: boolean;
  hosts: Array<HostSplunkLb$Outbound>;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSplunkLb$Outbound | undefined;
  authToken: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSplunkLb$outboundSchema: z.ZodType<
  OutputSplunkLb$Outbound,
  z.ZodTypeDef,
  OutputSplunkLb
> = z.object({
  id: z.string().optional(),
  type: TypeSplunkLb$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  maxConcurrentSenders: z.number().default(0),
  nestedFields: NestedFieldSerializationSplunkLb$outboundSchema.default("none"),
  throttleRatePerSec: z.string().default("0"),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  tls: z.lazy(() => TLSSettingsClientSideSplunkLb$outboundSchema).optional(),
  enableMultiMetrics: z.boolean().default(false),
  enableACK: z.boolean().default(true),
  logFailedRequests: z.boolean().default(false),
  maxS2Sversion: MaxS2SVersionSplunkLb$outboundSchema.default("v3"),
  onBackpressure: BackpressureBehaviorSplunkLb$outboundSchema.default("block"),
  indexerDiscovery: z.boolean().default(false),
  senderUnhealthyTimeAllowance: z.number().default(100),
  authType: AuthenticationMethodSplunkLb$outboundSchema.default("manual"),
  description: z.string().optional(),
  maxFailedHealthChecks: z.number().default(1),
  compress: CompressCompressionSplunkLb$outboundSchema.default("disabled"),
  indexerDiscoveryConfigs: z.lazy(() => IndexerDiscoveryConfigs$outboundSchema)
    .optional(),
  excludeSelf: z.boolean().default(false),
  hosts: z.array(z.lazy(() => HostSplunkLb$outboundSchema)),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSplunkLb$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionSplunkLb$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSplunkLb$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSplunkLb$outboundSchema).optional(),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSplunkLbToJSON(outputSplunkLb: OutputSplunkLb): string {
  return JSON.stringify(OutputSplunkLb$outboundSchema.parse(outputSplunkLb));
}
export function outputSplunkLbFromJSON(
  jsonString: string,
): SafeParseResult<OutputSplunkLb, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSplunkLb$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSplunkLb' from JSON`,
  );
}

/** @internal */
export const OutputTypeSplunk$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSplunk
> = z.nativeEnum(OutputTypeSplunk);
/** @internal */
export const OutputTypeSplunk$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSplunk
> = OutputTypeSplunk$inboundSchema;

/** @internal */
export const NestedFieldSerializationSplunk$inboundSchema: z.ZodType<
  NestedFieldSerializationSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(NestedFieldSerializationSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const NestedFieldSerializationSplunk$outboundSchema: z.ZodType<
  NestedFieldSerializationSplunk,
  z.ZodTypeDef,
  NestedFieldSerializationSplunk
> = z.union([
  z.nativeEnum(NestedFieldSerializationSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMinimumTLSVersionSplunk$inboundSchema: z.ZodType<
  OutputMinimumTLSVersionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMinimumTLSVersionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMinimumTLSVersionSplunk$outboundSchema: z.ZodType<
  OutputMinimumTLSVersionSplunk,
  z.ZodTypeDef,
  OutputMinimumTLSVersionSplunk
> = z.union([
  z.nativeEnum(OutputMinimumTLSVersionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputMaximumTLSVersionSplunk$inboundSchema: z.ZodType<
  OutputMaximumTLSVersionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaximumTLSVersionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaximumTLSVersionSplunk$outboundSchema: z.ZodType<
  OutputMaximumTLSVersionSplunk,
  z.ZodTypeDef,
  OutputMaximumTLSVersionSplunk
> = z.union([
  z.nativeEnum(OutputMaximumTLSVersionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideSplunk$inboundSchema: z.ZodType<
  TLSSettingsClientSideSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionSplunk$inboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionSplunk$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideSplunk$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideSplunk$outboundSchema: z.ZodType<
  TLSSettingsClientSideSplunk$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideSplunk
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: OutputMinimumTLSVersionSplunk$outboundSchema.optional(),
  maxVersion: OutputMaximumTLSVersionSplunk$outboundSchema.optional(),
});

export function tlsSettingsClientSideSplunkToJSON(
  tlsSettingsClientSideSplunk: TLSSettingsClientSideSplunk,
): string {
  return JSON.stringify(
    TLSSettingsClientSideSplunk$outboundSchema.parse(
      tlsSettingsClientSideSplunk,
    ),
  );
}
export function tlsSettingsClientSideSplunkFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideSplunk' from JSON`,
  );
}

/** @internal */
export const OutputMaxS2SVersionSplunk$inboundSchema: z.ZodType<
  OutputMaxS2SVersionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMaxS2SVersionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMaxS2SVersionSplunk$outboundSchema: z.ZodType<
  OutputMaxS2SVersionSplunk,
  z.ZodTypeDef,
  OutputMaxS2SVersionSplunk
> = z.union([
  z.nativeEnum(OutputMaxS2SVersionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const BackpressureBehaviorSplunk$inboundSchema: z.ZodType<
  BackpressureBehaviorSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSplunk$outboundSchema: z.ZodType<
  BackpressureBehaviorSplunk,
  z.ZodTypeDef,
  BackpressureBehaviorSplunk
> = z.union([
  z.nativeEnum(BackpressureBehaviorSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationMethodSplunk$inboundSchema: z.ZodType<
  AuthenticationMethodSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodSplunk$outboundSchema: z.ZodType<
  AuthenticationMethodSplunk,
  z.ZodTypeDef,
  AuthenticationMethodSplunk
> = z.union([
  z.nativeEnum(AuthenticationMethodSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCompressCompressionSplunk$inboundSchema: z.ZodType<
  OutputCompressCompressionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCompressCompressionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCompressCompressionSplunk$outboundSchema: z.ZodType<
  OutputCompressCompressionSplunk,
  z.ZodTypeDef,
  OutputCompressCompressionSplunk
> = z.union([
  z.nativeEnum(OutputCompressCompressionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputModeSplunk$inboundSchema: z.ZodType<
  OutputModeSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputModeSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputModeSplunk$outboundSchema: z.ZodType<
  OutputModeSplunk,
  z.ZodTypeDef,
  OutputModeSplunk
> = z.union([
  z.nativeEnum(OutputModeSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressCompressionSplunk$inboundSchema: z.ZodType<
  PqCompressCompressionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressCompressionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressCompressionSplunk$outboundSchema: z.ZodType<
  PqCompressCompressionSplunk,
  z.ZodTypeDef,
  PqCompressCompressionSplunk
> = z.union([
  z.nativeEnum(PqCompressCompressionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSplunk$inboundSchema: z.ZodType<
  QueueFullBehaviorSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSplunk$outboundSchema: z.ZodType<
  QueueFullBehaviorSplunk,
  z.ZodTypeDef,
  QueueFullBehaviorSplunk
> = z.union([
  z.nativeEnum(QueueFullBehaviorSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputPqControlsSplunk$inboundSchema: z.ZodType<
  OutputPqControlsSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type OutputPqControlsSplunk$Outbound = {};

/** @internal */
export const OutputPqControlsSplunk$outboundSchema: z.ZodType<
  OutputPqControlsSplunk$Outbound,
  z.ZodTypeDef,
  OutputPqControlsSplunk
> = z.object({});

export function outputPqControlsSplunkToJSON(
  outputPqControlsSplunk: OutputPqControlsSplunk,
): string {
  return JSON.stringify(
    OutputPqControlsSplunk$outboundSchema.parse(outputPqControlsSplunk),
  );
}
export function outputPqControlsSplunkFromJSON(
  jsonString: string,
): SafeParseResult<OutputPqControlsSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputPqControlsSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputPqControlsSplunk' from JSON`,
  );
}

/** @internal */
export const OutputSplunk$inboundSchema: z.ZodType<
  OutputSplunk,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSplunk$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    host: z.string(),
    port: z.number().default(9997),
    nestedFields: NestedFieldSerializationSplunk$inboundSchema.default("none"),
    throttleRatePerSec: z.string().default("0"),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    tls: z.lazy(() => TLSSettingsClientSideSplunk$inboundSchema).optional(),
    enableMultiMetrics: z.boolean().default(false),
    enableACK: z.boolean().default(true),
    logFailedRequests: z.boolean().default(false),
    maxS2Sversion: OutputMaxS2SVersionSplunk$inboundSchema.default("v3"),
    onBackpressure: BackpressureBehaviorSplunk$inboundSchema.default("block"),
    authType: AuthenticationMethodSplunk$inboundSchema.default("manual"),
    description: z.string().optional(),
    maxFailedHealthChecks: z.number().default(1),
    compress: OutputCompressCompressionSplunk$inboundSchema.default("disabled"),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: OutputModeSplunk$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: PqCompressCompressionSplunk$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSplunk$inboundSchema.default("block"),
    pqControls: z.lazy(() => OutputPqControlsSplunk$inboundSchema).optional(),
    authToken: z.string().default(""),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSplunk$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  host: string;
  port: number;
  nestedFields: string;
  throttleRatePerSec: string;
  connectionTimeout: number;
  writeTimeout: number;
  tls?: TLSSettingsClientSideSplunk$Outbound | undefined;
  enableMultiMetrics: boolean;
  enableACK: boolean;
  logFailedRequests: boolean;
  maxS2Sversion: string;
  onBackpressure: string;
  authType: string;
  description?: string | undefined;
  maxFailedHealthChecks: number;
  compress: string;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: OutputPqControlsSplunk$Outbound | undefined;
  authToken: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSplunk$outboundSchema: z.ZodType<
  OutputSplunk$Outbound,
  z.ZodTypeDef,
  OutputSplunk
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSplunk$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  host: z.string(),
  port: z.number().default(9997),
  nestedFields: NestedFieldSerializationSplunk$outboundSchema.default("none"),
  throttleRatePerSec: z.string().default("0"),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  tls: z.lazy(() => TLSSettingsClientSideSplunk$outboundSchema).optional(),
  enableMultiMetrics: z.boolean().default(false),
  enableACK: z.boolean().default(true),
  logFailedRequests: z.boolean().default(false),
  maxS2Sversion: OutputMaxS2SVersionSplunk$outboundSchema.default("v3"),
  onBackpressure: BackpressureBehaviorSplunk$outboundSchema.default("block"),
  authType: AuthenticationMethodSplunk$outboundSchema.default("manual"),
  description: z.string().optional(),
  maxFailedHealthChecks: z.number().default(1),
  compress: OutputCompressCompressionSplunk$outboundSchema.default("disabled"),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: OutputModeSplunk$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressCompressionSplunk$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSplunk$outboundSchema.default("block"),
  pqControls: z.lazy(() => OutputPqControlsSplunk$outboundSchema).optional(),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSplunkToJSON(outputSplunk: OutputSplunk): string {
  return JSON.stringify(OutputSplunk$outboundSchema.parse(outputSplunk));
}
export function outputSplunkFromJSON(
  jsonString: string,
): SafeParseResult<OutputSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSplunk' from JSON`,
  );
}

/** @internal */
export const OutputTypeSyslog$inboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSyslog
> = z.nativeEnum(OutputTypeSyslog);
/** @internal */
export const OutputTypeSyslog$outboundSchema: z.ZodNativeEnum<
  typeof OutputTypeSyslog
> = OutputTypeSyslog$inboundSchema;

/** @internal */
export const ProtocolSyslog$inboundSchema: z.ZodType<
  ProtocolSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ProtocolSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ProtocolSyslog$outboundSchema: z.ZodType<
  ProtocolSyslog,
  z.ZodTypeDef,
  ProtocolSyslog
> = z.union([
  z.nativeEnum(ProtocolSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const Facility$inboundSchema: z.ZodType<
  Facility,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(Facility),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const Facility$outboundSchema: z.ZodType<
  Facility,
  z.ZodTypeDef,
  Facility
> = z.union([
  z.nativeEnum(Facility),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const SeveritySyslog$inboundSchema: z.ZodType<
  SeveritySyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SeveritySyslog),
    z.number().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SeveritySyslog$outboundSchema: z.ZodType<
  SeveritySyslog,
  z.ZodTypeDef,
  SeveritySyslog
> = z.union([
  z.nativeEnum(SeveritySyslog),
  z.number().and(z.custom<Unrecognized<number>>()),
]);

/** @internal */
export const MessageFormatSyslog$inboundSchema: z.ZodType<
  MessageFormatSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MessageFormatSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MessageFormatSyslog$outboundSchema: z.ZodType<
  MessageFormatSyslog,
  z.ZodTypeDef,
  MessageFormatSyslog
> = z.union([
  z.nativeEnum(MessageFormatSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TimestampFormat$inboundSchema: z.ZodType<
  TimestampFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TimestampFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TimestampFormat$outboundSchema: z.ZodType<
  TimestampFormat,
  z.ZodTypeDef,
  TimestampFormat
> = z.union([
  z.nativeEnum(TimestampFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSyslog$inboundSchema: z.ZodType<
  TLSSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TLSSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TLSSyslog$outboundSchema: z.ZodType<
  TLSSyslog,
  z.ZodTypeDef,
  TLSSyslog
> = z.union([
  z.nativeEnum(TLSSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const HostSyslog$inboundSchema: z.ZodType<
  HostSyslog,
  z.ZodTypeDef,
  unknown
> = z.object({
  host: z.string(),
  port: z.number(),
  tls: TLSSyslog$inboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});
/** @internal */
export type HostSyslog$Outbound = {
  host: string;
  port: number;
  tls: string;
  servername?: string | undefined;
  weight: number;
};

/** @internal */
export const HostSyslog$outboundSchema: z.ZodType<
  HostSyslog$Outbound,
  z.ZodTypeDef,
  HostSyslog
> = z.object({
  host: z.string(),
  port: z.number(),
  tls: TLSSyslog$outboundSchema.default("inherit"),
  servername: z.string().optional(),
  weight: z.number().default(1),
});

export function hostSyslogToJSON(hostSyslog: HostSyslog): string {
  return JSON.stringify(HostSyslog$outboundSchema.parse(hostSyslog));
}
export function hostSyslogFromJSON(
  jsonString: string,
): SafeParseResult<HostSyslog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostSyslog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostSyslog' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionSyslog$inboundSchema: z.ZodType<
  MinimumTLSVersionSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionSyslog$outboundSchema: z.ZodType<
  MinimumTLSVersionSyslog,
  z.ZodTypeDef,
  MinimumTLSVersionSyslog
> = z.union([
  z.nativeEnum(MinimumTLSVersionSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionSyslog$inboundSchema: z.ZodType<
  MaximumTLSVersionSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionSyslog$outboundSchema: z.ZodType<
  MaximumTLSVersionSyslog,
  z.ZodTypeDef,
  MaximumTLSVersionSyslog
> = z.union([
  z.nativeEnum(MaximumTLSVersionSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideSyslog$inboundSchema: z.ZodType<
  TLSSettingsClientSideSyslog,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionSyslog$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionSyslog$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideSyslog$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideSyslog$outboundSchema: z.ZodType<
  TLSSettingsClientSideSyslog$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideSyslog
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionSyslog$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionSyslog$outboundSchema.optional(),
});

export function tlsSettingsClientSideSyslogToJSON(
  tlsSettingsClientSideSyslog: TLSSettingsClientSideSyslog,
): string {
  return JSON.stringify(
    TLSSettingsClientSideSyslog$outboundSchema.parse(
      tlsSettingsClientSideSyslog,
    ),
  );
}
export function tlsSettingsClientSideSyslogFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideSyslog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideSyslog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideSyslog' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSyslog$inboundSchema: z.ZodType<
  BackpressureBehaviorSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSyslog$outboundSchema: z.ZodType<
  BackpressureBehaviorSyslog,
  z.ZodTypeDef,
  BackpressureBehaviorSyslog
> = z.union([
  z.nativeEnum(BackpressureBehaviorSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSyslog$inboundSchema: z.ZodType<
  ModeSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSyslog$outboundSchema: z.ZodType<
  ModeSyslog,
  z.ZodTypeDef,
  ModeSyslog
> = z.union([
  z.nativeEnum(ModeSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSyslog$inboundSchema: z.ZodType<
  CompressionSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSyslog$outboundSchema: z.ZodType<
  CompressionSyslog,
  z.ZodTypeDef,
  CompressionSyslog
> = z.union([
  z.nativeEnum(CompressionSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSyslog$inboundSchema: z.ZodType<
  QueueFullBehaviorSyslog,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSyslog),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSyslog$outboundSchema: z.ZodType<
  QueueFullBehaviorSyslog,
  z.ZodTypeDef,
  QueueFullBehaviorSyslog
> = z.union([
  z.nativeEnum(QueueFullBehaviorSyslog),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSyslog$inboundSchema: z.ZodType<
  PqControlsSyslog,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSyslog$Outbound = {};

/** @internal */
export const PqControlsSyslog$outboundSchema: z.ZodType<
  PqControlsSyslog$Outbound,
  z.ZodTypeDef,
  PqControlsSyslog
> = z.object({});

export function pqControlsSyslogToJSON(
  pqControlsSyslog: PqControlsSyslog,
): string {
  return JSON.stringify(
    PqControlsSyslog$outboundSchema.parse(pqControlsSyslog),
  );
}
export function pqControlsSyslogFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSyslog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSyslog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSyslog' from JSON`,
  );
}

/** @internal */
export const OutputSyslog$inboundSchema: z.ZodType<
  OutputSyslog,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: OutputTypeSyslog$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    protocol: ProtocolSyslog$inboundSchema.default("tcp"),
    facility: Facility$inboundSchema.default(1),
    severity: SeveritySyslog$inboundSchema.default(5),
    appName: z.string().default("Cribl"),
    messageFormat: MessageFormatSyslog$inboundSchema.default("rfc3164"),
    timestampFormat: TimestampFormat$inboundSchema.default("syslog"),
    throttleRatePerSec: z.string().default("0"),
    octetCountFraming: z.boolean().optional(),
    logFailedRequests: z.boolean().default(false),
    description: z.string().optional(),
    loadBalanced: z.boolean().default(true),
    host: z.string().optional(),
    port: z.number().optional(),
    excludeSelf: z.boolean().default(false),
    hosts: z.array(z.lazy(() => HostSyslog$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
    maxConcurrentSenders: z.number().default(0),
    connectionTimeout: z.number().default(10000),
    writeTimeout: z.number().default(60000),
    tls: z.lazy(() => TLSSettingsClientSideSyslog$inboundSchema).optional(),
    onBackpressure: BackpressureBehaviorSyslog$inboundSchema.default("block"),
    maxRecordSize: z.number().default(1500),
    udpDnsResolvePeriodSec: z.number().default(0),
    enableIpSpoofing: z.boolean().default(false),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSyslog$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSyslog$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSyslog$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSyslog$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputSyslog$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol: string;
  facility: number;
  severity: number;
  appName: string;
  messageFormat: string;
  timestampFormat: string;
  throttleRatePerSec: string;
  octetCountFraming?: boolean | undefined;
  logFailedRequests: boolean;
  description?: string | undefined;
  loadBalanced: boolean;
  host?: string | undefined;
  port?: number | undefined;
  excludeSelf: boolean;
  hosts?: Array<HostSyslog$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  maxConcurrentSenders: number;
  connectionTimeout: number;
  writeTimeout: number;
  tls?: TLSSettingsClientSideSyslog$Outbound | undefined;
  onBackpressure: string;
  maxRecordSize: number;
  udpDnsResolvePeriodSec: number;
  enableIpSpoofing: boolean;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSyslog$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSyslog$outboundSchema: z.ZodType<
  OutputSyslog$Outbound,
  z.ZodTypeDef,
  OutputSyslog
> = z.object({
  id: z.string().optional(),
  type: OutputTypeSyslog$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: ProtocolSyslog$outboundSchema.default("tcp"),
  facility: Facility$outboundSchema.default(1),
  severity: SeveritySyslog$outboundSchema.default(5),
  appName: z.string().default("Cribl"),
  messageFormat: MessageFormatSyslog$outboundSchema.default("rfc3164"),
  timestampFormat: TimestampFormat$outboundSchema.default("syslog"),
  throttleRatePerSec: z.string().default("0"),
  octetCountFraming: z.boolean().optional(),
  logFailedRequests: z.boolean().default(false),
  description: z.string().optional(),
  loadBalanced: z.boolean().default(true),
  host: z.string().optional(),
  port: z.number().optional(),
  excludeSelf: z.boolean().default(false),
  hosts: z.array(z.lazy(() => HostSyslog$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  maxConcurrentSenders: z.number().default(0),
  connectionTimeout: z.number().default(10000),
  writeTimeout: z.number().default(60000),
  tls: z.lazy(() => TLSSettingsClientSideSyslog$outboundSchema).optional(),
  onBackpressure: BackpressureBehaviorSyslog$outboundSchema.default("block"),
  maxRecordSize: z.number().default(1500),
  udpDnsResolvePeriodSec: z.number().default(0),
  enableIpSpoofing: z.boolean().default(false),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSyslog$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSyslog$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSyslog$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSyslog$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputSyslogToJSON(outputSyslog: OutputSyslog): string {
  return JSON.stringify(OutputSyslog$outboundSchema.parse(outputSyslog));
}
export function outputSyslogFromJSON(
  jsonString: string,
): SafeParseResult<OutputSyslog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSyslog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSyslog' from JSON`,
  );
}

/** @internal */
export const TypeDevnull$inboundSchema: z.ZodNativeEnum<typeof TypeDevnull> = z
  .nativeEnum(TypeDevnull);
/** @internal */
export const TypeDevnull$outboundSchema: z.ZodNativeEnum<typeof TypeDevnull> =
  TypeDevnull$inboundSchema;

/** @internal */
export const OutputDevnull$inboundSchema: z.ZodType<
  OutputDevnull,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDevnull$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDevnull$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDevnull$outboundSchema: z.ZodType<
  OutputDevnull$Outbound,
  z.ZodTypeDef,
  OutputDevnull
> = z.object({
  id: z.string().optional(),
  type: TypeDevnull$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDevnullToJSON(outputDevnull: OutputDevnull): string {
  return JSON.stringify(OutputDevnull$outboundSchema.parse(outputDevnull));
}
export function outputDevnullFromJSON(
  jsonString: string,
): SafeParseResult<OutputDevnull, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDevnull$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDevnull' from JSON`,
  );
}

/** @internal */
export const TypeSentinel$inboundSchema: z.ZodNativeEnum<typeof TypeSentinel> =
  z.nativeEnum(TypeSentinel);
/** @internal */
export const TypeSentinel$outboundSchema: z.ZodNativeEnum<typeof TypeSentinel> =
  TypeSentinel$inboundSchema;

/** @internal */
export const ExtraHttpHeaderSentinel$inboundSchema: z.ZodType<
  ExtraHttpHeaderSentinel,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderSentinel$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderSentinel$outboundSchema: z.ZodType<
  ExtraHttpHeaderSentinel$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderSentinel
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderSentinelToJSON(
  extraHttpHeaderSentinel: ExtraHttpHeaderSentinel,
): string {
  return JSON.stringify(
    ExtraHttpHeaderSentinel$outboundSchema.parse(extraHttpHeaderSentinel),
  );
}
export function extraHttpHeaderSentinelFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderSentinel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderSentinel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderSentinel' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeSentinel$inboundSchema: z.ZodType<
  FailedRequestLoggingModeSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeSentinel$outboundSchema: z.ZodType<
  FailedRequestLoggingModeSentinel,
  z.ZodTypeDef,
  FailedRequestLoggingModeSentinel
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingSentinel$inboundSchema: z.ZodType<
  ResponseRetrySettingSentinel,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingSentinel$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingSentinel$outboundSchema: z.ZodType<
  ResponseRetrySettingSentinel$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingSentinel
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingSentinelToJSON(
  responseRetrySettingSentinel: ResponseRetrySettingSentinel,
): string {
  return JSON.stringify(
    ResponseRetrySettingSentinel$outboundSchema.parse(
      responseRetrySettingSentinel,
    ),
  );
}
export function responseRetrySettingSentinelFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingSentinel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingSentinel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingSentinel' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsSentinel$inboundSchema: z.ZodType<
  TimeoutRetrySettingsSentinel,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsSentinel$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsSentinel$outboundSchema: z.ZodType<
  TimeoutRetrySettingsSentinel$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsSentinel
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsSentinelToJSON(
  timeoutRetrySettingsSentinel: TimeoutRetrySettingsSentinel,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsSentinel$outboundSchema.parse(
      timeoutRetrySettingsSentinel,
    ),
  );
}
export function timeoutRetrySettingsSentinelFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsSentinel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsSentinel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsSentinel' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorSentinel$inboundSchema: z.ZodType<
  BackpressureBehaviorSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorSentinel$outboundSchema: z.ZodType<
  BackpressureBehaviorSentinel,
  z.ZodTypeDef,
  BackpressureBehaviorSentinel
> = z.union([
  z.nativeEnum(BackpressureBehaviorSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthType$inboundSchema: z.ZodType<
  AuthType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthType$outboundSchema: z.ZodType<
  AuthType,
  z.ZodTypeDef,
  AuthType
> = z.union([
  z.nativeEnum(AuthType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const EndpointConfiguration$inboundSchema: z.ZodType<
  EndpointConfiguration,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(EndpointConfiguration),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const EndpointConfiguration$outboundSchema: z.ZodType<
  EndpointConfiguration,
  z.ZodTypeDef,
  EndpointConfiguration
> = z.union([
  z.nativeEnum(EndpointConfiguration),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FormatSentinel$inboundSchema: z.ZodType<
  FormatSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FormatSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FormatSentinel$outboundSchema: z.ZodType<
  FormatSentinel,
  z.ZodTypeDef,
  FormatSentinel
> = z.union([
  z.nativeEnum(FormatSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ModeSentinel$inboundSchema: z.ZodType<
  ModeSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSentinel$outboundSchema: z.ZodType<
  ModeSentinel,
  z.ZodTypeDef,
  ModeSentinel
> = z.union([
  z.nativeEnum(ModeSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSentinel$inboundSchema: z.ZodType<
  CompressionSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSentinel$outboundSchema: z.ZodType<
  CompressionSentinel,
  z.ZodTypeDef,
  CompressionSentinel
> = z.union([
  z.nativeEnum(CompressionSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorSentinel$inboundSchema: z.ZodType<
  QueueFullBehaviorSentinel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorSentinel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorSentinel$outboundSchema: z.ZodType<
  QueueFullBehaviorSentinel,
  z.ZodTypeDef,
  QueueFullBehaviorSentinel
> = z.union([
  z.nativeEnum(QueueFullBehaviorSentinel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSentinel$inboundSchema: z.ZodType<
  PqControlsSentinel,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSentinel$Outbound = {};

/** @internal */
export const PqControlsSentinel$outboundSchema: z.ZodType<
  PqControlsSentinel$Outbound,
  z.ZodTypeDef,
  PqControlsSentinel
> = z.object({});

export function pqControlsSentinelToJSON(
  pqControlsSentinel: PqControlsSentinel,
): string {
  return JSON.stringify(
    PqControlsSentinel$outboundSchema.parse(pqControlsSentinel),
  );
}
export function pqControlsSentinelFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSentinel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSentinel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSentinel' from JSON`,
  );
}

/** @internal */
export const OutputSentinel$inboundSchema: z.ZodType<
  OutputSentinel,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSentinel$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    keepAlive: z.boolean().default(true),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(1000),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderSentinel$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeSentinel$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingSentinel$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsSentinel$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorSentinel$inboundSchema.default("block"),
    authType: AuthType$inboundSchema.optional(),
    loginUrl: z.string(),
    secret: z.string(),
    client_id: z.string(),
    scope: z.string().default("https://monitor.azure.com/.default"),
    endpointURLConfiguration: EndpointConfiguration$inboundSchema.default(
      "url",
    ),
    totalMemoryLimitKB: z.number().optional(),
    description: z.string().optional(),
    format: FormatSentinel$inboundSchema.optional(),
    customSourceExpression: z.string().default("__httpOut"),
    customDropWhenNull: z.boolean().default(false),
    customEventDelimiter: z.string().default("\\n"),
    customContentType: z.string().default("application/x-ndjson"),
    customPayloadExpression: z.string().default("`${events}`"),
    advancedContentType: z.string().default("application/json"),
    formatEventCode: z.string().optional(),
    formatPayloadCode: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeSentinel$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionSentinel$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorSentinel$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsSentinel$inboundSchema).optional(),
    url: z.string().optional(),
    dcrID: z.string().optional(),
    dceEndpoint: z.string().optional(),
    streamName: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
).transform((v) => {
  return remap$(v, {
    "client_id": "clientId",
  });
});
/** @internal */
export type OutputSentinel$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  keepAlive: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderSentinel$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingSentinel$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsSentinel$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType?: string | undefined;
  loginUrl: string;
  secret: string;
  client_id: string;
  scope: string;
  endpointURLConfiguration: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  format?: string | undefined;
  customSourceExpression: string;
  customDropWhenNull: boolean;
  customEventDelimiter: string;
  customContentType: string;
  customPayloadExpression: string;
  advancedContentType: string;
  formatEventCode?: string | undefined;
  formatPayloadCode?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsSentinel$Outbound | undefined;
  url?: string | undefined;
  dcrID?: string | undefined;
  dceEndpoint?: string | undefined;
  streamName?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputSentinel$outboundSchema: z.ZodType<
  OutputSentinel$Outbound,
  z.ZodTypeDef,
  OutputSentinel
> = z.object({
  id: z.string().optional(),
  type: TypeSentinel$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  keepAlive: z.boolean().default(true),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(1000),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(
    z.lazy(() => ExtraHttpHeaderSentinel$outboundSchema),
  ).optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeSentinel$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingSentinel$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() =>
    TimeoutRetrySettingsSentinel$outboundSchema
  ).optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorSentinel$outboundSchema.default("block"),
  authType: AuthType$outboundSchema.optional(),
  loginUrl: z.string(),
  secret: z.string(),
  clientId: z.string(),
  scope: z.string().default("https://monitor.azure.com/.default"),
  endpointURLConfiguration: EndpointConfiguration$outboundSchema.default("url"),
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  format: FormatSentinel$outboundSchema.optional(),
  customSourceExpression: z.string().default("__httpOut"),
  customDropWhenNull: z.boolean().default(false),
  customEventDelimiter: z.string().default("\\n"),
  customContentType: z.string().default("application/x-ndjson"),
  customPayloadExpression: z.string().default("`${events}`"),
  advancedContentType: z.string().default("application/json"),
  formatEventCode: z.string().optional(),
  formatPayloadCode: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeSentinel$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionSentinel$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorSentinel$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsSentinel$outboundSchema).optional(),
  url: z.string().optional(),
  dcrID: z.string().optional(),
  dceEndpoint: z.string().optional(),
  streamName: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      clientId: "client_id",
      additionalProperties: null,
    }),
  };
});

export function outputSentinelToJSON(outputSentinel: OutputSentinel): string {
  return JSON.stringify(OutputSentinel$outboundSchema.parse(outputSentinel));
}
export function outputSentinelFromJSON(
  jsonString: string,
): SafeParseResult<OutputSentinel, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputSentinel$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputSentinel' from JSON`,
  );
}

/** @internal */
export const TypeWebhook$inboundSchema: z.ZodNativeEnum<typeof TypeWebhook> = z
  .nativeEnum(TypeWebhook);
/** @internal */
export const TypeWebhook$outboundSchema: z.ZodNativeEnum<typeof TypeWebhook> =
  TypeWebhook$inboundSchema;

/** @internal */
export const MethodWebhook$inboundSchema: z.ZodType<
  MethodWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MethodWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MethodWebhook$outboundSchema: z.ZodType<
  MethodWebhook,
  z.ZodTypeDef,
  MethodWebhook
> = z.union([
  z.nativeEnum(MethodWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const FormatWebhook$inboundSchema: z.ZodType<
  FormatWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FormatWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FormatWebhook$outboundSchema: z.ZodType<
  FormatWebhook,
  z.ZodTypeDef,
  FormatWebhook
> = z.union([
  z.nativeEnum(FormatWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ExtraHttpHeaderWebhook$inboundSchema: z.ZodType<
  ExtraHttpHeaderWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type ExtraHttpHeaderWebhook$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const ExtraHttpHeaderWebhook$outboundSchema: z.ZodType<
  ExtraHttpHeaderWebhook$Outbound,
  z.ZodTypeDef,
  ExtraHttpHeaderWebhook
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function extraHttpHeaderWebhookToJSON(
  extraHttpHeaderWebhook: ExtraHttpHeaderWebhook,
): string {
  return JSON.stringify(
    ExtraHttpHeaderWebhook$outboundSchema.parse(extraHttpHeaderWebhook),
  );
}
export function extraHttpHeaderWebhookFromJSON(
  jsonString: string,
): SafeParseResult<ExtraHttpHeaderWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ExtraHttpHeaderWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ExtraHttpHeaderWebhook' from JSON`,
  );
}

/** @internal */
export const FailedRequestLoggingModeWebhook$inboundSchema: z.ZodType<
  FailedRequestLoggingModeWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(FailedRequestLoggingModeWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const FailedRequestLoggingModeWebhook$outboundSchema: z.ZodType<
  FailedRequestLoggingModeWebhook,
  z.ZodTypeDef,
  FailedRequestLoggingModeWebhook
> = z.union([
  z.nativeEnum(FailedRequestLoggingModeWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ResponseRetrySettingWebhook$inboundSchema: z.ZodType<
  ResponseRetrySettingWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type ResponseRetrySettingWebhook$Outbound = {
  httpStatus: number;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const ResponseRetrySettingWebhook$outboundSchema: z.ZodType<
  ResponseRetrySettingWebhook$Outbound,
  z.ZodTypeDef,
  ResponseRetrySettingWebhook
> = z.object({
  httpStatus: z.number(),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function responseRetrySettingWebhookToJSON(
  responseRetrySettingWebhook: ResponseRetrySettingWebhook,
): string {
  return JSON.stringify(
    ResponseRetrySettingWebhook$outboundSchema.parse(
      responseRetrySettingWebhook,
    ),
  );
}
export function responseRetrySettingWebhookFromJSON(
  jsonString: string,
): SafeParseResult<ResponseRetrySettingWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ResponseRetrySettingWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ResponseRetrySettingWebhook' from JSON`,
  );
}

/** @internal */
export const TimeoutRetrySettingsWebhook$inboundSchema: z.ZodType<
  TimeoutRetrySettingsWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});
/** @internal */
export type TimeoutRetrySettingsWebhook$Outbound = {
  timeoutRetry: boolean;
  initialBackoff: number;
  backoffRate: number;
  maxBackoff: number;
};

/** @internal */
export const TimeoutRetrySettingsWebhook$outboundSchema: z.ZodType<
  TimeoutRetrySettingsWebhook$Outbound,
  z.ZodTypeDef,
  TimeoutRetrySettingsWebhook
> = z.object({
  timeoutRetry: z.boolean().default(false),
  initialBackoff: z.number().default(1000),
  backoffRate: z.number().default(2),
  maxBackoff: z.number().default(10000),
});

export function timeoutRetrySettingsWebhookToJSON(
  timeoutRetrySettingsWebhook: TimeoutRetrySettingsWebhook,
): string {
  return JSON.stringify(
    TimeoutRetrySettingsWebhook$outboundSchema.parse(
      timeoutRetrySettingsWebhook,
    ),
  );
}
export function timeoutRetrySettingsWebhookFromJSON(
  jsonString: string,
): SafeParseResult<TimeoutRetrySettingsWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TimeoutRetrySettingsWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TimeoutRetrySettingsWebhook' from JSON`,
  );
}

/** @internal */
export const BackpressureBehaviorWebhook$inboundSchema: z.ZodType<
  BackpressureBehaviorWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(BackpressureBehaviorWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const BackpressureBehaviorWebhook$outboundSchema: z.ZodType<
  BackpressureBehaviorWebhook,
  z.ZodTypeDef,
  BackpressureBehaviorWebhook
> = z.union([
  z.nativeEnum(BackpressureBehaviorWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthenticationTypeWebhook$inboundSchema: z.ZodType<
  AuthenticationTypeWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeWebhook$outboundSchema: z.ZodType<
  AuthenticationTypeWebhook,
  z.ZodTypeDef,
  AuthenticationTypeWebhook
> = z.union([
  z.nativeEnum(AuthenticationTypeWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MinimumTLSVersionWebhook$inboundSchema: z.ZodType<
  MinimumTLSVersionWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionWebhook$outboundSchema: z.ZodType<
  MinimumTLSVersionWebhook,
  z.ZodTypeDef,
  MinimumTLSVersionWebhook
> = z.union([
  z.nativeEnum(MinimumTLSVersionWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionWebhook$inboundSchema: z.ZodType<
  MaximumTLSVersionWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionWebhook$outboundSchema: z.ZodType<
  MaximumTLSVersionWebhook,
  z.ZodTypeDef,
  MaximumTLSVersionWebhook
> = z.union([
  z.nativeEnum(MaximumTLSVersionWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsClientSideWebhook$inboundSchema: z.ZodType<
  TLSSettingsClientSideWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionWebhook$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionWebhook$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsClientSideWebhook$Outbound = {
  disabled: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsClientSideWebhook$outboundSchema: z.ZodType<
  TLSSettingsClientSideWebhook$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideWebhook
> = z.object({
  disabled: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: MinimumTLSVersionWebhook$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionWebhook$outboundSchema.optional(),
});

export function tlsSettingsClientSideWebhookToJSON(
  tlsSettingsClientSideWebhook: TLSSettingsClientSideWebhook,
): string {
  return JSON.stringify(
    TLSSettingsClientSideWebhook$outboundSchema.parse(
      tlsSettingsClientSideWebhook,
    ),
  );
}
export function tlsSettingsClientSideWebhookFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideWebhook' from JSON`,
  );
}

/** @internal */
export const ModeWebhook$inboundSchema: z.ZodType<
  ModeWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeWebhook$outboundSchema: z.ZodType<
  ModeWebhook,
  z.ZodTypeDef,
  ModeWebhook
> = z.union([
  z.nativeEnum(ModeWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionWebhook$inboundSchema: z.ZodType<
  CompressionWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWebhook$outboundSchema: z.ZodType<
  CompressionWebhook,
  z.ZodTypeDef,
  CompressionWebhook
> = z.union([
  z.nativeEnum(CompressionWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueueFullBehaviorWebhook$inboundSchema: z.ZodType<
  QueueFullBehaviorWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueueFullBehaviorWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueueFullBehaviorWebhook$outboundSchema: z.ZodType<
  QueueFullBehaviorWebhook,
  z.ZodTypeDef,
  QueueFullBehaviorWebhook
> = z.union([
  z.nativeEnum(QueueFullBehaviorWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWebhook$inboundSchema: z.ZodType<
  PqControlsWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWebhook$Outbound = {};

/** @internal */
export const PqControlsWebhook$outboundSchema: z.ZodType<
  PqControlsWebhook$Outbound,
  z.ZodTypeDef,
  PqControlsWebhook
> = z.object({});

export function pqControlsWebhookToJSON(
  pqControlsWebhook: PqControlsWebhook,
): string {
  return JSON.stringify(
    PqControlsWebhook$outboundSchema.parse(pqControlsWebhook),
  );
}
export function pqControlsWebhookFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWebhook' from JSON`,
  );
}

/** @internal */
export const OauthParamWebhook$inboundSchema: z.ZodType<
  OauthParamWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamWebhook$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamWebhook$outboundSchema: z.ZodType<
  OauthParamWebhook$Outbound,
  z.ZodTypeDef,
  OauthParamWebhook
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamWebhookToJSON(
  oauthParamWebhook: OauthParamWebhook,
): string {
  return JSON.stringify(
    OauthParamWebhook$outboundSchema.parse(oauthParamWebhook),
  );
}
export function oauthParamWebhookFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamWebhook' from JSON`,
  );
}

/** @internal */
export const OauthHeaderWebhook$inboundSchema: z.ZodType<
  OauthHeaderWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderWebhook$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderWebhook$outboundSchema: z.ZodType<
  OauthHeaderWebhook$Outbound,
  z.ZodTypeDef,
  OauthHeaderWebhook
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderWebhookToJSON(
  oauthHeaderWebhook: OauthHeaderWebhook,
): string {
  return JSON.stringify(
    OauthHeaderWebhook$outboundSchema.parse(oauthHeaderWebhook),
  );
}
export function oauthHeaderWebhookFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderWebhook' from JSON`,
  );
}

/** @internal */
export const UrlWebhook$inboundSchema: z.ZodType<
  UrlWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});
/** @internal */
export type UrlWebhook$Outbound = {
  url: string;
  weight: number;
};

/** @internal */
export const UrlWebhook$outboundSchema: z.ZodType<
  UrlWebhook$Outbound,
  z.ZodTypeDef,
  UrlWebhook
> = z.object({
  url: z.string(),
  weight: z.number().default(1),
});

export function urlWebhookToJSON(urlWebhook: UrlWebhook): string {
  return JSON.stringify(UrlWebhook$outboundSchema.parse(urlWebhook));
}
export function urlWebhookFromJSON(
  jsonString: string,
): SafeParseResult<UrlWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UrlWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UrlWebhook' from JSON`,
  );
}

/** @internal */
export const OutputWebhook$inboundSchema: z.ZodType<
  OutputWebhook,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWebhook$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    method: MethodWebhook$inboundSchema.default("POST"),
    format: FormatWebhook$inboundSchema.default("ndjson"),
    keepAlive: z.boolean().default(true),
    concurrency: z.number().default(5),
    maxPayloadSizeKB: z.number().default(4096),
    maxPayloadEvents: z.number().default(0),
    compress: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    timeoutSec: z.number().default(30),
    flushPeriodSec: z.number().default(1),
    extraHttpHeaders: z.array(
      z.lazy(() => ExtraHttpHeaderWebhook$inboundSchema),
    ).optional(),
    useRoundRobinDns: z.boolean().default(false),
    failedRequestLoggingMode: FailedRequestLoggingModeWebhook$inboundSchema
      .default("none"),
    safeHeaders: z.array(z.string()).optional(),
    responseRetrySettings: z.array(
      z.lazy(() => ResponseRetrySettingWebhook$inboundSchema),
    ).optional(),
    timeoutRetrySettings: z.lazy(() =>
      TimeoutRetrySettingsWebhook$inboundSchema
    ).optional(),
    responseHonorRetryAfterHeader: z.boolean().default(false),
    onBackpressure: BackpressureBehaviorWebhook$inboundSchema.default("block"),
    authType: AuthenticationTypeWebhook$inboundSchema.default("none"),
    tls: z.lazy(() => TLSSettingsClientSideWebhook$inboundSchema).optional(),
    totalMemoryLimitKB: z.number().optional(),
    loadBalanced: z.boolean().default(false),
    description: z.string().optional(),
    customSourceExpression: z.string().default("__httpOut"),
    customDropWhenNull: z.boolean().default(false),
    customEventDelimiter: z.string().default("\\n"),
    customContentType: z.string().default("application/x-ndjson"),
    customPayloadExpression: z.string().default("`${events}`"),
    advancedContentType: z.string().default("application/json"),
    formatEventCode: z.string().optional(),
    formatPayloadCode: z.string().optional(),
    pqStrictOrdering: z.boolean().default(true),
    pqRatePerSec: z.number().default(0),
    pqMode: ModeWebhook$inboundSchema.default("error"),
    pqMaxBufferSize: z.number().default(42),
    pqMaxBackpressureSec: z.number().default(30),
    pqMaxFileSize: z.string().default("1 MB"),
    pqMaxSize: z.string().default("5GB"),
    pqPath: z.string().default("$CRIBL_HOME/state/queues"),
    pqCompress: CompressionWebhook$inboundSchema.default("none"),
    pqOnBackpressure: QueueFullBehaviorWebhook$inboundSchema.default("block"),
    pqControls: z.lazy(() => PqControlsWebhook$inboundSchema).optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamWebhook$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderWebhook$inboundSchema))
      .optional(),
    url: z.string().optional(),
    excludeSelf: z.boolean().default(false),
    urls: z.array(z.lazy(() => UrlWebhook$inboundSchema)).optional(),
    dnsResolvePeriodSec: z.number().default(600),
    loadBalanceStatsPeriodSec: z.number().default(300),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputWebhook$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  method: string;
  format: string;
  keepAlive: boolean;
  concurrency: number;
  maxPayloadSizeKB: number;
  maxPayloadEvents: number;
  compress: boolean;
  rejectUnauthorized: boolean;
  timeoutSec: number;
  flushPeriodSec: number;
  extraHttpHeaders?: Array<ExtraHttpHeaderWebhook$Outbound> | undefined;
  useRoundRobinDns: boolean;
  failedRequestLoggingMode: string;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<ResponseRetrySettingWebhook$Outbound>
    | undefined;
  timeoutRetrySettings?: TimeoutRetrySettingsWebhook$Outbound | undefined;
  responseHonorRetryAfterHeader: boolean;
  onBackpressure: string;
  authType: string;
  tls?: TLSSettingsClientSideWebhook$Outbound | undefined;
  totalMemoryLimitKB?: number | undefined;
  loadBalanced: boolean;
  description?: string | undefined;
  customSourceExpression: string;
  customDropWhenNull: boolean;
  customEventDelimiter: string;
  customContentType: string;
  customPayloadExpression: string;
  advancedContentType: string;
  formatEventCode?: string | undefined;
  formatPayloadCode?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: PqControlsWebhook$Outbound | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamWebhook$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderWebhook$Outbound> | undefined;
  url?: string | undefined;
  excludeSelf: boolean;
  urls?: Array<UrlWebhook$Outbound> | undefined;
  dnsResolvePeriodSec: number;
  loadBalanceStatsPeriodSec: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputWebhook$outboundSchema: z.ZodType<
  OutputWebhook$Outbound,
  z.ZodTypeDef,
  OutputWebhook
> = z.object({
  id: z.string().optional(),
  type: TypeWebhook$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  method: MethodWebhook$outboundSchema.default("POST"),
  format: FormatWebhook$outboundSchema.default("ndjson"),
  keepAlive: z.boolean().default(true),
  concurrency: z.number().default(5),
  maxPayloadSizeKB: z.number().default(4096),
  maxPayloadEvents: z.number().default(0),
  compress: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  timeoutSec: z.number().default(30),
  flushPeriodSec: z.number().default(1),
  extraHttpHeaders: z.array(z.lazy(() => ExtraHttpHeaderWebhook$outboundSchema))
    .optional(),
  useRoundRobinDns: z.boolean().default(false),
  failedRequestLoggingMode: FailedRequestLoggingModeWebhook$outboundSchema
    .default("none"),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    z.lazy(() => ResponseRetrySettingWebhook$outboundSchema),
  ).optional(),
  timeoutRetrySettings: z.lazy(() => TimeoutRetrySettingsWebhook$outboundSchema)
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().default(false),
  onBackpressure: BackpressureBehaviorWebhook$outboundSchema.default("block"),
  authType: AuthenticationTypeWebhook$outboundSchema.default("none"),
  tls: z.lazy(() => TLSSettingsClientSideWebhook$outboundSchema).optional(),
  totalMemoryLimitKB: z.number().optional(),
  loadBalanced: z.boolean().default(false),
  description: z.string().optional(),
  customSourceExpression: z.string().default("__httpOut"),
  customDropWhenNull: z.boolean().default(false),
  customEventDelimiter: z.string().default("\\n"),
  customContentType: z.string().default("application/x-ndjson"),
  customPayloadExpression: z.string().default("`${events}`"),
  advancedContentType: z.string().default("application/json"),
  formatEventCode: z.string().optional(),
  formatPayloadCode: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: ModeWebhook$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: CompressionWebhook$outboundSchema.default("none"),
  pqOnBackpressure: QueueFullBehaviorWebhook$outboundSchema.default("block"),
  pqControls: z.lazy(() => PqControlsWebhook$outboundSchema).optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamWebhook$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderWebhook$outboundSchema))
    .optional(),
  url: z.string().optional(),
  excludeSelf: z.boolean().default(false),
  urls: z.array(z.lazy(() => UrlWebhook$outboundSchema)).optional(),
  dnsResolvePeriodSec: z.number().default(600),
  loadBalanceStatsPeriodSec: z.number().default(300),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputWebhookToJSON(outputWebhook: OutputWebhook): string {
  return JSON.stringify(OutputWebhook$outboundSchema.parse(outputWebhook));
}
export function outputWebhookFromJSON(
  jsonString: string,
): SafeParseResult<OutputWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputWebhook' from JSON`,
  );
}

/** @internal */
export const TypeDefault$inboundSchema: z.ZodNativeEnum<typeof TypeDefault> = z
  .nativeEnum(TypeDefault);
/** @internal */
export const TypeDefault$outboundSchema: z.ZodNativeEnum<typeof TypeDefault> =
  TypeDefault$inboundSchema;

/** @internal */
export const OutputDefault$inboundSchema: z.ZodType<
  OutputDefault,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDefault$inboundSchema,
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    defaultId: z.string(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type OutputDefault$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  defaultId: string;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const OutputDefault$outboundSchema: z.ZodType<
  OutputDefault$Outbound,
  z.ZodTypeDef,
  OutputDefault
> = z.object({
  id: z.string().optional(),
  type: TypeDefault$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  defaultId: z.string(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function outputDefaultToJSON(outputDefault: OutputDefault): string {
  return JSON.stringify(OutputDefault$outboundSchema.parse(outputDefault));
}
export function outputDefaultFromJSON(
  jsonString: string,
): SafeParseResult<OutputDefault, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputDefault$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputDefault' from JSON`,
  );
}

/** @internal */
export const Output$inboundSchema: z.ZodType<Output, z.ZodTypeDef, unknown> = z
  .union([
    z.lazy(() => OutputAzureDataExplorer$inboundSchema).and(
      z.object({ type: z.literal("azure_data_explorer") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSecurityLake$inboundSchema).and(
      z.object({ type: z.literal("security_lake") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputChronicle$inboundSchema).and(
      z.object({ type: z.literal("chronicle") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSentinel$inboundSchema).and(
      z.object({ type: z.literal("sentinel") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputGoogleCloudLogging$inboundSchema).and(
      z.object({ type: z.literal("google_cloud_logging") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputExabeam$inboundSchema).and(
      z.object({ type: z.literal("exabeam") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputMsk$inboundSchema).and(
      z.object({ type: z.literal("msk") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => OutputCloudwatch$inboundSchema).and(
      z.object({ type: z.literal("cloudwatch") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputClickHouse$inboundSchema).and(
      z.object({ type: z.literal("click_house") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDatabricks$inboundSchema).and(
      z.object({ type: z.literal("databricks") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputKinesis$inboundSchema).and(
      z.object({ type: z.literal("kinesis") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputAzureEventhub$inboundSchema).and(
      z.object({ type: z.literal("azure_eventhub") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputGoogleCloudStorage$inboundSchema).and(
      z.object({ type: z.literal("google_cloud_storage") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputKafka$inboundSchema).and(
      z.object({ type: z.literal("kafka") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputConfluentCloud$inboundSchema).and(
      z.object({ type: z.literal("confluent_cloud") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputElasticCloud$inboundSchema).and(
      z.object({ type: z.literal("elastic_cloud") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputNewrelicEvents$inboundSchema).and(
      z.object({ type: z.literal("newrelic_events") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputMinio$inboundSchema).and(
      z.object({ type: z.literal("minio") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSns$inboundSchema).and(
      z.object({ type: z.literal("sns") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => OutputSqs$inboundSchema).and(
      z.object({ type: z.literal("sqs") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => OutputMicrosoftFabric$inboundSchema).and(
      z.object({ type: z.literal("microsoft_fabric") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputCloudflareR2$inboundSchema).and(
      z.object({ type: z.literal("cloudflare_r2") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDefault$inboundSchema).and(
      z.object({ type: z.literal("default") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSplunk$inboundSchema).and(
      z.object({ type: z.literal("splunk") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSplunkLb$inboundSchema).and(
      z.object({ type: z.literal("splunk_lb") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputFilesystem$inboundSchema).and(
      z.object({ type: z.literal("filesystem") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputS3$inboundSchema).and(
      z.object({ type: z.literal("s3") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => OutputAzureBlob$inboundSchema).and(
      z.object({ type: z.literal("azure_blob") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputHoneycomb$inboundSchema).and(
      z.object({ type: z.literal("honeycomb") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputGooglePubsub$inboundSchema).and(
      z.object({ type: z.literal("google_pubsub") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputElastic$inboundSchema).and(
      z.object({ type: z.literal("elastic") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputInfluxdb$inboundSchema).and(
      z.object({ type: z.literal("influxdb") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputStatsd$inboundSchema).and(
      z.object({ type: z.literal("statsd") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputStatsdExt$inboundSchema).and(
      z.object({ type: z.literal("statsd_ext") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputGraphite$inboundSchema).and(
      z.object({ type: z.literal("graphite") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputRouter$inboundSchema).and(
      z.object({ type: z.literal("router") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSnmp$inboundSchema).and(
      z.object({ type: z.literal("snmp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSumoLogic$inboundSchema).and(
      z.object({ type: z.literal("sumo_logic") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputLoki$inboundSchema).and(
      z.object({ type: z.literal("loki") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputPrometheus$inboundSchema).and(
      z.object({ type: z.literal("prometheus") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputOpenTelemetry$inboundSchema).and(
      z.object({ type: z.literal("open_telemetry") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputServiceNow$inboundSchema).and(
      z.object({ type: z.literal("service_now") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputCrowdstrikeNextGenSiem$inboundSchema).and(
      z.object({ type: z.literal("crowdstrike_next_gen_siem") }).transform((
        v,
      ) => ({ type: v.type })),
    ),
    z.lazy(() => OutputDlS3$inboundSchema).and(
      z.object({ type: z.literal("dl_s3") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputNetflow$inboundSchema).and(
      z.object({ type: z.literal("netflow") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDynatraceOtlp$inboundSchema).and(
      z.object({ type: z.literal("dynatrace_otlp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputWebhook$inboundSchema).and(
      z.object({ type: z.literal("webhook") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDevnull$inboundSchema).and(
      z.object({ type: z.literal("devnull") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSyslog$inboundSchema).and(
      z.object({ type: z.literal("syslog") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSplunkHec$inboundSchema).and(
      z.object({ type: z.literal("splunk_hec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputTcpjson$inboundSchema).and(
      z.object({ type: z.literal("tcpjson") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputWavefront$inboundSchema).and(
      z.object({ type: z.literal("wavefront") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSignalfx$inboundSchema).and(
      z.object({ type: z.literal("signalfx") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputAzureLogs$inboundSchema).and(
      z.object({ type: z.literal("azure_logs") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputGoogleChronicle$inboundSchema).and(
      z.object({ type: z.literal("google_chronicle") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputNewrelic$inboundSchema).and(
      z.object({ type: z.literal("newrelic") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDatadog$inboundSchema).and(
      z.object({ type: z.literal("datadog") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputRing$inboundSchema).and(
      z.object({ type: z.literal("ring") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDataset$inboundSchema).and(
      z.object({ type: z.literal("dataset") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputCriblTcp$inboundSchema).and(
      z.object({ type: z.literal("cribl_tcp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputCriblHttp$inboundSchema).and(
      z.object({ type: z.literal("cribl_http") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputHumioHec$inboundSchema).and(
      z.object({ type: z.literal("humio_hec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputCriblLake$inboundSchema).and(
      z.object({ type: z.literal("cribl_lake") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDiskSpool$inboundSchema).and(
      z.object({ type: z.literal("disk_spool") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputXsiam$inboundSchema).and(
      z.object({ type: z.literal("xsiam") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputDynatraceHttp$inboundSchema).and(
      z.object({ type: z.literal("dynatrace_http") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => OutputSentinelOneAiSiem$inboundSchema).and(
      z.object({ type: z.literal("sentinel_one_ai_siem") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.union([
      z.lazy(() => OutputGrafanaCloudGrafanaCloud1$inboundSchema),
      z.lazy(() => OutputGrafanaCloudGrafanaCloud2$inboundSchema),
    ]).and(
      z.object({ type: z.literal("grafana_cloud") }).transform((v) => ({
        type: v.type,
      })),
    ),
  ]);
/** @internal */
export type Output$Outbound =
  | (OutputAzureDataExplorer$Outbound & { type: "azure_data_explorer" })
  | (OutputSecurityLake$Outbound & { type: "security_lake" })
  | (OutputChronicle$Outbound & { type: "chronicle" })
  | (OutputSentinel$Outbound & { type: "sentinel" })
  | (OutputGoogleCloudLogging$Outbound & { type: "google_cloud_logging" })
  | (OutputExabeam$Outbound & { type: "exabeam" })
  | (OutputMsk$Outbound & { type: "msk" })
  | (OutputCloudwatch$Outbound & { type: "cloudwatch" })
  | (OutputClickHouse$Outbound & { type: "click_house" })
  | (OutputDatabricks$Outbound & { type: "databricks" })
  | (OutputKinesis$Outbound & { type: "kinesis" })
  | (OutputAzureEventhub$Outbound & { type: "azure_eventhub" })
  | (OutputGoogleCloudStorage$Outbound & { type: "google_cloud_storage" })
  | (OutputKafka$Outbound & { type: "kafka" })
  | (OutputConfluentCloud$Outbound & { type: "confluent_cloud" })
  | (OutputElasticCloud$Outbound & { type: "elastic_cloud" })
  | (OutputNewrelicEvents$Outbound & { type: "newrelic_events" })
  | (OutputMinio$Outbound & { type: "minio" })
  | (OutputSns$Outbound & { type: "sns" })
  | (OutputSqs$Outbound & { type: "sqs" })
  | (OutputMicrosoftFabric$Outbound & { type: "microsoft_fabric" })
  | (OutputCloudflareR2$Outbound & { type: "cloudflare_r2" })
  | (OutputDefault$Outbound & { type: "default" })
  | (OutputSplunk$Outbound & { type: "splunk" })
  | (OutputSplunkLb$Outbound & { type: "splunk_lb" })
  | (OutputFilesystem$Outbound & { type: "filesystem" })
  | (OutputS3$Outbound & { type: "s3" })
  | (OutputAzureBlob$Outbound & { type: "azure_blob" })
  | (OutputHoneycomb$Outbound & { type: "honeycomb" })
  | (OutputGooglePubsub$Outbound & { type: "google_pubsub" })
  | (OutputElastic$Outbound & { type: "elastic" })
  | (OutputInfluxdb$Outbound & { type: "influxdb" })
  | (OutputStatsd$Outbound & { type: "statsd" })
  | (OutputStatsdExt$Outbound & { type: "statsd_ext" })
  | (OutputGraphite$Outbound & { type: "graphite" })
  | (OutputRouter$Outbound & { type: "router" })
  | (OutputSnmp$Outbound & { type: "snmp" })
  | (OutputSumoLogic$Outbound & { type: "sumo_logic" })
  | (OutputLoki$Outbound & { type: "loki" })
  | (OutputPrometheus$Outbound & { type: "prometheus" })
  | (OutputOpenTelemetry$Outbound & { type: "open_telemetry" })
  | (OutputServiceNow$Outbound & { type: "service_now" })
  | (OutputCrowdstrikeNextGenSiem$Outbound & {
    type: "crowdstrike_next_gen_siem";
  })
  | (OutputDlS3$Outbound & { type: "dl_s3" })
  | (OutputNetflow$Outbound & { type: "netflow" })
  | (OutputDynatraceOtlp$Outbound & { type: "dynatrace_otlp" })
  | (OutputWebhook$Outbound & { type: "webhook" })
  | (OutputDevnull$Outbound & { type: "devnull" })
  | (OutputSyslog$Outbound & { type: "syslog" })
  | (OutputSplunkHec$Outbound & { type: "splunk_hec" })
  | (OutputTcpjson$Outbound & { type: "tcpjson" })
  | (OutputWavefront$Outbound & { type: "wavefront" })
  | (OutputSignalfx$Outbound & { type: "signalfx" })
  | (OutputAzureLogs$Outbound & { type: "azure_logs" })
  | (OutputGoogleChronicle$Outbound & { type: "google_chronicle" })
  | (OutputNewrelic$Outbound & { type: "newrelic" })
  | (OutputDatadog$Outbound & { type: "datadog" })
  | (OutputRing$Outbound & { type: "ring" })
  | (OutputDataset$Outbound & { type: "dataset" })
  | (OutputCriblTcp$Outbound & { type: "cribl_tcp" })
  | (OutputCriblHttp$Outbound & { type: "cribl_http" })
  | (OutputHumioHec$Outbound & { type: "humio_hec" })
  | (OutputCriblLake$Outbound & { type: "cribl_lake" })
  | (OutputDiskSpool$Outbound & { type: "disk_spool" })
  | (OutputXsiam$Outbound & { type: "xsiam" })
  | (OutputDynatraceHttp$Outbound & { type: "dynatrace_http" })
  | (OutputSentinelOneAiSiem$Outbound & { type: "sentinel_one_ai_siem" })
  | (
    | OutputGrafanaCloudGrafanaCloud1$Outbound
    | OutputGrafanaCloudGrafanaCloud2$Outbound & { type: "grafana_cloud" }
  );

/** @internal */
export const Output$outboundSchema: z.ZodType<
  Output$Outbound,
  z.ZodTypeDef,
  Output
> = z.union([
  z.lazy(() => OutputAzureDataExplorer$outboundSchema).and(
    z.object({ type: z.literal("azure_data_explorer") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSecurityLake$outboundSchema).and(
    z.object({ type: z.literal("security_lake") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputChronicle$outboundSchema).and(
    z.object({ type: z.literal("chronicle") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSentinel$outboundSchema).and(
    z.object({ type: z.literal("sentinel") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputGoogleCloudLogging$outboundSchema).and(
    z.object({ type: z.literal("google_cloud_logging") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputExabeam$outboundSchema).and(
    z.object({ type: z.literal("exabeam") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputMsk$outboundSchema).and(
    z.object({ type: z.literal("msk") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputCloudwatch$outboundSchema).and(
    z.object({ type: z.literal("cloudwatch") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputClickHouse$outboundSchema).and(
    z.object({ type: z.literal("click_house") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDatabricks$outboundSchema).and(
    z.object({ type: z.literal("databricks") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputKinesis$outboundSchema).and(
    z.object({ type: z.literal("kinesis") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputAzureEventhub$outboundSchema).and(
    z.object({ type: z.literal("azure_eventhub") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputGoogleCloudStorage$outboundSchema).and(
    z.object({ type: z.literal("google_cloud_storage") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputKafka$outboundSchema).and(
    z.object({ type: z.literal("kafka") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputConfluentCloud$outboundSchema).and(
    z.object({ type: z.literal("confluent_cloud") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputElasticCloud$outboundSchema).and(
    z.object({ type: z.literal("elastic_cloud") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputNewrelicEvents$outboundSchema).and(
    z.object({ type: z.literal("newrelic_events") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputMinio$outboundSchema).and(
    z.object({ type: z.literal("minio") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputSns$outboundSchema).and(
    z.object({ type: z.literal("sns") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputSqs$outboundSchema).and(
    z.object({ type: z.literal("sqs") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputMicrosoftFabric$outboundSchema).and(
    z.object({ type: z.literal("microsoft_fabric") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputCloudflareR2$outboundSchema).and(
    z.object({ type: z.literal("cloudflare_r2") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDefault$outboundSchema).and(
    z.object({ type: z.literal("default") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSplunk$outboundSchema).and(
    z.object({ type: z.literal("splunk") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSplunkLb$outboundSchema).and(
    z.object({ type: z.literal("splunk_lb") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputFilesystem$outboundSchema).and(
    z.object({ type: z.literal("filesystem") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputS3$outboundSchema).and(
    z.object({ type: z.literal("s3") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputAzureBlob$outboundSchema).and(
    z.object({ type: z.literal("azure_blob") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputHoneycomb$outboundSchema).and(
    z.object({ type: z.literal("honeycomb") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputGooglePubsub$outboundSchema).and(
    z.object({ type: z.literal("google_pubsub") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputElastic$outboundSchema).and(
    z.object({ type: z.literal("elastic") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputInfluxdb$outboundSchema).and(
    z.object({ type: z.literal("influxdb") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputStatsd$outboundSchema).and(
    z.object({ type: z.literal("statsd") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputStatsdExt$outboundSchema).and(
    z.object({ type: z.literal("statsd_ext") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputGraphite$outboundSchema).and(
    z.object({ type: z.literal("graphite") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputRouter$outboundSchema).and(
    z.object({ type: z.literal("router") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSnmp$outboundSchema).and(
    z.object({ type: z.literal("snmp") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputSumoLogic$outboundSchema).and(
    z.object({ type: z.literal("sumo_logic") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputLoki$outboundSchema).and(
    z.object({ type: z.literal("loki") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputPrometheus$outboundSchema).and(
    z.object({ type: z.literal("prometheus") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputOpenTelemetry$outboundSchema).and(
    z.object({ type: z.literal("open_telemetry") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputServiceNow$outboundSchema).and(
    z.object({ type: z.literal("service_now") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputCrowdstrikeNextGenSiem$outboundSchema).and(
    z.object({ type: z.literal("crowdstrike_next_gen_siem") }).transform((
      v,
    ) => ({ type: v.type })),
  ),
  z.lazy(() => OutputDlS3$outboundSchema).and(
    z.object({ type: z.literal("dl_s3") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputNetflow$outboundSchema).and(
    z.object({ type: z.literal("netflow") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDynatraceOtlp$outboundSchema).and(
    z.object({ type: z.literal("dynatrace_otlp") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputWebhook$outboundSchema).and(
    z.object({ type: z.literal("webhook") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDevnull$outboundSchema).and(
    z.object({ type: z.literal("devnull") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSyslog$outboundSchema).and(
    z.object({ type: z.literal("syslog") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSplunkHec$outboundSchema).and(
    z.object({ type: z.literal("splunk_hec") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputTcpjson$outboundSchema).and(
    z.object({ type: z.literal("tcpjson") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputWavefront$outboundSchema).and(
    z.object({ type: z.literal("wavefront") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSignalfx$outboundSchema).and(
    z.object({ type: z.literal("signalfx") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputAzureLogs$outboundSchema).and(
    z.object({ type: z.literal("azure_logs") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputGoogleChronicle$outboundSchema).and(
    z.object({ type: z.literal("google_chronicle") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputNewrelic$outboundSchema).and(
    z.object({ type: z.literal("newrelic") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDatadog$outboundSchema).and(
    z.object({ type: z.literal("datadog") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputRing$outboundSchema).and(
    z.object({ type: z.literal("ring") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputDataset$outboundSchema).and(
    z.object({ type: z.literal("dataset") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputCriblTcp$outboundSchema).and(
    z.object({ type: z.literal("cribl_tcp") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputCriblHttp$outboundSchema).and(
    z.object({ type: z.literal("cribl_http") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputHumioHec$outboundSchema).and(
    z.object({ type: z.literal("humio_hec") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputCriblLake$outboundSchema).and(
    z.object({ type: z.literal("cribl_lake") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputDiskSpool$outboundSchema).and(
    z.object({ type: z.literal("disk_spool") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputXsiam$outboundSchema).and(
    z.object({ type: z.literal("xsiam") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => OutputDynatraceHttp$outboundSchema).and(
    z.object({ type: z.literal("dynatrace_http") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => OutputSentinelOneAiSiem$outboundSchema).and(
    z.object({ type: z.literal("sentinel_one_ai_siem") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.union([
    z.lazy(() => OutputGrafanaCloudGrafanaCloud1$outboundSchema),
    z.lazy(() => OutputGrafanaCloudGrafanaCloud2$outboundSchema),
  ]).and(
    z.object({ type: z.literal("grafana_cloud") }).transform((v) => ({
      type: v.type,
    })),
  ),
]);

export function outputToJSON(output: Output): string {
  return JSON.stringify(Output$outboundSchema.parse(output));
}
export function outputFromJSON(
  jsonString: string,
): SafeParseResult<Output, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Output$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Output' from JSON`,
  );
}
