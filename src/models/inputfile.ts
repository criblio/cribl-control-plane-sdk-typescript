/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { ClosedEnum, OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnections,
  ItemsTypeConnections$inboundSchema,
  ItemsTypeConnections$Outbound,
  ItemsTypeConnections$outboundSchema,
} from "./itemstypeconnections.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";

export const InputFilePqEnabledTrueWithPqConstraintType = {
  File: "file",
} as const;
export type InputFilePqEnabledTrueWithPqConstraintType = ClosedEnum<
  typeof InputFilePqEnabledTrueWithPqConstraintType
>;

/**
 * Choose how to discover files to monitor
 */
export const PqEnabledTrueWithPqConstraintMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type PqEnabledTrueWithPqConstraintMode = OpenEnum<
  typeof PqEnabledTrueWithPqConstraintMode
>;

export type InputFilePqEnabledTrueWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputFilePqEnabledTrueWithPqConstraintType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: PqEnabledTrueWithPqConstraintMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
};

export const InputFilePqEnabledFalseWithPqConstraintType = {
  File: "file",
} as const;
export type InputFilePqEnabledFalseWithPqConstraintType = ClosedEnum<
  typeof InputFilePqEnabledFalseWithPqConstraintType
>;

/**
 * Choose how to discover files to monitor
 */
export const PqEnabledFalseWithPqConstraintMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type PqEnabledFalseWithPqConstraintMode = OpenEnum<
  typeof PqEnabledFalseWithPqConstraintMode
>;

export type InputFilePqEnabledFalseWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputFilePqEnabledFalseWithPqConstraintType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: PqEnabledFalseWithPqConstraintMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
};

export const InputFileSendToRoutesFalseWithConnectionsConstraintType = {
  File: "file",
} as const;
export type InputFileSendToRoutesFalseWithConnectionsConstraintType =
  ClosedEnum<typeof InputFileSendToRoutesFalseWithConnectionsConstraintType>;

/**
 * Choose how to discover files to monitor
 */
export const SendToRoutesFalseWithConnectionsConstraintMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type SendToRoutesFalseWithConnectionsConstraintMode = OpenEnum<
  typeof SendToRoutesFalseWithConnectionsConstraintMode
>;

export type InputFileSendToRoutesFalseWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputFileSendToRoutesFalseWithConnectionsConstraintType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: SendToRoutesFalseWithConnectionsConstraintMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
};

export const InputFileSendToRoutesTrueWithConnectionsConstraintType = {
  File: "file",
} as const;
export type InputFileSendToRoutesTrueWithConnectionsConstraintType = ClosedEnum<
  typeof InputFileSendToRoutesTrueWithConnectionsConstraintType
>;

/**
 * Choose how to discover files to monitor
 */
export const SendToRoutesTrueWithConnectionsConstraintMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type SendToRoutesTrueWithConnectionsConstraintMode = OpenEnum<
  typeof SendToRoutesTrueWithConnectionsConstraintMode
>;

export type InputFileSendToRoutesTrueWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputFileSendToRoutesTrueWithConnectionsConstraintType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: SendToRoutesTrueWithConnectionsConstraintMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
};

export type InputFile =
  | InputFileSendToRoutesTrueWithConnectionsConstraint
  | InputFileSendToRoutesFalseWithConnectionsConstraint
  | InputFilePqEnabledFalseWithPqConstraint
  | InputFilePqEnabledTrueWithPqConstraint;

/** @internal */
export const InputFilePqEnabledTrueWithPqConstraintType$inboundSchema:
  z.ZodNativeEnum<typeof InputFilePqEnabledTrueWithPqConstraintType> = z
    .nativeEnum(InputFilePqEnabledTrueWithPqConstraintType);
/** @internal */
export const InputFilePqEnabledTrueWithPqConstraintType$outboundSchema:
  z.ZodNativeEnum<typeof InputFilePqEnabledTrueWithPqConstraintType> =
    InputFilePqEnabledTrueWithPqConstraintType$inboundSchema;

/** @internal */
export const PqEnabledTrueWithPqConstraintMode$inboundSchema: z.ZodType<
  PqEnabledTrueWithPqConstraintMode,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(PqEnabledTrueWithPqConstraintMode);
/** @internal */
export const PqEnabledTrueWithPqConstraintMode$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  PqEnabledTrueWithPqConstraintMode
> = openEnums.outboundSchema(PqEnabledTrueWithPqConstraintMode);

/** @internal */
export const InputFilePqEnabledTrueWithPqConstraint$inboundSchema: z.ZodType<
  InputFilePqEnabledTrueWithPqConstraint,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  pq: PqType$inboundSchema.optional(),
  id: z.string().optional(),
  type: InputFilePqEnabledTrueWithPqConstraintType$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
  mode: PqEnabledTrueWithPqConstraintMode$inboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});
/** @internal */
export type InputFilePqEnabledTrueWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
};

/** @internal */
export const InputFilePqEnabledTrueWithPqConstraint$outboundSchema: z.ZodType<
  InputFilePqEnabledTrueWithPqConstraint$Outbound,
  z.ZodTypeDef,
  InputFilePqEnabledTrueWithPqConstraint
> = z.object({
  pqEnabled: z.boolean().default(false),
  pq: PqType$outboundSchema.optional(),
  id: z.string().optional(),
  type: InputFilePqEnabledTrueWithPqConstraintType$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
  mode: PqEnabledTrueWithPqConstraintMode$outboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});

export function inputFilePqEnabledTrueWithPqConstraintToJSON(
  inputFilePqEnabledTrueWithPqConstraint:
    InputFilePqEnabledTrueWithPqConstraint,
): string {
  return JSON.stringify(
    InputFilePqEnabledTrueWithPqConstraint$outboundSchema.parse(
      inputFilePqEnabledTrueWithPqConstraint,
    ),
  );
}
export function inputFilePqEnabledTrueWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<InputFilePqEnabledTrueWithPqConstraint, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      InputFilePqEnabledTrueWithPqConstraint$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFilePqEnabledTrueWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputFilePqEnabledFalseWithPqConstraintType$inboundSchema:
  z.ZodNativeEnum<typeof InputFilePqEnabledFalseWithPqConstraintType> = z
    .nativeEnum(InputFilePqEnabledFalseWithPqConstraintType);
/** @internal */
export const InputFilePqEnabledFalseWithPqConstraintType$outboundSchema:
  z.ZodNativeEnum<typeof InputFilePqEnabledFalseWithPqConstraintType> =
    InputFilePqEnabledFalseWithPqConstraintType$inboundSchema;

/** @internal */
export const PqEnabledFalseWithPqConstraintMode$inboundSchema: z.ZodType<
  PqEnabledFalseWithPqConstraintMode,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(PqEnabledFalseWithPqConstraintMode);
/** @internal */
export const PqEnabledFalseWithPqConstraintMode$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  PqEnabledFalseWithPqConstraintMode
> = openEnums.outboundSchema(PqEnabledFalseWithPqConstraintMode);

/** @internal */
export const InputFilePqEnabledFalseWithPqConstraint$inboundSchema: z.ZodType<
  InputFilePqEnabledFalseWithPqConstraint,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  pq: PqType$inboundSchema.optional(),
  id: z.string().optional(),
  type: InputFilePqEnabledFalseWithPqConstraintType$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
  mode: PqEnabledFalseWithPqConstraintMode$inboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});
/** @internal */
export type InputFilePqEnabledFalseWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
};

/** @internal */
export const InputFilePqEnabledFalseWithPqConstraint$outboundSchema: z.ZodType<
  InputFilePqEnabledFalseWithPqConstraint$Outbound,
  z.ZodTypeDef,
  InputFilePqEnabledFalseWithPqConstraint
> = z.object({
  pqEnabled: z.boolean().default(false),
  pq: PqType$outboundSchema.optional(),
  id: z.string().optional(),
  type: InputFilePqEnabledFalseWithPqConstraintType$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
  mode: PqEnabledFalseWithPqConstraintMode$outboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});

export function inputFilePqEnabledFalseWithPqConstraintToJSON(
  inputFilePqEnabledFalseWithPqConstraint:
    InputFilePqEnabledFalseWithPqConstraint,
): string {
  return JSON.stringify(
    InputFilePqEnabledFalseWithPqConstraint$outboundSchema.parse(
      inputFilePqEnabledFalseWithPqConstraint,
    ),
  );
}
export function inputFilePqEnabledFalseWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputFilePqEnabledFalseWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputFilePqEnabledFalseWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputFilePqEnabledFalseWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputFileSendToRoutesFalseWithConnectionsConstraintType$inboundSchema:
  z.ZodNativeEnum<
    typeof InputFileSendToRoutesFalseWithConnectionsConstraintType
  > = z.nativeEnum(InputFileSendToRoutesFalseWithConnectionsConstraintType);
/** @internal */
export const InputFileSendToRoutesFalseWithConnectionsConstraintType$outboundSchema:
  z.ZodNativeEnum<
    typeof InputFileSendToRoutesFalseWithConnectionsConstraintType
  > = InputFileSendToRoutesFalseWithConnectionsConstraintType$inboundSchema;

/** @internal */
export const SendToRoutesFalseWithConnectionsConstraintMode$inboundSchema:
  z.ZodType<
    SendToRoutesFalseWithConnectionsConstraintMode,
    z.ZodTypeDef,
    unknown
  > = openEnums.inboundSchema(SendToRoutesFalseWithConnectionsConstraintMode);
/** @internal */
export const SendToRoutesFalseWithConnectionsConstraintMode$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    SendToRoutesFalseWithConnectionsConstraintMode
  > = openEnums.outboundSchema(SendToRoutesFalseWithConnectionsConstraintMode);

/** @internal */
export const InputFileSendToRoutesFalseWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputFileSendToRoutesFalseWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputFileSendToRoutesFalseWithConnectionsConstraintType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    mode: SendToRoutesFalseWithConnectionsConstraintMode$inboundSchema.default(
      "manual",
    ),
    interval: z.number().default(10),
    filenames: z.array(z.string()).optional(),
    filterArchivedFiles: z.boolean().default(false),
    tailOnly: z.boolean().default(true),
    idleTimeout: z.number().default(300),
    minAgeDur: z.string().optional(),
    maxAgeDur: z.string().optional(),
    checkFileModTime: z.boolean().default(false),
    forceText: z.boolean().default(false),
    hashLen: z.number().default(256),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    description: z.string().optional(),
    path: z.string().optional(),
    depth: z.number().optional(),
    suppressMissingPathErrors: z.boolean().default(false),
    deleteFiles: z.boolean().default(false),
    includeUnidentifiableBinary: z.boolean().default(false),
  });
/** @internal */
export type InputFileSendToRoutesFalseWithConnectionsConstraint$Outbound = {
  sendToRoutes: boolean;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  pq?: PqType$Outbound | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
};

/** @internal */
export const InputFileSendToRoutesFalseWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputFileSendToRoutesFalseWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputFileSendToRoutesFalseWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type:
      InputFileSendToRoutesFalseWithConnectionsConstraintType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    mode: SendToRoutesFalseWithConnectionsConstraintMode$outboundSchema.default(
      "manual",
    ),
    interval: z.number().default(10),
    filenames: z.array(z.string()).optional(),
    filterArchivedFiles: z.boolean().default(false),
    tailOnly: z.boolean().default(true),
    idleTimeout: z.number().default(300),
    minAgeDur: z.string().optional(),
    maxAgeDur: z.string().optional(),
    checkFileModTime: z.boolean().default(false),
    forceText: z.boolean().default(false),
    hashLen: z.number().default(256),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    description: z.string().optional(),
    path: z.string().optional(),
    depth: z.number().optional(),
    suppressMissingPathErrors: z.boolean().default(false),
    deleteFiles: z.boolean().default(false),
    includeUnidentifiableBinary: z.boolean().default(false),
  });

export function inputFileSendToRoutesFalseWithConnectionsConstraintToJSON(
  inputFileSendToRoutesFalseWithConnectionsConstraint:
    InputFileSendToRoutesFalseWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputFileSendToRoutesFalseWithConnectionsConstraint$outboundSchema.parse(
      inputFileSendToRoutesFalseWithConnectionsConstraint,
    ),
  );
}
export function inputFileSendToRoutesFalseWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputFileSendToRoutesFalseWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputFileSendToRoutesFalseWithConnectionsConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputFileSendToRoutesFalseWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputFileSendToRoutesTrueWithConnectionsConstraintType$inboundSchema:
  z.ZodNativeEnum<
    typeof InputFileSendToRoutesTrueWithConnectionsConstraintType
  > = z.nativeEnum(InputFileSendToRoutesTrueWithConnectionsConstraintType);
/** @internal */
export const InputFileSendToRoutesTrueWithConnectionsConstraintType$outboundSchema:
  z.ZodNativeEnum<
    typeof InputFileSendToRoutesTrueWithConnectionsConstraintType
  > = InputFileSendToRoutesTrueWithConnectionsConstraintType$inboundSchema;

/** @internal */
export const SendToRoutesTrueWithConnectionsConstraintMode$inboundSchema:
  z.ZodType<
    SendToRoutesTrueWithConnectionsConstraintMode,
    z.ZodTypeDef,
    unknown
  > = openEnums.inboundSchema(SendToRoutesTrueWithConnectionsConstraintMode);
/** @internal */
export const SendToRoutesTrueWithConnectionsConstraintMode$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    SendToRoutesTrueWithConnectionsConstraintMode
  > = openEnums.outboundSchema(SendToRoutesTrueWithConnectionsConstraintMode);

/** @internal */
export const InputFileSendToRoutesTrueWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputFileSendToRoutesTrueWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputFileSendToRoutesTrueWithConnectionsConstraintType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    mode: SendToRoutesTrueWithConnectionsConstraintMode$inboundSchema.default(
      "manual",
    ),
    interval: z.number().default(10),
    filenames: z.array(z.string()).optional(),
    filterArchivedFiles: z.boolean().default(false),
    tailOnly: z.boolean().default(true),
    idleTimeout: z.number().default(300),
    minAgeDur: z.string().optional(),
    maxAgeDur: z.string().optional(),
    checkFileModTime: z.boolean().default(false),
    forceText: z.boolean().default(false),
    hashLen: z.number().default(256),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    description: z.string().optional(),
    path: z.string().optional(),
    depth: z.number().optional(),
    suppressMissingPathErrors: z.boolean().default(false),
    deleteFiles: z.boolean().default(false),
    includeUnidentifiableBinary: z.boolean().default(false),
  });
/** @internal */
export type InputFileSendToRoutesTrueWithConnectionsConstraint$Outbound = {
  sendToRoutes: boolean;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  pq?: PqType$Outbound | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
};

/** @internal */
export const InputFileSendToRoutesTrueWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputFileSendToRoutesTrueWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputFileSendToRoutesTrueWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputFileSendToRoutesTrueWithConnectionsConstraintType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    mode: SendToRoutesTrueWithConnectionsConstraintMode$outboundSchema.default(
      "manual",
    ),
    interval: z.number().default(10),
    filenames: z.array(z.string()).optional(),
    filterArchivedFiles: z.boolean().default(false),
    tailOnly: z.boolean().default(true),
    idleTimeout: z.number().default(300),
    minAgeDur: z.string().optional(),
    maxAgeDur: z.string().optional(),
    checkFileModTime: z.boolean().default(false),
    forceText: z.boolean().default(false),
    hashLen: z.number().default(256),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    description: z.string().optional(),
    path: z.string().optional(),
    depth: z.number().optional(),
    suppressMissingPathErrors: z.boolean().default(false),
    deleteFiles: z.boolean().default(false),
    includeUnidentifiableBinary: z.boolean().default(false),
  });

export function inputFileSendToRoutesTrueWithConnectionsConstraintToJSON(
  inputFileSendToRoutesTrueWithConnectionsConstraint:
    InputFileSendToRoutesTrueWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputFileSendToRoutesTrueWithConnectionsConstraint$outboundSchema.parse(
      inputFileSendToRoutesTrueWithConnectionsConstraint,
    ),
  );
}
export function inputFileSendToRoutesTrueWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputFileSendToRoutesTrueWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputFileSendToRoutesTrueWithConnectionsConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputFileSendToRoutesTrueWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputFile$inboundSchema: z.ZodType<
  InputFile,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() =>
    InputFileSendToRoutesTrueWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() =>
    InputFileSendToRoutesFalseWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() => InputFilePqEnabledFalseWithPqConstraint$inboundSchema),
  z.lazy(() => InputFilePqEnabledTrueWithPqConstraint$inboundSchema),
]);
/** @internal */
export type InputFile$Outbound =
  | InputFileSendToRoutesTrueWithConnectionsConstraint$Outbound
  | InputFileSendToRoutesFalseWithConnectionsConstraint$Outbound
  | InputFilePqEnabledFalseWithPqConstraint$Outbound
  | InputFilePqEnabledTrueWithPqConstraint$Outbound;

/** @internal */
export const InputFile$outboundSchema: z.ZodType<
  InputFile$Outbound,
  z.ZodTypeDef,
  InputFile
> = z.union([
  z.lazy(() =>
    InputFileSendToRoutesTrueWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() =>
    InputFileSendToRoutesFalseWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() => InputFilePqEnabledFalseWithPqConstraint$outboundSchema),
  z.lazy(() => InputFilePqEnabledTrueWithPqConstraint$outboundSchema),
]);

export function inputFileToJSON(inputFile: InputFile): string {
  return JSON.stringify(InputFile$outboundSchema.parse(inputFile));
}
export function inputFileFromJSON(
  jsonString: string,
): SafeParseResult<InputFile, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFile$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFile' from JSON`,
  );
}
