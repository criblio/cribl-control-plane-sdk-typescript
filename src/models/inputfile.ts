/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnections,
  ItemsTypeConnections$inboundSchema,
  ItemsTypeConnections$Outbound,
  ItemsTypeConnections$outboundSchema,
} from "./itemstypeconnections.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";

/**
 * Choose how to discover files to monitor
 */
export const InputFileMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type InputFileMode = OpenEnum<typeof InputFileMode>;

export type InputFile = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: "file";
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  pq?: PqType | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: InputFileMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
};

/** @internal */
export const InputFileMode$inboundSchema: z.ZodType<
  InputFileMode,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(InputFileMode);
/** @internal */
export const InputFileMode$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  InputFileMode
> = openEnums.outboundSchema(InputFileMode);

/** @internal */
export const InputFile$inboundSchema: z.ZodType<
  InputFile,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  type: z.literal("file"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  mode: InputFileMode$inboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});
/** @internal */
export type InputFile$Outbound = {
  id?: string | undefined;
  type: "file";
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
};

/** @internal */
export const InputFile$outboundSchema: z.ZodType<
  InputFile$Outbound,
  z.ZodTypeDef,
  InputFile
> = z.object({
  id: z.string().optional(),
  type: z.literal("file"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  mode: InputFileMode$outboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
});

export function inputFileToJSON(inputFile: InputFile): string {
  return JSON.stringify(InputFile$outboundSchema.parse(inputFile));
}
export function inputFileFromJSON(
  jsonString: string,
): SafeParseResult<InputFile, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFile$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFile' from JSON`,
  );
}
