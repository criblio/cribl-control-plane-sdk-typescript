/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { remap as remap$ } from "../../lib/primitives.js";
import * as openEnums from "../../types/enums.js";
import { OpenEnum } from "../../types/enums.js";
import * as models from "../index.js";
import {
  CreateOutputSystemByPackAuthenticationMethodAzureLogs,
  CreateOutputSystemByPackAuthenticationMethodAzureLogs$outboundSchema,
  CreateOutputSystemByPackOutputAzureEventhub,
  CreateOutputSystemByPackOutputAzureEventhub$Outbound,
  CreateOutputSystemByPackOutputAzureEventhub$outboundSchema,
  CreateOutputSystemByPackOutputChronicle,
  CreateOutputSystemByPackOutputChronicle$Outbound,
  CreateOutputSystemByPackOutputChronicle$outboundSchema,
  CreateOutputSystemByPackOutputClickHouse,
  CreateOutputSystemByPackOutputClickHouse$Outbound,
  CreateOutputSystemByPackOutputClickHouse$outboundSchema,
  CreateOutputSystemByPackOutputCloudflareR2,
  CreateOutputSystemByPackOutputCloudflareR2$Outbound,
  CreateOutputSystemByPackOutputCloudflareR2$outboundSchema,
  CreateOutputSystemByPackOutputCloudwatch,
  CreateOutputSystemByPackOutputCloudwatch$Outbound,
  CreateOutputSystemByPackOutputCloudwatch$outboundSchema,
  CreateOutputSystemByPackOutputConfluentCloud,
  CreateOutputSystemByPackOutputConfluentCloud$Outbound,
  CreateOutputSystemByPackOutputConfluentCloud$outboundSchema,
  CreateOutputSystemByPackOutputCriblHttp,
  CreateOutputSystemByPackOutputCriblHttp$Outbound,
  CreateOutputSystemByPackOutputCriblHttp$outboundSchema,
  CreateOutputSystemByPackOutputCriblLake,
  CreateOutputSystemByPackOutputCriblLake$Outbound,
  CreateOutputSystemByPackOutputCriblLake$outboundSchema,
  CreateOutputSystemByPackOutputCriblSearchEngine,
  CreateOutputSystemByPackOutputCriblSearchEngine$Outbound,
  CreateOutputSystemByPackOutputCriblSearchEngine$outboundSchema,
  CreateOutputSystemByPackOutputCriblTcp,
  CreateOutputSystemByPackOutputCriblTcp$Outbound,
  CreateOutputSystemByPackOutputCriblTcp$outboundSchema,
  CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem,
  CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$Outbound,
  CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$outboundSchema,
  CreateOutputSystemByPackOutputDatabricks,
  CreateOutputSystemByPackOutputDatabricks$Outbound,
  CreateOutputSystemByPackOutputDatabricks$outboundSchema,
  CreateOutputSystemByPackOutputDatadog,
  CreateOutputSystemByPackOutputDatadog$Outbound,
  CreateOutputSystemByPackOutputDatadog$outboundSchema,
  CreateOutputSystemByPackOutputDataset,
  CreateOutputSystemByPackOutputDataset$Outbound,
  CreateOutputSystemByPackOutputDataset$outboundSchema,
  CreateOutputSystemByPackOutputDiskSpool,
  CreateOutputSystemByPackOutputDiskSpool$Outbound,
  CreateOutputSystemByPackOutputDiskSpool$outboundSchema,
  CreateOutputSystemByPackOutputDlS3,
  CreateOutputSystemByPackOutputDlS3$Outbound,
  CreateOutputSystemByPackOutputDlS3$outboundSchema,
  CreateOutputSystemByPackOutputDynatraceHttp,
  CreateOutputSystemByPackOutputDynatraceHttp$Outbound,
  CreateOutputSystemByPackOutputDynatraceHttp$outboundSchema,
  CreateOutputSystemByPackOutputDynatraceOtlp,
  CreateOutputSystemByPackOutputDynatraceOtlp$Outbound,
  CreateOutputSystemByPackOutputDynatraceOtlp$outboundSchema,
  CreateOutputSystemByPackOutputElastic,
  CreateOutputSystemByPackOutputElastic$Outbound,
  CreateOutputSystemByPackOutputElastic$outboundSchema,
  CreateOutputSystemByPackOutputElasticCloud,
  CreateOutputSystemByPackOutputElasticCloud$Outbound,
  CreateOutputSystemByPackOutputElasticCloud$outboundSchema,
  CreateOutputSystemByPackOutputExabeam,
  CreateOutputSystemByPackOutputExabeam$Outbound,
  CreateOutputSystemByPackOutputExabeam$outboundSchema,
  CreateOutputSystemByPackOutputGoogleChronicle,
  CreateOutputSystemByPackOutputGoogleChronicle$Outbound,
  CreateOutputSystemByPackOutputGoogleChronicle$outboundSchema,
  CreateOutputSystemByPackOutputGoogleCloudLogging,
  CreateOutputSystemByPackOutputGoogleCloudLogging$Outbound,
  CreateOutputSystemByPackOutputGoogleCloudLogging$outboundSchema,
  CreateOutputSystemByPackOutputGoogleCloudStorage,
  CreateOutputSystemByPackOutputGoogleCloudStorage$Outbound,
  CreateOutputSystemByPackOutputGoogleCloudStorage$outboundSchema,
  CreateOutputSystemByPackOutputGooglePubsub,
  CreateOutputSystemByPackOutputGooglePubsub$Outbound,
  CreateOutputSystemByPackOutputGooglePubsub$outboundSchema,
  CreateOutputSystemByPackOutputGrafanaCloudUnion,
  CreateOutputSystemByPackOutputGrafanaCloudUnion$Outbound,
  CreateOutputSystemByPackOutputGrafanaCloudUnion$outboundSchema,
  CreateOutputSystemByPackOutputGraphite,
  CreateOutputSystemByPackOutputGraphite$Outbound,
  CreateOutputSystemByPackOutputGraphite$outboundSchema,
  CreateOutputSystemByPackOutputHoneycomb,
  CreateOutputSystemByPackOutputHoneycomb$Outbound,
  CreateOutputSystemByPackOutputHoneycomb$outboundSchema,
  CreateOutputSystemByPackOutputHumioHec,
  CreateOutputSystemByPackOutputHumioHec$Outbound,
  CreateOutputSystemByPackOutputHumioHec$outboundSchema,
  CreateOutputSystemByPackOutputInfluxdb,
  CreateOutputSystemByPackOutputInfluxdb$Outbound,
  CreateOutputSystemByPackOutputInfluxdb$outboundSchema,
  CreateOutputSystemByPackOutputKafka,
  CreateOutputSystemByPackOutputKafka$Outbound,
  CreateOutputSystemByPackOutputKafka$outboundSchema,
  CreateOutputSystemByPackOutputKinesis,
  CreateOutputSystemByPackOutputKinesis$Outbound,
  CreateOutputSystemByPackOutputKinesis$outboundSchema,
  CreateOutputSystemByPackOutputLoki,
  CreateOutputSystemByPackOutputLoki$Outbound,
  CreateOutputSystemByPackOutputLoki$outboundSchema,
  CreateOutputSystemByPackOutputMicrosoftFabric,
  CreateOutputSystemByPackOutputMicrosoftFabric$Outbound,
  CreateOutputSystemByPackOutputMicrosoftFabric$outboundSchema,
  CreateOutputSystemByPackOutputMinio,
  CreateOutputSystemByPackOutputMinio$Outbound,
  CreateOutputSystemByPackOutputMinio$outboundSchema,
  CreateOutputSystemByPackOutputMsk,
  CreateOutputSystemByPackOutputMsk$Outbound,
  CreateOutputSystemByPackOutputMsk$outboundSchema,
  CreateOutputSystemByPackOutputNetflow,
  CreateOutputSystemByPackOutputNetflow$Outbound,
  CreateOutputSystemByPackOutputNetflow$outboundSchema,
  CreateOutputSystemByPackOutputNewrelic,
  CreateOutputSystemByPackOutputNewrelic$Outbound,
  CreateOutputSystemByPackOutputNewrelic$outboundSchema,
  CreateOutputSystemByPackOutputNewrelicEvents,
  CreateOutputSystemByPackOutputNewrelicEvents$Outbound,
  CreateOutputSystemByPackOutputNewrelicEvents$outboundSchema,
  CreateOutputSystemByPackOutputOpenTelemetry,
  CreateOutputSystemByPackOutputOpenTelemetry$Outbound,
  CreateOutputSystemByPackOutputOpenTelemetry$outboundSchema,
  CreateOutputSystemByPackOutputPrometheus,
  CreateOutputSystemByPackOutputPrometheus$Outbound,
  CreateOutputSystemByPackOutputPrometheus$outboundSchema,
  CreateOutputSystemByPackOutputRing,
  CreateOutputSystemByPackOutputRing$Outbound,
  CreateOutputSystemByPackOutputRing$outboundSchema,
  CreateOutputSystemByPackOutputRouter,
  CreateOutputSystemByPackOutputRouter$Outbound,
  CreateOutputSystemByPackOutputRouter$outboundSchema,
  CreateOutputSystemByPackOutputSecurityLake,
  CreateOutputSystemByPackOutputSecurityLake$Outbound,
  CreateOutputSystemByPackOutputSecurityLake$outboundSchema,
  CreateOutputSystemByPackOutputSentinelOneAiSiem,
  CreateOutputSystemByPackOutputSentinelOneAiSiem$Outbound,
  CreateOutputSystemByPackOutputSentinelOneAiSiem$outboundSchema,
  CreateOutputSystemByPackOutputServiceNow,
  CreateOutputSystemByPackOutputServiceNow$Outbound,
  CreateOutputSystemByPackOutputServiceNow$outboundSchema,
  CreateOutputSystemByPackOutputSnmp,
  CreateOutputSystemByPackOutputSnmp$Outbound,
  CreateOutputSystemByPackOutputSnmp$outboundSchema,
  CreateOutputSystemByPackOutputSns,
  CreateOutputSystemByPackOutputSns$Outbound,
  CreateOutputSystemByPackOutputSns$outboundSchema,
  CreateOutputSystemByPackOutputSqs,
  CreateOutputSystemByPackOutputSqs$Outbound,
  CreateOutputSystemByPackOutputSqs$outboundSchema,
  CreateOutputSystemByPackOutputStatsd,
  CreateOutputSystemByPackOutputStatsd$Outbound,
  CreateOutputSystemByPackOutputStatsd$outboundSchema,
  CreateOutputSystemByPackOutputStatsdExt,
  CreateOutputSystemByPackOutputStatsdExt$Outbound,
  CreateOutputSystemByPackOutputStatsdExt$outboundSchema,
  CreateOutputSystemByPackOutputSumoLogic,
  CreateOutputSystemByPackOutputSumoLogic$Outbound,
  CreateOutputSystemByPackOutputSumoLogic$outboundSchema,
  CreateOutputSystemByPackOutputXsiam,
  CreateOutputSystemByPackOutputXsiam$Outbound,
  CreateOutputSystemByPackOutputXsiam$outboundSchema,
  CreateOutputSystemByPackPqControlsAzureLogs,
  CreateOutputSystemByPackPqControlsAzureLogs$Outbound,
  CreateOutputSystemByPackPqControlsAzureLogs$outboundSchema,
} from "./createoutputsystembypackpqcontrolsazurelogs.js";

export type CreateOutputSystemByPackOutputAzureLogs = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "azure_logs";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
   */
  logType: string;
  /**
   * Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
   */
  resourceId?: string | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
   */
  apiUrl?: string | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Enter workspace ID and workspace key directly, or select a stored secret
   */
  authType?: CreateOutputSystemByPackAuthenticationMethodAzureLogs | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsAzureLogs | undefined;
  /**
   * Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
   */
  workspaceId?: string | undefined;
  /**
   * Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.
   */
  workspaceKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  keypairSecret?: string | undefined;
  /**
   * Binds 'workspaceId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'workspaceId' at runtime.
   */
  __template_workspaceId?: string | undefined;
  /**
   * Binds 'workspaceKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'workspaceKey' at runtime.
   */
  __template_workspaceKey?: string | undefined;
};

export const CreateOutputSystemByPackIngestionMode = {
  /**
   * Batching
   */
  Batching: "batching",
  /**
   * Streaming
   */
  Streaming: "streaming",
} as const;
export type CreateOutputSystemByPackIngestionMode = OpenEnum<
  typeof CreateOutputSystemByPackIngestionMode
>;

/**
 * The type of OAuth 2.0 client credentials grant flow to use
 */
export const CreateOutputSystemByPackOauthTypeAuthenticationMethod = {
  /**
   * Client secret
   */
  ClientSecret: "clientSecret",
  /**
   * Client secret (text secret)
   */
  ClientTextSecret: "clientTextSecret",
  /**
   * Certificate
   */
  Certificate: "certificate",
} as const;
/**
 * The type of OAuth 2.0 client credentials grant flow to use
 */
export type CreateOutputSystemByPackOauthTypeAuthenticationMethod = OpenEnum<
  typeof CreateOutputSystemByPackOauthTypeAuthenticationMethod
>;

export type CreateOutputSystemByPackCertificate = {
  /**
   * The certificate you registered as credentials for your app in the Azure portal
   */
  certificateName?: string | undefined;
};

export const CreateOutputSystemByPackPrefixOptional = {
  /**
   * drop-by
   */
  DropBy: "dropBy",
  /**
   * ingest-by
   */
  IngestBy: "ingestBy",
} as const;
export type CreateOutputSystemByPackPrefixOptional = OpenEnum<
  typeof CreateOutputSystemByPackPrefixOptional
>;

export type CreateOutputSystemByPackExtentTag = {
  prefix?: CreateOutputSystemByPackPrefixOptional | undefined;
  value: string;
};

export type CreateOutputSystemByPackIngestIfNotExist = {
  value: string;
};

/**
 * Level of ingestion status reporting. Defaults to FailuresOnly.
 */
export const CreateOutputSystemByPackReportLevel = {
  /**
   * FailuresOnly
   */
  FailuresOnly: "failuresOnly",
  /**
   * DoNotReport
   */
  DoNotReport: "doNotReport",
  /**
   * FailuresAndSuccesses
   */
  FailuresAndSuccesses: "failuresAndSuccesses",
} as const;
/**
 * Level of ingestion status reporting. Defaults to FailuresOnly.
 */
export type CreateOutputSystemByPackReportLevel = OpenEnum<
  typeof CreateOutputSystemByPackReportLevel
>;

/**
 * Target of the ingestion status reporting. Defaults to Queue.
 */
export const CreateOutputSystemByPackReportMethod = {
  /**
   * Queue
   */
  Queue: "queue",
  /**
   * Table
   */
  Table: "table",
  /**
   * QueueAndTable
   */
  QueueAndTable: "queueAndTable",
} as const;
/**
 * Target of the ingestion status reporting. Defaults to Queue.
 */
export type CreateOutputSystemByPackReportMethod = OpenEnum<
  typeof CreateOutputSystemByPackReportMethod
>;

export type CreateOutputSystemByPackAdditionalProperty = {
  key: string;
  value: string;
};

export type CreateOutputSystemByPackPqControlsAzureDataExplorer = {};

export type CreateOutputSystemByPackOutputAzureDataExplorer = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "azure_data_explorer";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The base URI for your cluster. Typically, `https://<cluster>.<region>.kusto.windows.net`.
   */
  clusterUrl: string;
  /**
   * Name of the database containing the table where data will be ingested
   */
  database: string;
  /**
   * Name of the table to ingest data into
   */
  table: string;
  /**
   * When saving or starting the Destination, validate the database name and credentials; also validate table name, except when creating a new table. Disable if your Azure app does not have both the Database Viewer and the Table Viewer role.
   */
  validateDatabaseSettings?: boolean | undefined;
  ingestMode?: CreateOutputSystemByPackIngestionMode | undefined;
  /**
   * Endpoint used to acquire authentication tokens from Azure
   */
  oauthEndpoint: models.MicrosoftEntraIdAuthenticationEndpointOptionsSasl;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory
   */
  tenantId: string;
  /**
   * client_id to pass in the OAuth request parameter
   */
  clientId: string;
  /**
   * Scope to pass in the OAuth request parameter
   */
  scope: string;
  /**
   * The type of OAuth 2.0 client credentials grant flow to use
   */
  oauthType: CreateOutputSystemByPackOauthTypeAuthenticationMethod;
  description?: string | undefined;
  /**
   * The client secret that you generated for your app in the Azure portal
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  certificate?: CreateOutputSystemByPackCertificate | undefined;
  /**
   * Format of the output data
   */
  format?: models.DataFormatOptions | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress: models.CompressionOptions2;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: models.CompressionLevelOptions | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: models.ParquetVersionOptions | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: models.DataPageVersionOptions | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<models.ItemsTypeKeyValueMetadata> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Send a JSON mapping object instead of specifying an existing named data mapping
   */
  isMappingObj?: boolean | undefined;
  /**
   * Enter a JSON object that defines your desired data mapping
   */
  mappingObj?: string | undefined;
  /**
   * Enter the name of a data mapping associated with your target table. Or, if incoming event and target table fields match exactly, you can leave the field empty.
   */
  mappingRef?: string | undefined;
  /**
   * The ingestion service URI for your cluster. Typically, `https://ingest-<cluster>.<region>.kusto.windows.net`.
   */
  ingestUrl?: string | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: models.DiskSpaceProtectionOptions | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  retrySettings?: models.RetrySettingsType | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Bypass the data management service's aggregation mechanism
   */
  flushImmediately?: boolean | undefined;
  /**
   * Prevent blob deletion after ingestion is complete
   */
  retainBlobOnSuccess?: boolean | undefined;
  /**
   * Strings or tags associated with the extent (ingested data shard)
   */
  extentTags?: Array<CreateOutputSystemByPackExtentTag> | undefined;
  /**
   * Prevents duplicate ingestion by verifying whether an extent with the specified ingest-by tag already exists
   */
  ingestIfNotExists?:
    | Array<CreateOutputSystemByPackIngestIfNotExist>
    | undefined;
  /**
   * Level of ingestion status reporting. Defaults to FailuresOnly.
   */
  reportLevel?: CreateOutputSystemByPackReportLevel | undefined;
  /**
   * Target of the ingestion status reporting. Defaults to Queue.
   */
  reportMethod?: CreateOutputSystemByPackReportMethod | undefined;
  /**
   * Optionally, enter additional configuration properties to send to the ingestion service
   */
  additionalProperties?:
    | Array<CreateOutputSystemByPackAdditionalProperty>
    | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsAzureDataExplorer | undefined;
  /**
   * Binds 'clusterUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clusterUrl' at runtime.
   */
  __template_clusterUrl?: string | undefined;
  /**
   * Binds 'database' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'database' at runtime.
   */
  __template_database?: string | undefined;
  /**
   * Binds 'table' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'table' at runtime.
   */
  __template_table?: string | undefined;
  /**
   * Binds 'tenantId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'tenantId' at runtime.
   */
  __template_tenantId?: string | undefined;
  /**
   * Binds 'clientId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientId' at runtime.
   */
  __template_clientId?: string | undefined;
  /**
   * Binds 'scope' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'scope' at runtime.
   */
  __template_scope?: string | undefined;
  /**
   * Binds 'clientSecret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientSecret' at runtime.
   */
  __template_clientSecret?: string | undefined;
  /**
   * Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
   */
  __template_format?: string | undefined;
  /**
   * Binds 'ingestUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'ingestUrl' at runtime.
   */
  __template_ingestUrl?: string | undefined;
};

export const CreateOutputSystemByPackBlobAccessTier = {
  /**
   * Default account access tier
   */
  Inferred: "Inferred",
  /**
   * Hot tier
   */
  Hot: "Hot",
  /**
   * Cool tier
   */
  Cool: "Cool",
  /**
   * Cold tier
   */
  Cold: "Cold",
  /**
   * Archive tier
   */
  Archive: "Archive",
} as const;
export type CreateOutputSystemByPackBlobAccessTier = OpenEnum<
  typeof CreateOutputSystemByPackBlobAccessTier
>;

export type CreateOutputSystemByPackOutputAzureBlob = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "azure_blob";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The Azure Blob Storage container name. Name can include only lowercase letters, numbers, and hyphens. For dynamic container names, enter a JavaScript expression within quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myContainer-${C.env["CRIBL_WORKER_ID"]}`.
   */
  containerName: string;
  /**
   * Create the configured container in Azure Blob Storage if it does not already exist
   */
  createContainer?: boolean | undefined;
  /**
   * Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`.
   */
  destPath?: string | undefined;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath: string;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Maximum number of parts to upload in parallel per file
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: models.DataFormatOptions | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions1 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: models.DiskSpaceProtectionOptions | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType | undefined;
  authType?: models.AuthenticationMethodOptions | undefined;
  storageClass?: CreateOutputSystemByPackBlobAccessTier | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: models.CompressionOptions2 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: models.CompressionLevelOptions | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: models.ParquetVersionOptions | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: models.DataPageVersionOptions | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<models.ItemsTypeKeyValueMetadata> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: models.CertificateTypeAzureBlobAuthTypeClientCert | undefined;
  /**
   * Binds 'containerName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'containerName' at runtime.
   */
  __template_containerName?: string | undefined;
  /**
   * Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
   */
  __template_format?: string | undefined;
  /**
   * Binds 'connectionString' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'connectionString' at runtime.
   */
  __template_connectionString?: string | undefined;
  /**
   * Binds 'tenantId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'tenantId' at runtime.
   */
  __template_tenantId?: string | undefined;
  /**
   * Binds 'clientId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'clientId' at runtime.
   */
  __template_clientId?: string | undefined;
};

export type CreateOutputSystemByPackOutputS3 = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "s3";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * Region where the S3 bucket is located
   */
  region?: string | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
   */
  awsSecretKey?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: models.SignatureVersionOptionsS3CollectorConf | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath: string;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
   */
  destPath?: string | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: models.ObjectAclOptions | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: models.StorageClassOptions | undefined;
  serverSideEncryption?:
    | models.ServerSideEncryptionForUploadedObjectsOptions
    | undefined;
  /**
   * ID or ARN of the KMS customer-managed key to use for encryption
   */
  kmsKeyId?: string | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: models.DataFormatOptions | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions1 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: models.DiskSpaceProtectionOptions | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Maximum number of files that can be waiting for upload before backpressure is applied
   */
  maxClosingFilesToBackpressure?: number | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: models.CompressionOptions2 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: models.CompressionLevelOptions | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: models.ParquetVersionOptions | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: models.DataPageVersionOptions | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<models.ItemsTypeKeyValueMetadata> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Binds 'bucket' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'bucket' at runtime.
   */
  __template_bucket?: string | undefined;
  /**
   * Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime.
   */
  __template_region?: string | undefined;
  /**
   * Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime.
   */
  __template_awsSecretKey?: string | undefined;
  /**
   * Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime.
   */
  __template_assumeRoleArn?: string | undefined;
  /**
   * Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime.
   */
  __template_assumeRoleExternalId?: string | undefined;
  /**
   * Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
   */
  __template_format?: string | undefined;
  /**
   * Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime.
   */
  __template_awsApiKey?: string | undefined;
};

export type CreateOutputSystemByPackOutputFilesystem = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "filesystem";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Final destination for the output files
   */
  destPath: string;
  /**
   * Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: models.DataFormatOptions | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions1 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: models.DiskSpaceProtectionOptions | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: models.CompressionOptions2 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: models.CompressionLevelOptions | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: models.ParquetVersionOptions | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: models.DataPageVersionOptions | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<models.ItemsTypeKeyValueMetadata> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * Binds 'format' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'format' at runtime.
   */
  __template_format?: string | undefined;
};

export type CreateOutputSystemByPackPqControlsSignalfx = {};

export type CreateOutputSystemByPackOutputSignalfx = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "signalfx";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * SignalFx realm name, e.g. "us0". For a complete list of available SignalFx realm names, please check [here](https://docs.splunk.com/observability/en/get-started/service-description.html#sd-regions).
   */
  realm: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  description?: string | undefined;
  /**
   * SignalFx API access token (see [here](https://docs.signalfx.com/en/latest/admin-guide/tokens.html#working-with-access-tokens))
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSignalfx | undefined;
};

export type CreateOutputSystemByPackPqControlsWavefront = {};

export type CreateOutputSystemByPackOutputWavefront = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "wavefront";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * WaveFront domain name, e.g. "longboard"
   */
  domain: string;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  description?: string | undefined;
  /**
   * WaveFront API authentication token (see [here](https://docs.wavefront.com/wavefront_api.html#generating-an-api-token))
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWavefront | undefined;
};

export type CreateOutputSystemByPackPqControlsTcpjson = {};

export type CreateOutputSystemByPackOutputTcpjson = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "tcpjson";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Use load-balanced destinations
   */
  loadBalanced?: boolean | undefined;
  /**
   * Codec to use to compress the data before sending
   */
  compression?: models.CompressionOptions1 | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  tls?: models.TlsSettingsClientSideTypeKafkaSchemaRegistry | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  /**
   * The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
   */
  tokenTTLMinutes?: number | undefined;
  /**
   * Upon connection, send a header-like record containing the auth token and other metadata.This record will not contain an actual event – only subsequent records will.
   */
  sendHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  description?: string | undefined;
  /**
   * The hostname of the receiver
   */
  host?: string | undefined;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of hosts to load-balance data to
   */
  hosts?: Array<models.ItemsTypeHosts> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsTcpjson | undefined;
  /**
   * Optional authentication token to include as part of the connection header
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
   */
  __template_host?: string | undefined;
  /**
   * Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
   */
  __template_port?: string | undefined;
};

export type CreateOutputSystemByPackPqControlsWizHec = {};

export type CreateOutputSystemByPackOutputWizHec = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "wiz_hec";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
   */
  nextQueue?: string | undefined;
  /**
   * In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
   */
  tcpRouting?: string | undefined;
  tls?: models.TlsSettingsClientSideType1 | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * The unique identifier for the specific Cribl connector defined in your Wiz Settings. This is used to cross-validate the bearer token and ensure traffic is originating from the authorized integration.
   */
  wiz_connector_id: string;
  /**
   * Your Wiz deployment environment.
   */
  wiz_environment: string;
  /**
   * Your Wiz deployment data center (e.g., us1, us8, eu1). From Tenant Info → Data Center and Regions → Tenant Data Center in your Wiz console.
   */
  data_center: string;
  wiz_sourcetype: string;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWizHec | undefined;
  /**
   * Wiz Defend Auth token
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Binds 'wiz_environment' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'wiz_environment' at runtime.
   */
  __template_wiz_environment?: string | undefined;
  /**
   * Binds 'data_center' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'data_center' at runtime.
   */
  __template_data_center?: string | undefined;
  /**
   * Binds 'wiz_sourcetype' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'wiz_sourcetype' at runtime.
   */
  __template_wiz_sourcetype?: string | undefined;
};

export type CreateOutputSystemByPackUrlSplunkHec = {
  /**
   * URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
   */
  url: string;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
  /**
   * Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
   */
  __template_url?: string | undefined;
};

export type CreateOutputSystemByPackPqControlsSplunkHec = {};

export type CreateOutputSystemByPackOutputSplunkHec = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "splunk_hec";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
   */
  nextQueue?: string | undefined;
  /**
   * In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
   */
  tcpRouting?: string | undefined;
  tls?: models.TlsSettingsClientSideType1 | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Output metrics in multiple-metric format, supported in Splunk 8.0 and above to allow multiple metrics in a single event.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  description?: string | undefined;
  /**
   * URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
   */
  url?: string | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<CreateOutputSystemByPackUrlSplunkHec> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Splunk HEC authentication token
   */
  token?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunkHec | undefined;
  /**
   * Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
   */
  __template_url?: string | undefined;
};

export type CreateOutputSystemByPackAuthToken = {
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

/**
 * List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
 */
export type CreateOutputSystemByPackIndexerDiscoveryConfigs = {
  /**
   * Clustering site of the indexers from where indexers need to be discovered. In case of single site cluster, it defaults to 'default' site.
   */
  site: string;
  /**
   * Full URI of Splunk cluster manager (scheme://host:port). Example: https://managerAddress:8089
   */
  masterUri: string;
  /**
   * Time interval, in seconds, between two consecutive indexer list fetches from cluster manager
   */
  refreshIntervalSec: number;
  /**
   * During indexer discovery, reject cluster manager certificates that are not authorized by the system's CA. Disable to allow untrusted (for example, self-signed) certificates.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Tokens required to authenticate to cluster manager for indexer discovery
   */
  authTokens?: Array<CreateOutputSystemByPackAuthToken> | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

export type CreateOutputSystemByPackPqControlsSplunkLb = {};

export type CreateOutputSystemByPackOutputSplunkLb = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "splunk_lb";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * How to serialize nested fields into index-time fields
   */
  nestedFields?: models.NestedFieldSerializationOptions | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: models.TlsSettingsClientSideTypeKafkaSchemaRegistry | undefined;
  /**
   * Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
   */
  enableACK?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * The highest S2S protocol version to advertise during handshake
   */
  maxS2Sversion?: models.MaxS2SVersionOptions | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Automatically discover indexers in indexer clustering environment.
   */
  indexerDiscovery?: boolean | undefined;
  /**
   * How long (in milliseconds) each LB endpoint can report blocked before the Destination reports unhealthy, blocking the sender. (Grace period for fluctuations.) Use 0 to disable; max 1 minute.
   */
  senderUnhealthyTimeAllowance?: number | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  description?: string | undefined;
  /**
   * Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
   */
  maxFailedHealthChecks?: number | undefined;
  /**
   * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
   */
  compress?: models.CompressionOptions | undefined;
  /**
   * List of configurations to set up indexer discovery in Splunk Indexer clustering environment.
   */
  indexerDiscoveryConfigs?:
    | CreateOutputSystemByPackIndexerDiscoveryConfigs
    | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of Splunk indexers to load-balance data to.
   */
  hosts: Array<models.ItemsTypeHosts>;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunkLb | undefined;
  /**
   * Shared secret token to use when establishing a connection to a Splunk indexer.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
};

export type CreateOutputSystemByPackPqControlsSplunk = {};

export type CreateOutputSystemByPackOutputSplunk = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "splunk";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The hostname of the receiver
   */
  host: string;
  /**
   * The port to connect to on the provided host
   */
  port: number;
  /**
   * How to serialize nested fields into index-time fields
   */
  nestedFields?: models.NestedFieldSerializationOptions | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: models.TlsSettingsClientSideTypeKafkaSchemaRegistry | undefined;
  /**
   * Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
   */
  enableMultiMetrics?: boolean | undefined;
  /**
   * Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
   */
  enableACK?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  /**
   * The highest S2S protocol version to advertise during handshake
   */
  maxS2Sversion?: models.MaxS2SVersionOptions | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: models.AuthenticationMethodOptionsAuthTokensItems | undefined;
  description?: string | undefined;
  /**
   * Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
   */
  maxFailedHealthChecks?: number | undefined;
  /**
   * Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
   */
  compress?: models.CompressionOptions | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunk | undefined;
  /**
   * Shared secret token to use when establishing a connection to a Splunk indexer.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
   */
  __template_host?: string | undefined;
  /**
   * Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
   */
  __template_port?: string | undefined;
};

/**
 * The network protocol to use for sending out syslog messages
 */
export const CreateOutputSystemByPackProtocolSyslog = {
  /**
   * TCP
   */
  Tcp: "tcp",
  /**
   * UDP
   */
  Udp: "udp",
} as const;
/**
 * The network protocol to use for sending out syslog messages
 */
export type CreateOutputSystemByPackProtocolSyslog = OpenEnum<
  typeof CreateOutputSystemByPackProtocolSyslog
>;

/**
 * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
 */
export const CreateOutputSystemByPackFacility = {
  Zero: 0,
  One: 1,
  Two: 2,
  Three: 3,
  Four: 4,
  Five: 5,
  Six: 6,
  Seven: 7,
  Eight: 8,
  Nine: 9,
  Ten: 10,
  Eleven: 11,
  Twelve: 12,
  Thirteen: 13,
  Fourteen: 14,
  Fifteen: 15,
  Sixteen: 16,
  Seventeen: 17,
  Eighteen: 18,
  Nineteen: 19,
  Twenty: 20,
  TwentyOne: 21,
} as const;
/**
 * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
 */
export type CreateOutputSystemByPackFacility = OpenEnum<
  typeof CreateOutputSystemByPackFacility
>;

/**
 * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
 */
export const CreateOutputSystemByPackSeveritySyslog = {
  /**
   * emergency
   */
  Emergency: 0,
  /**
   * alert
   */
  Alert: 1,
  /**
   * critical
   */
  Critical: 2,
  /**
   * error
   */
  Error: 3,
  /**
   * warning
   */
  Warning: 4,
  /**
   * notice
   */
  Notice: 5,
  /**
   * info
   */
  Info: 6,
  /**
   * debug
   */
  Debug: 7,
} as const;
/**
 * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
 */
export type CreateOutputSystemByPackSeveritySyslog = OpenEnum<
  typeof CreateOutputSystemByPackSeveritySyslog
>;

/**
 * The syslog message format depending on the receiver's support
 */
export const CreateOutputSystemByPackMessageFormat = {
  /**
   * RFC3164
   */
  Rfc3164: "rfc3164",
  /**
   * RFC5424
   */
  Rfc5424: "rfc5424",
} as const;
/**
 * The syslog message format depending on the receiver's support
 */
export type CreateOutputSystemByPackMessageFormat = OpenEnum<
  typeof CreateOutputSystemByPackMessageFormat
>;

/**
 * Timestamp format to use when serializing event's time field
 */
export const CreateOutputSystemByPackTimestampFormat = {
  /**
   * Syslog
   */
  Syslog: "syslog",
  /**
   * ISO8601
   */
  Iso8601: "iso8601",
} as const;
/**
 * Timestamp format to use when serializing event's time field
 */
export type CreateOutputSystemByPackTimestampFormat = OpenEnum<
  typeof CreateOutputSystemByPackTimestampFormat
>;

export type CreateOutputSystemByPackPqControlsSyslog = {};

export type CreateOutputSystemByPackOutputSyslog = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "syslog";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The network protocol to use for sending out syslog messages
   */
  protocol?: CreateOutputSystemByPackProtocolSyslog | undefined;
  /**
   * Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
   */
  facility?: CreateOutputSystemByPackFacility | undefined;
  /**
   * Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
   */
  severity?: CreateOutputSystemByPackSeveritySyslog | undefined;
  /**
   * Default name for device or application that originated the message. Defaults to Cribl, but will be overwritten by value of __appname if set.
   */
  appName?: string | undefined;
  /**
   * The syslog message format depending on the receiver's support
   */
  messageFormat?: CreateOutputSystemByPackMessageFormat | undefined;
  /**
   * Timestamp format to use when serializing event's time field
   */
  timestampFormat?: CreateOutputSystemByPackTimestampFormat | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Prefix messages with the byte count of the message. If disabled, no prefix will be set, and the message will be appended with a \n.
   */
  octetCountFraming?: boolean | undefined;
  /**
   * Use to troubleshoot issues with sending data
   */
  logFailedRequests?: boolean | undefined;
  description?: string | undefined;
  /**
   * For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs.  If this setting is disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  /**
   * The hostname of the receiver
   */
  host?: string | undefined;
  /**
   * The port to connect to on the provided host
   */
  port?: number | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  /**
   * Set of hosts to load-balance data to
   */
  hosts?: Array<models.ItemsTypeHosts> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
   */
  maxConcurrentSenders?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for the connection to establish before retrying
   */
  connectionTimeout?: number | undefined;
  /**
   * Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead
   */
  writeTimeout?: number | undefined;
  tls?: models.TlsSettingsClientSideTypeKafkaSchemaRegistry | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Maximum size of syslog messages. Make sure this value is less than or equal to the MTU to avoid UDP packet fragmentation.
   */
  maxRecordSize?: number | undefined;
  /**
   * How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every message sent will incur a DNS lookup.
   */
  udpDnsResolvePeriodSec?: number | undefined;
  /**
   * Send Syslog traffic using the original event's Source IP and port. To enable this, you must install the external `udp-sender` helper binary at `/usr/bin/udp-sender` on all Worker Nodes and grant it the `CAP_NET_RAW` capability.
   */
  enableIpSpoofing?: boolean | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSyslog | undefined;
  /**
   * Binds 'host' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'host' at runtime.
   */
  __template_host?: string | undefined;
  /**
   * Binds 'port' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'port' at runtime.
   */
  __template_port?: string | undefined;
};

export type CreateOutputSystemByPackOutputDevnull = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "devnull";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
};

export const CreateOutputSystemByPackAuthType = {
  Oauth: "oauth",
} as const;
export type CreateOutputSystemByPackAuthType = OpenEnum<
  typeof CreateOutputSystemByPackAuthType
>;

/**
 * Enter the data collection endpoint URL or the individual ID
 */
export const CreateOutputSystemByPackEndpointConfiguration = {
  /**
   * URL
   */
  Url: "url",
  /**
   * ID
   */
  Id: "ID",
} as const;
/**
 * Enter the data collection endpoint URL or the individual ID
 */
export type CreateOutputSystemByPackEndpointConfiguration = OpenEnum<
  typeof CreateOutputSystemByPackEndpointConfiguration
>;

export const CreateOutputSystemByPackFormatSentinel = {
  Ndjson: "ndjson",
  JsonArray: "json_array",
  Custom: "custom",
  Advanced: "advanced",
} as const;
export type CreateOutputSystemByPackFormatSentinel = OpenEnum<
  typeof CreateOutputSystemByPackFormatSentinel
>;

export type CreateOutputSystemByPackPqControlsSentinel = {};

export type CreateOutputSystemByPackOutputSentinel = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "sentinel";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size (KB) of the request body (defaults to the API's maximum limit of 1000 KB)
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  authType?: CreateOutputSystemByPackAuthType | undefined;
  /**
   * URL for OAuth
   */
  loginUrl: string;
  /**
   * Secret parameter value to pass in request body
   */
  secret: string;
  /**
   * JavaScript expression to compute the Client ID for the Azure application. Can be a constant.
   */
  client_id: string;
  /**
   * Scope to pass in the OAuth request
   */
  scope?: string | undefined;
  /**
   * Enter the data collection endpoint URL or the individual ID
   */
  endpointURLConfiguration: CreateOutputSystemByPackEndpointConfiguration;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  format?: CreateOutputSystemByPackFormatSentinel | undefined;
  /**
   * Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
   */
  customSourceExpression?: string | undefined;
  /**
   * Whether to drop events when the source expression evaluates to null
   */
  customDropWhenNull?: boolean | undefined;
  /**
   * Delimiter string to insert between individual events. Defaults to newline character.
   */
  customEventDelimiter?: string | undefined;
  /**
   * Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
   */
  customContentType?: string | undefined;
  /**
   * Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
   */
  customPayloadExpression?: string | undefined;
  /**
   * HTTP content-type header value
   */
  advancedContentType?: string | undefined;
  /**
   * Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatEventCode?: string | undefined;
  /**
   * Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatPayloadCode?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSentinel | undefined;
  /**
   * URL to send events to. Can be overwritten by an event's __url field.
   */
  url?: string | undefined;
  /**
   * Immutable ID for the Data Collection Rule (DCR)
   */
  dcrID?: string | undefined;
  /**
   * Data collection endpoint (DCE) URL. In the format: `https://<Endpoint-Name>-<Identifier>.<Region>.ingest.monitor.azure.com`
   */
  dceEndpoint?: string | undefined;
  /**
   * The name of the stream (Sentinel table) in which to store the events
   */
  streamName?: string | undefined;
  /**
   * Binds 'loginUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'loginUrl' at runtime.
   */
  __template_loginUrl?: string | undefined;
  /**
   * Binds 'secret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'secret' at runtime.
   */
  __template_secret?: string | undefined;
  /**
   * Binds 'client_id' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'client_id' at runtime.
   */
  __template_client_id?: string | undefined;
  /**
   * Binds 'scope' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'scope' at runtime.
   */
  __template_scope?: string | undefined;
  /**
   * Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
   */
  __template_url?: string | undefined;
  /**
   * Binds 'dcrID' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'dcrID' at runtime.
   */
  __template_dcrID?: string | undefined;
  /**
   * Binds 'dceEndpoint' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'dceEndpoint' at runtime.
   */
  __template_dceEndpoint?: string | undefined;
  /**
   * Binds 'streamName' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'streamName' at runtime.
   */
  __template_streamName?: string | undefined;
};

/**
 * How to format events before sending out
 */
export const CreateOutputSystemByPackFormatWebhook = {
  /**
   * NDJSON (Newline Delimited JSON)
   */
  Ndjson: "ndjson",
  /**
   * JSON Array
   */
  JsonArray: "json_array",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Advanced
   */
  Advanced: "advanced",
} as const;
/**
 * How to format events before sending out
 */
export type CreateOutputSystemByPackFormatWebhook = OpenEnum<
  typeof CreateOutputSystemByPackFormatWebhook
>;

/**
 * Authentication method to use for the HTTP request
 */
export const CreateOutputSystemByPackAuthenticationTypeWebhook = {
  /**
   * None
   */
  None: "none",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
  /**
   * Token
   */
  Token: "token",
  /**
   * Token (text secret)
   */
  TextSecret: "textSecret",
  /**
   * OAuth
   */
  Oauth: "oauth",
} as const;
/**
 * Authentication method to use for the HTTP request
 */
export type CreateOutputSystemByPackAuthenticationTypeWebhook = OpenEnum<
  typeof CreateOutputSystemByPackAuthenticationTypeWebhook
>;

export type CreateOutputSystemByPackPqControlsWebhook = {};

export type CreateOutputSystemByPackOauthParam = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type CreateOutputSystemByPackOauthHeader = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type CreateOutputSystemByPackUrlWebhook = {
  /**
   * URL of a webhook endpoint to send events to, such as http://localhost:10200
   */
  url: string;
  /**
   * Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
   */
  weight?: number | undefined;
  /**
   * Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
   */
  __template_url?: string | undefined;
};

export type CreateOutputSystemByPackOutputWebhook = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "webhook";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * The method to use when sending events
   */
  method?: models.MethodOptions | undefined;
  /**
   * How to format events before sending out
   */
  format?: CreateOutputSystemByPackFormatWebhook | undefined;
  /**
   * Disable to close the connection immediately after sending the outgoing request
   */
  keepAlive?: boolean | undefined;
  /**
   * Maximum number of ongoing requests before blocking
   */
  concurrency?: number | undefined;
  /**
   * Maximum size, in KB, of the request body
   */
  maxPayloadSizeKB?: number | undefined;
  /**
   * Maximum number of events to include in the request body. Default is 0 (unlimited).
   */
  maxPayloadEvents?: number | undefined;
  /**
   * Compress the payload body before sending
   */
  compress?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
   *
   * @remarks
   *         Enabled by default. When this setting is also present in TLS Settings (Client Side),
   *         that value will take precedence.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Amount of time, in seconds, to wait for a request to complete before canceling it
   */
  timeoutSec?: number | undefined;
  /**
   * Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
   */
  flushPeriodSec?: number | undefined;
  /**
   * Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields).
   */
  extraHttpHeaders?: Array<models.ItemsTypeExtraHttpHeaders> | undefined;
  /**
   * Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
   */
  failedRequestLoggingMode?: models.FailedRequestLoggingModeOptions | undefined;
  /**
   * List of headers that are safe to log in plain text
   */
  safeHeaders?: Array<string> | undefined;
  /**
   * Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
   */
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
   */
  responseHonorRetryAfterHeader?: boolean | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: models.BackpressureBehaviorOptions | undefined;
  /**
   * Authentication method to use for the HTTP request
   */
  authType?: CreateOutputSystemByPackAuthenticationTypeWebhook | undefined;
  tls?: models.TlsSettingsClientSideType1 | undefined;
  /**
   * Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
   */
  totalMemoryLimitKB?: number | undefined;
  /**
   * Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
   */
  loadBalanced?: boolean | undefined;
  description?: string | undefined;
  /**
   * Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
   */
  customSourceExpression?: string | undefined;
  /**
   * Whether to drop events when the source expression evaluates to null
   */
  customDropWhenNull?: boolean | undefined;
  /**
   * Delimiter string to insert between individual events. Defaults to newline character.
   */
  customEventDelimiter?: string | undefined;
  /**
   * Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
   */
  customContentType?: string | undefined;
  /**
   * Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
   */
  customPayloadExpression?: string | undefined;
  /**
   * HTTP content-type header value
   */
  advancedContentType?: string | undefined;
  /**
   * Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatEventCode?: string | undefined;
  /**
   * Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
   */
  formatPayloadCode?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: models.ModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: models.CompressionOptionsPq | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: models.QueueFullBehaviorOptions | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWebhook | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<CreateOutputSystemByPackOauthParam> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<CreateOutputSystemByPackOauthHeader> | undefined;
  /**
   * URL of a webhook endpoint to send events to, such as http://localhost:10200
   */
  url?: string | undefined;
  /**
   * Exclude all IPs of the current host from the list of any resolved hostnames
   */
  excludeSelf?: boolean | undefined;
  urls?: Array<CreateOutputSystemByPackUrlWebhook> | undefined;
  /**
   * The interval in which to re-resolve any hostnames and pick up destinations from A records
   */
  dnsResolvePeriodSec?: number | undefined;
  /**
   * How far back in time to keep traffic stats for load balancing purposes
   */
  loadBalanceStatsPeriodSec?: number | undefined;
  /**
   * Binds 'loginUrl' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'loginUrl' at runtime.
   */
  __template_loginUrl?: string | undefined;
  /**
   * Binds 'secret' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'secret' at runtime.
   */
  __template_secret?: string | undefined;
  /**
   * Binds 'url' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'url' at runtime.
   */
  __template_url?: string | undefined;
};

export type CreateOutputSystemByPackOutputDefault = {
  /**
   * Unique ID for this output
   */
  id: string;
  type: "default";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the default output. This will be used whenever a nonexistent/deleted output is referenced.
   */
  defaultId: string | null;
};

/**
 * Output object
 */
export type CreateOutputSystemByPackRequestBody =
  | CreateOutputSystemByPackOutputDefault
  | CreateOutputSystemByPackOutputWebhook
  | CreateOutputSystemByPackOutputSentinel
  | CreateOutputSystemByPackOutputDevnull
  | CreateOutputSystemByPackOutputSyslog
  | CreateOutputSystemByPackOutputSplunk
  | CreateOutputSystemByPackOutputSplunkLb
  | CreateOutputSystemByPackOutputSplunkHec
  | CreateOutputSystemByPackOutputWizHec
  | CreateOutputSystemByPackOutputTcpjson
  | CreateOutputSystemByPackOutputWavefront
  | CreateOutputSystemByPackOutputSignalfx
  | CreateOutputSystemByPackOutputFilesystem
  | CreateOutputSystemByPackOutputS3
  | CreateOutputSystemByPackOutputAzureBlob
  | CreateOutputSystemByPackOutputAzureDataExplorer
  | CreateOutputSystemByPackOutputAzureLogs
  | CreateOutputSystemByPackOutputKinesis
  | CreateOutputSystemByPackOutputHoneycomb
  | CreateOutputSystemByPackOutputAzureEventhub
  | CreateOutputSystemByPackOutputGoogleChronicle
  | CreateOutputSystemByPackOutputGoogleCloudStorage
  | CreateOutputSystemByPackOutputGoogleCloudLogging
  | CreateOutputSystemByPackOutputGooglePubsub
  | CreateOutputSystemByPackOutputExabeam
  | CreateOutputSystemByPackOutputKafka
  | CreateOutputSystemByPackOutputConfluentCloud
  | CreateOutputSystemByPackOutputMsk
  | CreateOutputSystemByPackOutputElastic
  | CreateOutputSystemByPackOutputElasticCloud
  | CreateOutputSystemByPackOutputNewrelic
  | CreateOutputSystemByPackOutputNewrelicEvents
  | CreateOutputSystemByPackOutputInfluxdb
  | CreateOutputSystemByPackOutputCloudwatch
  | CreateOutputSystemByPackOutputMinio
  | CreateOutputSystemByPackOutputStatsd
  | CreateOutputSystemByPackOutputStatsdExt
  | CreateOutputSystemByPackOutputGraphite
  | CreateOutputSystemByPackOutputRouter
  | CreateOutputSystemByPackOutputSns
  | CreateOutputSystemByPackOutputSqs
  | CreateOutputSystemByPackOutputSnmp
  | CreateOutputSystemByPackOutputSumoLogic
  | CreateOutputSystemByPackOutputDatadog
  | (CreateOutputSystemByPackOutputGrafanaCloudUnion & {
    type: "grafana_cloud";
  })
  | CreateOutputSystemByPackOutputLoki
  | CreateOutputSystemByPackOutputPrometheus
  | CreateOutputSystemByPackOutputRing
  | CreateOutputSystemByPackOutputOpenTelemetry
  | CreateOutputSystemByPackOutputServiceNow
  | CreateOutputSystemByPackOutputDataset
  | CreateOutputSystemByPackOutputCriblTcp
  | CreateOutputSystemByPackOutputCriblHttp
  | CreateOutputSystemByPackOutputCriblSearchEngine
  | CreateOutputSystemByPackOutputHumioHec
  | CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem
  | CreateOutputSystemByPackOutputDlS3
  | CreateOutputSystemByPackOutputSecurityLake
  | CreateOutputSystemByPackOutputCriblLake
  | CreateOutputSystemByPackOutputDiskSpool
  | CreateOutputSystemByPackOutputClickHouse
  | CreateOutputSystemByPackOutputXsiam
  | CreateOutputSystemByPackOutputNetflow
  | CreateOutputSystemByPackOutputDynatraceHttp
  | CreateOutputSystemByPackOutputDynatraceOtlp
  | CreateOutputSystemByPackOutputSentinelOneAiSiem
  | CreateOutputSystemByPackOutputChronicle
  | CreateOutputSystemByPackOutputDatabricks
  | CreateOutputSystemByPackOutputMicrosoftFabric
  | CreateOutputSystemByPackOutputCloudflareR2;

export type CreateOutputSystemByPackRequest = {
  /**
   * The <code>id</code> of the Pack to create.
   */
  pack: string;
  /**
   * Output object
   */
  requestBody:
    | CreateOutputSystemByPackOutputDefault
    | CreateOutputSystemByPackOutputWebhook
    | CreateOutputSystemByPackOutputSentinel
    | CreateOutputSystemByPackOutputDevnull
    | CreateOutputSystemByPackOutputSyslog
    | CreateOutputSystemByPackOutputSplunk
    | CreateOutputSystemByPackOutputSplunkLb
    | CreateOutputSystemByPackOutputSplunkHec
    | CreateOutputSystemByPackOutputWizHec
    | CreateOutputSystemByPackOutputTcpjson
    | CreateOutputSystemByPackOutputWavefront
    | CreateOutputSystemByPackOutputSignalfx
    | CreateOutputSystemByPackOutputFilesystem
    | CreateOutputSystemByPackOutputS3
    | CreateOutputSystemByPackOutputAzureBlob
    | CreateOutputSystemByPackOutputAzureDataExplorer
    | CreateOutputSystemByPackOutputAzureLogs
    | CreateOutputSystemByPackOutputKinesis
    | CreateOutputSystemByPackOutputHoneycomb
    | CreateOutputSystemByPackOutputAzureEventhub
    | CreateOutputSystemByPackOutputGoogleChronicle
    | CreateOutputSystemByPackOutputGoogleCloudStorage
    | CreateOutputSystemByPackOutputGoogleCloudLogging
    | CreateOutputSystemByPackOutputGooglePubsub
    | CreateOutputSystemByPackOutputExabeam
    | CreateOutputSystemByPackOutputKafka
    | CreateOutputSystemByPackOutputConfluentCloud
    | CreateOutputSystemByPackOutputMsk
    | CreateOutputSystemByPackOutputElastic
    | CreateOutputSystemByPackOutputElasticCloud
    | CreateOutputSystemByPackOutputNewrelic
    | CreateOutputSystemByPackOutputNewrelicEvents
    | CreateOutputSystemByPackOutputInfluxdb
    | CreateOutputSystemByPackOutputCloudwatch
    | CreateOutputSystemByPackOutputMinio
    | CreateOutputSystemByPackOutputStatsd
    | CreateOutputSystemByPackOutputStatsdExt
    | CreateOutputSystemByPackOutputGraphite
    | CreateOutputSystemByPackOutputRouter
    | CreateOutputSystemByPackOutputSns
    | CreateOutputSystemByPackOutputSqs
    | CreateOutputSystemByPackOutputSnmp
    | CreateOutputSystemByPackOutputSumoLogic
    | CreateOutputSystemByPackOutputDatadog
    | (CreateOutputSystemByPackOutputGrafanaCloudUnion & {
      type: "grafana_cloud";
    })
    | CreateOutputSystemByPackOutputLoki
    | CreateOutputSystemByPackOutputPrometheus
    | CreateOutputSystemByPackOutputRing
    | CreateOutputSystemByPackOutputOpenTelemetry
    | CreateOutputSystemByPackOutputServiceNow
    | CreateOutputSystemByPackOutputDataset
    | CreateOutputSystemByPackOutputCriblTcp
    | CreateOutputSystemByPackOutputCriblHttp
    | CreateOutputSystemByPackOutputCriblSearchEngine
    | CreateOutputSystemByPackOutputHumioHec
    | CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem
    | CreateOutputSystemByPackOutputDlS3
    | CreateOutputSystemByPackOutputSecurityLake
    | CreateOutputSystemByPackOutputCriblLake
    | CreateOutputSystemByPackOutputDiskSpool
    | CreateOutputSystemByPackOutputClickHouse
    | CreateOutputSystemByPackOutputXsiam
    | CreateOutputSystemByPackOutputNetflow
    | CreateOutputSystemByPackOutputDynatraceHttp
    | CreateOutputSystemByPackOutputDynatraceOtlp
    | CreateOutputSystemByPackOutputSentinelOneAiSiem
    | CreateOutputSystemByPackOutputChronicle
    | CreateOutputSystemByPackOutputDatabricks
    | CreateOutputSystemByPackOutputMicrosoftFabric
    | CreateOutputSystemByPackOutputCloudflareR2;
};

/** @internal */
export type CreateOutputSystemByPackOutputAzureLogs$Outbound = {
  id: string;
  type: "azure_logs";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  logType: string;
  resourceId?: string | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  useRoundRobinDns?: boolean | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  apiUrl?: string | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  authType?: string | undefined;
  description?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsAzureLogs$Outbound | undefined;
  workspaceId?: string | undefined;
  workspaceKey?: string | undefined;
  keypairSecret?: string | undefined;
  __template_workspaceId?: string | undefined;
  __template_workspaceKey?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputAzureLogs$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputAzureLogs$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputAzureLogs
> = z.object({
  id: z.string(),
  type: z.literal("azure_logs"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  logType: z.string(),
  resourceId: z.string().optional(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  useRoundRobinDns: z.boolean().optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  apiUrl: z.string().optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  authType: CreateOutputSystemByPackAuthenticationMethodAzureLogs$outboundSchema
    .optional(),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: CreateOutputSystemByPackPqControlsAzureLogs$outboundSchema
    .optional(),
  workspaceId: z.string().optional(),
  workspaceKey: z.string().optional(),
  keypairSecret: z.string().optional(),
  __template_workspaceId: z.string().optional(),
  __template_workspaceKey: z.string().optional(),
});

export function createOutputSystemByPackOutputAzureLogsToJSON(
  createOutputSystemByPackOutputAzureLogs:
    CreateOutputSystemByPackOutputAzureLogs,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputAzureLogs$outboundSchema.parse(
      createOutputSystemByPackOutputAzureLogs,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackIngestionMode$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackIngestionMode
> = openEnums.outboundSchema(CreateOutputSystemByPackIngestionMode);

/** @internal */
export const CreateOutputSystemByPackOauthTypeAuthenticationMethod$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    CreateOutputSystemByPackOauthTypeAuthenticationMethod
  > = openEnums.outboundSchema(
    CreateOutputSystemByPackOauthTypeAuthenticationMethod,
  );

/** @internal */
export type CreateOutputSystemByPackCertificate$Outbound = {
  certificateName?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackCertificate$outboundSchema: z.ZodType<
  CreateOutputSystemByPackCertificate$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackCertificate
> = z.object({
  certificateName: z.string().optional(),
});

export function createOutputSystemByPackCertificateToJSON(
  createOutputSystemByPackCertificate: CreateOutputSystemByPackCertificate,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackCertificate$outboundSchema.parse(
      createOutputSystemByPackCertificate,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackPrefixOptional$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackPrefixOptional
> = openEnums.outboundSchema(CreateOutputSystemByPackPrefixOptional);

/** @internal */
export type CreateOutputSystemByPackExtentTag$Outbound = {
  prefix?: string | undefined;
  value: string;
};

/** @internal */
export const CreateOutputSystemByPackExtentTag$outboundSchema: z.ZodType<
  CreateOutputSystemByPackExtentTag$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackExtentTag
> = z.object({
  prefix: CreateOutputSystemByPackPrefixOptional$outboundSchema.optional(),
  value: z.string(),
});

export function createOutputSystemByPackExtentTagToJSON(
  createOutputSystemByPackExtentTag: CreateOutputSystemByPackExtentTag,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackExtentTag$outboundSchema.parse(
      createOutputSystemByPackExtentTag,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackIngestIfNotExist$Outbound = {
  value: string;
};

/** @internal */
export const CreateOutputSystemByPackIngestIfNotExist$outboundSchema: z.ZodType<
  CreateOutputSystemByPackIngestIfNotExist$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackIngestIfNotExist
> = z.object({
  value: z.string(),
});

export function createOutputSystemByPackIngestIfNotExistToJSON(
  createOutputSystemByPackIngestIfNotExist:
    CreateOutputSystemByPackIngestIfNotExist,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackIngestIfNotExist$outboundSchema.parse(
      createOutputSystemByPackIngestIfNotExist,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackReportLevel$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackReportLevel
> = openEnums.outboundSchema(CreateOutputSystemByPackReportLevel);

/** @internal */
export const CreateOutputSystemByPackReportMethod$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackReportMethod
> = openEnums.outboundSchema(CreateOutputSystemByPackReportMethod);

/** @internal */
export type CreateOutputSystemByPackAdditionalProperty$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const CreateOutputSystemByPackAdditionalProperty$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackAdditionalProperty$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackAdditionalProperty
  > = z.object({
    key: z.string(),
    value: z.string(),
  });

export function createOutputSystemByPackAdditionalPropertyToJSON(
  createOutputSystemByPackAdditionalProperty:
    CreateOutputSystemByPackAdditionalProperty,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackAdditionalProperty$outboundSchema.parse(
      createOutputSystemByPackAdditionalProperty,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsAzureDataExplorer$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsAzureDataExplorer$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsAzureDataExplorer$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsAzureDataExplorer
  > = z.object({});

export function createOutputSystemByPackPqControlsAzureDataExplorerToJSON(
  createOutputSystemByPackPqControlsAzureDataExplorer:
    CreateOutputSystemByPackPqControlsAzureDataExplorer,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsAzureDataExplorer$outboundSchema.parse(
      createOutputSystemByPackPqControlsAzureDataExplorer,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputAzureDataExplorer$Outbound = {
  id: string;
  type: "azure_data_explorer";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  clusterUrl: string;
  database: string;
  table: string;
  validateDatabaseSettings?: boolean | undefined;
  ingestMode?: string | undefined;
  oauthEndpoint: string;
  tenantId: string;
  clientId: string;
  scope: string;
  oauthType: string;
  description?: string | undefined;
  clientSecret?: string | undefined;
  textSecret?: string | undefined;
  certificate?: CreateOutputSystemByPackCertificate$Outbound | undefined;
  format?: string | undefined;
  compress: string;
  compressionLevel?: string | undefined;
  automaticSchema?: boolean | undefined;
  parquetSchema?: string | undefined;
  parquetVersion?: string | undefined;
  parquetDataPageVersion?: string | undefined;
  parquetRowGroupLength?: number | undefined;
  parquetPageSize?: string | undefined;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<models.ItemsTypeKeyValueMetadata$Outbound>
    | undefined;
  enableStatistics?: boolean | undefined;
  enableWritePageIndex?: boolean | undefined;
  enablePageChecksum?: boolean | undefined;
  removeEmptyDirs?: boolean | undefined;
  emptyDirCleanupSec?: number | undefined;
  directoryBatchSize?: number | undefined;
  deadletterEnabled?: boolean | undefined;
  deadletterPath?: string | undefined;
  maxRetryNum?: number | undefined;
  isMappingObj?: boolean | undefined;
  mappingObj?: string | undefined;
  mappingRef?: string | undefined;
  ingestUrl?: string | undefined;
  onBackpressure?: string | undefined;
  stagePath?: string | undefined;
  fileNameSuffix?: string | undefined;
  maxFileSizeMB?: number | undefined;
  maxFileOpenTimeSec?: number | undefined;
  maxFileIdleTimeSec?: number | undefined;
  maxOpenFiles?: number | undefined;
  maxConcurrentFileParts?: number | undefined;
  onDiskFullBackpressure?: string | undefined;
  addIdToStagePath?: boolean | undefined;
  retrySettings?: models.RetrySettingsType$Outbound | undefined;
  timeoutSec?: number | undefined;
  flushImmediately?: boolean | undefined;
  retainBlobOnSuccess?: boolean | undefined;
  extentTags?: Array<CreateOutputSystemByPackExtentTag$Outbound> | undefined;
  ingestIfNotExists?:
    | Array<CreateOutputSystemByPackIngestIfNotExist$Outbound>
    | undefined;
  reportLevel?: string | undefined;
  reportMethod?: string | undefined;
  additionalProperties?:
    | Array<CreateOutputSystemByPackAdditionalProperty$Outbound>
    | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  flushPeriodSec?: number | undefined;
  rejectUnauthorized?: boolean | undefined;
  useRoundRobinDns?: boolean | undefined;
  keepAlive?: boolean | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?:
    | CreateOutputSystemByPackPqControlsAzureDataExplorer$Outbound
    | undefined;
  __template_clusterUrl?: string | undefined;
  __template_database?: string | undefined;
  __template_table?: string | undefined;
  __template_tenantId?: string | undefined;
  __template_clientId?: string | undefined;
  __template_scope?: string | undefined;
  __template_clientSecret?: string | undefined;
  __template_format?: string | undefined;
  __template_ingestUrl?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputAzureDataExplorer$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackOutputAzureDataExplorer$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackOutputAzureDataExplorer
  > = z.object({
    id: z.string(),
    type: z.literal("azure_data_explorer"),
    pipeline: z.string().optional(),
    systemFields: z.array(z.string()).optional(),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    clusterUrl: z.string(),
    database: z.string(),
    table: z.string(),
    validateDatabaseSettings: z.boolean().optional(),
    ingestMode: CreateOutputSystemByPackIngestionMode$outboundSchema.optional(),
    oauthEndpoint:
      models.MicrosoftEntraIdAuthenticationEndpointOptionsSasl$outboundSchema,
    tenantId: z.string(),
    clientId: z.string(),
    scope: z.string(),
    oauthType:
      CreateOutputSystemByPackOauthTypeAuthenticationMethod$outboundSchema,
    description: z.string().optional(),
    clientSecret: z.string().optional(),
    textSecret: z.string().optional(),
    certificate: z.lazy(() =>
      CreateOutputSystemByPackCertificate$outboundSchema
    ).optional(),
    format: models.DataFormatOptions$outboundSchema.optional(),
    compress: models.CompressionOptions2$outboundSchema,
    compressionLevel: models.CompressionLevelOptions$outboundSchema.optional(),
    automaticSchema: z.boolean().optional(),
    parquetSchema: z.string().optional(),
    parquetVersion: models.ParquetVersionOptions$outboundSchema.optional(),
    parquetDataPageVersion: models.DataPageVersionOptions$outboundSchema
      .optional(),
    parquetRowGroupLength: z.number().optional(),
    parquetPageSize: z.string().optional(),
    shouldLogInvalidRows: z.boolean().optional(),
    keyValueMetadata: z.array(models.ItemsTypeKeyValueMetadata$outboundSchema)
      .optional(),
    enableStatistics: z.boolean().optional(),
    enableWritePageIndex: z.boolean().optional(),
    enablePageChecksum: z.boolean().optional(),
    removeEmptyDirs: z.boolean().optional(),
    emptyDirCleanupSec: z.number().optional(),
    directoryBatchSize: z.number().optional(),
    deadletterEnabled: z.boolean().optional(),
    deadletterPath: z.string().optional(),
    maxRetryNum: z.number().optional(),
    isMappingObj: z.boolean().optional(),
    mappingObj: z.string().optional(),
    mappingRef: z.string().optional(),
    ingestUrl: z.string().optional(),
    onBackpressure: models.BackpressureBehaviorOptions$outboundSchema
      .optional(),
    stagePath: z.string().optional(),
    fileNameSuffix: z.string().optional(),
    maxFileSizeMB: z.number().optional(),
    maxFileOpenTimeSec: z.number().optional(),
    maxFileIdleTimeSec: z.number().optional(),
    maxOpenFiles: z.number().optional(),
    maxConcurrentFileParts: z.number().optional(),
    onDiskFullBackpressure: models.DiskSpaceProtectionOptions$outboundSchema
      .optional(),
    addIdToStagePath: z.boolean().optional(),
    retrySettings: models.RetrySettingsType$outboundSchema.optional(),
    timeoutSec: z.number().optional(),
    flushImmediately: z.boolean().optional(),
    retainBlobOnSuccess: z.boolean().optional(),
    extentTags: z.array(
      z.lazy(() => CreateOutputSystemByPackExtentTag$outboundSchema),
    ).optional(),
    ingestIfNotExists: z.array(
      z.lazy(() => CreateOutputSystemByPackIngestIfNotExist$outboundSchema),
    ).optional(),
    reportLevel: CreateOutputSystemByPackReportLevel$outboundSchema.optional(),
    reportMethod: CreateOutputSystemByPackReportMethod$outboundSchema
      .optional(),
    additionalProperties: z.array(
      z.lazy(() => CreateOutputSystemByPackAdditionalProperty$outboundSchema),
    ).optional(),
    responseRetrySettings: z.array(
      models.ItemsTypeResponseRetrySettings$outboundSchema,
    ).optional(),
    timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
      .optional(),
    responseHonorRetryAfterHeader: z.boolean().optional(),
    concurrency: z.number().optional(),
    maxPayloadSizeKB: z.number().optional(),
    maxPayloadEvents: z.number().optional(),
    flushPeriodSec: z.number().optional(),
    rejectUnauthorized: z.boolean().optional(),
    useRoundRobinDns: z.boolean().optional(),
    keepAlive: z.boolean().optional(),
    pqStrictOrdering: z.boolean().optional(),
    pqRatePerSec: z.number().optional(),
    pqMode: models.ModeOptions$outboundSchema.optional(),
    pqMaxBufferSize: z.number().optional(),
    pqMaxBackpressureSec: z.number().optional(),
    pqMaxFileSize: z.string().optional(),
    pqMaxSize: z.string().optional(),
    pqPath: z.string().optional(),
    pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
    pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
    pqControls: z.lazy(() =>
      CreateOutputSystemByPackPqControlsAzureDataExplorer$outboundSchema
    ).optional(),
    __template_clusterUrl: z.string().optional(),
    __template_database: z.string().optional(),
    __template_table: z.string().optional(),
    __template_tenantId: z.string().optional(),
    __template_clientId: z.string().optional(),
    __template_scope: z.string().optional(),
    __template_clientSecret: z.string().optional(),
    __template_format: z.string().optional(),
    __template_ingestUrl: z.string().optional(),
  });

export function createOutputSystemByPackOutputAzureDataExplorerToJSON(
  createOutputSystemByPackOutputAzureDataExplorer:
    CreateOutputSystemByPackOutputAzureDataExplorer,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputAzureDataExplorer$outboundSchema.parse(
      createOutputSystemByPackOutputAzureDataExplorer,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackBlobAccessTier$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackBlobAccessTier
> = openEnums.outboundSchema(CreateOutputSystemByPackBlobAccessTier);

/** @internal */
export type CreateOutputSystemByPackOutputAzureBlob$Outbound = {
  id: string;
  type: "azure_blob";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  containerName: string;
  createContainer?: boolean | undefined;
  destPath?: string | undefined;
  stagePath: string;
  addIdToStagePath?: boolean | undefined;
  maxConcurrentFileParts?: number | undefined;
  removeEmptyDirs?: boolean | undefined;
  partitionExpr?: string | undefined;
  format?: string | undefined;
  baseFileName?: string | undefined;
  fileNameSuffix?: string | undefined;
  maxFileSizeMB?: number | undefined;
  maxFileOpenTimeSec?: number | undefined;
  maxFileIdleTimeSec?: number | undefined;
  maxOpenFiles?: number | undefined;
  headerLine?: string | undefined;
  writeHighWaterMark?: number | undefined;
  onBackpressure?: string | undefined;
  deadletterEnabled?: boolean | undefined;
  onDiskFullBackpressure?: string | undefined;
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType$Outbound | undefined;
  authType?: string | undefined;
  storageClass?: string | undefined;
  description?: string | undefined;
  compress?: string | undefined;
  compressionLevel?: string | undefined;
  automaticSchema?: boolean | undefined;
  parquetSchema?: string | undefined;
  parquetVersion?: string | undefined;
  parquetDataPageVersion?: string | undefined;
  parquetRowGroupLength?: number | undefined;
  parquetPageSize?: string | undefined;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<models.ItemsTypeKeyValueMetadata$Outbound>
    | undefined;
  enableStatistics?: boolean | undefined;
  enableWritePageIndex?: boolean | undefined;
  enablePageChecksum?: boolean | undefined;
  emptyDirCleanupSec?: number | undefined;
  directoryBatchSize?: number | undefined;
  deadletterPath?: string | undefined;
  maxRetryNum?: number | undefined;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?:
    | models.CertificateTypeAzureBlobAuthTypeClientCert$Outbound
    | undefined;
  __template_containerName?: string | undefined;
  __template_format?: string | undefined;
  __template_connectionString?: string | undefined;
  __template_tenantId?: string | undefined;
  __template_clientId?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputAzureBlob$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputAzureBlob$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputAzureBlob
> = z.object({
  id: z.string(),
  type: z.literal("azure_blob"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  containerName: z.string(),
  createContainer: z.boolean().optional(),
  destPath: z.string().optional(),
  stagePath: z.string(),
  addIdToStagePath: z.boolean().optional(),
  maxConcurrentFileParts: z.number().optional(),
  removeEmptyDirs: z.boolean().optional(),
  partitionExpr: z.string().optional(),
  format: models.DataFormatOptions$outboundSchema.optional(),
  baseFileName: z.string().optional(),
  fileNameSuffix: z.string().optional(),
  maxFileSizeMB: z.number().optional(),
  maxFileOpenTimeSec: z.number().optional(),
  maxFileIdleTimeSec: z.number().optional(),
  maxOpenFiles: z.number().optional(),
  headerLine: z.string().optional(),
  writeHighWaterMark: z.number().optional(),
  onBackpressure: models.BackpressureBehaviorOptions1$outboundSchema.optional(),
  deadletterEnabled: z.boolean().optional(),
  onDiskFullBackpressure: models.DiskSpaceProtectionOptions$outboundSchema
    .optional(),
  forceCloseOnShutdown: z.boolean().optional(),
  retrySettings: models.RetrySettingsType$outboundSchema.optional(),
  authType: models.AuthenticationMethodOptions$outboundSchema.optional(),
  storageClass: CreateOutputSystemByPackBlobAccessTier$outboundSchema
    .optional(),
  description: z.string().optional(),
  compress: models.CompressionOptions2$outboundSchema.optional(),
  compressionLevel: models.CompressionLevelOptions$outboundSchema.optional(),
  automaticSchema: z.boolean().optional(),
  parquetSchema: z.string().optional(),
  parquetVersion: models.ParquetVersionOptions$outboundSchema.optional(),
  parquetDataPageVersion: models.DataPageVersionOptions$outboundSchema
    .optional(),
  parquetRowGroupLength: z.number().optional(),
  parquetPageSize: z.string().optional(),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(models.ItemsTypeKeyValueMetadata$outboundSchema)
    .optional(),
  enableStatistics: z.boolean().optional(),
  enableWritePageIndex: z.boolean().optional(),
  enablePageChecksum: z.boolean().optional(),
  emptyDirCleanupSec: z.number().optional(),
  directoryBatchSize: z.number().optional(),
  deadletterPath: z.string().optional(),
  maxRetryNum: z.number().optional(),
  connectionString: z.string().optional(),
  textSecret: z.string().optional(),
  storageAccountName: z.string().optional(),
  tenantId: z.string().optional(),
  clientId: z.string().optional(),
  azureCloud: z.string().optional(),
  endpointSuffix: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificate: models.CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema
    .optional(),
  __template_containerName: z.string().optional(),
  __template_format: z.string().optional(),
  __template_connectionString: z.string().optional(),
  __template_tenantId: z.string().optional(),
  __template_clientId: z.string().optional(),
});

export function createOutputSystemByPackOutputAzureBlobToJSON(
  createOutputSystemByPackOutputAzureBlob:
    CreateOutputSystemByPackOutputAzureBlob,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputAzureBlob$outboundSchema.parse(
      createOutputSystemByPackOutputAzureBlob,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputS3$Outbound = {
  id: string;
  type: "s3";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region?: string | undefined;
  awsSecretKey?: string | undefined;
  awsAuthenticationMethod?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion?: string | undefined;
  reuseConnections?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  enableAssumeRole?: boolean | undefined;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds?: number | undefined;
  stagePath: string;
  addIdToStagePath?: boolean | undefined;
  destPath?: string | undefined;
  objectACL?: string | undefined;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  kmsKeyId?: string | undefined;
  removeEmptyDirs?: boolean | undefined;
  partitionExpr?: string | undefined;
  format?: string | undefined;
  baseFileName?: string | undefined;
  fileNameSuffix?: string | undefined;
  maxFileSizeMB?: number | undefined;
  maxOpenFiles?: number | undefined;
  headerLine?: string | undefined;
  writeHighWaterMark?: number | undefined;
  onBackpressure?: string | undefined;
  deadletterEnabled?: boolean | undefined;
  onDiskFullBackpressure?: string | undefined;
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType$Outbound | undefined;
  maxFileOpenTimeSec?: number | undefined;
  maxFileIdleTimeSec?: number | undefined;
  maxConcurrentFileParts?: number | undefined;
  verifyPermissions?: boolean | undefined;
  maxClosingFilesToBackpressure?: number | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress?: string | undefined;
  compressionLevel?: string | undefined;
  automaticSchema?: boolean | undefined;
  parquetSchema?: string | undefined;
  parquetVersion?: string | undefined;
  parquetDataPageVersion?: string | undefined;
  parquetRowGroupLength?: number | undefined;
  parquetPageSize?: string | undefined;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<models.ItemsTypeKeyValueMetadata$Outbound>
    | undefined;
  enableStatistics?: boolean | undefined;
  enableWritePageIndex?: boolean | undefined;
  enablePageChecksum?: boolean | undefined;
  emptyDirCleanupSec?: number | undefined;
  directoryBatchSize?: number | undefined;
  deadletterPath?: string | undefined;
  maxRetryNum?: number | undefined;
  __template_bucket?: string | undefined;
  __template_region?: string | undefined;
  __template_awsSecretKey?: string | undefined;
  __template_assumeRoleArn?: string | undefined;
  __template_assumeRoleExternalId?: string | undefined;
  __template_format?: string | undefined;
  __template_awsApiKey?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputS3$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputS3$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputS3
> = z.object({
  id: z.string(),
  type: z.literal("s3"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsAuthenticationMethod: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: models.SignatureVersionOptionsS3CollectorConf$outboundSchema
    .optional(),
  reuseConnections: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  enableAssumeRole: z.boolean().optional(),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().optional(),
  stagePath: z.string(),
  addIdToStagePath: z.boolean().optional(),
  destPath: z.string().optional(),
  objectACL: models.ObjectAclOptions$outboundSchema.optional(),
  storageClass: models.StorageClassOptions$outboundSchema.optional(),
  serverSideEncryption: models
    .ServerSideEncryptionForUploadedObjectsOptions$outboundSchema.optional(),
  kmsKeyId: z.string().optional(),
  removeEmptyDirs: z.boolean().optional(),
  partitionExpr: z.string().optional(),
  format: models.DataFormatOptions$outboundSchema.optional(),
  baseFileName: z.string().optional(),
  fileNameSuffix: z.string().optional(),
  maxFileSizeMB: z.number().optional(),
  maxOpenFiles: z.number().optional(),
  headerLine: z.string().optional(),
  writeHighWaterMark: z.number().optional(),
  onBackpressure: models.BackpressureBehaviorOptions1$outboundSchema.optional(),
  deadletterEnabled: z.boolean().optional(),
  onDiskFullBackpressure: models.DiskSpaceProtectionOptions$outboundSchema
    .optional(),
  forceCloseOnShutdown: z.boolean().optional(),
  retrySettings: models.RetrySettingsType$outboundSchema.optional(),
  maxFileOpenTimeSec: z.number().optional(),
  maxFileIdleTimeSec: z.number().optional(),
  maxConcurrentFileParts: z.number().optional(),
  verifyPermissions: z.boolean().optional(),
  maxClosingFilesToBackpressure: z.number().optional(),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: models.CompressionOptions2$outboundSchema.optional(),
  compressionLevel: models.CompressionLevelOptions$outboundSchema.optional(),
  automaticSchema: z.boolean().optional(),
  parquetSchema: z.string().optional(),
  parquetVersion: models.ParquetVersionOptions$outboundSchema.optional(),
  parquetDataPageVersion: models.DataPageVersionOptions$outboundSchema
    .optional(),
  parquetRowGroupLength: z.number().optional(),
  parquetPageSize: z.string().optional(),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(models.ItemsTypeKeyValueMetadata$outboundSchema)
    .optional(),
  enableStatistics: z.boolean().optional(),
  enableWritePageIndex: z.boolean().optional(),
  enablePageChecksum: z.boolean().optional(),
  emptyDirCleanupSec: z.number().optional(),
  directoryBatchSize: z.number().optional(),
  deadletterPath: z.string().optional(),
  maxRetryNum: z.number().optional(),
  __template_bucket: z.string().optional(),
  __template_region: z.string().optional(),
  __template_awsSecretKey: z.string().optional(),
  __template_assumeRoleArn: z.string().optional(),
  __template_assumeRoleExternalId: z.string().optional(),
  __template_format: z.string().optional(),
  __template_awsApiKey: z.string().optional(),
});

export function createOutputSystemByPackOutputS3ToJSON(
  createOutputSystemByPackOutputS3: CreateOutputSystemByPackOutputS3,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputS3$outboundSchema.parse(
      createOutputSystemByPackOutputS3,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputFilesystem$Outbound = {
  id: string;
  type: "filesystem";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  destPath: string;
  stagePath?: string | undefined;
  addIdToStagePath?: boolean | undefined;
  removeEmptyDirs?: boolean | undefined;
  partitionExpr?: string | undefined;
  format?: string | undefined;
  baseFileName?: string | undefined;
  fileNameSuffix?: string | undefined;
  maxFileSizeMB?: number | undefined;
  maxFileOpenTimeSec?: number | undefined;
  maxFileIdleTimeSec?: number | undefined;
  maxOpenFiles?: number | undefined;
  headerLine?: string | undefined;
  writeHighWaterMark?: number | undefined;
  onBackpressure?: string | undefined;
  deadletterEnabled?: boolean | undefined;
  onDiskFullBackpressure?: string | undefined;
  forceCloseOnShutdown?: boolean | undefined;
  retrySettings?: models.RetrySettingsType$Outbound | undefined;
  description?: string | undefined;
  compress?: string | undefined;
  compressionLevel?: string | undefined;
  automaticSchema?: boolean | undefined;
  parquetSchema?: string | undefined;
  parquetVersion?: string | undefined;
  parquetDataPageVersion?: string | undefined;
  parquetRowGroupLength?: number | undefined;
  parquetPageSize?: string | undefined;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<models.ItemsTypeKeyValueMetadata$Outbound>
    | undefined;
  enableStatistics?: boolean | undefined;
  enableWritePageIndex?: boolean | undefined;
  enablePageChecksum?: boolean | undefined;
  emptyDirCleanupSec?: number | undefined;
  directoryBatchSize?: number | undefined;
  deadletterPath?: string | undefined;
  maxRetryNum?: number | undefined;
  __template_format?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputFilesystem$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputFilesystem$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputFilesystem
> = z.object({
  id: z.string(),
  type: z.literal("filesystem"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  destPath: z.string(),
  stagePath: z.string().optional(),
  addIdToStagePath: z.boolean().optional(),
  removeEmptyDirs: z.boolean().optional(),
  partitionExpr: z.string().optional(),
  format: models.DataFormatOptions$outboundSchema.optional(),
  baseFileName: z.string().optional(),
  fileNameSuffix: z.string().optional(),
  maxFileSizeMB: z.number().optional(),
  maxFileOpenTimeSec: z.number().optional(),
  maxFileIdleTimeSec: z.number().optional(),
  maxOpenFiles: z.number().optional(),
  headerLine: z.string().optional(),
  writeHighWaterMark: z.number().optional(),
  onBackpressure: models.BackpressureBehaviorOptions1$outboundSchema.optional(),
  deadletterEnabled: z.boolean().optional(),
  onDiskFullBackpressure: models.DiskSpaceProtectionOptions$outboundSchema
    .optional(),
  forceCloseOnShutdown: z.boolean().optional(),
  retrySettings: models.RetrySettingsType$outboundSchema.optional(),
  description: z.string().optional(),
  compress: models.CompressionOptions2$outboundSchema.optional(),
  compressionLevel: models.CompressionLevelOptions$outboundSchema.optional(),
  automaticSchema: z.boolean().optional(),
  parquetSchema: z.string().optional(),
  parquetVersion: models.ParquetVersionOptions$outboundSchema.optional(),
  parquetDataPageVersion: models.DataPageVersionOptions$outboundSchema
    .optional(),
  parquetRowGroupLength: z.number().optional(),
  parquetPageSize: z.string().optional(),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(models.ItemsTypeKeyValueMetadata$outboundSchema)
    .optional(),
  enableStatistics: z.boolean().optional(),
  enableWritePageIndex: z.boolean().optional(),
  enablePageChecksum: z.boolean().optional(),
  emptyDirCleanupSec: z.number().optional(),
  directoryBatchSize: z.number().optional(),
  deadletterPath: z.string().optional(),
  maxRetryNum: z.number().optional(),
  __template_format: z.string().optional(),
});

export function createOutputSystemByPackOutputFilesystemToJSON(
  createOutputSystemByPackOutputFilesystem:
    CreateOutputSystemByPackOutputFilesystem,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputFilesystem$outboundSchema.parse(
      createOutputSystemByPackOutputFilesystem,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsSignalfx$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSignalfx$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsSignalfx$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsSignalfx
  > = z.object({});

export function createOutputSystemByPackPqControlsSignalfxToJSON(
  createOutputSystemByPackPqControlsSignalfx:
    CreateOutputSystemByPackPqControlsSignalfx,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSignalfx$outboundSchema.parse(
      createOutputSystemByPackPqControlsSignalfx,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSignalfx$Outbound = {
  id: string;
  type: "signalfx";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  authType?: string | undefined;
  realm: string;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  useRoundRobinDns?: boolean | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSignalfx$Outbound | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSignalfx$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSignalfx$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSignalfx
> = z.object({
  id: z.string(),
  type: z.literal("signalfx"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  realm: z.string(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  useRoundRobinDns: z.boolean().optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSignalfx$outboundSchema
  ).optional(),
});

export function createOutputSystemByPackOutputSignalfxToJSON(
  createOutputSystemByPackOutputSignalfx:
    CreateOutputSystemByPackOutputSignalfx,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSignalfx$outboundSchema.parse(
      createOutputSystemByPackOutputSignalfx,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsWavefront$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsWavefront$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsWavefront$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsWavefront
  > = z.object({});

export function createOutputSystemByPackPqControlsWavefrontToJSON(
  createOutputSystemByPackPqControlsWavefront:
    CreateOutputSystemByPackPqControlsWavefront,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsWavefront$outboundSchema.parse(
      createOutputSystemByPackPqControlsWavefront,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputWavefront$Outbound = {
  id: string;
  type: "wavefront";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  authType?: string | undefined;
  domain: string;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  useRoundRobinDns?: boolean | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  description?: string | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWavefront$Outbound | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputWavefront$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputWavefront$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputWavefront
> = z.object({
  id: z.string(),
  type: z.literal("wavefront"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  domain: z.string(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  useRoundRobinDns: z.boolean().optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  description: z.string().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsWavefront$outboundSchema
  ).optional(),
});

export function createOutputSystemByPackOutputWavefrontToJSON(
  createOutputSystemByPackOutputWavefront:
    CreateOutputSystemByPackOutputWavefront,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputWavefront$outboundSchema.parse(
      createOutputSystemByPackOutputWavefront,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsTcpjson$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsTcpjson$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsTcpjson$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsTcpjson
  > = z.object({});

export function createOutputSystemByPackPqControlsTcpjsonToJSON(
  createOutputSystemByPackPqControlsTcpjson:
    CreateOutputSystemByPackPqControlsTcpjson,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsTcpjson$outboundSchema.parse(
      createOutputSystemByPackPqControlsTcpjson,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputTcpjson$Outbound = {
  id: string;
  type: "tcpjson";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced?: boolean | undefined;
  compression?: string | undefined;
  logFailedRequests?: boolean | undefined;
  throttleRatePerSec?: string | undefined;
  tls?:
    | models.TlsSettingsClientSideTypeKafkaSchemaRegistry$Outbound
    | undefined;
  connectionTimeout?: number | undefined;
  writeTimeout?: number | undefined;
  tokenTTLMinutes?: number | undefined;
  sendHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  authType?: string | undefined;
  description?: string | undefined;
  host?: string | undefined;
  port?: number | undefined;
  excludeSelf?: boolean | undefined;
  hosts?: Array<models.ItemsTypeHosts$Outbound> | undefined;
  dnsResolvePeriodSec?: number | undefined;
  loadBalanceStatsPeriodSec?: number | undefined;
  maxConcurrentSenders?: number | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsTcpjson$Outbound | undefined;
  authToken?: string | undefined;
  textSecret?: string | undefined;
  __template_host?: string | undefined;
  __template_port?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputTcpjson$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputTcpjson$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputTcpjson
> = z.object({
  id: z.string(),
  type: z.literal("tcpjson"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().optional(),
  compression: models.CompressionOptions1$outboundSchema.optional(),
  logFailedRequests: z.boolean().optional(),
  throttleRatePerSec: z.string().optional(),
  tls: models.TlsSettingsClientSideTypeKafkaSchemaRegistry$outboundSchema
    .optional(),
  connectionTimeout: z.number().optional(),
  writeTimeout: z.number().optional(),
  tokenTTLMinutes: z.number().optional(),
  sendHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  description: z.string().optional(),
  host: z.string().optional(),
  port: z.number().optional(),
  excludeSelf: z.boolean().optional(),
  hosts: z.array(models.ItemsTypeHosts$outboundSchema).optional(),
  dnsResolvePeriodSec: z.number().optional(),
  loadBalanceStatsPeriodSec: z.number().optional(),
  maxConcurrentSenders: z.number().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsTcpjson$outboundSchema
  ).optional(),
  authToken: z.string().optional(),
  textSecret: z.string().optional(),
  __template_host: z.string().optional(),
  __template_port: z.string().optional(),
});

export function createOutputSystemByPackOutputTcpjsonToJSON(
  createOutputSystemByPackOutputTcpjson: CreateOutputSystemByPackOutputTcpjson,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputTcpjson$outboundSchema.parse(
      createOutputSystemByPackOutputTcpjson,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsWizHec$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsWizHec$outboundSchema: z.ZodType<
  CreateOutputSystemByPackPqControlsWizHec$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackPqControlsWizHec
> = z.object({});

export function createOutputSystemByPackPqControlsWizHecToJSON(
  createOutputSystemByPackPqControlsWizHec:
    CreateOutputSystemByPackPqControlsWizHec,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsWizHec$outboundSchema.parse(
      createOutputSystemByPackPqControlsWizHec,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputWizHec$Outbound = {
  id: string;
  type: "wiz_hec";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  nextQueue?: string | undefined;
  tcpRouting?: string | undefined;
  tls?: models.TlsSettingsClientSideType1$Outbound | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  authType?: string | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  wiz_connector_id: string;
  wiz_environment: string;
  data_center: string;
  wiz_sourcetype: string;
  description?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWizHec$Outbound | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  __template_wiz_environment?: string | undefined;
  __template_data_center?: string | undefined;
  __template_wiz_sourcetype?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputWizHec$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputWizHec$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputWizHec
> = z.object({
  id: z.string(),
  type: z.literal("wiz_hec"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  nextQueue: z.string().optional(),
  tcpRouting: z.string().optional(),
  tls: models.TlsSettingsClientSideType1$outboundSchema.optional(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  wiz_connector_id: z.string(),
  wiz_environment: z.string(),
  data_center: z.string(),
  wiz_sourcetype: z.string(),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsWizHec$outboundSchema
  ).optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  __template_wiz_environment: z.string().optional(),
  __template_data_center: z.string().optional(),
  __template_wiz_sourcetype: z.string().optional(),
});

export function createOutputSystemByPackOutputWizHecToJSON(
  createOutputSystemByPackOutputWizHec: CreateOutputSystemByPackOutputWizHec,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputWizHec$outboundSchema.parse(
      createOutputSystemByPackOutputWizHec,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackUrlSplunkHec$Outbound = {
  url: string;
  weight?: number | undefined;
  __template_url?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackUrlSplunkHec$outboundSchema: z.ZodType<
  CreateOutputSystemByPackUrlSplunkHec$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackUrlSplunkHec
> = z.object({
  url: z.string(),
  weight: z.number().optional(),
  __template_url: z.string().optional(),
});

export function createOutputSystemByPackUrlSplunkHecToJSON(
  createOutputSystemByPackUrlSplunkHec: CreateOutputSystemByPackUrlSplunkHec,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackUrlSplunkHec$outboundSchema.parse(
      createOutputSystemByPackUrlSplunkHec,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsSplunkHec$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSplunkHec$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsSplunkHec$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsSplunkHec
  > = z.object({});

export function createOutputSystemByPackPqControlsSplunkHecToJSON(
  createOutputSystemByPackPqControlsSplunkHec:
    CreateOutputSystemByPackPqControlsSplunkHec,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSplunkHec$outboundSchema.parse(
      createOutputSystemByPackPqControlsSplunkHec,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSplunkHec$Outbound = {
  id: string;
  type: "splunk_hec";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  loadBalanced?: boolean | undefined;
  nextQueue?: string | undefined;
  tcpRouting?: string | undefined;
  tls?: models.TlsSettingsClientSideType1$Outbound | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  enableMultiMetrics?: boolean | undefined;
  authType?: string | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  description?: string | undefined;
  url?: string | undefined;
  useRoundRobinDns?: boolean | undefined;
  excludeSelf?: boolean | undefined;
  urls?: Array<CreateOutputSystemByPackUrlSplunkHec$Outbound> | undefined;
  dnsResolvePeriodSec?: number | undefined;
  loadBalanceStatsPeriodSec?: number | undefined;
  token?: string | undefined;
  textSecret?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunkHec$Outbound | undefined;
  __template_url?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSplunkHec$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSplunkHec$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSplunkHec
> = z.object({
  id: z.string(),
  type: z.literal("splunk_hec"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  loadBalanced: z.boolean().optional(),
  nextQueue: z.string().optional(),
  tcpRouting: z.string().optional(),
  tls: models.TlsSettingsClientSideType1$outboundSchema.optional(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  enableMultiMetrics: z.boolean().optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  description: z.string().optional(),
  url: z.string().optional(),
  useRoundRobinDns: z.boolean().optional(),
  excludeSelf: z.boolean().optional(),
  urls: z.array(
    z.lazy(() => CreateOutputSystemByPackUrlSplunkHec$outboundSchema),
  ).optional(),
  dnsResolvePeriodSec: z.number().optional(),
  loadBalanceStatsPeriodSec: z.number().optional(),
  token: z.string().optional(),
  textSecret: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSplunkHec$outboundSchema
  ).optional(),
  __template_url: z.string().optional(),
});

export function createOutputSystemByPackOutputSplunkHecToJSON(
  createOutputSystemByPackOutputSplunkHec:
    CreateOutputSystemByPackOutputSplunkHec,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSplunkHec$outboundSchema.parse(
      createOutputSystemByPackOutputSplunkHec,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackAuthToken$Outbound = {
  authType?: string | undefined;
  authToken?: string | undefined;
  textSecret?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackAuthToken$outboundSchema: z.ZodType<
  CreateOutputSystemByPackAuthToken$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackAuthToken
> = z.object({
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  authToken: z.string().optional(),
  textSecret: z.string().optional(),
});

export function createOutputSystemByPackAuthTokenToJSON(
  createOutputSystemByPackAuthToken: CreateOutputSystemByPackAuthToken,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackAuthToken$outboundSchema.parse(
      createOutputSystemByPackAuthToken,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackIndexerDiscoveryConfigs$Outbound = {
  site: string;
  masterUri: string;
  refreshIntervalSec: number;
  rejectUnauthorized?: boolean | undefined;
  authTokens?: Array<CreateOutputSystemByPackAuthToken$Outbound> | undefined;
  authType?: string | undefined;
  authToken?: string | undefined;
  textSecret?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackIndexerDiscoveryConfigs$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackIndexerDiscoveryConfigs$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackIndexerDiscoveryConfigs
  > = z.object({
    site: z.string(),
    masterUri: z.string(),
    refreshIntervalSec: z.number(),
    rejectUnauthorized: z.boolean().optional(),
    authTokens: z.array(
      z.lazy(() => CreateOutputSystemByPackAuthToken$outboundSchema),
    ).optional(),
    authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
      .optional(),
    authToken: z.string().optional(),
    textSecret: z.string().optional(),
  });

export function createOutputSystemByPackIndexerDiscoveryConfigsToJSON(
  createOutputSystemByPackIndexerDiscoveryConfigs:
    CreateOutputSystemByPackIndexerDiscoveryConfigs,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackIndexerDiscoveryConfigs$outboundSchema.parse(
      createOutputSystemByPackIndexerDiscoveryConfigs,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsSplunkLb$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSplunkLb$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsSplunkLb$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsSplunkLb
  > = z.object({});

export function createOutputSystemByPackPqControlsSplunkLbToJSON(
  createOutputSystemByPackPqControlsSplunkLb:
    CreateOutputSystemByPackPqControlsSplunkLb,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSplunkLb$outboundSchema.parse(
      createOutputSystemByPackPqControlsSplunkLb,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSplunkLb$Outbound = {
  id: string;
  type: "splunk_lb";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  dnsResolvePeriodSec?: number | undefined;
  loadBalanceStatsPeriodSec?: number | undefined;
  maxConcurrentSenders?: number | undefined;
  nestedFields?: string | undefined;
  throttleRatePerSec?: string | undefined;
  connectionTimeout?: number | undefined;
  writeTimeout?: number | undefined;
  tls?:
    | models.TlsSettingsClientSideTypeKafkaSchemaRegistry$Outbound
    | undefined;
  enableMultiMetrics?: boolean | undefined;
  enableACK?: boolean | undefined;
  logFailedRequests?: boolean | undefined;
  maxS2Sversion?: string | undefined;
  onBackpressure?: string | undefined;
  indexerDiscovery?: boolean | undefined;
  senderUnhealthyTimeAllowance?: number | undefined;
  authType?: string | undefined;
  description?: string | undefined;
  maxFailedHealthChecks?: number | undefined;
  compress?: string | undefined;
  indexerDiscoveryConfigs?:
    | CreateOutputSystemByPackIndexerDiscoveryConfigs$Outbound
    | undefined;
  excludeSelf?: boolean | undefined;
  hosts: Array<models.ItemsTypeHosts$Outbound>;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunkLb$Outbound | undefined;
  authToken?: string | undefined;
  textSecret?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSplunkLb$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSplunkLb$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSplunkLb
> = z.object({
  id: z.string(),
  type: z.literal("splunk_lb"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  dnsResolvePeriodSec: z.number().optional(),
  loadBalanceStatsPeriodSec: z.number().optional(),
  maxConcurrentSenders: z.number().optional(),
  nestedFields: models.NestedFieldSerializationOptions$outboundSchema
    .optional(),
  throttleRatePerSec: z.string().optional(),
  connectionTimeout: z.number().optional(),
  writeTimeout: z.number().optional(),
  tls: models.TlsSettingsClientSideTypeKafkaSchemaRegistry$outboundSchema
    .optional(),
  enableMultiMetrics: z.boolean().optional(),
  enableACK: z.boolean().optional(),
  logFailedRequests: z.boolean().optional(),
  maxS2Sversion: models.MaxS2SVersionOptions$outboundSchema.optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  indexerDiscovery: z.boolean().optional(),
  senderUnhealthyTimeAllowance: z.number().optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  description: z.string().optional(),
  maxFailedHealthChecks: z.number().optional(),
  compress: models.CompressionOptions$outboundSchema.optional(),
  indexerDiscoveryConfigs: z.lazy(() =>
    CreateOutputSystemByPackIndexerDiscoveryConfigs$outboundSchema
  ).optional(),
  excludeSelf: z.boolean().optional(),
  hosts: z.array(models.ItemsTypeHosts$outboundSchema),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSplunkLb$outboundSchema
  ).optional(),
  authToken: z.string().optional(),
  textSecret: z.string().optional(),
});

export function createOutputSystemByPackOutputSplunkLbToJSON(
  createOutputSystemByPackOutputSplunkLb:
    CreateOutputSystemByPackOutputSplunkLb,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSplunkLb$outboundSchema.parse(
      createOutputSystemByPackOutputSplunkLb,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackPqControlsSplunk$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSplunk$outboundSchema: z.ZodType<
  CreateOutputSystemByPackPqControlsSplunk$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackPqControlsSplunk
> = z.object({});

export function createOutputSystemByPackPqControlsSplunkToJSON(
  createOutputSystemByPackPqControlsSplunk:
    CreateOutputSystemByPackPqControlsSplunk,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSplunk$outboundSchema.parse(
      createOutputSystemByPackPqControlsSplunk,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSplunk$Outbound = {
  id: string;
  type: "splunk";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  host: string;
  port: number;
  nestedFields?: string | undefined;
  throttleRatePerSec?: string | undefined;
  connectionTimeout?: number | undefined;
  writeTimeout?: number | undefined;
  tls?:
    | models.TlsSettingsClientSideTypeKafkaSchemaRegistry$Outbound
    | undefined;
  enableMultiMetrics?: boolean | undefined;
  enableACK?: boolean | undefined;
  logFailedRequests?: boolean | undefined;
  maxS2Sversion?: string | undefined;
  onBackpressure?: string | undefined;
  authType?: string | undefined;
  description?: string | undefined;
  maxFailedHealthChecks?: number | undefined;
  compress?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSplunk$Outbound | undefined;
  authToken?: string | undefined;
  textSecret?: string | undefined;
  __template_host?: string | undefined;
  __template_port?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSplunk$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSplunk$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSplunk
> = z.object({
  id: z.string(),
  type: z.literal("splunk"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  host: z.string(),
  port: z.number(),
  nestedFields: models.NestedFieldSerializationOptions$outboundSchema
    .optional(),
  throttleRatePerSec: z.string().optional(),
  connectionTimeout: z.number().optional(),
  writeTimeout: z.number().optional(),
  tls: models.TlsSettingsClientSideTypeKafkaSchemaRegistry$outboundSchema
    .optional(),
  enableMultiMetrics: z.boolean().optional(),
  enableACK: z.boolean().optional(),
  logFailedRequests: z.boolean().optional(),
  maxS2Sversion: models.MaxS2SVersionOptions$outboundSchema.optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  authType: models.AuthenticationMethodOptionsAuthTokensItems$outboundSchema
    .optional(),
  description: z.string().optional(),
  maxFailedHealthChecks: z.number().optional(),
  compress: models.CompressionOptions$outboundSchema.optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSplunk$outboundSchema
  ).optional(),
  authToken: z.string().optional(),
  textSecret: z.string().optional(),
  __template_host: z.string().optional(),
  __template_port: z.string().optional(),
});

export function createOutputSystemByPackOutputSplunkToJSON(
  createOutputSystemByPackOutputSplunk: CreateOutputSystemByPackOutputSplunk,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSplunk$outboundSchema.parse(
      createOutputSystemByPackOutputSplunk,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackProtocolSyslog$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackProtocolSyslog
> = openEnums.outboundSchema(CreateOutputSystemByPackProtocolSyslog);

/** @internal */
export const CreateOutputSystemByPackFacility$outboundSchema: z.ZodType<
  number,
  z.ZodTypeDef,
  CreateOutputSystemByPackFacility
> = openEnums.outboundSchemaInt(CreateOutputSystemByPackFacility);

/** @internal */
export const CreateOutputSystemByPackSeveritySyslog$outboundSchema: z.ZodType<
  number,
  z.ZodTypeDef,
  CreateOutputSystemByPackSeveritySyslog
> = openEnums.outboundSchemaInt(CreateOutputSystemByPackSeveritySyslog);

/** @internal */
export const CreateOutputSystemByPackMessageFormat$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackMessageFormat
> = openEnums.outboundSchema(CreateOutputSystemByPackMessageFormat);

/** @internal */
export const CreateOutputSystemByPackTimestampFormat$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackTimestampFormat
> = openEnums.outboundSchema(CreateOutputSystemByPackTimestampFormat);

/** @internal */
export type CreateOutputSystemByPackPqControlsSyslog$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSyslog$outboundSchema: z.ZodType<
  CreateOutputSystemByPackPqControlsSyslog$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackPqControlsSyslog
> = z.object({});

export function createOutputSystemByPackPqControlsSyslogToJSON(
  createOutputSystemByPackPqControlsSyslog:
    CreateOutputSystemByPackPqControlsSyslog,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSyslog$outboundSchema.parse(
      createOutputSystemByPackPqControlsSyslog,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSyslog$Outbound = {
  id: string;
  type: "syslog";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  protocol?: string | undefined;
  facility?: number | undefined;
  severity?: number | undefined;
  appName?: string | undefined;
  messageFormat?: string | undefined;
  timestampFormat?: string | undefined;
  throttleRatePerSec?: string | undefined;
  octetCountFraming?: boolean | undefined;
  logFailedRequests?: boolean | undefined;
  description?: string | undefined;
  loadBalanced?: boolean | undefined;
  host?: string | undefined;
  port?: number | undefined;
  excludeSelf?: boolean | undefined;
  hosts?: Array<models.ItemsTypeHosts$Outbound> | undefined;
  dnsResolvePeriodSec?: number | undefined;
  loadBalanceStatsPeriodSec?: number | undefined;
  maxConcurrentSenders?: number | undefined;
  connectionTimeout?: number | undefined;
  writeTimeout?: number | undefined;
  tls?:
    | models.TlsSettingsClientSideTypeKafkaSchemaRegistry$Outbound
    | undefined;
  onBackpressure?: string | undefined;
  maxRecordSize?: number | undefined;
  udpDnsResolvePeriodSec?: number | undefined;
  enableIpSpoofing?: boolean | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSyslog$Outbound | undefined;
  __template_host?: string | undefined;
  __template_port?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSyslog$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSyslog$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSyslog
> = z.object({
  id: z.string(),
  type: z.literal("syslog"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  protocol: CreateOutputSystemByPackProtocolSyslog$outboundSchema.optional(),
  facility: CreateOutputSystemByPackFacility$outboundSchema.optional(),
  severity: CreateOutputSystemByPackSeveritySyslog$outboundSchema.optional(),
  appName: z.string().optional(),
  messageFormat: CreateOutputSystemByPackMessageFormat$outboundSchema
    .optional(),
  timestampFormat: CreateOutputSystemByPackTimestampFormat$outboundSchema
    .optional(),
  throttleRatePerSec: z.string().optional(),
  octetCountFraming: z.boolean().optional(),
  logFailedRequests: z.boolean().optional(),
  description: z.string().optional(),
  loadBalanced: z.boolean().optional(),
  host: z.string().optional(),
  port: z.number().optional(),
  excludeSelf: z.boolean().optional(),
  hosts: z.array(models.ItemsTypeHosts$outboundSchema).optional(),
  dnsResolvePeriodSec: z.number().optional(),
  loadBalanceStatsPeriodSec: z.number().optional(),
  maxConcurrentSenders: z.number().optional(),
  connectionTimeout: z.number().optional(),
  writeTimeout: z.number().optional(),
  tls: models.TlsSettingsClientSideTypeKafkaSchemaRegistry$outboundSchema
    .optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  maxRecordSize: z.number().optional(),
  udpDnsResolvePeriodSec: z.number().optional(),
  enableIpSpoofing: z.boolean().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSyslog$outboundSchema
  ).optional(),
  __template_host: z.string().optional(),
  __template_port: z.string().optional(),
});

export function createOutputSystemByPackOutputSyslogToJSON(
  createOutputSystemByPackOutputSyslog: CreateOutputSystemByPackOutputSyslog,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSyslog$outboundSchema.parse(
      createOutputSystemByPackOutputSyslog,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputDevnull$Outbound = {
  id: string;
  type: "devnull";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputDevnull$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputDevnull$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputDevnull
> = z.object({
  id: z.string(),
  type: z.literal("devnull"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
});

export function createOutputSystemByPackOutputDevnullToJSON(
  createOutputSystemByPackOutputDevnull: CreateOutputSystemByPackOutputDevnull,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputDevnull$outboundSchema.parse(
      createOutputSystemByPackOutputDevnull,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackAuthType$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackAuthType
> = openEnums.outboundSchema(CreateOutputSystemByPackAuthType);

/** @internal */
export const CreateOutputSystemByPackEndpointConfiguration$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    CreateOutputSystemByPackEndpointConfiguration
  > = openEnums.outboundSchema(CreateOutputSystemByPackEndpointConfiguration);

/** @internal */
export const CreateOutputSystemByPackFormatSentinel$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackFormatSentinel
> = openEnums.outboundSchema(CreateOutputSystemByPackFormatSentinel);

/** @internal */
export type CreateOutputSystemByPackPqControlsSentinel$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsSentinel$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsSentinel$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsSentinel
  > = z.object({});

export function createOutputSystemByPackPqControlsSentinelToJSON(
  createOutputSystemByPackPqControlsSentinel:
    CreateOutputSystemByPackPqControlsSentinel,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsSentinel$outboundSchema.parse(
      createOutputSystemByPackPqControlsSentinel,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputSentinel$Outbound = {
  id: string;
  type: "sentinel";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  keepAlive?: boolean | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  useRoundRobinDns?: boolean | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  authType?: string | undefined;
  loginUrl: string;
  secret: string;
  client_id: string;
  scope?: string | undefined;
  endpointURLConfiguration: string;
  totalMemoryLimitKB?: number | undefined;
  description?: string | undefined;
  format?: string | undefined;
  customSourceExpression?: string | undefined;
  customDropWhenNull?: boolean | undefined;
  customEventDelimiter?: string | undefined;
  customContentType?: string | undefined;
  customPayloadExpression?: string | undefined;
  advancedContentType?: string | undefined;
  formatEventCode?: string | undefined;
  formatPayloadCode?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsSentinel$Outbound | undefined;
  url?: string | undefined;
  dcrID?: string | undefined;
  dceEndpoint?: string | undefined;
  streamName?: string | undefined;
  __template_loginUrl?: string | undefined;
  __template_secret?: string | undefined;
  __template_client_id?: string | undefined;
  __template_scope?: string | undefined;
  __template_url?: string | undefined;
  __template_dcrID?: string | undefined;
  __template_dceEndpoint?: string | undefined;
  __template_streamName?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputSentinel$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputSentinel$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputSentinel
> = z.object({
  id: z.string(),
  type: z.literal("sentinel"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  keepAlive: z.boolean().optional(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  useRoundRobinDns: z.boolean().optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  authType: CreateOutputSystemByPackAuthType$outboundSchema.optional(),
  loginUrl: z.string(),
  secret: z.string(),
  client_id: z.string(),
  scope: z.string().optional(),
  endpointURLConfiguration:
    CreateOutputSystemByPackEndpointConfiguration$outboundSchema,
  totalMemoryLimitKB: z.number().optional(),
  description: z.string().optional(),
  format: CreateOutputSystemByPackFormatSentinel$outboundSchema.optional(),
  customSourceExpression: z.string().optional(),
  customDropWhenNull: z.boolean().optional(),
  customEventDelimiter: z.string().optional(),
  customContentType: z.string().optional(),
  customPayloadExpression: z.string().optional(),
  advancedContentType: z.string().optional(),
  formatEventCode: z.string().optional(),
  formatPayloadCode: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsSentinel$outboundSchema
  ).optional(),
  url: z.string().optional(),
  dcrID: z.string().optional(),
  dceEndpoint: z.string().optional(),
  streamName: z.string().optional(),
  __template_loginUrl: z.string().optional(),
  __template_secret: z.string().optional(),
  __template_client_id: z.string().optional(),
  __template_scope: z.string().optional(),
  __template_url: z.string().optional(),
  __template_dcrID: z.string().optional(),
  __template_dceEndpoint: z.string().optional(),
  __template_streamName: z.string().optional(),
});

export function createOutputSystemByPackOutputSentinelToJSON(
  createOutputSystemByPackOutputSentinel:
    CreateOutputSystemByPackOutputSentinel,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputSentinel$outboundSchema.parse(
      createOutputSystemByPackOutputSentinel,
    ),
  );
}

/** @internal */
export const CreateOutputSystemByPackFormatWebhook$outboundSchema: z.ZodType<
  string,
  z.ZodTypeDef,
  CreateOutputSystemByPackFormatWebhook
> = openEnums.outboundSchema(CreateOutputSystemByPackFormatWebhook);

/** @internal */
export const CreateOutputSystemByPackAuthenticationTypeWebhook$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    CreateOutputSystemByPackAuthenticationTypeWebhook
  > = openEnums.outboundSchema(
    CreateOutputSystemByPackAuthenticationTypeWebhook,
  );

/** @internal */
export type CreateOutputSystemByPackPqControlsWebhook$Outbound = {};

/** @internal */
export const CreateOutputSystemByPackPqControlsWebhook$outboundSchema:
  z.ZodType<
    CreateOutputSystemByPackPqControlsWebhook$Outbound,
    z.ZodTypeDef,
    CreateOutputSystemByPackPqControlsWebhook
  > = z.object({});

export function createOutputSystemByPackPqControlsWebhookToJSON(
  createOutputSystemByPackPqControlsWebhook:
    CreateOutputSystemByPackPqControlsWebhook,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackPqControlsWebhook$outboundSchema.parse(
      createOutputSystemByPackPqControlsWebhook,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOauthParam$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const CreateOutputSystemByPackOauthParam$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOauthParam$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOauthParam
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function createOutputSystemByPackOauthParamToJSON(
  createOutputSystemByPackOauthParam: CreateOutputSystemByPackOauthParam,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOauthParam$outboundSchema.parse(
      createOutputSystemByPackOauthParam,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOauthHeader$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const CreateOutputSystemByPackOauthHeader$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOauthHeader$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOauthHeader
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function createOutputSystemByPackOauthHeaderToJSON(
  createOutputSystemByPackOauthHeader: CreateOutputSystemByPackOauthHeader,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOauthHeader$outboundSchema.parse(
      createOutputSystemByPackOauthHeader,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackUrlWebhook$Outbound = {
  url: string;
  weight?: number | undefined;
  __template_url?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackUrlWebhook$outboundSchema: z.ZodType<
  CreateOutputSystemByPackUrlWebhook$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackUrlWebhook
> = z.object({
  url: z.string(),
  weight: z.number().optional(),
  __template_url: z.string().optional(),
});

export function createOutputSystemByPackUrlWebhookToJSON(
  createOutputSystemByPackUrlWebhook: CreateOutputSystemByPackUrlWebhook,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackUrlWebhook$outboundSchema.parse(
      createOutputSystemByPackUrlWebhook,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputWebhook$Outbound = {
  id: string;
  type: "webhook";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  method?: string | undefined;
  format?: string | undefined;
  keepAlive?: boolean | undefined;
  concurrency?: number | undefined;
  maxPayloadSizeKB?: number | undefined;
  maxPayloadEvents?: number | undefined;
  compress?: boolean | undefined;
  rejectUnauthorized?: boolean | undefined;
  timeoutSec?: number | undefined;
  flushPeriodSec?: number | undefined;
  extraHttpHeaders?:
    | Array<models.ItemsTypeExtraHttpHeaders$Outbound>
    | undefined;
  useRoundRobinDns?: boolean | undefined;
  failedRequestLoggingMode?: string | undefined;
  safeHeaders?: Array<string> | undefined;
  responseRetrySettings?:
    | Array<models.ItemsTypeResponseRetrySettings$Outbound>
    | undefined;
  timeoutRetrySettings?: models.TimeoutRetrySettingsType$Outbound | undefined;
  responseHonorRetryAfterHeader?: boolean | undefined;
  onBackpressure?: string | undefined;
  authType?: string | undefined;
  tls?: models.TlsSettingsClientSideType1$Outbound | undefined;
  totalMemoryLimitKB?: number | undefined;
  loadBalanced?: boolean | undefined;
  description?: string | undefined;
  customSourceExpression?: string | undefined;
  customDropWhenNull?: boolean | undefined;
  customEventDelimiter?: string | undefined;
  customContentType?: string | undefined;
  customPayloadExpression?: string | undefined;
  advancedContentType?: string | undefined;
  formatEventCode?: string | undefined;
  formatPayloadCode?: string | undefined;
  pqStrictOrdering?: boolean | undefined;
  pqRatePerSec?: number | undefined;
  pqMode?: string | undefined;
  pqMaxBufferSize?: number | undefined;
  pqMaxBackpressureSec?: number | undefined;
  pqMaxFileSize?: string | undefined;
  pqMaxSize?: string | undefined;
  pqPath?: string | undefined;
  pqCompress?: string | undefined;
  pqOnBackpressure?: string | undefined;
  pqControls?: CreateOutputSystemByPackPqControlsWebhook$Outbound | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr?: string | undefined;
  tokenTimeoutSecs?: number | undefined;
  oauthParams?: Array<CreateOutputSystemByPackOauthParam$Outbound> | undefined;
  oauthHeaders?:
    | Array<CreateOutputSystemByPackOauthHeader$Outbound>
    | undefined;
  url?: string | undefined;
  excludeSelf?: boolean | undefined;
  urls?: Array<CreateOutputSystemByPackUrlWebhook$Outbound> | undefined;
  dnsResolvePeriodSec?: number | undefined;
  loadBalanceStatsPeriodSec?: number | undefined;
  __template_loginUrl?: string | undefined;
  __template_secret?: string | undefined;
  __template_url?: string | undefined;
};

/** @internal */
export const CreateOutputSystemByPackOutputWebhook$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputWebhook$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputWebhook
> = z.object({
  id: z.string(),
  type: z.literal("webhook"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  method: models.MethodOptions$outboundSchema.optional(),
  format: CreateOutputSystemByPackFormatWebhook$outboundSchema.optional(),
  keepAlive: z.boolean().optional(),
  concurrency: z.number().optional(),
  maxPayloadSizeKB: z.number().optional(),
  maxPayloadEvents: z.number().optional(),
  compress: z.boolean().optional(),
  rejectUnauthorized: z.boolean().optional(),
  timeoutSec: z.number().optional(),
  flushPeriodSec: z.number().optional(),
  extraHttpHeaders: z.array(models.ItemsTypeExtraHttpHeaders$outboundSchema)
    .optional(),
  useRoundRobinDns: z.boolean().optional(),
  failedRequestLoggingMode: models
    .FailedRequestLoggingModeOptions$outboundSchema.optional(),
  safeHeaders: z.array(z.string()).optional(),
  responseRetrySettings: z.array(
    models.ItemsTypeResponseRetrySettings$outboundSchema,
  ).optional(),
  timeoutRetrySettings: models.TimeoutRetrySettingsType$outboundSchema
    .optional(),
  responseHonorRetryAfterHeader: z.boolean().optional(),
  onBackpressure: models.BackpressureBehaviorOptions$outboundSchema.optional(),
  authType: CreateOutputSystemByPackAuthenticationTypeWebhook$outboundSchema
    .optional(),
  tls: models.TlsSettingsClientSideType1$outboundSchema.optional(),
  totalMemoryLimitKB: z.number().optional(),
  loadBalanced: z.boolean().optional(),
  description: z.string().optional(),
  customSourceExpression: z.string().optional(),
  customDropWhenNull: z.boolean().optional(),
  customEventDelimiter: z.string().optional(),
  customContentType: z.string().optional(),
  customPayloadExpression: z.string().optional(),
  advancedContentType: z.string().optional(),
  formatEventCode: z.string().optional(),
  formatPayloadCode: z.string().optional(),
  pqStrictOrdering: z.boolean().optional(),
  pqRatePerSec: z.number().optional(),
  pqMode: models.ModeOptions$outboundSchema.optional(),
  pqMaxBufferSize: z.number().optional(),
  pqMaxBackpressureSec: z.number().optional(),
  pqMaxFileSize: z.string().optional(),
  pqMaxSize: z.string().optional(),
  pqPath: z.string().optional(),
  pqCompress: models.CompressionOptionsPq$outboundSchema.optional(),
  pqOnBackpressure: models.QueueFullBehaviorOptions$outboundSchema.optional(),
  pqControls: z.lazy(() =>
    CreateOutputSystemByPackPqControlsWebhook$outboundSchema
  ).optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().optional(),
  tokenTimeoutSecs: z.number().optional(),
  oauthParams: z.array(
    z.lazy(() => CreateOutputSystemByPackOauthParam$outboundSchema),
  ).optional(),
  oauthHeaders: z.array(
    z.lazy(() => CreateOutputSystemByPackOauthHeader$outboundSchema),
  ).optional(),
  url: z.string().optional(),
  excludeSelf: z.boolean().optional(),
  urls: z.array(z.lazy(() => CreateOutputSystemByPackUrlWebhook$outboundSchema))
    .optional(),
  dnsResolvePeriodSec: z.number().optional(),
  loadBalanceStatsPeriodSec: z.number().optional(),
  __template_loginUrl: z.string().optional(),
  __template_secret: z.string().optional(),
  __template_url: z.string().optional(),
});

export function createOutputSystemByPackOutputWebhookToJSON(
  createOutputSystemByPackOutputWebhook: CreateOutputSystemByPackOutputWebhook,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputWebhook$outboundSchema.parse(
      createOutputSystemByPackOutputWebhook,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackOutputDefault$Outbound = {
  id: string;
  type: "default";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  defaultId: string | null;
};

/** @internal */
export const CreateOutputSystemByPackOutputDefault$outboundSchema: z.ZodType<
  CreateOutputSystemByPackOutputDefault$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackOutputDefault
> = z.object({
  id: z.string(),
  type: z.literal("default"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  defaultId: z.nullable(z.string()),
});

export function createOutputSystemByPackOutputDefaultToJSON(
  createOutputSystemByPackOutputDefault: CreateOutputSystemByPackOutputDefault,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackOutputDefault$outboundSchema.parse(
      createOutputSystemByPackOutputDefault,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackRequestBody$Outbound =
  | CreateOutputSystemByPackOutputDefault$Outbound
  | CreateOutputSystemByPackOutputWebhook$Outbound
  | CreateOutputSystemByPackOutputSentinel$Outbound
  | CreateOutputSystemByPackOutputDevnull$Outbound
  | CreateOutputSystemByPackOutputSyslog$Outbound
  | CreateOutputSystemByPackOutputSplunk$Outbound
  | CreateOutputSystemByPackOutputSplunkLb$Outbound
  | CreateOutputSystemByPackOutputSplunkHec$Outbound
  | CreateOutputSystemByPackOutputWizHec$Outbound
  | CreateOutputSystemByPackOutputTcpjson$Outbound
  | CreateOutputSystemByPackOutputWavefront$Outbound
  | CreateOutputSystemByPackOutputSignalfx$Outbound
  | CreateOutputSystemByPackOutputFilesystem$Outbound
  | CreateOutputSystemByPackOutputS3$Outbound
  | CreateOutputSystemByPackOutputAzureBlob$Outbound
  | CreateOutputSystemByPackOutputAzureDataExplorer$Outbound
  | CreateOutputSystemByPackOutputAzureLogs$Outbound
  | CreateOutputSystemByPackOutputKinesis$Outbound
  | CreateOutputSystemByPackOutputHoneycomb$Outbound
  | CreateOutputSystemByPackOutputAzureEventhub$Outbound
  | CreateOutputSystemByPackOutputGoogleChronicle$Outbound
  | CreateOutputSystemByPackOutputGoogleCloudStorage$Outbound
  | CreateOutputSystemByPackOutputGoogleCloudLogging$Outbound
  | CreateOutputSystemByPackOutputGooglePubsub$Outbound
  | CreateOutputSystemByPackOutputExabeam$Outbound
  | CreateOutputSystemByPackOutputKafka$Outbound
  | CreateOutputSystemByPackOutputConfluentCloud$Outbound
  | CreateOutputSystemByPackOutputMsk$Outbound
  | CreateOutputSystemByPackOutputElastic$Outbound
  | CreateOutputSystemByPackOutputElasticCloud$Outbound
  | CreateOutputSystemByPackOutputNewrelic$Outbound
  | CreateOutputSystemByPackOutputNewrelicEvents$Outbound
  | CreateOutputSystemByPackOutputInfluxdb$Outbound
  | CreateOutputSystemByPackOutputCloudwatch$Outbound
  | CreateOutputSystemByPackOutputMinio$Outbound
  | CreateOutputSystemByPackOutputStatsd$Outbound
  | CreateOutputSystemByPackOutputStatsdExt$Outbound
  | CreateOutputSystemByPackOutputGraphite$Outbound
  | CreateOutputSystemByPackOutputRouter$Outbound
  | CreateOutputSystemByPackOutputSns$Outbound
  | CreateOutputSystemByPackOutputSqs$Outbound
  | CreateOutputSystemByPackOutputSnmp$Outbound
  | CreateOutputSystemByPackOutputSumoLogic$Outbound
  | CreateOutputSystemByPackOutputDatadog$Outbound
  | (CreateOutputSystemByPackOutputGrafanaCloudUnion$Outbound & {
    type: "grafana_cloud";
  })
  | CreateOutputSystemByPackOutputLoki$Outbound
  | CreateOutputSystemByPackOutputPrometheus$Outbound
  | CreateOutputSystemByPackOutputRing$Outbound
  | CreateOutputSystemByPackOutputOpenTelemetry$Outbound
  | CreateOutputSystemByPackOutputServiceNow$Outbound
  | CreateOutputSystemByPackOutputDataset$Outbound
  | CreateOutputSystemByPackOutputCriblTcp$Outbound
  | CreateOutputSystemByPackOutputCriblHttp$Outbound
  | CreateOutputSystemByPackOutputCriblSearchEngine$Outbound
  | CreateOutputSystemByPackOutputHumioHec$Outbound
  | CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$Outbound
  | CreateOutputSystemByPackOutputDlS3$Outbound
  | CreateOutputSystemByPackOutputSecurityLake$Outbound
  | CreateOutputSystemByPackOutputCriblLake$Outbound
  | CreateOutputSystemByPackOutputDiskSpool$Outbound
  | CreateOutputSystemByPackOutputClickHouse$Outbound
  | CreateOutputSystemByPackOutputXsiam$Outbound
  | CreateOutputSystemByPackOutputNetflow$Outbound
  | CreateOutputSystemByPackOutputDynatraceHttp$Outbound
  | CreateOutputSystemByPackOutputDynatraceOtlp$Outbound
  | CreateOutputSystemByPackOutputSentinelOneAiSiem$Outbound
  | CreateOutputSystemByPackOutputChronicle$Outbound
  | CreateOutputSystemByPackOutputDatabricks$Outbound
  | CreateOutputSystemByPackOutputMicrosoftFabric$Outbound
  | CreateOutputSystemByPackOutputCloudflareR2$Outbound;

/** @internal */
export const CreateOutputSystemByPackRequestBody$outboundSchema: z.ZodType<
  CreateOutputSystemByPackRequestBody$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackRequestBody
> = z.union([
  z.lazy(() => CreateOutputSystemByPackOutputDefault$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputWebhook$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSentinel$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputDevnull$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSyslog$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSplunk$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSplunkLb$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSplunkHec$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputWizHec$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputTcpjson$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputWavefront$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputSignalfx$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputFilesystem$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputS3$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputAzureBlob$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputAzureDataExplorer$outboundSchema),
  z.lazy(() => CreateOutputSystemByPackOutputAzureLogs$outboundSchema),
  CreateOutputSystemByPackOutputKinesis$outboundSchema,
  CreateOutputSystemByPackOutputHoneycomb$outboundSchema,
  CreateOutputSystemByPackOutputAzureEventhub$outboundSchema,
  CreateOutputSystemByPackOutputGoogleChronicle$outboundSchema,
  CreateOutputSystemByPackOutputGoogleCloudStorage$outboundSchema,
  CreateOutputSystemByPackOutputGoogleCloudLogging$outboundSchema,
  CreateOutputSystemByPackOutputGooglePubsub$outboundSchema,
  CreateOutputSystemByPackOutputExabeam$outboundSchema,
  CreateOutputSystemByPackOutputKafka$outboundSchema,
  CreateOutputSystemByPackOutputConfluentCloud$outboundSchema,
  CreateOutputSystemByPackOutputMsk$outboundSchema,
  CreateOutputSystemByPackOutputElastic$outboundSchema,
  CreateOutputSystemByPackOutputElasticCloud$outboundSchema,
  CreateOutputSystemByPackOutputNewrelic$outboundSchema,
  CreateOutputSystemByPackOutputNewrelicEvents$outboundSchema,
  CreateOutputSystemByPackOutputInfluxdb$outboundSchema,
  CreateOutputSystemByPackOutputCloudwatch$outboundSchema,
  CreateOutputSystemByPackOutputMinio$outboundSchema,
  CreateOutputSystemByPackOutputStatsd$outboundSchema,
  CreateOutputSystemByPackOutputStatsdExt$outboundSchema,
  CreateOutputSystemByPackOutputGraphite$outboundSchema,
  CreateOutputSystemByPackOutputRouter$outboundSchema,
  CreateOutputSystemByPackOutputSns$outboundSchema,
  CreateOutputSystemByPackOutputSqs$outboundSchema,
  CreateOutputSystemByPackOutputSnmp$outboundSchema,
  CreateOutputSystemByPackOutputSumoLogic$outboundSchema,
  CreateOutputSystemByPackOutputDatadog$outboundSchema,
  CreateOutputSystemByPackOutputGrafanaCloudUnion$outboundSchema.and(
    z.object({ type: z.literal("grafana_cloud") }),
  ),
  CreateOutputSystemByPackOutputLoki$outboundSchema,
  CreateOutputSystemByPackOutputPrometheus$outboundSchema,
  CreateOutputSystemByPackOutputRing$outboundSchema,
  CreateOutputSystemByPackOutputOpenTelemetry$outboundSchema,
  CreateOutputSystemByPackOutputServiceNow$outboundSchema,
  CreateOutputSystemByPackOutputDataset$outboundSchema,
  CreateOutputSystemByPackOutputCriblTcp$outboundSchema,
  CreateOutputSystemByPackOutputCriblHttp$outboundSchema,
  CreateOutputSystemByPackOutputCriblSearchEngine$outboundSchema,
  CreateOutputSystemByPackOutputHumioHec$outboundSchema,
  CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$outboundSchema,
  CreateOutputSystemByPackOutputDlS3$outboundSchema,
  CreateOutputSystemByPackOutputSecurityLake$outboundSchema,
  CreateOutputSystemByPackOutputCriblLake$outboundSchema,
  CreateOutputSystemByPackOutputDiskSpool$outboundSchema,
  CreateOutputSystemByPackOutputClickHouse$outboundSchema,
  CreateOutputSystemByPackOutputXsiam$outboundSchema,
  CreateOutputSystemByPackOutputNetflow$outboundSchema,
  CreateOutputSystemByPackOutputDynatraceHttp$outboundSchema,
  CreateOutputSystemByPackOutputDynatraceOtlp$outboundSchema,
  CreateOutputSystemByPackOutputSentinelOneAiSiem$outboundSchema,
  CreateOutputSystemByPackOutputChronicle$outboundSchema,
  CreateOutputSystemByPackOutputDatabricks$outboundSchema,
  CreateOutputSystemByPackOutputMicrosoftFabric$outboundSchema,
  CreateOutputSystemByPackOutputCloudflareR2$outboundSchema,
]);

export function createOutputSystemByPackRequestBodyToJSON(
  createOutputSystemByPackRequestBody: CreateOutputSystemByPackRequestBody,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackRequestBody$outboundSchema.parse(
      createOutputSystemByPackRequestBody,
    ),
  );
}

/** @internal */
export type CreateOutputSystemByPackRequest$Outbound = {
  pack: string;
  RequestBody:
    | CreateOutputSystemByPackOutputDefault$Outbound
    | CreateOutputSystemByPackOutputWebhook$Outbound
    | CreateOutputSystemByPackOutputSentinel$Outbound
    | CreateOutputSystemByPackOutputDevnull$Outbound
    | CreateOutputSystemByPackOutputSyslog$Outbound
    | CreateOutputSystemByPackOutputSplunk$Outbound
    | CreateOutputSystemByPackOutputSplunkLb$Outbound
    | CreateOutputSystemByPackOutputSplunkHec$Outbound
    | CreateOutputSystemByPackOutputWizHec$Outbound
    | CreateOutputSystemByPackOutputTcpjson$Outbound
    | CreateOutputSystemByPackOutputWavefront$Outbound
    | CreateOutputSystemByPackOutputSignalfx$Outbound
    | CreateOutputSystemByPackOutputFilesystem$Outbound
    | CreateOutputSystemByPackOutputS3$Outbound
    | CreateOutputSystemByPackOutputAzureBlob$Outbound
    | CreateOutputSystemByPackOutputAzureDataExplorer$Outbound
    | CreateOutputSystemByPackOutputAzureLogs$Outbound
    | CreateOutputSystemByPackOutputKinesis$Outbound
    | CreateOutputSystemByPackOutputHoneycomb$Outbound
    | CreateOutputSystemByPackOutputAzureEventhub$Outbound
    | CreateOutputSystemByPackOutputGoogleChronicle$Outbound
    | CreateOutputSystemByPackOutputGoogleCloudStorage$Outbound
    | CreateOutputSystemByPackOutputGoogleCloudLogging$Outbound
    | CreateOutputSystemByPackOutputGooglePubsub$Outbound
    | CreateOutputSystemByPackOutputExabeam$Outbound
    | CreateOutputSystemByPackOutputKafka$Outbound
    | CreateOutputSystemByPackOutputConfluentCloud$Outbound
    | CreateOutputSystemByPackOutputMsk$Outbound
    | CreateOutputSystemByPackOutputElastic$Outbound
    | CreateOutputSystemByPackOutputElasticCloud$Outbound
    | CreateOutputSystemByPackOutputNewrelic$Outbound
    | CreateOutputSystemByPackOutputNewrelicEvents$Outbound
    | CreateOutputSystemByPackOutputInfluxdb$Outbound
    | CreateOutputSystemByPackOutputCloudwatch$Outbound
    | CreateOutputSystemByPackOutputMinio$Outbound
    | CreateOutputSystemByPackOutputStatsd$Outbound
    | CreateOutputSystemByPackOutputStatsdExt$Outbound
    | CreateOutputSystemByPackOutputGraphite$Outbound
    | CreateOutputSystemByPackOutputRouter$Outbound
    | CreateOutputSystemByPackOutputSns$Outbound
    | CreateOutputSystemByPackOutputSqs$Outbound
    | CreateOutputSystemByPackOutputSnmp$Outbound
    | CreateOutputSystemByPackOutputSumoLogic$Outbound
    | CreateOutputSystemByPackOutputDatadog$Outbound
    | (CreateOutputSystemByPackOutputGrafanaCloudUnion$Outbound & {
      type: "grafana_cloud";
    })
    | CreateOutputSystemByPackOutputLoki$Outbound
    | CreateOutputSystemByPackOutputPrometheus$Outbound
    | CreateOutputSystemByPackOutputRing$Outbound
    | CreateOutputSystemByPackOutputOpenTelemetry$Outbound
    | CreateOutputSystemByPackOutputServiceNow$Outbound
    | CreateOutputSystemByPackOutputDataset$Outbound
    | CreateOutputSystemByPackOutputCriblTcp$Outbound
    | CreateOutputSystemByPackOutputCriblHttp$Outbound
    | CreateOutputSystemByPackOutputCriblSearchEngine$Outbound
    | CreateOutputSystemByPackOutputHumioHec$Outbound
    | CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$Outbound
    | CreateOutputSystemByPackOutputDlS3$Outbound
    | CreateOutputSystemByPackOutputSecurityLake$Outbound
    | CreateOutputSystemByPackOutputCriblLake$Outbound
    | CreateOutputSystemByPackOutputDiskSpool$Outbound
    | CreateOutputSystemByPackOutputClickHouse$Outbound
    | CreateOutputSystemByPackOutputXsiam$Outbound
    | CreateOutputSystemByPackOutputNetflow$Outbound
    | CreateOutputSystemByPackOutputDynatraceHttp$Outbound
    | CreateOutputSystemByPackOutputDynatraceOtlp$Outbound
    | CreateOutputSystemByPackOutputSentinelOneAiSiem$Outbound
    | CreateOutputSystemByPackOutputChronicle$Outbound
    | CreateOutputSystemByPackOutputDatabricks$Outbound
    | CreateOutputSystemByPackOutputMicrosoftFabric$Outbound
    | CreateOutputSystemByPackOutputCloudflareR2$Outbound;
};

/** @internal */
export const CreateOutputSystemByPackRequest$outboundSchema: z.ZodType<
  CreateOutputSystemByPackRequest$Outbound,
  z.ZodTypeDef,
  CreateOutputSystemByPackRequest
> = z.object({
  pack: z.string(),
  requestBody: z.union([
    z.lazy(() => CreateOutputSystemByPackOutputDefault$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputWebhook$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSentinel$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputDevnull$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSyslog$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSplunk$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSplunkLb$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSplunkHec$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputWizHec$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputTcpjson$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputWavefront$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputSignalfx$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputFilesystem$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputS3$outboundSchema),
    z.lazy(() => CreateOutputSystemByPackOutputAzureBlob$outboundSchema),
    z.lazy(() =>
      CreateOutputSystemByPackOutputAzureDataExplorer$outboundSchema
    ),
    z.lazy(() => CreateOutputSystemByPackOutputAzureLogs$outboundSchema),
    CreateOutputSystemByPackOutputKinesis$outboundSchema,
    CreateOutputSystemByPackOutputHoneycomb$outboundSchema,
    CreateOutputSystemByPackOutputAzureEventhub$outboundSchema,
    CreateOutputSystemByPackOutputGoogleChronicle$outboundSchema,
    CreateOutputSystemByPackOutputGoogleCloudStorage$outboundSchema,
    CreateOutputSystemByPackOutputGoogleCloudLogging$outboundSchema,
    CreateOutputSystemByPackOutputGooglePubsub$outboundSchema,
    CreateOutputSystemByPackOutputExabeam$outboundSchema,
    CreateOutputSystemByPackOutputKafka$outboundSchema,
    CreateOutputSystemByPackOutputConfluentCloud$outboundSchema,
    CreateOutputSystemByPackOutputMsk$outboundSchema,
    CreateOutputSystemByPackOutputElastic$outboundSchema,
    CreateOutputSystemByPackOutputElasticCloud$outboundSchema,
    CreateOutputSystemByPackOutputNewrelic$outboundSchema,
    CreateOutputSystemByPackOutputNewrelicEvents$outboundSchema,
    CreateOutputSystemByPackOutputInfluxdb$outboundSchema,
    CreateOutputSystemByPackOutputCloudwatch$outboundSchema,
    CreateOutputSystemByPackOutputMinio$outboundSchema,
    CreateOutputSystemByPackOutputStatsd$outboundSchema,
    CreateOutputSystemByPackOutputStatsdExt$outboundSchema,
    CreateOutputSystemByPackOutputGraphite$outboundSchema,
    CreateOutputSystemByPackOutputRouter$outboundSchema,
    CreateOutputSystemByPackOutputSns$outboundSchema,
    CreateOutputSystemByPackOutputSqs$outboundSchema,
    CreateOutputSystemByPackOutputSnmp$outboundSchema,
    CreateOutputSystemByPackOutputSumoLogic$outboundSchema,
    CreateOutputSystemByPackOutputDatadog$outboundSchema,
    CreateOutputSystemByPackOutputGrafanaCloudUnion$outboundSchema.and(
      z.object({ type: z.literal("grafana_cloud") }),
    ),
    CreateOutputSystemByPackOutputLoki$outboundSchema,
    CreateOutputSystemByPackOutputPrometheus$outboundSchema,
    CreateOutputSystemByPackOutputRing$outboundSchema,
    CreateOutputSystemByPackOutputOpenTelemetry$outboundSchema,
    CreateOutputSystemByPackOutputServiceNow$outboundSchema,
    CreateOutputSystemByPackOutputDataset$outboundSchema,
    CreateOutputSystemByPackOutputCriblTcp$outboundSchema,
    CreateOutputSystemByPackOutputCriblHttp$outboundSchema,
    CreateOutputSystemByPackOutputCriblSearchEngine$outboundSchema,
    CreateOutputSystemByPackOutputHumioHec$outboundSchema,
    CreateOutputSystemByPackOutputCrowdstrikeNextGenSiem$outboundSchema,
    CreateOutputSystemByPackOutputDlS3$outboundSchema,
    CreateOutputSystemByPackOutputSecurityLake$outboundSchema,
    CreateOutputSystemByPackOutputCriblLake$outboundSchema,
    CreateOutputSystemByPackOutputDiskSpool$outboundSchema,
    CreateOutputSystemByPackOutputClickHouse$outboundSchema,
    CreateOutputSystemByPackOutputXsiam$outboundSchema,
    CreateOutputSystemByPackOutputNetflow$outboundSchema,
    CreateOutputSystemByPackOutputDynatraceHttp$outboundSchema,
    CreateOutputSystemByPackOutputDynatraceOtlp$outboundSchema,
    CreateOutputSystemByPackOutputSentinelOneAiSiem$outboundSchema,
    CreateOutputSystemByPackOutputChronicle$outboundSchema,
    CreateOutputSystemByPackOutputDatabricks$outboundSchema,
    CreateOutputSystemByPackOutputMicrosoftFabric$outboundSchema,
    CreateOutputSystemByPackOutputCloudflareR2$outboundSchema,
  ]),
}).transform((v) => {
  return remap$(v, {
    requestBody: "RequestBody",
  });
});

export function createOutputSystemByPackRequestToJSON(
  createOutputSystemByPackRequest: CreateOutputSystemByPackRequest,
): string {
  return JSON.stringify(
    CreateOutputSystemByPackRequest$outboundSchema.parse(
      createOutputSystemByPackRequest,
    ),
  );
}
