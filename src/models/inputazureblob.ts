/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  AuthenticationMethodOptions,
  AuthenticationMethodOptions$inboundSchema,
  AuthenticationMethodOptions$outboundSchema,
} from "./authenticationmethodoptions.js";
import {
  CertificateTypeAzureBlobAuthTypeClientCert,
  CertificateTypeAzureBlobAuthTypeClientCert$inboundSchema,
  CertificateTypeAzureBlobAuthTypeClientCert$Outbound,
  CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema,
} from "./certificatetypeazureblobauthtypeclientcert.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnections,
  ItemsTypeConnections$inboundSchema,
  ItemsTypeConnections$Outbound,
  ItemsTypeConnections$outboundSchema,
} from "./itemstypeconnections.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";

export const InputAzureBlobType = {
  AzureBlob: "azure_blob",
} as const;
export type InputAzureBlobType = ClosedEnum<typeof InputAzureBlobType>;

export type InputAzureBlobPqEnabledTrueWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputAzureBlobType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
   */
  maxMessages?: number | undefined;
  /**
   * The duration (in seconds) which pollers should be validated and restarted if exited
   */
  servicePeriodSecs?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  authType?: AuthenticationMethodOptions | undefined;
  description?: string | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert | undefined;
};

export type InputAzureBlobPqEnabledFalseWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputAzureBlobType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
   */
  maxMessages?: number | undefined;
  /**
   * The duration (in seconds) which pollers should be validated and restarted if exited
   */
  servicePeriodSecs?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  authType?: AuthenticationMethodOptions | undefined;
  description?: string | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert | undefined;
};

export type InputAzureBlobSendToRoutesFalseWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputAzureBlobType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
   */
  maxMessages?: number | undefined;
  /**
   * The duration (in seconds) which pollers should be validated and restarted if exited
   */
  servicePeriodSecs?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  authType?: AuthenticationMethodOptions | undefined;
  description?: string | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert | undefined;
};

export type InputAzureBlobSendToRoutesTrueWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputAzureBlobType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
   */
  maxMessages?: number | undefined;
  /**
   * The duration (in seconds) which pollers should be validated and restarted if exited
   */
  servicePeriodSecs?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  authType?: AuthenticationMethodOptions | undefined;
  description?: string | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert | undefined;
};

export type InputAzureBlob =
  | InputAzureBlobSendToRoutesTrueWithConnectionsConstraint
  | InputAzureBlobSendToRoutesFalseWithConnectionsConstraint
  | InputAzureBlobPqEnabledFalseWithPqConstraint
  | InputAzureBlobPqEnabledTrueWithPqConstraint;

/** @internal */
export const InputAzureBlobType$inboundSchema: z.ZodNativeEnum<
  typeof InputAzureBlobType
> = z.nativeEnum(InputAzureBlobType);
/** @internal */
export const InputAzureBlobType$outboundSchema: z.ZodNativeEnum<
  typeof InputAzureBlobType
> = InputAzureBlobType$inboundSchema;

/** @internal */
export const InputAzureBlobPqEnabledTrueWithPqConstraint$inboundSchema:
  z.ZodType<
    InputAzureBlobPqEnabledTrueWithPqConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$inboundSchema.optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$inboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$inboundSchema
      .optional(),
  });
/** @internal */
export type InputAzureBlobPqEnabledTrueWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  queueName: string;
  fileFilter: string;
  visibilityTimeout: number;
  numReceivers: number;
  maxMessages: number;
  servicePeriodSecs: number;
  skipOnError: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  authType: string;
  description?: string | undefined;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert$Outbound | undefined;
};

/** @internal */
export const InputAzureBlobPqEnabledTrueWithPqConstraint$outboundSchema:
  z.ZodType<
    InputAzureBlobPqEnabledTrueWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputAzureBlobPqEnabledTrueWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$outboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema
      .optional(),
  });

export function inputAzureBlobPqEnabledTrueWithPqConstraintToJSON(
  inputAzureBlobPqEnabledTrueWithPqConstraint:
    InputAzureBlobPqEnabledTrueWithPqConstraint,
): string {
  return JSON.stringify(
    InputAzureBlobPqEnabledTrueWithPqConstraint$outboundSchema.parse(
      inputAzureBlobPqEnabledTrueWithPqConstraint,
    ),
  );
}
export function inputAzureBlobPqEnabledTrueWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputAzureBlobPqEnabledTrueWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputAzureBlobPqEnabledTrueWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputAzureBlobPqEnabledTrueWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputAzureBlobPqEnabledFalseWithPqConstraint$inboundSchema:
  z.ZodType<
    InputAzureBlobPqEnabledFalseWithPqConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$inboundSchema.optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$inboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$inboundSchema
      .optional(),
  });
/** @internal */
export type InputAzureBlobPqEnabledFalseWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  queueName: string;
  fileFilter: string;
  visibilityTimeout: number;
  numReceivers: number;
  maxMessages: number;
  servicePeriodSecs: number;
  skipOnError: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  authType: string;
  description?: string | undefined;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert$Outbound | undefined;
};

/** @internal */
export const InputAzureBlobPqEnabledFalseWithPqConstraint$outboundSchema:
  z.ZodType<
    InputAzureBlobPqEnabledFalseWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputAzureBlobPqEnabledFalseWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$outboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema
      .optional(),
  });

export function inputAzureBlobPqEnabledFalseWithPqConstraintToJSON(
  inputAzureBlobPqEnabledFalseWithPqConstraint:
    InputAzureBlobPqEnabledFalseWithPqConstraint,
): string {
  return JSON.stringify(
    InputAzureBlobPqEnabledFalseWithPqConstraint$outboundSchema.parse(
      inputAzureBlobPqEnabledFalseWithPqConstraint,
    ),
  );
}
export function inputAzureBlobPqEnabledFalseWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputAzureBlobPqEnabledFalseWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputAzureBlobPqEnabledFalseWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputAzureBlobPqEnabledFalseWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$inboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$inboundSchema
      .optional(),
  });
/** @internal */
export type InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$Outbound =
  {
    sendToRoutes: boolean;
    connections?: Array<ItemsTypeConnections$Outbound> | undefined;
    id?: string | undefined;
    type: string;
    disabled: boolean;
    pipeline?: string | undefined;
    environment?: string | undefined;
    pqEnabled: boolean;
    streamtags?: Array<string> | undefined;
    pq?: PqType$Outbound | undefined;
    queueName: string;
    fileFilter: string;
    visibilityTimeout: number;
    numReceivers: number;
    maxMessages: number;
    servicePeriodSecs: number;
    skipOnError: boolean;
    metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
    breakerRulesets?: Array<string> | undefined;
    staleChannelFlushMs: number;
    parquetChunkSizeMB: number;
    parquetChunkDownloadTimeout: number;
    authType: string;
    description?: string | undefined;
    connectionString?: string | undefined;
    textSecret?: string | undefined;
    storageAccountName?: string | undefined;
    tenantId?: string | undefined;
    clientId?: string | undefined;
    azureCloud?: string | undefined;
    endpointSuffix?: string | undefined;
    clientTextSecret?: string | undefined;
    certificate?:
      | CertificateTypeAzureBlobAuthTypeClientCert$Outbound
      | undefined;
  };

/** @internal */
export const InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$outboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema
      .optional(),
  });

export function inputAzureBlobSendToRoutesFalseWithConnectionsConstraintToJSON(
  inputAzureBlobSendToRoutesFalseWithConnectionsConstraint:
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$outboundSchema
      .parse(inputAzureBlobSendToRoutesFalseWithConnectionsConstraint),
  );
}
export function inputAzureBlobSendToRoutesFalseWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputAzureBlobSendToRoutesFalseWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputAzureBlobSendToRoutesFalseWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$inboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$inboundSchema
      .optional(),
  });
/** @internal */
export type InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$Outbound = {
  sendToRoutes: boolean;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  pq?: PqType$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  visibilityTimeout: number;
  numReceivers: number;
  maxMessages: number;
  servicePeriodSecs: number;
  skipOnError: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  authType: string;
  description?: string | undefined;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?: CertificateTypeAzureBlobAuthTypeClientCert$Outbound | undefined;
};

/** @internal */
export const InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputAzureBlobType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: AuthenticationMethodOptions$outboundSchema.default("manual"),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: CertificateTypeAzureBlobAuthTypeClientCert$outboundSchema
      .optional(),
  });

export function inputAzureBlobSendToRoutesTrueWithConnectionsConstraintToJSON(
  inputAzureBlobSendToRoutesTrueWithConnectionsConstraint:
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$outboundSchema
      .parse(inputAzureBlobSendToRoutesTrueWithConnectionsConstraint),
  );
}
export function inputAzureBlobSendToRoutesTrueWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputAzureBlobSendToRoutesTrueWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputAzureBlobSendToRoutesTrueWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputAzureBlob$inboundSchema: z.ZodType<
  InputAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() =>
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() =>
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() => InputAzureBlobPqEnabledFalseWithPqConstraint$inboundSchema),
  z.lazy(() => InputAzureBlobPqEnabledTrueWithPqConstraint$inboundSchema),
]);
/** @internal */
export type InputAzureBlob$Outbound =
  | InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$Outbound
  | InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$Outbound
  | InputAzureBlobPqEnabledFalseWithPqConstraint$Outbound
  | InputAzureBlobPqEnabledTrueWithPqConstraint$Outbound;

/** @internal */
export const InputAzureBlob$outboundSchema: z.ZodType<
  InputAzureBlob$Outbound,
  z.ZodTypeDef,
  InputAzureBlob
> = z.union([
  z.lazy(() =>
    InputAzureBlobSendToRoutesTrueWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() =>
    InputAzureBlobSendToRoutesFalseWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() => InputAzureBlobPqEnabledFalseWithPqConstraint$outboundSchema),
  z.lazy(() => InputAzureBlobPqEnabledTrueWithPqConstraint$outboundSchema),
]);

export function inputAzureBlobToJSON(inputAzureBlob: InputAzureBlob): string {
  return JSON.stringify(InputAzureBlob$outboundSchema.parse(inputAzureBlob));
}
export function inputAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<InputAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAzureBlob' from JSON`,
  );
}
