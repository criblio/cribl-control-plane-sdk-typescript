/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  AwsAuthenticationMethodOptions,
  AwsAuthenticationMethodOptions$inboundSchema,
  AwsAuthenticationMethodOptions$outboundSchema,
} from "./awsauthenticationmethodoptions.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  MetadataType,
  MetadataType$inboundSchema,
  MetadataType$Outbound,
  MetadataType$outboundSchema,
} from "./metadatatype.js";
import {
  OnBackpressureOptions,
  OnBackpressureOptions$inboundSchema,
  OnBackpressureOptions$outboundSchema,
} from "./onbackpressureoptions.js";
import {
  PqCompressOptions,
  PqCompressOptions$inboundSchema,
  PqCompressOptions$outboundSchema,
} from "./pqcompressoptions.js";
import {
  PqModeOptions,
  PqModeOptions$inboundSchema,
  PqModeOptions$outboundSchema,
} from "./pqmodeoptions.js";
import {
  PqOnBackpressureOptions,
  PqOnBackpressureOptions$inboundSchema,
  PqOnBackpressureOptions$outboundSchema,
} from "./pqonbackpressureoptions.js";
import {
  TypeGooglePubsubOption,
  TypeGooglePubsubOption$inboundSchema,
  TypeGooglePubsubOption$outboundSchema,
} from "./typegooglepubsuboption.js";

export type OutputGooglePubsubGooglePubsub5 = {
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OnBackpressureOptions | undefined;
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGooglePubsubOption;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  googleAuthMethod?: AwsAuthenticationMethodOptions | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: PqModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressOptions | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: PqOnBackpressureOptions | undefined;
  pqControls: MetadataType;
};

export type OutputGooglePubsubGooglePubsub4 = {
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OnBackpressureOptions | undefined;
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGooglePubsubOption;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  googleAuthMethod?: AwsAuthenticationMethodOptions | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: PqModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressOptions | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: PqOnBackpressureOptions | undefined;
  pqControls?: MetadataType | undefined;
};

export type OutputGooglePubsubGooglePubsub3 = {
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  googleAuthMethod?: AwsAuthenticationMethodOptions | undefined;
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGooglePubsubOption;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret: string;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OnBackpressureOptions | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: PqModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressOptions | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: PqOnBackpressureOptions | undefined;
  pqControls?: MetadataType | undefined;
};

export type OutputGooglePubsubGooglePubsub2 = {
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  googleAuthMethod?: AwsAuthenticationMethodOptions | undefined;
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGooglePubsubOption;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials: string;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OnBackpressureOptions | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: PqModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressOptions | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: PqOnBackpressureOptions | undefined;
  pqControls?: MetadataType | undefined;
};

export type OutputGooglePubsubGooglePubsub1 = {
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  googleAuthMethod?: AwsAuthenticationMethodOptions | undefined;
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: TypeGooglePubsubOption;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * ID of the topic to send events to.
   */
  topicName: string;
  /**
   * If enabled, create topic if it does not exist.
   */
  createTopic?: boolean | undefined;
  /**
   * If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  /**
   * Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * The maximum number of items the Google API should batch before it sends them to the topic.
   */
  batchSize?: number | undefined;
  /**
   * The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
   */
  batchTimeout?: number | undefined;
  /**
   * Maximum number of queued batches before blocking.
   */
  maxQueueSize?: number | undefined;
  /**
   * Maximum size (KB) of batches to send.
   */
  maxRecordSizeKB?: number | undefined;
  /**
   * Maximum time to wait before sending a batch (when batch size limit is not reached)
   */
  flushPeriod?: number | undefined;
  /**
   * The maximum number of in-progress API requests before backpressure is applied.
   */
  maxInProgress?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OnBackpressureOptions | undefined;
  description?: string | undefined;
  /**
   * Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
   */
  pqStrictOrdering?: boolean | undefined;
  /**
   * Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
   */
  pqRatePerSec?: number | undefined;
  /**
   * In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
   */
  pqMode?: PqModeOptions | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  pqMaxBufferSize?: number | undefined;
  /**
   * How long (in seconds) to wait for backpressure to resolve before engaging the queue
   */
  pqMaxBackpressureSec?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
   */
  pqMaxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  pqMaxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
   */
  pqPath?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  pqCompress?: PqCompressOptions | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  pqOnBackpressure?: PqOnBackpressureOptions | undefined;
  pqControls?: MetadataType | undefined;
};

export type OutputGooglePubsub =
  | OutputGooglePubsubGooglePubsub2
  | OutputGooglePubsubGooglePubsub3
  | OutputGooglePubsubGooglePubsub5
  | OutputGooglePubsubGooglePubsub1
  | OutputGooglePubsubGooglePubsub4;

/** @internal */
export const OutputGooglePubsubGooglePubsub5$inboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub5,
  z.ZodTypeDef,
  unknown
> = z.object({
  onBackpressure: OnBackpressureOptions$inboundSchema.default("block"),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  googleAuthMethod: AwsAuthenticationMethodOptions$inboundSchema.default(
    "auto",
  ),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$inboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$inboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  pqControls: MetadataType$inboundSchema,
});
/** @internal */
export type OutputGooglePubsubGooglePubsub5$Outbound = {
  onBackpressure: string;
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  googleAuthMethod: string;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls: MetadataType$Outbound;
};

/** @internal */
export const OutputGooglePubsubGooglePubsub5$outboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub5$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsubGooglePubsub5
> = z.object({
  onBackpressure: OnBackpressureOptions$outboundSchema.default("block"),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  googleAuthMethod: AwsAuthenticationMethodOptions$outboundSchema.default(
    "auto",
  ),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$outboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  pqControls: MetadataType$outboundSchema,
});

export function outputGooglePubsubGooglePubsub5ToJSON(
  outputGooglePubsubGooglePubsub5: OutputGooglePubsubGooglePubsub5,
): string {
  return JSON.stringify(
    OutputGooglePubsubGooglePubsub5$outboundSchema.parse(
      outputGooglePubsubGooglePubsub5,
    ),
  );
}
export function outputGooglePubsubGooglePubsub5FromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsubGooglePubsub5, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsubGooglePubsub5$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsubGooglePubsub5' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsubGooglePubsub4$inboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub4,
  z.ZodTypeDef,
  unknown
> = z.object({
  onBackpressure: OnBackpressureOptions$inboundSchema.default("block"),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  googleAuthMethod: AwsAuthenticationMethodOptions$inboundSchema.default(
    "auto",
  ),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$inboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$inboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  pqControls: MetadataType$inboundSchema.optional(),
});
/** @internal */
export type OutputGooglePubsubGooglePubsub4$Outbound = {
  onBackpressure: string;
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  googleAuthMethod: string;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: MetadataType$Outbound | undefined;
};

/** @internal */
export const OutputGooglePubsubGooglePubsub4$outboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub4$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsubGooglePubsub4
> = z.object({
  onBackpressure: OnBackpressureOptions$outboundSchema.default("block"),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  googleAuthMethod: AwsAuthenticationMethodOptions$outboundSchema.default(
    "auto",
  ),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$outboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  pqControls: MetadataType$outboundSchema.optional(),
});

export function outputGooglePubsubGooglePubsub4ToJSON(
  outputGooglePubsubGooglePubsub4: OutputGooglePubsubGooglePubsub4,
): string {
  return JSON.stringify(
    OutputGooglePubsubGooglePubsub4$outboundSchema.parse(
      outputGooglePubsubGooglePubsub4,
    ),
  );
}
export function outputGooglePubsubGooglePubsub4FromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsubGooglePubsub4, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsubGooglePubsub4$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsubGooglePubsub4' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsubGooglePubsub3$inboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub3,
  z.ZodTypeDef,
  unknown
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$inboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$inboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$inboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$inboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  pqControls: MetadataType$inboundSchema.optional(),
});
/** @internal */
export type OutputGooglePubsubGooglePubsub3$Outbound = {
  googleAuthMethod: string;
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  serviceAccountCredentials?: string | undefined;
  secret: string;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: MetadataType$Outbound | undefined;
};

/** @internal */
export const OutputGooglePubsubGooglePubsub3$outboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub3$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsubGooglePubsub3
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$outboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$outboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$outboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  pqControls: MetadataType$outboundSchema.optional(),
});

export function outputGooglePubsubGooglePubsub3ToJSON(
  outputGooglePubsubGooglePubsub3: OutputGooglePubsubGooglePubsub3,
): string {
  return JSON.stringify(
    OutputGooglePubsubGooglePubsub3$outboundSchema.parse(
      outputGooglePubsubGooglePubsub3,
    ),
  );
}
export function outputGooglePubsubGooglePubsub3FromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsubGooglePubsub3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsubGooglePubsub3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsubGooglePubsub3' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsubGooglePubsub2$inboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub2,
  z.ZodTypeDef,
  unknown
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$inboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$inboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$inboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$inboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  pqControls: MetadataType$inboundSchema.optional(),
});
/** @internal */
export type OutputGooglePubsubGooglePubsub2$Outbound = {
  googleAuthMethod: string;
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  serviceAccountCredentials: string;
  secret?: string | undefined;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: MetadataType$Outbound | undefined;
};

/** @internal */
export const OutputGooglePubsubGooglePubsub2$outboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub2$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsubGooglePubsub2
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$outboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$outboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$outboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  pqControls: MetadataType$outboundSchema.optional(),
});

export function outputGooglePubsubGooglePubsub2ToJSON(
  outputGooglePubsubGooglePubsub2: OutputGooglePubsubGooglePubsub2,
): string {
  return JSON.stringify(
    OutputGooglePubsubGooglePubsub2$outboundSchema.parse(
      outputGooglePubsubGooglePubsub2,
    ),
  );
}
export function outputGooglePubsubGooglePubsub2FromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsubGooglePubsub2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsubGooglePubsub2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsubGooglePubsub2' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsubGooglePubsub1$inboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub1,
  z.ZodTypeDef,
  unknown
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$inboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$inboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$inboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$inboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  pqControls: MetadataType$inboundSchema.optional(),
});
/** @internal */
export type OutputGooglePubsubGooglePubsub1$Outbound = {
  googleAuthMethod: string;
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  topicName: string;
  createTopic: boolean;
  orderedDelivery: boolean;
  region?: string | undefined;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  batchSize: number;
  batchTimeout: number;
  maxQueueSize: number;
  maxRecordSizeKB: number;
  flushPeriod: number;
  maxInProgress: number;
  onBackpressure: string;
  description?: string | undefined;
  pqStrictOrdering: boolean;
  pqRatePerSec: number;
  pqMode: string;
  pqMaxBufferSize: number;
  pqMaxBackpressureSec: number;
  pqMaxFileSize: string;
  pqMaxSize: string;
  pqPath: string;
  pqCompress: string;
  pqOnBackpressure: string;
  pqControls?: MetadataType$Outbound | undefined;
};

/** @internal */
export const OutputGooglePubsubGooglePubsub1$outboundSchema: z.ZodType<
  OutputGooglePubsubGooglePubsub1$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsubGooglePubsub1
> = z.object({
  googleAuthMethod: AwsAuthenticationMethodOptions$outboundSchema.default(
    "auto",
  ),
  id: z.string().optional(),
  type: TypeGooglePubsubOption$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  topicName: z.string(),
  createTopic: z.boolean().default(false),
  orderedDelivery: z.boolean().default(false),
  region: z.string().optional(),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  batchSize: z.number().default(1000),
  batchTimeout: z.number().default(100),
  maxQueueSize: z.number().default(100),
  maxRecordSizeKB: z.number().default(256),
  flushPeriod: z.number().default(1),
  maxInProgress: z.number().default(10),
  onBackpressure: OnBackpressureOptions$outboundSchema.default("block"),
  description: z.string().optional(),
  pqStrictOrdering: z.boolean().default(true),
  pqRatePerSec: z.number().default(0),
  pqMode: PqModeOptions$outboundSchema.default("error"),
  pqMaxBufferSize: z.number().default(42),
  pqMaxBackpressureSec: z.number().default(30),
  pqMaxFileSize: z.string().default("1 MB"),
  pqMaxSize: z.string().default("5GB"),
  pqPath: z.string().default("$CRIBL_HOME/state/queues"),
  pqCompress: PqCompressOptions$outboundSchema.default("none"),
  pqOnBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  pqControls: MetadataType$outboundSchema.optional(),
});

export function outputGooglePubsubGooglePubsub1ToJSON(
  outputGooglePubsubGooglePubsub1: OutputGooglePubsubGooglePubsub1,
): string {
  return JSON.stringify(
    OutputGooglePubsubGooglePubsub1$outboundSchema.parse(
      outputGooglePubsubGooglePubsub1,
    ),
  );
}
export function outputGooglePubsubGooglePubsub1FromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsubGooglePubsub1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsubGooglePubsub1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsubGooglePubsub1' from JSON`,
  );
}

/** @internal */
export const OutputGooglePubsub$inboundSchema: z.ZodType<
  OutputGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => OutputGooglePubsubGooglePubsub2$inboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub3$inboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub5$inboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub1$inboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub4$inboundSchema),
]);
/** @internal */
export type OutputGooglePubsub$Outbound =
  | OutputGooglePubsubGooglePubsub2$Outbound
  | OutputGooglePubsubGooglePubsub3$Outbound
  | OutputGooglePubsubGooglePubsub5$Outbound
  | OutputGooglePubsubGooglePubsub1$Outbound
  | OutputGooglePubsubGooglePubsub4$Outbound;

/** @internal */
export const OutputGooglePubsub$outboundSchema: z.ZodType<
  OutputGooglePubsub$Outbound,
  z.ZodTypeDef,
  OutputGooglePubsub
> = z.union([
  z.lazy(() => OutputGooglePubsubGooglePubsub2$outboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub3$outboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub5$outboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub1$outboundSchema),
  z.lazy(() => OutputGooglePubsubGooglePubsub4$outboundSchema),
]);

export function outputGooglePubsubToJSON(
  outputGooglePubsub: OutputGooglePubsub,
): string {
  return JSON.stringify(
    OutputGooglePubsub$outboundSchema.parse(outputGooglePubsub),
  );
}
export function outputGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<OutputGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGooglePubsub' from JSON`,
  );
}
