/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import {
  catchUnrecognizedEnum,
  ClosedEnum,
  OpenEnum,
  Unrecognized,
} from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";

export const OutputCloudflareR2Type = {
  CloudflareR2: "cloudflare_r2",
} as const;
export type OutputCloudflareR2Type = ClosedEnum<typeof OutputCloudflareR2Type>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const OutputCloudflareR2AuthenticationMethod = {
  Auto: "auto",
  Secret: "secret",
  Manual: "manual",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type OutputCloudflareR2AuthenticationMethod = OpenEnum<
  typeof OutputCloudflareR2AuthenticationMethod
>;

/**
 * Signature version to use for signing MinIO requests
 */
export const OutputCloudflareR2SignatureVersion = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing MinIO requests
 */
export type OutputCloudflareR2SignatureVersion = OpenEnum<
  typeof OutputCloudflareR2SignatureVersion
>;

/**
 * Storage class to select for uploaded objects
 */
export const OutputCloudflareR2StorageClass = {
  /**
   * Standard
   */
  Standard: "STANDARD",
  /**
   * Reduced Redundancy Storage
   */
  ReducedRedundancy: "REDUCED_REDUNDANCY",
} as const;
/**
 * Storage class to select for uploaded objects
 */
export type OutputCloudflareR2StorageClass = OpenEnum<
  typeof OutputCloudflareR2StorageClass
>;

/**
 * Server-side encryption for uploaded objects
 */
export const OutputCloudflareR2ServerSideEncryption = {
  /**
   * Amazon S3 Managed Key
   */
  Aes256: "AES256",
} as const;
/**
 * Server-side encryption for uploaded objects
 */
export type OutputCloudflareR2ServerSideEncryption = OpenEnum<
  typeof OutputCloudflareR2ServerSideEncryption
>;

/**
 * Format of the output data
 */
export const OutputCloudflareR2DataFormat = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * Raw
   */
  Raw: "raw",
  /**
   * Parquet
   */
  Parquet: "parquet",
} as const;
/**
 * Format of the output data
 */
export type OutputCloudflareR2DataFormat = OpenEnum<
  typeof OutputCloudflareR2DataFormat
>;

/**
 * How to handle events when all receivers are exerting backpressure
 */
export const OutputCloudflareR2BackpressureBehavior = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when all receivers are exerting backpressure
 */
export type OutputCloudflareR2BackpressureBehavior = OpenEnum<
  typeof OutputCloudflareR2BackpressureBehavior
>;

/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export const OutputCloudflareR2DiskSpaceProtection = {
  /**
   * Block
   */
  Block: "block",
  /**
   * Drop
   */
  Drop: "drop",
} as const;
/**
 * How to handle events when disk space is below the global 'Min free disk space' limit
 */
export type OutputCloudflareR2DiskSpaceProtection = OpenEnum<
  typeof OutputCloudflareR2DiskSpaceProtection
>;

/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export const OutputCloudflareR2Compression = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format to apply to HTTP content before it is delivered
 */
export type OutputCloudflareR2Compression = OpenEnum<
  typeof OutputCloudflareR2Compression
>;

/**
 * Compression level to apply before moving files to final destination
 */
export const OutputCloudflareR2CompressionLevel = {
  /**
   * Best Speed
   */
  BestSpeed: "best_speed",
  /**
   * Normal
   */
  Normal: "normal",
  /**
   * Best Compression
   */
  BestCompression: "best_compression",
} as const;
/**
 * Compression level to apply before moving files to final destination
 */
export type OutputCloudflareR2CompressionLevel = OpenEnum<
  typeof OutputCloudflareR2CompressionLevel
>;

/**
 * Determines which data types are supported and how they are represented
 */
export const OutputCloudflareR2ParquetVersion = {
  /**
   * 1.0
   */
  Parquet10: "PARQUET_1_0",
  /**
   * 2.4
   */
  Parquet24: "PARQUET_2_4",
  /**
   * 2.6
   */
  Parquet26: "PARQUET_2_6",
} as const;
/**
 * Determines which data types are supported and how they are represented
 */
export type OutputCloudflareR2ParquetVersion = OpenEnum<
  typeof OutputCloudflareR2ParquetVersion
>;

/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export const OutputCloudflareR2DataPageVersion = {
  /**
   * V1
   */
  DataPageV1: "DATA_PAGE_V1",
  /**
   * V2
   */
  DataPageV2: "DATA_PAGE_V2",
} as const;
/**
 * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
 */
export type OutputCloudflareR2DataPageVersion = OpenEnum<
  typeof OutputCloudflareR2DataPageVersion
>;

export type OutputCloudflareR2KeyValueMetadatum = {
  key?: string | undefined;
  value: string;
};

export type OutputCloudflareR2 = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputCloudflareR2Type;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Cloudflare R2 service URL (example: https://<ACCOUNT_ID>.r2.cloudflarestorage.com)
   */
  endpoint: string;
  /**
   * Name of the destination R2 bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
   */
  bucket: string;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: OutputCloudflareR2AuthenticationMethod | undefined;
  /**
   * Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
   */
  awsSecretKey?: string | undefined;
  region?: any | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
   */
  destPath?: string | undefined;
  /**
   * Signature version to use for signing MinIO requests
   */
  signatureVersion?: OutputCloudflareR2SignatureVersion | undefined;
  objectACL?: any | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: OutputCloudflareR2StorageClass | undefined;
  /**
   * Server-side encryption for uploaded objects
   */
  serverSideEncryption?: OutputCloudflareR2ServerSideEncryption | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: OutputCloudflareR2DataFormat | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: OutputCloudflareR2BackpressureBehavior | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: OutputCloudflareR2DiskSpaceProtection | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
   */
  maxConcurrentFileParts?: number | undefined;
  description?: string | undefined;
  /**
   * This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
   */
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: OutputCloudflareR2Compression | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: OutputCloudflareR2CompressionLevel | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: OutputCloudflareR2ParquetVersion | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: OutputCloudflareR2DataPageVersion | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<OutputCloudflareR2KeyValueMetadatum> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
};

/** @internal */
export const OutputCloudflareR2Type$inboundSchema: z.ZodNativeEnum<
  typeof OutputCloudflareR2Type
> = z.nativeEnum(OutputCloudflareR2Type);
/** @internal */
export const OutputCloudflareR2Type$outboundSchema: z.ZodNativeEnum<
  typeof OutputCloudflareR2Type
> = OutputCloudflareR2Type$inboundSchema;

/** @internal */
export const OutputCloudflareR2AuthenticationMethod$inboundSchema: z.ZodType<
  OutputCloudflareR2AuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2AuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2AuthenticationMethod$outboundSchema: z.ZodType<
  OutputCloudflareR2AuthenticationMethod,
  z.ZodTypeDef,
  OutputCloudflareR2AuthenticationMethod
> = z.union([
  z.nativeEnum(OutputCloudflareR2AuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2SignatureVersion$inboundSchema: z.ZodType<
  OutputCloudflareR2SignatureVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2SignatureVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2SignatureVersion$outboundSchema: z.ZodType<
  OutputCloudflareR2SignatureVersion,
  z.ZodTypeDef,
  OutputCloudflareR2SignatureVersion
> = z.union([
  z.nativeEnum(OutputCloudflareR2SignatureVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2StorageClass$inboundSchema: z.ZodType<
  OutputCloudflareR2StorageClass,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2StorageClass),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2StorageClass$outboundSchema: z.ZodType<
  OutputCloudflareR2StorageClass,
  z.ZodTypeDef,
  OutputCloudflareR2StorageClass
> = z.union([
  z.nativeEnum(OutputCloudflareR2StorageClass),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2ServerSideEncryption$inboundSchema: z.ZodType<
  OutputCloudflareR2ServerSideEncryption,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2ServerSideEncryption),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2ServerSideEncryption$outboundSchema: z.ZodType<
  OutputCloudflareR2ServerSideEncryption,
  z.ZodTypeDef,
  OutputCloudflareR2ServerSideEncryption
> = z.union([
  z.nativeEnum(OutputCloudflareR2ServerSideEncryption),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2DataFormat$inboundSchema: z.ZodType<
  OutputCloudflareR2DataFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2DataFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2DataFormat$outboundSchema: z.ZodType<
  OutputCloudflareR2DataFormat,
  z.ZodTypeDef,
  OutputCloudflareR2DataFormat
> = z.union([
  z.nativeEnum(OutputCloudflareR2DataFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2BackpressureBehavior$inboundSchema: z.ZodType<
  OutputCloudflareR2BackpressureBehavior,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2BackpressureBehavior),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2BackpressureBehavior$outboundSchema: z.ZodType<
  OutputCloudflareR2BackpressureBehavior,
  z.ZodTypeDef,
  OutputCloudflareR2BackpressureBehavior
> = z.union([
  z.nativeEnum(OutputCloudflareR2BackpressureBehavior),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2DiskSpaceProtection$inboundSchema: z.ZodType<
  OutputCloudflareR2DiskSpaceProtection,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2DiskSpaceProtection),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2DiskSpaceProtection$outboundSchema: z.ZodType<
  OutputCloudflareR2DiskSpaceProtection,
  z.ZodTypeDef,
  OutputCloudflareR2DiskSpaceProtection
> = z.union([
  z.nativeEnum(OutputCloudflareR2DiskSpaceProtection),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2Compression$inboundSchema: z.ZodType<
  OutputCloudflareR2Compression,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2Compression),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2Compression$outboundSchema: z.ZodType<
  OutputCloudflareR2Compression,
  z.ZodTypeDef,
  OutputCloudflareR2Compression
> = z.union([
  z.nativeEnum(OutputCloudflareR2Compression),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2CompressionLevel$inboundSchema: z.ZodType<
  OutputCloudflareR2CompressionLevel,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2CompressionLevel),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2CompressionLevel$outboundSchema: z.ZodType<
  OutputCloudflareR2CompressionLevel,
  z.ZodTypeDef,
  OutputCloudflareR2CompressionLevel
> = z.union([
  z.nativeEnum(OutputCloudflareR2CompressionLevel),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2ParquetVersion$inboundSchema: z.ZodType<
  OutputCloudflareR2ParquetVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2ParquetVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2ParquetVersion$outboundSchema: z.ZodType<
  OutputCloudflareR2ParquetVersion,
  z.ZodTypeDef,
  OutputCloudflareR2ParquetVersion
> = z.union([
  z.nativeEnum(OutputCloudflareR2ParquetVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2DataPageVersion$inboundSchema: z.ZodType<
  OutputCloudflareR2DataPageVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputCloudflareR2DataPageVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputCloudflareR2DataPageVersion$outboundSchema: z.ZodType<
  OutputCloudflareR2DataPageVersion,
  z.ZodTypeDef,
  OutputCloudflareR2DataPageVersion
> = z.union([
  z.nativeEnum(OutputCloudflareR2DataPageVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OutputCloudflareR2KeyValueMetadatum$inboundSchema: z.ZodType<
  OutputCloudflareR2KeyValueMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});
/** @internal */
export type OutputCloudflareR2KeyValueMetadatum$Outbound = {
  key: string;
  value: string;
};

/** @internal */
export const OutputCloudflareR2KeyValueMetadatum$outboundSchema: z.ZodType<
  OutputCloudflareR2KeyValueMetadatum$Outbound,
  z.ZodTypeDef,
  OutputCloudflareR2KeyValueMetadatum
> = z.object({
  key: z.string().default(""),
  value: z.string(),
});

export function outputCloudflareR2KeyValueMetadatumToJSON(
  outputCloudflareR2KeyValueMetadatum: OutputCloudflareR2KeyValueMetadatum,
): string {
  return JSON.stringify(
    OutputCloudflareR2KeyValueMetadatum$outboundSchema.parse(
      outputCloudflareR2KeyValueMetadatum,
    ),
  );
}
export function outputCloudflareR2KeyValueMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<OutputCloudflareR2KeyValueMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      OutputCloudflareR2KeyValueMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCloudflareR2KeyValueMetadatum' from JSON`,
  );
}

/** @internal */
export const OutputCloudflareR2$inboundSchema: z.ZodType<
  OutputCloudflareR2,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  type: OutputCloudflareR2Type$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  endpoint: z.string(),
  bucket: z.string(),
  awsAuthenticationMethod: OutputCloudflareR2AuthenticationMethod$inboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.any().optional(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().optional(),
  signatureVersion: OutputCloudflareR2SignatureVersion$inboundSchema.default(
    "v4",
  ),
  objectACL: z.any().optional(),
  storageClass: OutputCloudflareR2StorageClass$inboundSchema.optional(),
  serverSideEncryption: OutputCloudflareR2ServerSideEncryption$inboundSchema
    .optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  verifyPermissions: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: OutputCloudflareR2DataFormat$inboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: OutputCloudflareR2BackpressureBehavior$inboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: OutputCloudflareR2DiskSpaceProtection$inboundSchema
    .default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: OutputCloudflareR2Compression$inboundSchema.default("gzip"),
  compressionLevel: OutputCloudflareR2CompressionLevel$inboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: OutputCloudflareR2ParquetVersion$inboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: OutputCloudflareR2DataPageVersion$inboundSchema
    .default("DATA_PAGE_V2"),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => OutputCloudflareR2KeyValueMetadatum$inboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
});
/** @internal */
export type OutputCloudflareR2$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  endpoint: string;
  bucket: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: any | undefined;
  stagePath: string;
  addIdToStagePath: boolean;
  destPath?: string | undefined;
  signatureVersion: string;
  objectACL?: any | undefined;
  storageClass?: string | undefined;
  serverSideEncryption?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  verifyPermissions: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxConcurrentFileParts: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?:
    | Array<OutputCloudflareR2KeyValueMetadatum$Outbound>
    | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
};

/** @internal */
export const OutputCloudflareR2$outboundSchema: z.ZodType<
  OutputCloudflareR2$Outbound,
  z.ZodTypeDef,
  OutputCloudflareR2
> = z.object({
  id: z.string().optional(),
  type: OutputCloudflareR2Type$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  endpoint: z.string(),
  bucket: z.string(),
  awsAuthenticationMethod: OutputCloudflareR2AuthenticationMethod$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.any().optional(),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  addIdToStagePath: z.boolean().default(true),
  destPath: z.string().optional(),
  signatureVersion: OutputCloudflareR2SignatureVersion$outboundSchema.default(
    "v4",
  ),
  objectACL: z.any().optional(),
  storageClass: OutputCloudflareR2StorageClass$outboundSchema.optional(),
  serverSideEncryption: OutputCloudflareR2ServerSideEncryption$outboundSchema
    .optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  verifyPermissions: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: OutputCloudflareR2DataFormat$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: OutputCloudflareR2BackpressureBehavior$outboundSchema.default(
    "block",
  ),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: OutputCloudflareR2DiskSpaceProtection$outboundSchema
    .default("block"),
  forceCloseOnShutdown: z.boolean().default(false),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxConcurrentFileParts: z.number().default(4),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  compress: OutputCloudflareR2Compression$outboundSchema.default("gzip"),
  compressionLevel: OutputCloudflareR2CompressionLevel$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: OutputCloudflareR2ParquetVersion$outboundSchema.default(
    "PARQUET_2_6",
  ),
  parquetDataPageVersion: OutputCloudflareR2DataPageVersion$outboundSchema
    .default("DATA_PAGE_V2"),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(
    z.lazy(() => OutputCloudflareR2KeyValueMetadatum$outboundSchema),
  ).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
});

export function outputCloudflareR2ToJSON(
  outputCloudflareR2: OutputCloudflareR2,
): string {
  return JSON.stringify(
    OutputCloudflareR2$outboundSchema.parse(outputCloudflareR2),
  );
}
export function outputCloudflareR2FromJSON(
  jsonString: string,
): SafeParseResult<OutputCloudflareR2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputCloudflareR2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputCloudflareR2' from JSON`,
  );
}
