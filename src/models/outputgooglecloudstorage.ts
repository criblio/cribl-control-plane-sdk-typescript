/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  BackpressureBehaviorOptions1,
  BackpressureBehaviorOptions1$inboundSchema,
  BackpressureBehaviorOptions1$outboundSchema,
} from "./backpressurebehavioroptions1.js";
import {
  CompressionLevelOptions,
  CompressionLevelOptions$inboundSchema,
  CompressionLevelOptions$outboundSchema,
} from "./compressionleveloptions.js";
import {
  CompressionOptions2,
  CompressionOptions2$inboundSchema,
  CompressionOptions2$outboundSchema,
} from "./compressionoptions2.js";
import {
  DataFormatOptions,
  DataFormatOptions$inboundSchema,
  DataFormatOptions$outboundSchema,
} from "./dataformatoptions.js";
import {
  DataPageVersionOptions,
  DataPageVersionOptions$inboundSchema,
  DataPageVersionOptions$outboundSchema,
} from "./datapageversionoptions.js";
import {
  DiskSpaceProtectionOptions,
  DiskSpaceProtectionOptions$inboundSchema,
  DiskSpaceProtectionOptions$outboundSchema,
} from "./diskspaceprotectionoptions.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeKeyValueMetadata,
  ItemsTypeKeyValueMetadata$inboundSchema,
  ItemsTypeKeyValueMetadata$Outbound,
  ItemsTypeKeyValueMetadata$outboundSchema,
} from "./itemstypekeyvaluemetadata.js";
import {
  ObjectAclOptions1,
  ObjectAclOptions1$inboundSchema,
  ObjectAclOptions1$outboundSchema,
} from "./objectacloptions1.js";
import {
  ParquetVersionOptions,
  ParquetVersionOptions$inboundSchema,
  ParquetVersionOptions$outboundSchema,
} from "./parquetversionoptions.js";
import {
  SignatureVersionOptions5,
  SignatureVersionOptions5$inboundSchema,
  SignatureVersionOptions5$outboundSchema,
} from "./signatureversionoptions5.js";
import {
  StorageClassOptions1,
  StorageClassOptions1$inboundSchema,
  StorageClassOptions1$outboundSchema,
} from "./storageclassoptions1.js";

export const OutputGoogleCloudStorageAuthenticationMethod = {
  /**
   * auto
   */
  Auto: "auto",
  /**
   * manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
export type OutputGoogleCloudStorageAuthenticationMethod = OpenEnum<
  typeof OutputGoogleCloudStorageAuthenticationMethod
>;

export type OutputGoogleCloudStorage = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: "google_cloud_storage";
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Name of the destination bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a Global Variable: `myBucket-${C.vars.myVar}`.
   */
  bucket: string;
  /**
   * Region where the bucket is located
   */
  region: string;
  /**
   * Google Cloud Storage service endpoint
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Google Cloud Storage requests
   */
  signatureVersion?: SignatureVersionOptions5 | undefined;
  awsAuthenticationMethod?:
    | OutputGoogleCloudStorageAuthenticationMethod
    | undefined;
  /**
   * Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
   */
  stagePath?: string | undefined;
  /**
   * Prefix to prepend to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
   */
  destPath?: string | undefined;
  /**
   * Disable if you can access files within the bucket but not the bucket itself
   */
  verifyPermissions?: boolean | undefined;
  /**
   * Object ACL to assign to uploaded objects
   */
  objectACL?: ObjectAclOptions1 | undefined;
  /**
   * Storage class to select for uploaded objects
   */
  storageClass?: StorageClassOptions1 | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Add the Output ID value to staging location
   */
  addIdToStagePath?: boolean | undefined;
  /**
   * Remove empty staging directories after moving files
   */
  removeEmptyDirs?: boolean | undefined;
  /**
   * JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
   */
  partitionExpr?: string | undefined;
  /**
   * Format of the output data
   */
  format?: DataFormatOptions | undefined;
  /**
   * JavaScript expression to define the output filename prefix (can be constant)
   */
  baseFileName?: string | undefined;
  /**
   * JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
   */
  fileNameSuffix?: string | undefined;
  /**
   * Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
   */
  maxFileSizeMB?: number | undefined;
  /**
   * Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileOpenTimeSec?: number | undefined;
  /**
   * Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
   */
  maxFileIdleTimeSec?: number | undefined;
  /**
   * Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
   */
  maxOpenFiles?: number | undefined;
  /**
   * If set, this line will be written to the beginning of each output file
   */
  headerLine?: string | undefined;
  /**
   * Buffer size used to write to a file
   */
  writeHighWaterMark?: number | undefined;
  /**
   * How to handle events when all receivers are exerting backpressure
   */
  onBackpressure?: BackpressureBehaviorOptions1 | undefined;
  /**
   * If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
   */
  deadletterEnabled?: boolean | undefined;
  /**
   * How to handle events when disk space is below the global 'Min free disk space' limit
   */
  onDiskFullBackpressure?: DiskSpaceProtectionOptions | undefined;
  /**
   * Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
   */
  forceCloseOnShutdown?: boolean | undefined;
  description?: string | undefined;
  /**
   * Data compression format to apply to HTTP content before it is delivered
   */
  compress?: CompressionOptions2 | undefined;
  /**
   * Compression level to apply before moving files to final destination
   */
  compressionLevel?: CompressionLevelOptions | undefined;
  /**
   * Automatically calculate the schema based on the events of each Parquet file generated
   */
  automaticSchema?: boolean | undefined;
  /**
   * To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
   */
  parquetSchema?: string | undefined;
  /**
   * Determines which data types are supported and how they are represented
   */
  parquetVersion?: ParquetVersionOptions | undefined;
  /**
   * Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
   */
  parquetDataPageVersion?: DataPageVersionOptions | undefined;
  /**
   * The number of rows that every group will contain. The final group can contain a smaller number of rows.
   */
  parquetRowGroupLength?: number | undefined;
  /**
   * Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
   */
  parquetPageSize?: string | undefined;
  /**
   * Log up to 3 rows that @{product} skips due to data mismatch
   */
  shouldLogInvalidRows?: boolean | undefined;
  /**
   * The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
   */
  keyValueMetadata?: Array<ItemsTypeKeyValueMetadata> | undefined;
  /**
   * Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
   */
  enableStatistics?: boolean | undefined;
  /**
   * One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
   */
  enableWritePageIndex?: boolean | undefined;
  /**
   * Parquet tools can use the checksum of a Parquet page to verify data integrity
   */
  enablePageChecksum?: boolean | undefined;
  /**
   * How frequently, in seconds, to clean up empty directories
   */
  emptyDirCleanupSec?: number | undefined;
  /**
   * Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
   */
  directoryBatchSize?: number | undefined;
  /**
   * Storage location for files that fail to reach their final destination after maximum retries are exceeded
   */
  deadletterPath?: string | undefined;
  /**
   * The maximum number of times a file will attempt to move to its final destination before being dead-lettered
   */
  maxRetryNum?: number | undefined;
  /**
   * HMAC access key. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
   */
  awsApiKey?: string | undefined;
  /**
   * HMAC secret. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
   */
  awsSecretKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
};

/** @internal */
export const OutputGoogleCloudStorageAuthenticationMethod$inboundSchema:
  z.ZodType<
    OutputGoogleCloudStorageAuthenticationMethod,
    z.ZodTypeDef,
    unknown
  > = openEnums.inboundSchema(OutputGoogleCloudStorageAuthenticationMethod);
/** @internal */
export const OutputGoogleCloudStorageAuthenticationMethod$outboundSchema:
  z.ZodType<
    string,
    z.ZodTypeDef,
    OutputGoogleCloudStorageAuthenticationMethod
  > = openEnums.outboundSchema(OutputGoogleCloudStorageAuthenticationMethod);

/** @internal */
export const OutputGoogleCloudStorage$inboundSchema: z.ZodType<
  OutputGoogleCloudStorage,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  type: z.literal("google_cloud_storage"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string(),
  endpoint: z.string().default("https://storage.googleapis.com"),
  signatureVersion: SignatureVersionOptions5$inboundSchema.default("v4"),
  awsAuthenticationMethod:
    OutputGoogleCloudStorageAuthenticationMethod$inboundSchema.default(
      "manual",
    ),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  destPath: z.string().default(""),
  verifyPermissions: z.boolean().default(true),
  objectACL: ObjectAclOptions1$inboundSchema.default("private"),
  storageClass: StorageClassOptions1$inboundSchema.optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatOptions$inboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorOptions1$inboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionOptions$inboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  description: z.string().optional(),
  compress: CompressionOptions2$inboundSchema.default("gzip"),
  compressionLevel: CompressionLevelOptions$inboundSchema.default("best_speed"),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionOptions$inboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionOptions$inboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(ItemsTypeKeyValueMetadata$inboundSchema).optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  awsApiKey: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsSecret: z.string().optional(),
});
/** @internal */
export type OutputGoogleCloudStorage$Outbound = {
  id?: string | undefined;
  type: "google_cloud_storage";
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  bucket: string;
  region: string;
  endpoint: string;
  signatureVersion: string;
  awsAuthenticationMethod: string;
  stagePath: string;
  destPath: string;
  verifyPermissions: boolean;
  objectACL: string;
  storageClass?: string | undefined;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  addIdToStagePath: boolean;
  removeEmptyDirs: boolean;
  partitionExpr: string;
  format: string;
  baseFileName: string;
  fileNameSuffix: string;
  maxFileSizeMB: number;
  maxFileOpenTimeSec: number;
  maxFileIdleTimeSec: number;
  maxOpenFiles: number;
  headerLine: string;
  writeHighWaterMark: number;
  onBackpressure: string;
  deadletterEnabled: boolean;
  onDiskFullBackpressure: string;
  forceCloseOnShutdown: boolean;
  description?: string | undefined;
  compress: string;
  compressionLevel: string;
  automaticSchema: boolean;
  parquetSchema?: string | undefined;
  parquetVersion: string;
  parquetDataPageVersion: string;
  parquetRowGroupLength: number;
  parquetPageSize: string;
  shouldLogInvalidRows?: boolean | undefined;
  keyValueMetadata?: Array<ItemsTypeKeyValueMetadata$Outbound> | undefined;
  enableStatistics: boolean;
  enableWritePageIndex: boolean;
  enablePageChecksum: boolean;
  emptyDirCleanupSec: number;
  directoryBatchSize: number;
  deadletterPath: string;
  maxRetryNum: number;
  awsApiKey?: string | undefined;
  awsSecretKey?: string | undefined;
  awsSecret?: string | undefined;
};

/** @internal */
export const OutputGoogleCloudStorage$outboundSchema: z.ZodType<
  OutputGoogleCloudStorage$Outbound,
  z.ZodTypeDef,
  OutputGoogleCloudStorage
> = z.object({
  id: z.string().optional(),
  type: z.literal("google_cloud_storage"),
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  bucket: z.string(),
  region: z.string(),
  endpoint: z.string().default("https://storage.googleapis.com"),
  signatureVersion: SignatureVersionOptions5$outboundSchema.default("v4"),
  awsAuthenticationMethod:
    OutputGoogleCloudStorageAuthenticationMethod$outboundSchema.default(
      "manual",
    ),
  stagePath: z.string().default("$CRIBL_HOME/state/outputs/staging"),
  destPath: z.string().default(""),
  verifyPermissions: z.boolean().default(true),
  objectACL: ObjectAclOptions1$outboundSchema.default("private"),
  storageClass: StorageClassOptions1$outboundSchema.optional(),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  addIdToStagePath: z.boolean().default(true),
  removeEmptyDirs: z.boolean().default(true),
  partitionExpr: z.string().default(
    "C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')",
  ),
  format: DataFormatOptions$outboundSchema.default("json"),
  baseFileName: z.string().default("`CriblOut`"),
  fileNameSuffix: z.string().default(
    "`.${C.env[\"CRIBL_WORKER_ID\"]}.${__format}${__compression === \"gzip\" ? \".gz\" : \"\"}`",
  ),
  maxFileSizeMB: z.number().default(32),
  maxFileOpenTimeSec: z.number().default(300),
  maxFileIdleTimeSec: z.number().default(30),
  maxOpenFiles: z.number().default(100),
  headerLine: z.string().default(""),
  writeHighWaterMark: z.number().default(64),
  onBackpressure: BackpressureBehaviorOptions1$outboundSchema.default("block"),
  deadletterEnabled: z.boolean().default(false),
  onDiskFullBackpressure: DiskSpaceProtectionOptions$outboundSchema.default(
    "block",
  ),
  forceCloseOnShutdown: z.boolean().default(false),
  description: z.string().optional(),
  compress: CompressionOptions2$outboundSchema.default("gzip"),
  compressionLevel: CompressionLevelOptions$outboundSchema.default(
    "best_speed",
  ),
  automaticSchema: z.boolean().default(false),
  parquetSchema: z.string().optional(),
  parquetVersion: ParquetVersionOptions$outboundSchema.default("PARQUET_2_6"),
  parquetDataPageVersion: DataPageVersionOptions$outboundSchema.default(
    "DATA_PAGE_V2",
  ),
  parquetRowGroupLength: z.number().default(10000),
  parquetPageSize: z.string().default("1MB"),
  shouldLogInvalidRows: z.boolean().optional(),
  keyValueMetadata: z.array(ItemsTypeKeyValueMetadata$outboundSchema)
    .optional(),
  enableStatistics: z.boolean().default(true),
  enableWritePageIndex: z.boolean().default(true),
  enablePageChecksum: z.boolean().default(false),
  emptyDirCleanupSec: z.number().default(300),
  directoryBatchSize: z.number().default(1000),
  deadletterPath: z.string().default("$CRIBL_HOME/state/outputs/dead-letter"),
  maxRetryNum: z.number().default(20),
  awsApiKey: z.string().optional(),
  awsSecretKey: z.string().optional(),
  awsSecret: z.string().optional(),
});

export function outputGoogleCloudStorageToJSON(
  outputGoogleCloudStorage: OutputGoogleCloudStorage,
): string {
  return JSON.stringify(
    OutputGoogleCloudStorage$outboundSchema.parse(outputGoogleCloudStorage),
  );
}
export function outputGoogleCloudStorageFromJSON(
  jsonString: string,
): SafeParseResult<OutputGoogleCloudStorage, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputGoogleCloudStorage$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputGoogleCloudStorage' from JSON`,
  );
}
