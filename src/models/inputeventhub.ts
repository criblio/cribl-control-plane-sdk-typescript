/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { Result as SafeParseResult } from "../types/fp.js";
import * as types from "../types/primitives.js";
import {
  AuthenticationType1,
  AuthenticationType1$inboundSchema,
  AuthenticationType1$Outbound,
  AuthenticationType1$outboundSchema,
} from "./authenticationtype1.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnectionsOptional,
  ItemsTypeConnectionsOptional$inboundSchema,
  ItemsTypeConnectionsOptional$Outbound,
  ItemsTypeConnectionsOptional$outboundSchema,
} from "./itemstypeconnectionsoptional.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";
import {
  TlsSettingsClientSideType,
  TlsSettingsClientSideType$inboundSchema,
  TlsSettingsClientSideType$Outbound,
  TlsSettingsClientSideType$outboundSchema,
} from "./tlssettingsclientsidetype.js";

export type InputEventhub = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: "eventhub";
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnectionsOptional> | undefined;
  pq?: PqType | undefined;
  /**
   * List of Event Hubs Kafka brokers to connect to (example: yourdomain.servicebus.windows.net:9093). The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
   */
  brokers: Array<string>;
  /**
   * The name of the Event Hub (Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
   */
  topics: Array<string>;
  /**
   * The consumer group this instance belongs to. Default is 'Cribl'.
   */
  groupId?: string | undefined;
  /**
   * Start reading from earliest available data; relevant only during initial subscription
   */
  fromBeginning?: boolean | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: AuthenticationType1 | undefined;
  tls?: TlsSettingsClientSideType | undefined;
  /**
   *       Timeout (session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group-management facilities.
   *
   * @remarks
   *       If the client sends no heartbeats to the broker before the timeout expires, the broker will remove the client from the group and initiate a rebalance.
   *       Value must be lower than rebalanceTimeout.
   *       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  sessionTimeout?: number | undefined;
  /**
   *       Maximum allowed time (rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance begins.
   *
   * @remarks
   *       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
   *       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  rebalanceTimeout?: number | undefined;
  /**
   *       Expected time (heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
   *
   * @remarks
   *       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
   *       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  heartbeatInterval?: number | undefined;
  /**
   * How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitInterval?: number | undefined;
  /**
   * How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitThreshold?: number | undefined;
  /**
   * Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
   */
  maxBytesPerPartition?: number | undefined;
  /**
   * Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
   */
  maxBytes?: number | undefined;
  /**
   * Maximum number of network errors before the consumer re-creates a socket
   */
  maxSocketErrors?: number | undefined;
  /**
   * Minimize duplicate events by starting only one consumer for each topic partition
   */
  minimizeDuplicates?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  description?: string | undefined;
};

/** @internal */
export const InputEventhub$inboundSchema: z.ZodType<
  InputEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: types.optional(types.string()),
  type: types.literal("eventhub"),
  disabled: types.optional(types.boolean()),
  pipeline: types.optional(types.string()),
  sendToRoutes: types.optional(types.boolean()),
  environment: types.optional(types.string()),
  pqEnabled: types.optional(types.boolean()),
  streamtags: types.optional(z.array(types.string())),
  connections: types.optional(
    z.array(ItemsTypeConnectionsOptional$inboundSchema),
  ),
  pq: types.optional(PqType$inboundSchema),
  brokers: z.array(types.string()),
  topics: z.array(types.string()),
  groupId: types.optional(types.string()),
  fromBeginning: types.optional(types.boolean()),
  connectionTimeout: types.optional(types.number()),
  requestTimeout: types.optional(types.number()),
  maxRetries: types.optional(types.number()),
  maxBackOff: types.optional(types.number()),
  initialBackoff: types.optional(types.number()),
  backoffRate: types.optional(types.number()),
  authenticationTimeout: types.optional(types.number()),
  reauthenticationThreshold: types.optional(types.number()),
  sasl: types.optional(AuthenticationType1$inboundSchema),
  tls: types.optional(TlsSettingsClientSideType$inboundSchema),
  sessionTimeout: types.optional(types.number()),
  rebalanceTimeout: types.optional(types.number()),
  heartbeatInterval: types.optional(types.number()),
  autoCommitInterval: types.optional(types.number()),
  autoCommitThreshold: types.optional(types.number()),
  maxBytesPerPartition: types.optional(types.number()),
  maxBytes: types.optional(types.number()),
  maxSocketErrors: types.optional(types.number()),
  minimizeDuplicates: types.optional(types.boolean()),
  metadata: types.optional(
    z.array(ItemsTypeNotificationMetadata$inboundSchema),
  ),
  description: types.optional(types.string()),
});
/** @internal */
export type InputEventhub$Outbound = {
  id?: string | undefined;
  type: "eventhub";
  disabled?: boolean | undefined;
  pipeline?: string | undefined;
  sendToRoutes?: boolean | undefined;
  environment?: string | undefined;
  pqEnabled?: boolean | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnectionsOptional$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  brokers: Array<string>;
  topics: Array<string>;
  groupId?: string | undefined;
  fromBeginning?: boolean | undefined;
  connectionTimeout?: number | undefined;
  requestTimeout?: number | undefined;
  maxRetries?: number | undefined;
  maxBackOff?: number | undefined;
  initialBackoff?: number | undefined;
  backoffRate?: number | undefined;
  authenticationTimeout?: number | undefined;
  reauthenticationThreshold?: number | undefined;
  sasl?: AuthenticationType1$Outbound | undefined;
  tls?: TlsSettingsClientSideType$Outbound | undefined;
  sessionTimeout?: number | undefined;
  rebalanceTimeout?: number | undefined;
  heartbeatInterval?: number | undefined;
  autoCommitInterval?: number | undefined;
  autoCommitThreshold?: number | undefined;
  maxBytesPerPartition?: number | undefined;
  maxBytes?: number | undefined;
  maxSocketErrors?: number | undefined;
  minimizeDuplicates?: boolean | undefined;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  description?: string | undefined;
};

/** @internal */
export const InputEventhub$outboundSchema: z.ZodType<
  InputEventhub$Outbound,
  z.ZodTypeDef,
  InputEventhub
> = z.object({
  id: z.string().optional(),
  type: z.literal("eventhub"),
  disabled: z.boolean().optional(),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().optional(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ItemsTypeConnectionsOptional$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  brokers: z.array(z.string()),
  topics: z.array(z.string()),
  groupId: z.string().optional(),
  fromBeginning: z.boolean().optional(),
  connectionTimeout: z.number().optional(),
  requestTimeout: z.number().optional(),
  maxRetries: z.number().optional(),
  maxBackOff: z.number().optional(),
  initialBackoff: z.number().optional(),
  backoffRate: z.number().optional(),
  authenticationTimeout: z.number().optional(),
  reauthenticationThreshold: z.number().optional(),
  sasl: AuthenticationType1$outboundSchema.optional(),
  tls: TlsSettingsClientSideType$outboundSchema.optional(),
  sessionTimeout: z.number().optional(),
  rebalanceTimeout: z.number().optional(),
  heartbeatInterval: z.number().optional(),
  autoCommitInterval: z.number().optional(),
  autoCommitThreshold: z.number().optional(),
  maxBytesPerPartition: z.number().optional(),
  maxBytes: z.number().optional(),
  maxSocketErrors: z.number().optional(),
  minimizeDuplicates: z.boolean().optional(),
  metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
  description: z.string().optional(),
});

export function inputEventhubToJSON(inputEventhub: InputEventhub): string {
  return JSON.stringify(InputEventhub$outboundSchema.parse(inputEventhub));
}
export function inputEventhubFromJSON(
  jsonString: string,
): SafeParseResult<InputEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputEventhub' from JSON`,
  );
}
