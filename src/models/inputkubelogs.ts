/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  ConnectionsType,
  ConnectionsType$inboundSchema,
  ConnectionsType$Outbound,
  ConnectionsType$outboundSchema,
} from "./connectionstype.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  Metadata1Type,
  Metadata1Type$inboundSchema,
  Metadata1Type$Outbound,
  Metadata1Type$outboundSchema,
} from "./metadata1type.js";
import {
  PersistenceType,
  PersistenceType$inboundSchema,
  PersistenceType$Outbound,
  PersistenceType$outboundSchema,
} from "./persistencetype.js";
import {
  PodFilterType,
  PodFilterType$inboundSchema,
  PodFilterType$Outbound,
  PodFilterType$outboundSchema,
} from "./podfiltertype.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";

export const InputKubeLogsType4 = {
  KubeLogs: "kube_logs",
} as const;
export type InputKubeLogsType4 = ClosedEnum<typeof InputKubeLogsType4>;

export type InputKubeLogsKubeLogs4 = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType4;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq: PqType;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<PodFilterType> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  persistence?: PersistenceType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export const InputKubeLogsType3 = {
  KubeLogs: "kube_logs",
} as const;
export type InputKubeLogsType3 = ClosedEnum<typeof InputKubeLogsType3>;

export type InputKubeLogsKubeLogs3 = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType3;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq?: PqType | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<PodFilterType> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  persistence?: PersistenceType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export const InputKubeLogsType2 = {
  KubeLogs: "kube_logs",
} as const;
export type InputKubeLogsType2 = ClosedEnum<typeof InputKubeLogsType2>;

export type InputKubeLogsKubeLogs2 = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType2;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections: Array<ConnectionsType>;
  pq?: PqType | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<PodFilterType> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  persistence?: PersistenceType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export const InputKubeLogsType1 = {
  KubeLogs: "kube_logs",
} as const;
export type InputKubeLogsType1 = ClosedEnum<typeof InputKubeLogsType1>;

export type InputKubeLogsKubeLogs1 = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType1;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq?: PqType | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<PodFilterType> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  persistence?: PersistenceType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export type InputKubeLogs =
  | InputKubeLogsKubeLogs2
  | InputKubeLogsKubeLogs4
  | InputKubeLogsKubeLogs1
  | InputKubeLogsKubeLogs3;

/** @internal */
export const InputKubeLogsType4$inboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType4
> = z.nativeEnum(InputKubeLogsType4);
/** @internal */
export const InputKubeLogsType4$outboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType4
> = InputKubeLogsType4$inboundSchema;

/** @internal */
export const InputKubeLogsKubeLogs4$inboundSchema: z.ZodType<
  InputKubeLogsKubeLogs4,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputKubeLogsType4$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema,
  interval: z.number().default(15),
  rules: z.array(PodFilterType$inboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  persistence: PersistenceType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});
/** @internal */
export type InputKubeLogsKubeLogs4$Outbound = {
  pqEnabled: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq: PqType$Outbound;
  interval: number;
  rules?: Array<PodFilterType$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  persistence?: PersistenceType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsKubeLogs4$outboundSchema: z.ZodType<
  InputKubeLogsKubeLogs4$Outbound,
  z.ZodTypeDef,
  InputKubeLogsKubeLogs4
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputKubeLogsType4$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema,
  interval: z.number().default(15),
  rules: z.array(PodFilterType$outboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  persistence: PersistenceType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});

export function inputKubeLogsKubeLogs4ToJSON(
  inputKubeLogsKubeLogs4: InputKubeLogsKubeLogs4,
): string {
  return JSON.stringify(
    InputKubeLogsKubeLogs4$outboundSchema.parse(inputKubeLogsKubeLogs4),
  );
}
export function inputKubeLogsKubeLogs4FromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogsKubeLogs4, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogsKubeLogs4$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsKubeLogs4' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsType3$inboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType3
> = z.nativeEnum(InputKubeLogsType3);
/** @internal */
export const InputKubeLogsType3$outboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType3
> = InputKubeLogsType3$inboundSchema;

/** @internal */
export const InputKubeLogsKubeLogs3$inboundSchema: z.ZodType<
  InputKubeLogsKubeLogs3,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputKubeLogsType3$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$inboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  persistence: PersistenceType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});
/** @internal */
export type InputKubeLogsKubeLogs3$Outbound = {
  pqEnabled: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  interval: number;
  rules?: Array<PodFilterType$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  persistence?: PersistenceType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsKubeLogs3$outboundSchema: z.ZodType<
  InputKubeLogsKubeLogs3$Outbound,
  z.ZodTypeDef,
  InputKubeLogsKubeLogs3
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputKubeLogsType3$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$outboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  persistence: PersistenceType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});

export function inputKubeLogsKubeLogs3ToJSON(
  inputKubeLogsKubeLogs3: InputKubeLogsKubeLogs3,
): string {
  return JSON.stringify(
    InputKubeLogsKubeLogs3$outboundSchema.parse(inputKubeLogsKubeLogs3),
  );
}
export function inputKubeLogsKubeLogs3FromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogsKubeLogs3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogsKubeLogs3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsKubeLogs3' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsType2$inboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType2
> = z.nativeEnum(InputKubeLogsType2);
/** @internal */
export const InputKubeLogsType2$outboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType2
> = InputKubeLogsType2$inboundSchema;

/** @internal */
export const InputKubeLogsKubeLogs2$inboundSchema: z.ZodType<
  InputKubeLogsKubeLogs2,
  z.ZodTypeDef,
  unknown
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputKubeLogsType2$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema),
  pq: PqType$inboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$inboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  persistence: PersistenceType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});
/** @internal */
export type InputKubeLogsKubeLogs2$Outbound = {
  sendToRoutes: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections: Array<ConnectionsType$Outbound>;
  pq?: PqType$Outbound | undefined;
  interval: number;
  rules?: Array<PodFilterType$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  persistence?: PersistenceType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsKubeLogs2$outboundSchema: z.ZodType<
  InputKubeLogsKubeLogs2$Outbound,
  z.ZodTypeDef,
  InputKubeLogsKubeLogs2
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputKubeLogsType2$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema),
  pq: PqType$outboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$outboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  persistence: PersistenceType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});

export function inputKubeLogsKubeLogs2ToJSON(
  inputKubeLogsKubeLogs2: InputKubeLogsKubeLogs2,
): string {
  return JSON.stringify(
    InputKubeLogsKubeLogs2$outboundSchema.parse(inputKubeLogsKubeLogs2),
  );
}
export function inputKubeLogsKubeLogs2FromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogsKubeLogs2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogsKubeLogs2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsKubeLogs2' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsType1$inboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType1
> = z.nativeEnum(InputKubeLogsType1);
/** @internal */
export const InputKubeLogsType1$outboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType1
> = InputKubeLogsType1$inboundSchema;

/** @internal */
export const InputKubeLogsKubeLogs1$inboundSchema: z.ZodType<
  InputKubeLogsKubeLogs1,
  z.ZodTypeDef,
  unknown
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputKubeLogsType1$inboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$inboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  persistence: PersistenceType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});
/** @internal */
export type InputKubeLogsKubeLogs1$Outbound = {
  sendToRoutes: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  interval: number;
  rules?: Array<PodFilterType$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  persistence?: PersistenceType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsKubeLogs1$outboundSchema: z.ZodType<
  InputKubeLogsKubeLogs1$Outbound,
  z.ZodTypeDef,
  InputKubeLogsKubeLogs1
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputKubeLogsType1$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  interval: z.number().default(15),
  rules: z.array(PodFilterType$outboundSchema).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  persistence: PersistenceType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
});

export function inputKubeLogsKubeLogs1ToJSON(
  inputKubeLogsKubeLogs1: InputKubeLogsKubeLogs1,
): string {
  return JSON.stringify(
    InputKubeLogsKubeLogs1$outboundSchema.parse(inputKubeLogsKubeLogs1),
  );
}
export function inputKubeLogsKubeLogs1FromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogsKubeLogs1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogsKubeLogs1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsKubeLogs1' from JSON`,
  );
}

/** @internal */
export const InputKubeLogs$inboundSchema: z.ZodType<
  InputKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => InputKubeLogsKubeLogs2$inboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs4$inboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs1$inboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs3$inboundSchema),
]);
/** @internal */
export type InputKubeLogs$Outbound =
  | InputKubeLogsKubeLogs2$Outbound
  | InputKubeLogsKubeLogs4$Outbound
  | InputKubeLogsKubeLogs1$Outbound
  | InputKubeLogsKubeLogs3$Outbound;

/** @internal */
export const InputKubeLogs$outboundSchema: z.ZodType<
  InputKubeLogs$Outbound,
  z.ZodTypeDef,
  InputKubeLogs
> = z.union([
  z.lazy(() => InputKubeLogsKubeLogs2$outboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs4$outboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs1$outboundSchema),
  z.lazy(() => InputKubeLogsKubeLogs3$outboundSchema),
]);

export function inputKubeLogsToJSON(inputKubeLogs: InputKubeLogs): string {
  return JSON.stringify(InputKubeLogs$outboundSchema.parse(inputKubeLogs));
}
export function inputKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogs' from JSON`,
  );
}
