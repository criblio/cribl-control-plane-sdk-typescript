/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  DiskSpoolingType,
  DiskSpoolingType$inboundSchema,
  DiskSpoolingType$Outbound,
  DiskSpoolingType$outboundSchema,
} from "./diskspoolingtype.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnections,
  ItemsTypeConnections$inboundSchema,
  ItemsTypeConnections$Outbound,
  ItemsTypeConnections$outboundSchema,
} from "./itemstypeconnections.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";

export const InputKubeLogsType = {
  KubeLogs: "kube_logs",
} as const;
export type InputKubeLogsType = ClosedEnum<typeof InputKubeLogsType>;

export type InputKubeLogsRule = {
  /**
   * JavaScript expression applied to Pod objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type InputKubeLogsPqEnabledTrueWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<InputKubeLogsRule> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  persistence?: DiskSpoolingType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export type InputKubeLogsPqEnabledFalseWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<InputKubeLogsRule> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  persistence?: DiskSpoolingType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export type InputKubeLogsSendToRoutesFalseWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<InputKubeLogsRule> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  persistence?: DiskSpoolingType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export type InputKubeLogsSendToRoutesTrueWithConnectionsConstraint = {
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputKubeLogsType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<InputKubeLogsRule> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  persistence?: DiskSpoolingType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
};

export type InputKubeLogs =
  | InputKubeLogsSendToRoutesTrueWithConnectionsConstraint
  | InputKubeLogsSendToRoutesFalseWithConnectionsConstraint
  | InputKubeLogsPqEnabledFalseWithPqConstraint
  | InputKubeLogsPqEnabledTrueWithPqConstraint;

/** @internal */
export const InputKubeLogsType$inboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType
> = z.nativeEnum(InputKubeLogsType);
/** @internal */
export const InputKubeLogsType$outboundSchema: z.ZodNativeEnum<
  typeof InputKubeLogsType
> = InputKubeLogsType$inboundSchema;

/** @internal */
export const InputKubeLogsRule$inboundSchema: z.ZodType<
  InputKubeLogsRule,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type InputKubeLogsRule$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsRule$outboundSchema: z.ZodType<
  InputKubeLogsRule$Outbound,
  z.ZodTypeDef,
  InputKubeLogsRule
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function inputKubeLogsRuleToJSON(
  inputKubeLogsRule: InputKubeLogsRule,
): string {
  return JSON.stringify(
    InputKubeLogsRule$outboundSchema.parse(inputKubeLogsRule),
  );
}
export function inputKubeLogsRuleFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogsRule, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogsRule$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsRule' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsPqEnabledTrueWithPqConstraint$inboundSchema:
  z.ZodType<InputKubeLogsPqEnabledTrueWithPqConstraint, z.ZodTypeDef, unknown> =
    z.object({
      pqEnabled: z.boolean().default(false),
      pq: PqType$inboundSchema.optional(),
      id: z.string().optional(),
      type: InputKubeLogsType$inboundSchema,
      disabled: z.boolean().default(false),
      pipeline: z.string().optional(),
      sendToRoutes: z.boolean().default(true),
      environment: z.string().optional(),
      streamtags: z.array(z.string()).optional(),
      connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
      interval: z.number().default(15),
      rules: z.array(z.lazy(() => InputKubeLogsRule$inboundSchema)).optional(),
      timestamps: z.boolean().default(false),
      metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
      persistence: DiskSpoolingType$inboundSchema.optional(),
      breakerRulesets: z.array(z.string()).optional(),
      staleChannelFlushMs: z.number().default(10000),
      enableLoadBalancing: z.boolean().default(false),
      description: z.string().optional(),
    });
/** @internal */
export type InputKubeLogsPqEnabledTrueWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  interval: number;
  rules?: Array<InputKubeLogsRule$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  persistence?: DiskSpoolingType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsPqEnabledTrueWithPqConstraint$outboundSchema:
  z.ZodType<
    InputKubeLogsPqEnabledTrueWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputKubeLogsPqEnabledTrueWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$outboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    persistence: DiskSpoolingType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });

export function inputKubeLogsPqEnabledTrueWithPqConstraintToJSON(
  inputKubeLogsPqEnabledTrueWithPqConstraint:
    InputKubeLogsPqEnabledTrueWithPqConstraint,
): string {
  return JSON.stringify(
    InputKubeLogsPqEnabledTrueWithPqConstraint$outboundSchema.parse(
      inputKubeLogsPqEnabledTrueWithPqConstraint,
    ),
  );
}
export function inputKubeLogsPqEnabledTrueWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKubeLogsPqEnabledTrueWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKubeLogsPqEnabledTrueWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKubeLogsPqEnabledTrueWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsPqEnabledFalseWithPqConstraint$inboundSchema:
  z.ZodType<
    InputKubeLogsPqEnabledFalseWithPqConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$inboundSchema.optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$inboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    persistence: DiskSpoolingType$inboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });
/** @internal */
export type InputKubeLogsPqEnabledFalseWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  interval: number;
  rules?: Array<InputKubeLogsRule$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  persistence?: DiskSpoolingType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsPqEnabledFalseWithPqConstraint$outboundSchema:
  z.ZodType<
    InputKubeLogsPqEnabledFalseWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputKubeLogsPqEnabledFalseWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$outboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    persistence: DiskSpoolingType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });

export function inputKubeLogsPqEnabledFalseWithPqConstraintToJSON(
  inputKubeLogsPqEnabledFalseWithPqConstraint:
    InputKubeLogsPqEnabledFalseWithPqConstraint,
): string {
  return JSON.stringify(
    InputKubeLogsPqEnabledFalseWithPqConstraint$outboundSchema.parse(
      inputKubeLogsPqEnabledFalseWithPqConstraint,
    ),
  );
}
export function inputKubeLogsPqEnabledFalseWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKubeLogsPqEnabledFalseWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKubeLogsPqEnabledFalseWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKubeLogsPqEnabledFalseWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$inboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    persistence: DiskSpoolingType$inboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });
/** @internal */
export type InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$Outbound = {
  sendToRoutes: boolean;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  pq?: PqType$Outbound | undefined;
  interval: number;
  rules?: Array<InputKubeLogsRule$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  persistence?: DiskSpoolingType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$outboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    persistence: DiskSpoolingType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });

export function inputKubeLogsSendToRoutesFalseWithConnectionsConstraintToJSON(
  inputKubeLogsSendToRoutesFalseWithConnectionsConstraint:
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$outboundSchema
      .parse(inputKubeLogsSendToRoutesFalseWithConnectionsConstraint),
  );
}
export function inputKubeLogsSendToRoutesFalseWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKubeLogsSendToRoutesFalseWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsSendToRoutesFalseWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$inboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    persistence: DiskSpoolingType$inboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });
/** @internal */
export type InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$Outbound = {
  sendToRoutes: boolean;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  pq?: PqType$Outbound | undefined;
  interval: number;
  rules?: Array<InputKubeLogsRule$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  persistence?: DiskSpoolingType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputKubeLogsType$outboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => InputKubeLogsRule$outboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    persistence: DiskSpoolingType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  });

export function inputKubeLogsSendToRoutesTrueWithConnectionsConstraintToJSON(
  inputKubeLogsSendToRoutesTrueWithConnectionsConstraint:
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$outboundSchema.parse(
      inputKubeLogsSendToRoutesTrueWithConnectionsConstraint,
    ),
  );
}
export function inputKubeLogsSendToRoutesTrueWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKubeLogsSendToRoutesTrueWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogsSendToRoutesTrueWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputKubeLogs$inboundSchema: z.ZodType<
  InputKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() =>
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() =>
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() => InputKubeLogsPqEnabledFalseWithPqConstraint$inboundSchema),
  z.lazy(() => InputKubeLogsPqEnabledTrueWithPqConstraint$inboundSchema),
]);
/** @internal */
export type InputKubeLogs$Outbound =
  | InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$Outbound
  | InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$Outbound
  | InputKubeLogsPqEnabledFalseWithPqConstraint$Outbound
  | InputKubeLogsPqEnabledTrueWithPqConstraint$Outbound;

/** @internal */
export const InputKubeLogs$outboundSchema: z.ZodType<
  InputKubeLogs$Outbound,
  z.ZodTypeDef,
  InputKubeLogs
> = z.union([
  z.lazy(() =>
    InputKubeLogsSendToRoutesTrueWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() =>
    InputKubeLogsSendToRoutesFalseWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() => InputKubeLogsPqEnabledFalseWithPqConstraint$outboundSchema),
  z.lazy(() => InputKubeLogsPqEnabledTrueWithPqConstraint$outboundSchema),
]);

export function inputKubeLogsToJSON(inputKubeLogs: InputKubeLogs): string {
  return JSON.stringify(InputKubeLogs$outboundSchema.parse(inputKubeLogs));
}
export function inputKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogs' from JSON`,
  );
}
