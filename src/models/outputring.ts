/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  Format2Options,
  Format2Options$inboundSchema,
  Format2Options$outboundSchema,
} from "./format2options.js";
import {
  PqCompressOptions,
  PqCompressOptions$inboundSchema,
  PqCompressOptions$outboundSchema,
} from "./pqcompressoptions.js";
import {
  PqOnBackpressureOptions,
  PqOnBackpressureOptions$inboundSchema,
  PqOnBackpressureOptions$outboundSchema,
} from "./pqonbackpressureoptions.js";

export const OutputRingType = {
  Ring: "ring",
} as const;
export type OutputRingType = ClosedEnum<typeof OutputRingType>;

export type OutputRing = {
  /**
   * Unique ID for this output
   */
  id?: string | undefined;
  type: OutputRingType;
  /**
   * Pipeline to process data before sending out to this output
   */
  pipeline?: string | undefined;
  /**
   * Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
   */
  systemFields?: Array<string> | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Format to use to serialize events before writing to the Event Hubs Kafka brokers
   */
  format?: Format2Options | undefined;
  /**
   * JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
   */
  partitionExpr?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressOptions | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
   */
  destPath?: string | undefined;
  /**
   * How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
   */
  onBackpressure?: PqOnBackpressureOptions | undefined;
  description?: string | undefined;
};

/** @internal */
export const OutputRingType$inboundSchema: z.ZodNativeEnum<
  typeof OutputRingType
> = z.nativeEnum(OutputRingType);
/** @internal */
export const OutputRingType$outboundSchema: z.ZodNativeEnum<
  typeof OutputRingType
> = OutputRingType$inboundSchema;

/** @internal */
export const OutputRing$inboundSchema: z.ZodType<
  OutputRing,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  type: OutputRingType$inboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  format: Format2Options$inboundSchema.default("json"),
  partitionExpr: z.string().optional(),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PqCompressOptions$inboundSchema.default("none"),
  destPath: z.string().optional(),
  onBackpressure: PqOnBackpressureOptions$inboundSchema.default("block"),
  description: z.string().optional(),
});
/** @internal */
export type OutputRing$Outbound = {
  id?: string | undefined;
  type: string;
  pipeline?: string | undefined;
  systemFields?: Array<string> | undefined;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  format: string;
  partitionExpr?: string | undefined;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath?: string | undefined;
  onBackpressure: string;
  description?: string | undefined;
};

/** @internal */
export const OutputRing$outboundSchema: z.ZodType<
  OutputRing$Outbound,
  z.ZodTypeDef,
  OutputRing
> = z.object({
  id: z.string().optional(),
  type: OutputRingType$outboundSchema,
  pipeline: z.string().optional(),
  systemFields: z.array(z.string()).optional(),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  format: Format2Options$outboundSchema.default("json"),
  partitionExpr: z.string().optional(),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PqCompressOptions$outboundSchema.default("none"),
  destPath: z.string().optional(),
  onBackpressure: PqOnBackpressureOptions$outboundSchema.default("block"),
  description: z.string().optional(),
});

export function outputRingToJSON(outputRing: OutputRing): string {
  return JSON.stringify(OutputRing$outboundSchema.parse(outputRing));
}
export function outputRingFromJSON(
  jsonString: string,
): SafeParseResult<OutputRing, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OutputRing$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OutputRing' from JSON`,
  );
}
