/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { Collector, Collector$inboundSchema } from "./collector.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";

export const RunnableJobCollectionJobType = {
  Collection: "collection",
  Executor: "executor",
  ScheduledSearch: "scheduledSearch",
} as const;
export type RunnableJobCollectionJobType = OpenEnum<
  typeof RunnableJobCollectionJobType
>;

export const RunnableJobCollectionRunType = {
  Collection: "collection",
} as const;
export type RunnableJobCollectionRunType = OpenEnum<
  typeof RunnableJobCollectionRunType
>;

/**
 * Level at which to set task logging
 */
export const RunnableJobCollectionScheduleLogLevel = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
  Silly: "silly",
} as const;
/**
 * Level at which to set task logging
 */
export type RunnableJobCollectionScheduleLogLevel = OpenEnum<
  typeof RunnableJobCollectionScheduleLogLevel
>;

export type RunnableJobCollectionScheduleTimeWarning = {};

export type RunnableJobCollectionRunSettings = {
  type?: RunnableJobCollectionRunType | undefined;
  /**
   * Reschedule tasks that failed with non-fatal errors
   */
  rescheduleDroppedTasks?: boolean | undefined;
  /**
   * Maximum number of times a task can be rescheduled
   */
  maxTaskReschedule?: number | undefined;
  /**
   * Level at which to set task logging
   */
  logLevel?: RunnableJobCollectionScheduleLogLevel | undefined;
  /**
   * Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
   */
  mode?: string | undefined;
  timeRangeType?: string | undefined;
  /**
   * Earliest time to collect data for the selected timezone
   */
  earliest?: number | undefined;
  /**
   * Latest time to collect data for the selected timezone
   */
  latest?: number | undefined;
  timestampTimezone?: any | undefined;
  timeWarning?: RunnableJobCollectionScheduleTimeWarning | undefined;
  /**
   * A filter for tokens in the provided collect path and/or the events being collected
   */
  expression?: string | undefined;
  /**
   * Limits the bundle size for small tasks. For example,
   *
   * @remarks
   *
   *         if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.
   */
  minTaskSize?: string | undefined;
  /**
   * Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB,
   *
   * @remarks
   *
   *         you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.
   */
  maxTaskSize?: string | undefined;
};

/**
 * Configuration for a scheduled job
 */
export type RunnableJobCollectionSchedule = {
  /**
   * Enable to configure scheduling for this Collector
   */
  enabled?: boolean | undefined;
  /**
   * Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits
   */
  skippable?: boolean | undefined;
  /**
   * If Stream Leader (or single instance) restarts, run all missed jobs according to their original schedules
   */
  resumeMissed?: boolean | undefined;
  /**
   * A cron schedule on which to run this job
   */
  cronSchedule?: string | undefined;
  /**
   * The maximum number of instances of this scheduled job that may be running at any time
   */
  maxConcurrentRuns?: number | undefined;
  run?: RunnableJobCollectionRunSettings | undefined;
};

export const RunnableJobCollectionInputType = {
  Collection: "collection",
} as const;
export type RunnableJobCollectionInputType = OpenEnum<
  typeof RunnableJobCollectionInputType
>;

export type RunnableJobCollectionPreprocess = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type RunnableJobCollectionMetadatum = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type RunnableJobCollectionInput = {
  type?: RunnableJobCollectionInputType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  preprocess?: RunnableJobCollectionPreprocess | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<RunnableJobCollectionMetadatum> | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

/**
 * Level at which to set task logging
 */
export const RunnableJobCollectionLogLevel = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
  Silly: "silly",
} as const;
/**
 * Level at which to set task logging
 */
export type RunnableJobCollectionLogLevel = OpenEnum<
  typeof RunnableJobCollectionLogLevel
>;

/**
 * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
 */
export const RunnableJobCollectionMode = {
  List: "list",
  Preview: "preview",
  Run: "run",
} as const;
/**
 * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
 */
export type RunnableJobCollectionMode = OpenEnum<
  typeof RunnableJobCollectionMode
>;

export const TimeRange = {
  Absolute: "absolute",
  Relative: "relative",
} as const;
export type TimeRange = OpenEnum<typeof TimeRange>;

export type RunnableJobCollectionTimeWarning = {};

export const WhereToCapture = {
  /**
   * 1. Before pre-processing Pipeline
   */
  Zero: 0,
  /**
   * 2. Before the Routes
   */
  One: 1,
  /**
   * 3. Before post-processing Pipeline
   */
  Two: 2,
  /**
   * 4. Before the Destination
   */
  Three: 3,
} as const;
export type WhereToCapture = OpenEnum<typeof WhereToCapture>;

export type CaptureSettings = {
  /**
   * Amount of time to keep capture open, in seconds
   */
  duration?: number | undefined;
  /**
   * Maximum number of events to capture
   */
  maxEvents?: number | undefined;
  level?: WhereToCapture | undefined;
};

export type RunnableJobCollectionRun = {
  /**
   * Reschedule tasks that failed with non-fatal errors
   */
  rescheduleDroppedTasks?: boolean | undefined;
  /**
   * Maximum number of times a task can be rescheduled
   */
  maxTaskReschedule?: number | undefined;
  /**
   * Level at which to set task logging
   */
  logLevel?: RunnableJobCollectionLogLevel | undefined;
  /**
   * Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
   */
  mode?: RunnableJobCollectionMode | undefined;
  timeRangeType?: TimeRange | undefined;
  /**
   * Earliest time to collect data for the selected timezone
   */
  earliest?: number | undefined;
  /**
   * Latest time to collect data for the selected timezone
   */
  latest?: number | undefined;
  /**
   * Timezone to use for Earliest and Latest times
   */
  timestampTimezone?: string | undefined;
  timeWarning?: RunnableJobCollectionTimeWarning | undefined;
  /**
   * A filter for tokens in the provided collect path and/or the events being collected
   */
  expression?: string | undefined;
  /**
   * Limits the bundle size for small tasks. For example,
   *
   * @remarks
   *
   *         if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.
   */
  minTaskSize?: string | undefined;
  /**
   * Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB,
   *
   * @remarks
   *
   *         you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.
   */
  maxTaskSize?: string | undefined;
  /**
   * Send discover results to Routes
   */
  discoverToRoutes?: boolean | undefined;
  capture?: CaptureSettings | undefined;
};

export type RunnableJobCollection = {
  /**
   * Unique ID for this Job
   */
  id?: string | undefined;
  description?: string | undefined;
  type?: RunnableJobCollectionJobType | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * List of fields to remove from Discover results. Wildcards (for example, aws*) are allowed. This is useful when discovery returns sensitive fields that should not be exposed in the Jobs user interface.
   */
  removeFields?: Array<string> | undefined;
  /**
   * Resume the ad hoc job if a failure condition causes Stream to restart during job execution
   */
  resumeOnBoot?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Configuration for a scheduled job
   */
  schedule?: RunnableJobCollectionSchedule | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * If enabled, tasks are created and run by the same Worker Node
   */
  workerAffinity?: boolean | undefined;
  /**
   * Collector config wrapper
   */
  collector: Collector;
  input?: RunnableJobCollectionInput | undefined;
  run: RunnableJobCollectionRun;
};

/** @internal */
export const RunnableJobCollectionJobType$inboundSchema: z.ZodType<
  RunnableJobCollectionJobType,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionJobType);

/** @internal */
export const RunnableJobCollectionRunType$inboundSchema: z.ZodType<
  RunnableJobCollectionRunType,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionRunType);

/** @internal */
export const RunnableJobCollectionScheduleLogLevel$inboundSchema: z.ZodType<
  RunnableJobCollectionScheduleLogLevel,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionScheduleLogLevel);

/** @internal */
export const RunnableJobCollectionScheduleTimeWarning$inboundSchema: z.ZodType<
  RunnableJobCollectionScheduleTimeWarning,
  z.ZodTypeDef,
  unknown
> = z.object({});

export function runnableJobCollectionScheduleTimeWarningFromJSON(
  jsonString: string,
): SafeParseResult<
  RunnableJobCollectionScheduleTimeWarning,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      RunnableJobCollectionScheduleTimeWarning$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'RunnableJobCollectionScheduleTimeWarning' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionRunSettings$inboundSchema: z.ZodType<
  RunnableJobCollectionRunSettings,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RunnableJobCollectionRunType$inboundSchema.optional(),
  rescheduleDroppedTasks: z.boolean().default(true),
  maxTaskReschedule: z.number().default(1),
  logLevel: RunnableJobCollectionScheduleLogLevel$inboundSchema.default("info"),
  jobTimeout: z.string().default("0"),
  mode: z.string().default("list"),
  timeRangeType: z.string().default("relative"),
  earliest: z.number().optional(),
  latest: z.number().optional(),
  timestampTimezone: z.any().optional(),
  timeWarning: z.lazy(() =>
    RunnableJobCollectionScheduleTimeWarning$inboundSchema
  ).optional(),
  expression: z.string().default("true"),
  minTaskSize: z.string().default("1MB"),
  maxTaskSize: z.string().default("10MB"),
});

export function runnableJobCollectionRunSettingsFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionRunSettings, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionRunSettings$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionRunSettings' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionSchedule$inboundSchema: z.ZodType<
  RunnableJobCollectionSchedule,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().optional(),
  skippable: z.boolean().default(true),
  resumeMissed: z.boolean().default(false),
  cronSchedule: z.string().default("*/5 * * * *"),
  maxConcurrentRuns: z.number().default(1),
  run: z.lazy(() => RunnableJobCollectionRunSettings$inboundSchema).optional(),
});

export function runnableJobCollectionScheduleFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionSchedule, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionSchedule$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionSchedule' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionInputType$inboundSchema: z.ZodType<
  RunnableJobCollectionInputType,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionInputType);

/** @internal */
export const RunnableJobCollectionPreprocess$inboundSchema: z.ZodType<
  RunnableJobCollectionPreprocess,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function runnableJobCollectionPreprocessFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionPreprocess, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionPreprocess$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionPreprocess' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionMetadatum$inboundSchema: z.ZodType<
  RunnableJobCollectionMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function runnableJobCollectionMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionMetadatum' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionInput$inboundSchema: z.ZodType<
  RunnableJobCollectionInput,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RunnableJobCollectionInputType$inboundSchema.default("collection"),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  sendToRoutes: z.boolean().default(true),
  preprocess: z.lazy(() => RunnableJobCollectionPreprocess$inboundSchema)
    .optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(z.lazy(() => RunnableJobCollectionMetadatum$inboundSchema))
    .optional(),
  pipeline: z.string().optional(),
  output: z.string().optional(),
});

export function runnableJobCollectionInputFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionInput, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionInput$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionInput' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionLogLevel$inboundSchema: z.ZodType<
  RunnableJobCollectionLogLevel,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionLogLevel);

/** @internal */
export const RunnableJobCollectionMode$inboundSchema: z.ZodType<
  RunnableJobCollectionMode,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionMode);

/** @internal */
export const TimeRange$inboundSchema: z.ZodType<
  TimeRange,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(TimeRange);

/** @internal */
export const RunnableJobCollectionTimeWarning$inboundSchema: z.ZodType<
  RunnableJobCollectionTimeWarning,
  z.ZodTypeDef,
  unknown
> = z.object({});

export function runnableJobCollectionTimeWarningFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionTimeWarning, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionTimeWarning$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionTimeWarning' from JSON`,
  );
}

/** @internal */
export const WhereToCapture$inboundSchema: z.ZodType<
  WhereToCapture,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchemaInt(WhereToCapture);

/** @internal */
export const CaptureSettings$inboundSchema: z.ZodType<
  CaptureSettings,
  z.ZodTypeDef,
  unknown
> = z.object({
  duration: z.number().default(60),
  maxEvents: z.number().default(100),
  level: WhereToCapture$inboundSchema.default(0),
});

export function captureSettingsFromJSON(
  jsonString: string,
): SafeParseResult<CaptureSettings, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CaptureSettings$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CaptureSettings' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionRun$inboundSchema: z.ZodType<
  RunnableJobCollectionRun,
  z.ZodTypeDef,
  unknown
> = z.object({
  rescheduleDroppedTasks: z.boolean().default(true),
  maxTaskReschedule: z.number().default(1),
  logLevel: RunnableJobCollectionLogLevel$inboundSchema.default("info"),
  jobTimeout: z.string().default("0"),
  mode: RunnableJobCollectionMode$inboundSchema.default("list"),
  timeRangeType: TimeRange$inboundSchema.default("relative"),
  earliest: z.number().optional(),
  latest: z.number().optional(),
  timestampTimezone: z.string().default("UTC"),
  timeWarning: z.lazy(() => RunnableJobCollectionTimeWarning$inboundSchema)
    .optional(),
  expression: z.string().default("true"),
  minTaskSize: z.string().default("1MB"),
  maxTaskSize: z.string().default("10MB"),
  discoverToRoutes: z.boolean().default(false),
  capture: z.lazy(() => CaptureSettings$inboundSchema).optional(),
});

export function runnableJobCollectionRunFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionRun, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionRun$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionRun' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollection$inboundSchema: z.ZodType<
  RunnableJobCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  description: z.string().optional(),
  type: RunnableJobCollectionJobType$inboundSchema.optional(),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  removeFields: z.array(z.string()).optional(),
  resumeOnBoot: z.boolean().default(false),
  environment: z.string().optional(),
  schedule: z.lazy(() => RunnableJobCollectionSchedule$inboundSchema)
    .optional(),
  streamtags: z.array(z.string()).optional(),
  workerAffinity: z.boolean().default(false),
  collector: Collector$inboundSchema,
  input: z.lazy(() => RunnableJobCollectionInput$inboundSchema).optional(),
  run: z.lazy(() => RunnableJobCollectionRun$inboundSchema),
});

export function runnableJobCollectionFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollection' from JSON`,
  );
}
