/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import * as openEnums from "../types/enums.js";
import { OpenEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { Collector, Collector$inboundSchema } from "./collector.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  InputTypeSavedJobCollection,
  InputTypeSavedJobCollection$inboundSchema,
} from "./inputtypesavedjobcollection.js";
import {
  JobTypeOptionsSavedJobCollection,
  JobTypeOptionsSavedJobCollection$inboundSchema,
} from "./jobtypeoptionssavedjobcollection.js";
import {
  LogLevelOptionsSavedJobCollectionScheduleRun,
  LogLevelOptionsSavedJobCollectionScheduleRun$inboundSchema,
} from "./logleveloptionssavedjobcollectionschedulerun.js";
import { MetricsStore, MetricsStore$inboundSchema } from "./metricsstore.js";
import {
  ScheduleTypeRunnableJobCollection,
  ScheduleTypeRunnableJobCollection$inboundSchema,
} from "./scheduletyperunnablejobcollection.js";

/**
 * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
 */
export const RunnableJobCollectionMode = {
  List: "list",
  Preview: "preview",
  Run: "run",
} as const;
/**
 * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
 */
export type RunnableJobCollectionMode = OpenEnum<
  typeof RunnableJobCollectionMode
>;

export const TimeRange = {
  Absolute: "absolute",
  Relative: "relative",
} as const;
export type TimeRange = OpenEnum<typeof TimeRange>;

export const WhereToCapture = {
  /**
   * 1. Before pre-processing Pipeline
   */
  Zero: 0,
  /**
   * 2. Before the Routes
   */
  One: 1,
  /**
   * 3. Before post-processing Pipeline
   */
  Two: 2,
  /**
   * 4. Before the Destination
   */
  Three: 3,
} as const;
export type WhereToCapture = OpenEnum<typeof WhereToCapture>;

export type CaptureSettings = {
  /**
   * Amount of time to keep capture open, in seconds
   */
  duration: number;
  /**
   * Maximum number of events to capture
   */
  maxEvents: number;
  level: WhereToCapture;
};

export type RunnableJobCollectionRun = {
  /**
   * Reschedule tasks that failed with non-fatal errors
   */
  rescheduleDroppedTasks: boolean;
  /**
   * Maximum number of times a task can be rescheduled
   */
  maxTaskReschedule: number;
  /**
   * Level at which to set task logging
   */
  logLevel: LogLevelOptionsSavedJobCollectionScheduleRun;
  /**
   * Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.
   */
  jobTimeout: string;
  /**
   * Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
   */
  mode: RunnableJobCollectionMode;
  timeRangeType: TimeRange;
  /**
   * Earliest time to collect data for the selected timezone
   */
  earliest?: number | undefined;
  /**
   * Latest time to collect data for the selected timezone
   */
  latest?: number | undefined;
  /**
   * Timezone to use for Earliest and Latest times
   */
  timestampTimezone: string;
  timeWarning?: MetricsStore | undefined;
  /**
   * A filter for tokens in the provided collect path and/or the events being collected
   */
  expression: string;
  /**
   * Limits the bundle size for small tasks. For example,
   *
   * @remarks
   *
   *         if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.
   */
  minTaskSize: string;
  /**
   * Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB,
   *
   * @remarks
   *
   *         you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.
   */
  maxTaskSize: string;
  /**
   * Send discover results to Routes
   */
  discoverToRoutes: boolean;
  capture?: CaptureSettings | undefined;
};

export type RunnableJobCollection = {
  /**
   * Unique ID for this Job
   */
  id?: string | undefined;
  description?: string | undefined;
  type?: JobTypeOptionsSavedJobCollection | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl: string;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit: boolean;
  /**
   * List of fields to remove from Discover results. Wildcards (for example, aws*) are allowed. This is useful when discovery returns sensitive fields that should not be exposed in the Jobs user interface.
   */
  removeFields?: Array<string> | undefined;
  /**
   * Resume the ad hoc job if a failure condition causes Stream to restart during job execution
   */
  resumeOnBoot: boolean;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Configuration for a scheduled job
   */
  schedule?: ScheduleTypeRunnableJobCollection | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * If enabled, tasks are created and run by the same Worker Node
   */
  workerAffinity: boolean;
  /**
   * Collector configuration
   */
  collector: Collector;
  input?: InputTypeSavedJobCollection | undefined;
  run: RunnableJobCollectionRun;
};

/** @internal */
export const RunnableJobCollectionMode$inboundSchema: z.ZodType<
  RunnableJobCollectionMode,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(RunnableJobCollectionMode);

/** @internal */
export const TimeRange$inboundSchema: z.ZodType<
  TimeRange,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchema(TimeRange);

/** @internal */
export const WhereToCapture$inboundSchema: z.ZodType<
  WhereToCapture,
  z.ZodTypeDef,
  unknown
> = openEnums.inboundSchemaInt(WhereToCapture);

/** @internal */
export const CaptureSettings$inboundSchema: z.ZodType<
  CaptureSettings,
  z.ZodTypeDef,
  unknown
> = z.object({
  duration: z.number().default(60),
  maxEvents: z.number().default(100),
  level: WhereToCapture$inboundSchema.default(0),
});

export function captureSettingsFromJSON(
  jsonString: string,
): SafeParseResult<CaptureSettings, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CaptureSettings$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CaptureSettings' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollectionRun$inboundSchema: z.ZodType<
  RunnableJobCollectionRun,
  z.ZodTypeDef,
  unknown
> = z.object({
  rescheduleDroppedTasks: z.boolean().default(true),
  maxTaskReschedule: z.number().default(1),
  logLevel: LogLevelOptionsSavedJobCollectionScheduleRun$inboundSchema.default(
    "info",
  ),
  jobTimeout: z.string().default("0"),
  mode: RunnableJobCollectionMode$inboundSchema.default("list"),
  timeRangeType: TimeRange$inboundSchema.default("relative"),
  earliest: z.number().optional(),
  latest: z.number().optional(),
  timestampTimezone: z.string().default("UTC"),
  timeWarning: MetricsStore$inboundSchema.optional(),
  expression: z.string().default("true"),
  minTaskSize: z.string().default("1MB"),
  maxTaskSize: z.string().default("10MB"),
  discoverToRoutes: z.boolean().default(false),
  capture: z.lazy(() => CaptureSettings$inboundSchema).optional(),
});

export function runnableJobCollectionRunFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollectionRun, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollectionRun$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollectionRun' from JSON`,
  );
}

/** @internal */
export const RunnableJobCollection$inboundSchema: z.ZodType<
  RunnableJobCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  id: z.string().optional(),
  description: z.string().optional(),
  type: JobTypeOptionsSavedJobCollection$inboundSchema.optional(),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  removeFields: z.array(z.string()).optional(),
  resumeOnBoot: z.boolean().default(false),
  environment: z.string().optional(),
  schedule: ScheduleTypeRunnableJobCollection$inboundSchema.optional(),
  streamtags: z.array(z.string()).optional(),
  workerAffinity: z.boolean().default(false),
  collector: Collector$inboundSchema,
  input: InputTypeSavedJobCollection$inboundSchema.optional(),
  run: z.lazy(() => RunnableJobCollectionRun$inboundSchema),
});

export function runnableJobCollectionFromJSON(
  jsonString: string,
): SafeParseResult<RunnableJobCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RunnableJobCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RunnableJobCollection' from JSON`,
  );
}
