/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { remap as remap$ } from "../lib/primitives.js";
import {
  collectExtraKeys as collectExtraKeys$,
  safeParse,
} from "../lib/schemas.js";
import {
  catchUnrecognizedEnum,
  ClosedEnum,
  OpenEnum,
  Unrecognized,
} from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";

export const TypeCloudflareHec = {
  CloudflareHec: "cloudflare_hec",
} as const;
export type TypeCloudflareHec = ClosedEnum<typeof TypeCloudflareHec>;

export type ConnectionCloudflareHec = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCloudflareHec = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCloudflareHec = OpenEnum<typeof ModeCloudflareHec>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCloudflareHec = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCloudflareHec = OpenEnum<
  typeof CompressionCloudflareHec
>;

export type PqControlsCloudflareHec = {};

export type PqCloudflareHec = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCloudflareHec | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCloudflareHec | undefined;
  pqControls?: PqControlsCloudflareHec | undefined;
};

/**
 * Select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodCloudflareHec = {
  Secret: "secret",
} as const;
/**
 * Select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodCloudflareHec = OpenEnum<
  typeof AuthenticationMethodCloudflareHec
>;

export type AuthTokenMetadatumCloudflareHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokenCloudflareHec = {
  /**
   * Select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodCloudflareHec | undefined;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled?: boolean | undefined;
  description?: string | undefined;
  /**
   * Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
   */
  allowedIndexesAtToken?: Array<string> | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokenMetadatumCloudflareHec> | undefined;
};

export const MinimumTLSVersionCloudflareHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionCloudflareHec = OpenEnum<
  typeof MinimumTLSVersionCloudflareHec
>;

export const MaximumTLSVersionCloudflareHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionCloudflareHec = OpenEnum<
  typeof MaximumTLSVersionCloudflareHec
>;

export type TLSSettingsServerSideCloudflareHec = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionCloudflareHec | undefined;
  maxVersion?: MaximumTLSVersionCloudflareHec | undefined;
};

export type MetadatumCloudflareHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputCloudflareHec = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeCloudflareHec;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCloudflareHec> | undefined;
  pq?: PqCloudflareHec | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<AuthTokenCloudflareHec> | undefined;
  tls?: TLSSettingsServerSideCloudflareHec | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  enableHealthCheck?: any | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for the Cloudflare HTTP Event Collector API requests. This input supports the /event endpoint.
   */
  hecAPI: string;
  /**
   * Fields to add to every event. May be overridden by fields added at the token or request level.
   */
  metadata?: Array<MetadatumCloudflareHec> | undefined;
  /**
   * List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
   */
  allowedIndexes?: Array<string> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
   */
  accessControlAllowOrigin?: Array<string> | undefined;
  /**
   * HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
   */
  accessControlAllowHeaders?: Array<string> | undefined;
  /**
   * Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
   */
  emitTokenMetrics?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeZscalerHec = {
  ZscalerHec: "zscaler_hec",
} as const;
export type TypeZscalerHec = ClosedEnum<typeof TypeZscalerHec>;

export type ConnectionZscalerHec = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeZscalerHec = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeZscalerHec = OpenEnum<typeof ModeZscalerHec>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionZscalerHec = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionZscalerHec = OpenEnum<typeof CompressionZscalerHec>;

export type PqControlsZscalerHec = {};

export type PqZscalerHec = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeZscalerHec | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionZscalerHec | undefined;
  pqControls?: PqControlsZscalerHec | undefined;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodZscalerHec = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodZscalerHec = OpenEnum<
  typeof AuthenticationMethodZscalerHec
>;

export type AuthTokenMetadatumZscalerHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokenZscalerHec = {
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodZscalerHec | undefined;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled?: boolean | undefined;
  description?: string | undefined;
  /**
   * Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
   */
  allowedIndexesAtToken?: Array<string> | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokenMetadatumZscalerHec> | undefined;
};

export const MinimumTLSVersionZscalerHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionZscalerHec = OpenEnum<
  typeof MinimumTLSVersionZscalerHec
>;

export const MaximumTLSVersionZscalerHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionZscalerHec = OpenEnum<
  typeof MaximumTLSVersionZscalerHec
>;

export type TLSSettingsServerSideZscalerHec = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionZscalerHec | undefined;
  maxVersion?: MaximumTLSVersionZscalerHec | undefined;
};

export type MetadatumZscalerHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputZscalerHec = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeZscalerHec;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionZscalerHec> | undefined;
  pq?: PqZscalerHec | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<AuthTokenZscalerHec> | undefined;
  tls?: TLSSettingsServerSideZscalerHec | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  enableHealthCheck?: any | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
   */
  hecAPI?: string | undefined;
  /**
   * Fields to add to every event. May be overridden by fields added at the token or request level.
   */
  metadata?: Array<MetadatumZscalerHec> | undefined;
  /**
   * List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
   */
  allowedIndexes?: Array<string> | undefined;
  /**
   * Whether to enable Zscaler HEC acknowledgements
   */
  hecAcks?: boolean | undefined;
  /**
   * Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
   */
  accessControlAllowOrigin?: Array<string> | undefined;
  /**
   * Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
   */
  accessControlAllowHeaders?: Array<string> | undefined;
  /**
   * Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
   */
  emitTokenMetrics?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeSecurityLake = {
  SecurityLake: "security_lake",
} as const;
export type InputTypeSecurityLake = ClosedEnum<typeof InputTypeSecurityLake>;

export type ConnectionSecurityLake = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeSecurityLake = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeSecurityLake = OpenEnum<typeof ModeSecurityLake>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSecurityLake = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSecurityLake = OpenEnum<typeof CompressionSecurityLake>;

export type PqControlsSecurityLake = {};

export type PqSecurityLake = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeSecurityLake | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionSecurityLake | undefined;
  pqControls?: PqControlsSecurityLake | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const InputAuthenticationMethodSecurityLake = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type InputAuthenticationMethodSecurityLake = OpenEnum<
  typeof InputAuthenticationMethodSecurityLake
>;

/**
 * Signature version to use for signing S3 requests
 */
export const InputSignatureVersionSecurityLake = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type InputSignatureVersionSecurityLake = OpenEnum<
  typeof InputSignatureVersionSecurityLake
>;

export type PreprocessSecurityLake = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type MetadatumSecurityLake = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type CheckpointingSecurityLake = {
  /**
   * Resume processing files after an interruption
   */
  enabled?: boolean | undefined;
  /**
   * The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
   */
  retries?: number | undefined;
};

export const TagAfterProcessingSecurityLake = {
  False: "false",
  True: "true",
} as const;
export type TagAfterProcessingSecurityLake = OpenEnum<
  typeof TagAfterProcessingSecurityLake
>;

export type InputSecurityLake = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeSecurityLake;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSecurityLake> | undefined;
  pq?: PqSecurityLake | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: InputAuthenticationMethodSecurityLake | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: InputSignatureVersionSecurityLake | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
   */
  maxMessages?: number | undefined;
  /**
   * After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
   */
  socketTimeout?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Attach SQS notification metadata to a __sqsMetadata field on each event
   */
  includeSqsMetadata?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Amazon S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Use Assume Role credentials when accessing Amazon SQS
   */
  enableSQSAssumeRole?: boolean | undefined;
  preprocess?: PreprocessSecurityLake | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSecurityLake> | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  checkpointing?: CheckpointingSecurityLake | undefined;
  /**
   * How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
   */
  pollTimeout?: number | undefined;
  /**
   * Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
   */
  encoding?: string | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  tagAfterProcessing?: TagAfterProcessingSecurityLake | undefined;
  /**
   * The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagKey?: string | undefined;
  /**
   * The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagValue?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeNetflow = {
  Netflow: "netflow",
} as const;
export type InputTypeNetflow = ClosedEnum<typeof InputTypeNetflow>;

export type ConnectionNetflow = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeNetflow = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeNetflow = OpenEnum<typeof ModeNetflow>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionNetflow = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionNetflow = OpenEnum<typeof CompressionNetflow>;

export type PqControlsNetflow = {};

export type PqNetflow = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeNetflow | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionNetflow | undefined;
  pqControls?: PqControlsNetflow | undefined;
};

export type MetadatumNetflow = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputNetflow = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeNetflow;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionNetflow> | undefined;
  pq?: PqNetflow | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port?: number | undefined;
  /**
   * Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
   */
  enablePassThrough?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist.
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  /**
   * Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
   */
  templateCacheMinutes?: number | undefined;
  /**
   * Accept messages in Netflow V5 format.
   */
  v5Enabled?: boolean | undefined;
  /**
   * Accept messages in Netflow V9 format.
   */
  v9Enabled?: boolean | undefined;
  /**
   * Accept messages in IPFIX format.
   */
  ipfixEnabled?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumNetflow> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWizWebhook = {
  WizWebhook: "wiz_webhook",
} as const;
export type TypeWizWebhook = ClosedEnum<typeof TypeWizWebhook>;

export type ConnectionWizWebhook = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeWizWebhook = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeWizWebhook = OpenEnum<typeof ModeWizWebhook>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWizWebhook = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWizWebhook = OpenEnum<typeof CompressionWizWebhook>;

export type PqControlsWizWebhook = {};

export type PqWizWebhook = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeWizWebhook | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionWizWebhook | undefined;
  pqControls?: PqControlsWizWebhook | undefined;
};

export const MinimumTLSVersionWizWebhook = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionWizWebhook = OpenEnum<
  typeof MinimumTLSVersionWizWebhook
>;

export const MaximumTLSVersionWizWebhook = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionWizWebhook = OpenEnum<
  typeof MaximumTLSVersionWizWebhook
>;

export type TLSSettingsServerSideWizWebhook = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionWizWebhook | undefined;
  maxVersion?: MaximumTLSVersionWizWebhook | undefined;
};

export type MetadatumWizWebhook = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtMetadatumWizWebhook = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtWizWebhook = {
  /**
   * Shared secret to be provided by any client (Authorization: <token>)
   */
  token: string;
  description?: string | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokensExtMetadatumWizWebhook> | undefined;
};

export type InputWizWebhook = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeWizWebhook;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionWizWebhook> | undefined;
  pq?: PqWizWebhook | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideWizWebhook | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumWizWebhook> | undefined;
  /**
   * List of URI paths accepted by this input. Wildcards are supported (such as /api/v* /hook). Defaults to allow all.
   */
  allowedPaths?: Array<string> | undefined;
  /**
   * List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
   */
  allowedMethods?: Array<string> | undefined;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokensExt?: Array<AuthTokensExtWizWebhook> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWiz = {
  Wiz: "wiz",
} as const;
export type TypeWiz = ClosedEnum<typeof TypeWiz>;

export type ConnectionWiz = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeWiz = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeWiz = OpenEnum<typeof ModeWiz>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWiz = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWiz = OpenEnum<typeof CompressionWiz>;

export type PqControlsWiz = {};

export type PqWiz = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeWiz | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionWiz | undefined;
  pqControls?: PqControlsWiz | undefined;
};

export type ContentConfigWiz = {
  /**
   * The name of the Wiz query
   */
  contentType: string;
  contentDescription?: string | undefined;
  enabled?: boolean | undefined;
};

export type MetadatumWiz = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * The algorithm to use when performing HTTP retries
 */
export const RetryTypeWiz = {
  /**
   * Disabled
   */
  None: "none",
  /**
   * Backoff
   */
  Backoff: "backoff",
  /**
   * Static
   */
  Static: "static",
} as const;
/**
 * The algorithm to use when performing HTTP retries
 */
export type RetryTypeWiz = OpenEnum<typeof RetryTypeWiz>;

export type RetryRulesWiz = {
  /**
   * The algorithm to use when performing HTTP retries
   */
  type?: RetryTypeWiz | undefined;
  /**
   * Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
   */
  interval?: number | undefined;
  /**
   * The maximum number of times to retry a failed HTTP request
   */
  limit?: number | undefined;
  /**
   * Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
   */
  multiplier?: number | undefined;
  /**
   * List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
   */
  codes?: Array<number> | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
   */
  enableHeader?: boolean | undefined;
  /**
   * Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
   */
  retryConnectTimeout?: boolean | undefined;
  /**
   * Retry request when a connection reset (ECONNRESET) error occurs
   */
  retryConnectReset?: boolean | undefined;
};

/**
 * Enter client secret directly, or select a stored secret
 */
export const AuthenticationMethodWiz = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter client secret directly, or select a stored secret
 */
export type AuthenticationMethodWiz = OpenEnum<typeof AuthenticationMethodWiz>;

export type InputWiz = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeWiz;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionWiz> | undefined;
  pq?: PqWiz | undefined;
  /**
   * The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
   */
  endpoint?: string | undefined;
  /**
   * The authentication URL to generate an OAuth token
   */
  authUrl: string;
  /**
   * The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
   */
  authAudienceOverride?: string | undefined;
  /**
   * The client ID of the Wiz application
   */
  clientId: string;
  contentConfig: Array<ContentConfigWiz>;
  /**
   * HTTP request inactivity timeout. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumWiz> | undefined;
  retryRules?: RetryRulesWiz | undefined;
  /**
   * Enter client secret directly, or select a stored secret
   */
  authType?: AuthenticationMethodWiz | undefined;
  description?: string | undefined;
  /**
   * The client secret of the Wiz application
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputJournalFilesType = {
  JournalFiles: "journal_files",
} as const;
export type InputJournalFilesType = ClosedEnum<typeof InputJournalFilesType>;

export type InputJournalFilesConnection = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputJournalFilesMode = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputJournalFilesMode = OpenEnum<typeof InputJournalFilesMode>;

/**
 * Codec to use to compress the persisted data
 */
export const InputJournalFilesCompression = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputJournalFilesCompression = OpenEnum<
  typeof InputJournalFilesCompression
>;

export type InputJournalFilesPqControls = {};

export type InputJournalFilesPq = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputJournalFilesMode | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputJournalFilesCompression | undefined;
  pqControls?: InputJournalFilesPqControls | undefined;
};

export type InputJournalFilesRule = {
  /**
   * JavaScript expression applied to Journal objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type InputJournalFilesMetadatum = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputJournalFiles = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputJournalFilesType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputJournalFilesConnection> | undefined;
  pq?: InputJournalFilesPq | undefined;
  /**
   * Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
   */
  path: string;
  /**
   * Time, in seconds, between scanning for journals.
   */
  interval?: number | undefined;
  /**
   * The full path of discovered journals are matched against this wildcard list.
   */
  journals: Array<string>;
  /**
   * Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<InputJournalFilesRule> | undefined;
  /**
   * Skip log messages that are not part of the current boot session.
   */
  currentBoot?: boolean | undefined;
  /**
   * The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputJournalFilesMetadatum> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeRawUDP = {
  RawUdp: "raw_udp",
} as const;
export type TypeRawUDP = ClosedEnum<typeof TypeRawUDP>;

export type ConnectionRawUDP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeRawUDP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeRawUDP = OpenEnum<typeof ModeRawUDP>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionRawUDP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionRawUDP = OpenEnum<typeof CompressionRawUDP>;

export type PqControlsRawUDP = {};

export type PqRawUDP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeRawUDP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionRawUDP | undefined;
  pqControls?: PqControlsRawUDP | undefined;
};

export type MetadatumRawUDP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputRawUdp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeRawUDP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionRawUDP> | undefined;
  pq?: PqRawUDP | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Maximum number of events to buffer when downstream is blocking.
   */
  maxBufferSize?: number | undefined;
  /**
   * Regex matching IP addresses that are allowed to send data
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
   */
  singleMsgUdpPackets?: boolean | undefined;
  /**
   * If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
   */
  ingestRawBytes?: boolean | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumRawUDP> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWinEventLogs = {
  WinEventLogs: "win_event_logs",
} as const;
export type TypeWinEventLogs = ClosedEnum<typeof TypeWinEventLogs>;

export type ConnectionWinEventLogs = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeWinEventLogs = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeWinEventLogs = OpenEnum<typeof ModeWinEventLogs>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWinEventLogs = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWinEventLogs = OpenEnum<typeof CompressionWinEventLogs>;

export type PqControlsWinEventLogs = {};

export type PqWinEventLogs = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeWinEventLogs | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionWinEventLogs | undefined;
  pqControls?: PqControlsWinEventLogs | undefined;
};

/**
 * Read all stored and future event logs, or only future events
 */
export const ReadMode = {
  /**
   * Entire log
   */
  Oldest: "oldest",
  /**
   * From last entry
   */
  Newest: "newest",
} as const;
/**
 * Read all stored and future event logs, or only future events
 */
export type ReadMode = OpenEnum<typeof ReadMode>;

/**
 * Format of individual events
 */
export const EventFormat = {
  /**
   * JSON
   */
  Json: "json",
  /**
   * XML
   */
  Xml: "xml",
} as const;
/**
 * Format of individual events
 */
export type EventFormat = OpenEnum<typeof EventFormat>;

export type MetadatumWinEventLogs = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputWinEventLogs = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeWinEventLogs;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionWinEventLogs> | undefined;
  pq?: PqWinEventLogs | undefined;
  /**
   * Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
   */
  logNames: Array<string>;
  /**
   * Read all stored and future event logs, or only future events
   */
  readMode?: ReadMode | undefined;
  /**
   * Format of individual events
   */
  eventFormat?: EventFormat | undefined;
  /**
   * Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
   */
  disableNativeModule?: boolean | undefined;
  /**
   * Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
   */
  interval?: number | undefined;
  /**
   * The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
   */
  batchSize?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumWinEventLogs> | undefined;
  /**
   * The maximum number of bytes in an event before it is flushed to the pipelines
   */
  maxEventBytes?: number | undefined;
  description?: string | undefined;
  /**
   * Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
   */
  disableJsonRendering?: boolean | undefined;
  /**
   * Enable/disable the rendering of localized event message strings (Applicable for 4.8.0 nodes and newer that use the Native API)
   */
  disableXmlRendering?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWef = {
  Wef: "wef",
} as const;
export type TypeWef = ClosedEnum<typeof TypeWef>;

export type ConnectionWef = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeWef = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeWef = OpenEnum<typeof ModeWef>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWef = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWef = OpenEnum<typeof CompressionWef>;

export type PqControlsWef = {};

export type PqWef = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeWef | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionWef | undefined;
  pqControls?: PqControlsWef | undefined;
};

/**
 * How to authenticate incoming client connections
 */
export const AuthMethodAuthenticationMethod = {
  /**
   * Client certificate
   */
  ClientCert: "clientCert",
  /**
   * Kerberos
   */
  Kerberos: "kerberos",
} as const;
/**
 * How to authenticate incoming client connections
 */
export type AuthMethodAuthenticationMethod = OpenEnum<
  typeof AuthMethodAuthenticationMethod
>;

export const MinimumTLSVersionWef = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionWef = OpenEnum<typeof MinimumTLSVersionWef>;

export const MaximumTLSVersionWef = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionWef = OpenEnum<typeof MaximumTLSVersionWef>;

export type MTLSSettings = {
  /**
   * Enable TLS
   */
  disabled?: boolean | undefined;
  /**
   * Required for WEF certificate authentication
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Required for WEF certificate authentication
   */
  requestCert?: boolean | undefined;
  /**
   * Name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath: string;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath: string;
  /**
   * Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
   */
  caPath: string;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  minVersion?: MinimumTLSVersionWef | undefined;
  maxVersion?: MaximumTLSVersionWef | undefined;
  /**
   * Enable OCSP check of certificate
   */
  ocspCheck?: boolean | undefined;
  keytab?: any | undefined;
  principal?: any | undefined;
  /**
   * If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
   */
  ocspCheckFailClose?: boolean | undefined;
};

/**
 * Content format in which the endpoint should deliver events
 */
export const InputFormat = {
  Raw: "Raw",
  RenderedText: "RenderedText",
} as const;
/**
 * Content format in which the endpoint should deliver events
 */
export type InputFormat = OpenEnum<typeof InputFormat>;

export const QueryBuilderMode = {
  Simple: "simple",
  Xml: "xml",
} as const;
export type QueryBuilderMode = OpenEnum<typeof QueryBuilderMode>;

export type SubscriptionMetadatum = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type Subscription = {
  subscriptionName: string;
  /**
   * Version UUID for this subscription. If any subscription parameters are modified, this value will change.
   */
  version?: string | undefined;
  /**
   * Content format in which the endpoint should deliver events
   */
  contentFormat?: InputFormat | undefined;
  /**
   * Maximum time (in seconds) between endpoint checkins before considering it unavailable
   */
  heartbeatInterval?: number | undefined;
  /**
   * Interval (in seconds) over which the endpoint should collect events before sending them to Stream
   */
  batchTimeout?: number | undefined;
  /**
   * Newly subscribed endpoints will send previously existing events. Disable to receive new events only.
   */
  readExistingEvents?: boolean | undefined;
  /**
   * Keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events'. See [Cribl Docs](https://docs.cribl.io/stream/sources-wef/#subscriptions) for more details.
   */
  sendBookmarks?: boolean | undefined;
  /**
   * Receive compressed events from the source
   */
  compress?: boolean | undefined;
  /**
   * The DNS names of the endpoints that should forward these events. You may use wildcards, such as *.mydomain.com
   */
  targets: Array<string>;
  /**
   * The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
   */
  locale?: string | undefined;
  querySelector?: QueryBuilderMode | undefined;
  /**
   * Fields to add to events ingested under this subscription
   */
  metadata?: Array<SubscriptionMetadatum> | undefined;
};

export type MetadatumWef = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputWef = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeWef;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionWef> | undefined;
  pq?: PqWef | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port?: number | undefined;
  /**
   * How to authenticate incoming client connections
   */
  authMethod?: AuthMethodAuthenticationMethod | undefined;
  tls?: MTLSSettings | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Preserve the clients original IP address in the __srcIpPort field when connecting through an HTTP proxy that supports the X-Forwarded-For header. This does not apply to TCP-layer Proxy Protocol v1/v2.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
   */
  caFingerprint?: string | undefined;
  /**
   * Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
   */
  keytab?: string | undefined;
  /**
   * Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>
   */
  principal?: string | undefined;
  /**
   * Allow events to be ingested even if their MachineID does not match the client certificate CN
   */
  allowMachineIdMismatch?: boolean | undefined;
  /**
   * Subscriptions to events on forwarding endpoints
   */
  subscriptions: Array<Subscription>;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumWef> | undefined;
  description?: string | undefined;
  /**
   * Log a warning if the client certificate authority (CA) fingerprint does not match the expected value. A mismatch prevents Cribl from receiving events from the Windows Event Forwarder.
   */
  logFingerprintMismatch?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeAppscope = {
  Appscope: "appscope",
} as const;
export type TypeAppscope = ClosedEnum<typeof TypeAppscope>;

export type ConnectionAppscope = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeAppscope = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeAppscope = OpenEnum<typeof ModeAppscope>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionAppscope = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionAppscope = OpenEnum<typeof CompressionAppscope>;

export type PqControlsAppscope = {};

export type PqAppscope = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeAppscope | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionAppscope | undefined;
  pqControls?: PqControlsAppscope | undefined;
};

export type MetadatumAppscope = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type Allow = {
  /**
   * Specify the name of a process or family of processes.
   */
  procname: string;
  /**
   * Specify a string to substring-match against process command-line.
   */
  arg?: string | undefined;
  /**
   * Choose a config to apply to processes that match the process name and/or argument.
   */
  config: string;
};

export type FilterAppscope = {
  /**
   * Specify processes that AppScope should be loaded into, and the config to use.
   */
  allow?: Array<Allow> | undefined;
  /**
   * To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL.
   */
  transportURL?: string | undefined;
};

export const DataCompressionFormatAppscope = {
  None: "none",
  Gzip: "gzip",
} as const;
export type DataCompressionFormatAppscope = OpenEnum<
  typeof DataCompressionFormatAppscope
>;

export type PersistenceAppscope = {
  /**
   * Spool events and metrics on disk for Cribl Edge and Search
   */
  enable?: boolean | undefined;
  /**
   * Time span for each file bucket
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: DataCompressionFormatAppscope | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/appscope
   */
  destPath?: string | undefined;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodAppscope = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodAppscope = OpenEnum<
  typeof AuthenticationMethodAppscope
>;

export const MinimumTLSVersionAppscope = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionAppscope = OpenEnum<
  typeof MinimumTLSVersionAppscope
>;

export const MaximumTLSVersionAppscope = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionAppscope = OpenEnum<
  typeof MaximumTLSVersionAppscope
>;

export type TLSSettingsServerSideAppscope = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionAppscope | undefined;
  maxVersion?: MaximumTLSVersionAppscope | undefined;
};

export type InputAppscope = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeAppscope;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionAppscope> | undefined;
  pq?: PqAppscope | undefined;
  /**
   * Regex matching IP addresses that are allowed to establish a connection
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  /**
   * Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumAppscope> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port.
   */
  enableUnixPath?: boolean | undefined;
  filter?: FilterAppscope | undefined;
  persistence?: PersistenceAppscope | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodAppscope | undefined;
  description?: string | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port?: number | undefined;
  tls?: TLSSettingsServerSideAppscope | undefined;
  /**
   * Path to the UNIX domain socket to listen on.
   */
  unixSocketPath?: string | undefined;
  /**
   * Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions.
   */
  unixSocketPerms?: string | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeTCP = {
  Tcp: "tcp",
} as const;
export type TypeTCP = ClosedEnum<typeof TypeTCP>;

export type ConnectionTCP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeTCP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeTCP = OpenEnum<typeof ModeTCP>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionTCP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionTCP = OpenEnum<typeof CompressionTCP>;

export type PqControlsTCP = {};

export type PqTCP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeTCP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionTCP | undefined;
  pqControls?: PqControlsTCP | undefined;
};

export const MinimumTLSVersionTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionTCP = OpenEnum<typeof MinimumTLSVersionTCP>;

export const MaximumTLSVersionTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionTCP = OpenEnum<typeof MaximumTLSVersionTCP>;

export type TLSSettingsServerSideTCP = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionTCP | undefined;
  maxVersion?: MaximumTLSVersionTCP | undefined;
};

export type MetadatumTCP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type PreprocessTCP = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthenticationMethodTCP = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthenticationMethodTCP = OpenEnum<typeof AuthenticationMethodTCP>;

export type InputTcp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeTCP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionTCP> | undefined;
  pq?: PqTCP | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideTCP | undefined;
  /**
   * Regex matching IP addresses that are allowed to establish a connection
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  /**
   * Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumTCP> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
   */
  enableHeader?: boolean | undefined;
  preprocess?: PreprocessTCP | undefined;
  description?: string | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthenticationMethodTCP | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputFileType = {
  File: "file",
} as const;
export type InputFileType = ClosedEnum<typeof InputFileType>;

export type InputFileConnection = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputFilePqMode = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputFilePqMode = OpenEnum<typeof InputFilePqMode>;

/**
 * Codec to use to compress the persisted data
 */
export const InputFileCompression = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputFileCompression = OpenEnum<typeof InputFileCompression>;

export type InputFilePqControls = {};

export type InputFilePq = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputFilePqMode | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputFileCompression | undefined;
  pqControls?: InputFilePqControls | undefined;
};

/**
 * Choose how to discover files to monitor
 */
export const InputFileMode = {
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Auto
   */
  Auto: "auto",
} as const;
/**
 * Choose how to discover files to monitor
 */
export type InputFileMode = OpenEnum<typeof InputFileMode>;

export type InputFileMetadatum = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputFile = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputFileType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputFileConnection> | undefined;
  pq?: InputFilePq | undefined;
  /**
   * Choose how to discover files to monitor
   */
  mode?: InputFileMode | undefined;
  /**
   * Time, in seconds, between scanning for files
   */
  interval?: number | undefined;
  /**
   * The full path of discovered files are matched against this wildcard list
   */
  filenames?: Array<string> | undefined;
  /**
   * Apply filename allowlist to file entries in archive file types, like tar or zip.
   */
  filterArchivedFiles?: boolean | undefined;
  /**
   * Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
   */
  tailOnly?: boolean | undefined;
  /**
   * Time, in seconds, before an idle file is closed
   */
  idleTimeout?: number | undefined;
  /**
   * The minimum age of files to monitor. Format examples: 30s, 15m, 1h. Age is relative to file modification time. Leave empty to apply no age filters.
   */
  minAgeDur?: string | undefined;
  /**
   * The maximum age of event timestamps to collect. Format examples: 60s, 4h, 3d, 1w. Can be used in conjuction with "Check file modification times". Leave empty to apply no age filters.
   */
  maxAgeDur?: string | undefined;
  /**
   * Skip files with modification times earlier than the maximum age duration
   */
  checkFileModTime?: boolean | undefined;
  /**
   * Forces files containing binary data to be streamed as text
   */
  forceText?: boolean | undefined;
  /**
   * Length of file header bytes to use in hash for unique file identification
   */
  hashLen?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputFileMetadatum> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  description?: string | undefined;
  /**
   * Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
   */
  path?: string | undefined;
  /**
   * Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
   */
  depth?: number | undefined;
  suppressMissingPathErrors?: boolean | undefined;
  /**
   * Delete files after they have been collected
   */
  deleteFiles?: boolean | undefined;
  /**
   * Stream binary files as Base64-encoded chunks.
   */
  includeUnidentifiableBinary?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputSyslogType2 = {
  Syslog: "syslog",
} as const;
export type InputSyslogType2 = ClosedEnum<typeof InputSyslogType2>;

export type InputSyslogConnection2 = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputSyslogMode2 = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputSyslogMode2 = OpenEnum<typeof InputSyslogMode2>;

/**
 * Codec to use to compress the persisted data
 */
export const InputSyslogCompression2 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputSyslogCompression2 = OpenEnum<typeof InputSyslogCompression2>;

export type InputSyslogPqControls2 = {};

export type InputSyslogPq2 = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputSyslogMode2 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputSyslogCompression2 | undefined;
  pqControls?: InputSyslogPqControls2 | undefined;
};

export const InputSyslogMinimumTLSVersion2 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputSyslogMinimumTLSVersion2 = OpenEnum<
  typeof InputSyslogMinimumTLSVersion2
>;

export const InputSyslogMaximumTLSVersion2 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputSyslogMaximumTLSVersion2 = OpenEnum<
  typeof InputSyslogMaximumTLSVersion2
>;

export type InputSyslogTLSSettingsServerSide2 = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputSyslogMinimumTLSVersion2 | undefined;
  maxVersion?: InputSyslogMaximumTLSVersion2 | undefined;
};

export type InputSyslogMetadatum2 = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputSyslogSyslog2 = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputSyslogType2;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputSyslogConnection2> | undefined;
  pq?: InputSyslogPq2 | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * Enter UDP port number to listen on. Not required if listening on TCP.
   */
  udpPort?: number | undefined;
  /**
   * Enter TCP port number to listen on. Not required if listening on UDP.
   */
  tcpPort: number;
  /**
   * Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
   */
  maxBufferSize?: number | undefined;
  /**
   * Regex matching IP addresses that are allowed to send data
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Timezone to assign to timestamps without timezone info
   */
  timestampTimezone?: string | undefined;
  /**
   * Treat UDP packet data received as full syslog message
   */
  singleMsgUdpPackets?: boolean | undefined;
  /**
   * Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Wildcard list of fields to keep from source data; * = ALL (default)
   */
  keepFieldsList?: Array<string> | undefined;
  /**
   * Enable if incoming messages use octet counting per RFC 6587.
   */
  octetCounting?: boolean | undefined;
  /**
   * Enable if we should infer the syslog framing of the incoming messages.
   */
  inferFraming?: boolean | undefined;
  /**
   * Enable if we should infer octet counting only if the messages comply with RFC 5424.
   */
  strictlyInferOctetCounting?: boolean | undefined;
  /**
   * Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
   */
  allowNonStandardAppName?: boolean | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  tls?: InputSyslogTLSSettingsServerSide2 | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputSyslogMetadatum2> | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
  /**
   * When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
   */
  enableEnhancedProxyHeaderParsing?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputSyslogType1 = {
  Syslog: "syslog",
} as const;
export type InputSyslogType1 = ClosedEnum<typeof InputSyslogType1>;

export type InputSyslogConnection1 = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputSyslogMode1 = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputSyslogMode1 = OpenEnum<typeof InputSyslogMode1>;

/**
 * Codec to use to compress the persisted data
 */
export const InputSyslogCompression1 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputSyslogCompression1 = OpenEnum<typeof InputSyslogCompression1>;

export type InputSyslogPqControls1 = {};

export type InputSyslogPq1 = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputSyslogMode1 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputSyslogCompression1 | undefined;
  pqControls?: InputSyslogPqControls1 | undefined;
};

export const InputSyslogMinimumTLSVersion1 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputSyslogMinimumTLSVersion1 = OpenEnum<
  typeof InputSyslogMinimumTLSVersion1
>;

export const InputSyslogMaximumTLSVersion1 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputSyslogMaximumTLSVersion1 = OpenEnum<
  typeof InputSyslogMaximumTLSVersion1
>;

export type InputSyslogTLSSettingsServerSide1 = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputSyslogMinimumTLSVersion1 | undefined;
  maxVersion?: InputSyslogMaximumTLSVersion1 | undefined;
};

export type InputSyslogMetadatum1 = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputSyslogSyslog1 = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputSyslogType1;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputSyslogConnection1> | undefined;
  pq?: InputSyslogPq1 | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * Enter UDP port number to listen on. Not required if listening on TCP.
   */
  udpPort: number;
  /**
   * Enter TCP port number to listen on. Not required if listening on UDP.
   */
  tcpPort?: number | undefined;
  /**
   * Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
   */
  maxBufferSize?: number | undefined;
  /**
   * Regex matching IP addresses that are allowed to send data
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Timezone to assign to timestamps without timezone info
   */
  timestampTimezone?: string | undefined;
  /**
   * Treat UDP packet data received as full syslog message
   */
  singleMsgUdpPackets?: boolean | undefined;
  /**
   * Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Wildcard list of fields to keep from source data; * = ALL (default)
   */
  keepFieldsList?: Array<string> | undefined;
  /**
   * Enable if incoming messages use octet counting per RFC 6587.
   */
  octetCounting?: boolean | undefined;
  /**
   * Enable if we should infer the syslog framing of the incoming messages.
   */
  inferFraming?: boolean | undefined;
  /**
   * Enable if we should infer octet counting only if the messages comply with RFC 5424.
   */
  strictlyInferOctetCounting?: boolean | undefined;
  /**
   * Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
   */
  allowNonStandardAppName?: boolean | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  tls?: InputSyslogTLSSettingsServerSide1 | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputSyslogMetadatum1> | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
  /**
   * When enabled, parses PROXY protocol headers during the TLS handshake. Disable if compatibility issues arise.
   */
  enableEnhancedProxyHeaderParsing?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export type InputSyslog = InputSyslogSyslog1 | InputSyslogSyslog2;

export const InputTypeSqs = {
  Sqs: "sqs",
} as const;
export type InputTypeSqs = ClosedEnum<typeof InputTypeSqs>;

export type ConnectionSqs = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeSqs = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeSqs = OpenEnum<typeof PqModeSqs>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionSqs = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionSqs = OpenEnum<typeof PqCompressionSqs>;

export type InputPqControlsSqs = {};

export type PqSqs = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeSqs | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionSqs | undefined;
  pqControls?: InputPqControlsSqs | undefined;
};

/**
 * The queue type used (or created)
 */
export const InputQueueType = {
  /**
   * Standard
   */
  Standard: "standard",
  /**
   * FIFO
   */
  Fifo: "fifo",
} as const;
/**
 * The queue type used (or created)
 */
export type InputQueueType = OpenEnum<typeof InputQueueType>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const InputAuthenticationMethodSqs = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type InputAuthenticationMethodSqs = OpenEnum<
  typeof InputAuthenticationMethodSqs
>;

/**
 * Signature version to use for signing SQS requests
 */
export const InputSignatureVersionSqs = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing SQS requests
 */
export type InputSignatureVersionSqs = OpenEnum<
  typeof InputSignatureVersionSqs
>;

export type MetadatumSqs = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputSqs = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeSqs;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSqs> | undefined;
  pq?: PqSqs | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * The queue type used (or created)
   */
  queueType: InputQueueType;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * Create queue if it does not exist
   */
  createQueue?: boolean | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: InputAuthenticationMethodSqs | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing SQS requests
   */
  signatureVersion?: InputSignatureVersionSqs | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access SQS
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
   */
  maxMessages?: number | undefined;
  /**
   * After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
   */
  visibilityTimeout?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSqs> | undefined;
  /**
   * How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
   */
  pollTimeout?: number | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeModelDrivenTelemetry = {
  ModelDrivenTelemetry: "model_driven_telemetry",
} as const;
export type TypeModelDrivenTelemetry = ClosedEnum<
  typeof TypeModelDrivenTelemetry
>;

export type ConnectionModelDrivenTelemetry = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeModelDrivenTelemetry = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeModelDrivenTelemetry = OpenEnum<
  typeof ModeModelDrivenTelemetry
>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionModelDrivenTelemetry = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionModelDrivenTelemetry = OpenEnum<
  typeof CompressionModelDrivenTelemetry
>;

export type PqControlsModelDrivenTelemetry = {};

export type PqModelDrivenTelemetry = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeModelDrivenTelemetry | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionModelDrivenTelemetry | undefined;
  pqControls?: PqControlsModelDrivenTelemetry | undefined;
};

export const MinimumTLSVersionModelDrivenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionModelDrivenTelemetry = OpenEnum<
  typeof MinimumTLSVersionModelDrivenTelemetry
>;

export const MaximumTLSVersionModelDrivenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionModelDrivenTelemetry = OpenEnum<
  typeof MaximumTLSVersionModelDrivenTelemetry
>;

export type TLSSettingsServerSideModelDrivenTelemetry = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionModelDrivenTelemetry | undefined;
  maxVersion?: MaximumTLSVersionModelDrivenTelemetry | undefined;
};

export type MetadatumModelDrivenTelemetry = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputModelDrivenTelemetry = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeModelDrivenTelemetry;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionModelDrivenTelemetry> | undefined;
  pq?: PqModelDrivenTelemetry | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port?: number | undefined;
  tls?: TLSSettingsServerSideModelDrivenTelemetry | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumModelDrivenTelemetry> | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
   */
  shutdownTimeoutMs?: number | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeOpenTelemetry = {
  OpenTelemetry: "open_telemetry",
} as const;
export type InputTypeOpenTelemetry = ClosedEnum<typeof InputTypeOpenTelemetry>;

export type ConnectionOpenTelemetry = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeOpenTelemetry = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeOpenTelemetry = OpenEnum<typeof PqModeOpenTelemetry>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionOpenTelemetry = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionOpenTelemetry = OpenEnum<
  typeof PqCompressionOpenTelemetry
>;

export type InputPqControlsOpenTelemetry = {};

export type PqOpenTelemetry = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeOpenTelemetry | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionOpenTelemetry | undefined;
  pqControls?: InputPqControlsOpenTelemetry | undefined;
};

export const InputMinimumTLSVersionOpenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionOpenTelemetry = OpenEnum<
  typeof InputMinimumTLSVersionOpenTelemetry
>;

export const InputMaximumTLSVersionOpenTelemetry = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionOpenTelemetry = OpenEnum<
  typeof InputMaximumTLSVersionOpenTelemetry
>;

export type TLSSettingsServerSideOpenTelemetry = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionOpenTelemetry | undefined;
  maxVersion?: InputMaximumTLSVersionOpenTelemetry | undefined;
};

/**
 * Select whether to leverage gRPC or HTTP for OpenTelemetry
 */
export const InputProtocolOpenTelemetry = {
  /**
   * gRPC
   */
  Grpc: "grpc",
  /**
   * HTTP
   */
  Http: "http",
} as const;
/**
 * Select whether to leverage gRPC or HTTP for OpenTelemetry
 */
export type InputProtocolOpenTelemetry = OpenEnum<
  typeof InputProtocolOpenTelemetry
>;

/**
 * The version of OTLP Protobuf definitions to use when interpreting received data
 */
export const InputOTLPVersion = {
  /**
   * 0.10.0
   */
  ZeroDot10Dot0: "0.10.0",
  /**
   * 1.3.1
   */
  OneDot3Dot1: "1.3.1",
} as const;
/**
 * The version of OTLP Protobuf definitions to use when interpreting received data
 */
export type InputOTLPVersion = OpenEnum<typeof InputOTLPVersion>;

/**
 * OpenTelemetry authentication type
 */
export const InputAuthenticationTypeOpenTelemetry = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * OpenTelemetry authentication type
 */
export type InputAuthenticationTypeOpenTelemetry = OpenEnum<
  typeof InputAuthenticationTypeOpenTelemetry
>;

export type InputMetadatumOpenTelemetry = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputOauthParamOpenTelemetry = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type InputOauthHeaderOpenTelemetry = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputOpenTelemetry = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeOpenTelemetry;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionOpenTelemetry> | undefined;
  pq?: PqOpenTelemetry | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port?: number | undefined;
  tls?: TLSSettingsServerSideOpenTelemetry | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  enableProxyHeader?: any | undefined;
  captureHeaders?: any | undefined;
  activityLogSampleRate?: any | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist.
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Select whether to leverage gRPC or HTTP for OpenTelemetry
   */
  protocol?: InputProtocolOpenTelemetry | undefined;
  /**
   * Enable to extract each incoming span to a separate event
   */
  extractSpans?: boolean | undefined;
  /**
   * Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
   */
  extractMetrics?: boolean | undefined;
  /**
   * The version of OTLP Protobuf definitions to use when interpreting received data
   */
  otlpVersion?: InputOTLPVersion | undefined;
  /**
   * OpenTelemetry authentication type
   */
  authType?: InputAuthenticationTypeOpenTelemetry | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputMetadatumOpenTelemetry> | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<InputOauthParamOpenTelemetry> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<InputOauthHeaderOpenTelemetry> | undefined;
  /**
   * Enable to extract each incoming log record to a separate event
   */
  extractLogs?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeSnmp = {
  Snmp: "snmp",
} as const;
export type InputTypeSnmp = ClosedEnum<typeof InputTypeSnmp>;

export type ConnectionSnmp = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeSnmp = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeSnmp = OpenEnum<typeof ModeSnmp>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSnmp = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSnmp = OpenEnum<typeof CompressionSnmp>;

export type PqControlsSnmp = {};

export type PqSnmp = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeSnmp | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionSnmp | undefined;
  pqControls?: PqControlsSnmp | undefined;
};

export const AuthenticationProtocol = {
  /**
   * None
   */
  None: "none",
  /**
   * MD5
   */
  Md5: "md5",
  /**
   * SHA1
   */
  Sha: "sha",
  /**
   * SHA224
   */
  Sha224: "sha224",
  /**
   * SHA256
   */
  Sha256: "sha256",
  /**
   * SHA384
   */
  Sha384: "sha384",
  /**
   * SHA512
   */
  Sha512: "sha512",
} as const;
export type AuthenticationProtocol = OpenEnum<typeof AuthenticationProtocol>;

export type V3User = {
  name: string;
  authProtocol?: AuthenticationProtocol | undefined;
  authKey?: any | undefined;
  privProtocol?: string | undefined;
};

/**
 * Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
 */
export type SNMPv3Authentication = {
  v3AuthEnabled?: boolean | undefined;
  /**
   * Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
   */
  allowUnmatchedTrap?: boolean | undefined;
  /**
   * User credentials for receiving v3 traps
   */
  v3Users?: Array<V3User> | undefined;
};

export type MetadatumSnmp = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputSnmp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeSnmp;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSnmp> | undefined;
  pq?: PqSnmp | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * UDP port to receive SNMP traps on. Defaults to 162.
   */
  port?: number | undefined;
  /**
   * Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
   */
  snmpV3Auth?: SNMPv3Authentication | undefined;
  /**
   * Maximum number of events to buffer when downstream is blocking.
   */
  maxBufferSize?: number | undefined;
  /**
   * Regex matching IP addresses that are allowed to send data
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSnmp> | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  /**
   * If enabled, parses varbinds as an array of objects that include OID, value, and type
   */
  varbindsWithTypes?: boolean | undefined;
  /**
   * If enabled, the parser will attempt to parse varbind octet strings as UTF-8, first, otherwise will fallback to other methods
   */
  bestEffortParsing?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeS3Inventory = {
  S3Inventory: "s3_inventory",
} as const;
export type TypeS3Inventory = ClosedEnum<typeof TypeS3Inventory>;

export type ConnectionS3Inventory = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeS3Inventory = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeS3Inventory = OpenEnum<typeof ModeS3Inventory>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionS3Inventory = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionS3Inventory = OpenEnum<typeof CompressionS3Inventory>;

export type PqControlsS3Inventory = {};

export type PqS3Inventory = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeS3Inventory | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionS3Inventory | undefined;
  pqControls?: PqControlsS3Inventory | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodS3Inventory = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodS3Inventory = OpenEnum<
  typeof AuthenticationMethodS3Inventory
>;

/**
 * Signature version to use for signing S3 requests
 */
export const SignatureVersionS3Inventory = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type SignatureVersionS3Inventory = OpenEnum<
  typeof SignatureVersionS3Inventory
>;

export type PreprocessS3Inventory = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type MetadatumS3Inventory = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type CheckpointingS3Inventory = {
  /**
   * Resume processing files after an interruption
   */
  enabled?: boolean | undefined;
  /**
   * The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
   */
  retries?: number | undefined;
};

export const TagAfterProcessingS3Inventory = {
  False: "false",
  True: "true",
} as const;
export type TagAfterProcessingS3Inventory = OpenEnum<
  typeof TagAfterProcessingS3Inventory
>;

export type InputS3Inventory = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeS3Inventory;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionS3Inventory> | undefined;
  pq?: PqS3Inventory | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodS3Inventory | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: SignatureVersionS3Inventory | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
   */
  maxMessages?: number | undefined;
  /**
   * After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
   */
  socketTimeout?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Attach SQS notification metadata to a __sqsMetadata field on each event
   */
  includeSqsMetadata?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Amazon S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Use Assume Role credentials when accessing Amazon SQS
   */
  enableSQSAssumeRole?: boolean | undefined;
  preprocess?: PreprocessS3Inventory | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumS3Inventory> | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  checkpointing?: CheckpointingS3Inventory | undefined;
  /**
   * How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
   */
  pollTimeout?: number | undefined;
  /**
   * Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
   */
  checksumSuffix?: string | undefined;
  /**
   * Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
   */
  maxManifestSizeKB?: number | undefined;
  /**
   * If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
   */
  validateInventoryFiles?: boolean | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  tagAfterProcessing?: TagAfterProcessingS3Inventory | undefined;
  /**
   * The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagKey?: string | undefined;
  /**
   * The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagValue?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeS3 = {
  S3: "s3",
} as const;
export type InputTypeS3 = ClosedEnum<typeof InputTypeS3>;

export type ConnectionS3 = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeS3 = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeS3 = OpenEnum<typeof ModeS3>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionS3 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionS3 = OpenEnum<typeof PqCompressionS3>;

export type PqControlsS3 = {};

export type PqS3 = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeS3 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionS3 | undefined;
  pqControls?: PqControlsS3 | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const InputAuthenticationMethodS3 = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type InputAuthenticationMethodS3 = OpenEnum<
  typeof InputAuthenticationMethodS3
>;

/**
 * Signature version to use for signing S3 requests
 */
export const InputSignatureVersionS3 = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type InputSignatureVersionS3 = OpenEnum<typeof InputSignatureVersionS3>;

export type PreprocessS3 = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type MetadatumS3 = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type CheckpointingS3 = {
  /**
   * Resume processing files after an interruption
   */
  enabled?: boolean | undefined;
  /**
   * The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
   */
  retries?: number | undefined;
};

export type InputS3 = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeS3;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionS3> | undefined;
  pq?: PqS3 | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: InputAuthenticationMethodS3 | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: InputSignatureVersionS3 | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
   */
  maxMessages?: number | undefined;
  /**
   * After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
   */
  socketTimeout?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Attach SQS notification metadata to a __sqsMetadata field on each event
   */
  includeSqsMetadata?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Amazon S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Use Assume Role credentials when accessing Amazon SQS
   */
  enableSQSAssumeRole?: boolean | undefined;
  preprocess?: PreprocessS3 | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumS3> | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  checkpointing?: CheckpointingS3 | undefined;
  /**
   * How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
   */
  pollTimeout?: number | undefined;
  /**
   * Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
   */
  encoding?: string | undefined;
  /**
   * Add a tag to processed S3 objects. Requires s3:GetObjectTagging and s3:PutObjectTagging AWS permissions.
   */
  tagAfterProcessing?: boolean | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagKey?: string | undefined;
  /**
   * The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagValue?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeMetrics = {
  Metrics: "metrics",
} as const;
export type TypeMetrics = ClosedEnum<typeof TypeMetrics>;

export type ConnectionMetrics = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeMetrics = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeMetrics = OpenEnum<typeof ModeMetrics>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionMetrics = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionMetrics = OpenEnum<typeof CompressionMetrics>;

export type PqControlsMetrics = {};

export type PqMetrics = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeMetrics | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionMetrics | undefined;
  pqControls?: PqControlsMetrics | undefined;
};

export const MinimumTLSVersionMetrics = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionMetrics = OpenEnum<
  typeof MinimumTLSVersionMetrics
>;

export const MaximumTLSVersionMetrics = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionMetrics = OpenEnum<
  typeof MaximumTLSVersionMetrics
>;

export type TLSSettingsServerSideMetrics = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionMetrics | undefined;
  maxVersion?: MaximumTLSVersionMetrics | undefined;
};

export type MetadatumMetrics = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputMetrics = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeMetrics;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionMetrics> | undefined;
  pq?: PqMetrics | undefined;
  /**
   * Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
   */
  host?: string | undefined;
  /**
   * Enter UDP port number to listen on. Not required if listening on TCP.
   */
  udpPort?: number | undefined;
  /**
   * Enter TCP port number to listen on. Not required if listening on UDP.
   */
  tcpPort?: number | undefined;
  /**
   * Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
   */
  maxBufferSize?: number | undefined;
  /**
   * Regex matching IP addresses that are allowed to send data
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
   */
  enableProxyHeader?: boolean | undefined;
  tls?: TLSSettingsServerSideMetrics | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumMetrics> | undefined;
  /**
   * Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
   */
  udpSocketRxBufSize?: number | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCriblmetrics = {
  Criblmetrics: "criblmetrics",
} as const;
export type TypeCriblmetrics = ClosedEnum<typeof TypeCriblmetrics>;

export type ConnectionCriblmetrics = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCriblmetrics = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCriblmetrics = OpenEnum<typeof ModeCriblmetrics>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCriblmetrics = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCriblmetrics = OpenEnum<typeof CompressionCriblmetrics>;

export type PqControlsCriblmetrics = {};

export type PqCriblmetrics = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCriblmetrics | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCriblmetrics | undefined;
  pqControls?: PqControlsCriblmetrics | undefined;
};

export type MetadatumCriblmetrics = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputCriblmetrics = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeCriblmetrics;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCriblmetrics> | undefined;
  pq?: PqCriblmetrics | undefined;
  /**
   * A prefix that is applied to the metrics provided by Cribl Stream
   */
  prefix?: string | undefined;
  /**
   * Include granular metrics. Disabling this will drop the following metrics events: `cribl.logstream.host.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.index.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.source.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.sourcetype.(in_bytes,in_events,out_bytes,out_events)`.
   */
  fullFidelity?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCriblmetrics> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeKinesis = {
  Kinesis: "kinesis",
} as const;
export type InputTypeKinesis = ClosedEnum<typeof InputTypeKinesis>;

export type ConnectionKinesis = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeKinesis = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeKinesis = OpenEnum<typeof PqModeKinesis>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionKinesis = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionKinesis = OpenEnum<typeof PqCompressionKinesis>;

export type InputPqControlsKinesis = {};

export type PqKinesis = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeKinesis | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionKinesis | undefined;
  pqControls?: InputPqControlsKinesis | undefined;
};

/**
 * Location at which to start reading a shard for the first time
 */
export const ShardIteratorStart = {
  /**
   * Earliest record
   */
  TrimHorizon: "TRIM_HORIZON",
  /**
   * Latest record
   */
  Latest: "LATEST",
} as const;
/**
 * Location at which to start reading a shard for the first time
 */
export type ShardIteratorStart = OpenEnum<typeof ShardIteratorStart>;

/**
 * Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
 */
export const InputRecordDataFormat = {
  /**
   * Cribl
   */
  Cribl: "cribl",
  /**
   * Newline JSON
   */
  Ndjson: "ndjson",
  /**
   * Cloudwatch Logs
   */
  Cloudwatch: "cloudwatch",
  /**
   * Event per line
   */
  Line: "line",
} as const;
/**
 * Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
 */
export type InputRecordDataFormat = OpenEnum<typeof InputRecordDataFormat>;

/**
 * The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
 */
export const ShardLoadBalancing = {
  /**
   * Consistent Hashing
   */
  ConsistentHashing: "ConsistentHashing",
  /**
   * Round Robin
   */
  RoundRobin: "RoundRobin",
} as const;
/**
 * The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
 */
export type ShardLoadBalancing = OpenEnum<typeof ShardLoadBalancing>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const InputAuthenticationMethodKinesis = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type InputAuthenticationMethodKinesis = OpenEnum<
  typeof InputAuthenticationMethodKinesis
>;

/**
 * Signature version to use for signing Kinesis stream requests
 */
export const InputSignatureVersionKinesis = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing Kinesis stream requests
 */
export type InputSignatureVersionKinesis = OpenEnum<
  typeof InputSignatureVersionKinesis
>;

export type MetadatumKinesis = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputKinesis = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeKinesis;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionKinesis> | undefined;
  pq?: PqKinesis | undefined;
  /**
   * Kinesis Data Stream to read data from
   */
  streamName: string;
  /**
   * Time interval in minutes between consecutive service calls
   */
  serviceInterval?: number | undefined;
  /**
   * A JavaScript expression to be called with each shardId for the stream. If the expression evaluates to a truthy value, the shard will be processed.
   */
  shardExpr?: string | undefined;
  /**
   * Location at which to start reading a shard for the first time
   */
  shardIteratorType?: ShardIteratorStart | undefined;
  /**
   * Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
   */
  payloadFormat?: InputRecordDataFormat | undefined;
  /**
   * Maximum number of records per getRecords call
   */
  getRecordsLimit?: number | undefined;
  /**
   * Maximum number of records, across all shards, to pull down at once per Worker Process
   */
  getRecordsLimitTotal?: number | undefined;
  /**
   * The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
   */
  loadBalancingAlgorithm?: ShardLoadBalancing | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: InputAuthenticationMethodKinesis | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the Kinesis stream is located
   */
  region: string;
  /**
   * Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing Kinesis stream requests
   */
  signatureVersion?: InputSignatureVersionKinesis | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Kinesis stream
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Verify Kinesis Producer Library (KPL) event checksums
   */
  verifyKPLCheckSums?: boolean | undefined;
  /**
   * When resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this setting can cause data loss after a Worker Node's unexpected shutdown or restart.
   */
  avoidDuplicates?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumKinesis> | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeHTTPRaw = {
  HttpRaw: "http_raw",
} as const;
export type TypeHTTPRaw = ClosedEnum<typeof TypeHTTPRaw>;

export type ConnectionHTTPRaw = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeHTTPRaw = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeHTTPRaw = OpenEnum<typeof ModeHTTPRaw>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionHTTPRaw = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionHTTPRaw = OpenEnum<typeof CompressionHTTPRaw>;

export type PqControlsHTTPRaw = {};

export type PqHTTPRaw = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeHTTPRaw | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionHTTPRaw | undefined;
  pqControls?: PqControlsHTTPRaw | undefined;
};

export const MinimumTLSVersionHTTPRaw = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionHTTPRaw = OpenEnum<
  typeof MinimumTLSVersionHTTPRaw
>;

export const MaximumTLSVersionHTTPRaw = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionHTTPRaw = OpenEnum<
  typeof MaximumTLSVersionHTTPRaw
>;

export type TLSSettingsServerSideHTTPRaw = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionHTTPRaw | undefined;
  maxVersion?: MaximumTLSVersionHTTPRaw | undefined;
};

export type MetadatumHTTPRaw = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtMetadatumHTTPRaw = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtHTTPRaw = {
  /**
   * Shared secret to be provided by any client (Authorization: <token>)
   */
  token: string;
  description?: string | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokensExtMetadatumHTTPRaw> | undefined;
};

export type InputHttpRaw = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeHTTPRaw;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionHTTPRaw> | undefined;
  pq?: PqHTTPRaw | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideHTTPRaw | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumHTTPRaw> | undefined;
  /**
   * List of URI paths accepted by this input, wildcards are supported, e.g /api/v* /hook. Defaults to allow all.
   */
  allowedPaths?: Array<string> | undefined;
  /**
   * List of HTTP methods accepted by this input. Wildcards are supported (such as P*, GET). Defaults to allow all.
   */
  allowedMethods?: Array<string> | undefined;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokensExt?: Array<AuthTokensExtHTTPRaw> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDatagen = {
  Datagen: "datagen",
} as const;
export type TypeDatagen = ClosedEnum<typeof TypeDatagen>;

export type ConnectionDatagen = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeDatagen = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeDatagen = OpenEnum<typeof ModeDatagen>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionDatagen = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionDatagen = OpenEnum<typeof CompressionDatagen>;

export type PqControlsDatagen = {};

export type PqDatagen = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeDatagen | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionDatagen | undefined;
  pqControls?: PqControlsDatagen | undefined;
};

export type Sample = {
  sample: string;
  /**
   * Maximum number of events to generate per second per Worker Node. Defaults to 10.
   */
  eventsPerSec?: number | undefined;
};

export type MetadatumDatagen = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputDatagen = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeDatagen;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionDatagen> | undefined;
  pq?: PqDatagen | undefined;
  samples: Array<Sample>;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumDatagen> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeDatadogAgent = {
  DatadogAgent: "datadog_agent",
} as const;
export type TypeDatadogAgent = ClosedEnum<typeof TypeDatadogAgent>;

export type ConnectionDatadogAgent = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeDatadogAgent = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeDatadogAgent = OpenEnum<typeof ModeDatadogAgent>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionDatadogAgent = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionDatadogAgent = OpenEnum<typeof CompressionDatadogAgent>;

export type PqControlsDatadogAgent = {};

export type PqDatadogAgent = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeDatadogAgent | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionDatadogAgent | undefined;
  pqControls?: PqControlsDatadogAgent | undefined;
};

export const MinimumTLSVersionDatadogAgent = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionDatadogAgent = OpenEnum<
  typeof MinimumTLSVersionDatadogAgent
>;

export const MaximumTLSVersionDatadogAgent = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionDatadogAgent = OpenEnum<
  typeof MaximumTLSVersionDatadogAgent
>;

export type TLSSettingsServerSideDatadogAgent = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionDatadogAgent | undefined;
  maxVersion?: MaximumTLSVersionDatadogAgent | undefined;
};

export type MetadatumDatadogAgent = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type ProxyModeDatadogAgent = {
  /**
   * Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
   */
  enabled?: boolean | undefined;
  /**
   * Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
   */
  rejectUnauthorized?: boolean | undefined;
};

export type InputDatadogAgent = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeDatadogAgent;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionDatadogAgent> | undefined;
  pq?: PqDatadogAgent | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideDatadogAgent | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
   */
  extractMetrics?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumDatadogAgent> | undefined;
  proxyMode?: ProxyModeDatadogAgent | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCrowdstrike = {
  Crowdstrike: "crowdstrike",
} as const;
export type TypeCrowdstrike = ClosedEnum<typeof TypeCrowdstrike>;

export type ConnectionCrowdstrike = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCrowdstrike = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCrowdstrike = OpenEnum<typeof ModeCrowdstrike>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCrowdstrike = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCrowdstrike = OpenEnum<typeof CompressionCrowdstrike>;

export type PqControlsCrowdstrike = {};

export type PqCrowdstrike = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCrowdstrike | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCrowdstrike | undefined;
  pqControls?: PqControlsCrowdstrike | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AuthenticationMethodCrowdstrike = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AuthenticationMethodCrowdstrike = OpenEnum<
  typeof AuthenticationMethodCrowdstrike
>;

/**
 * Signature version to use for signing S3 requests
 */
export const SignatureVersionCrowdstrike = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing S3 requests
 */
export type SignatureVersionCrowdstrike = OpenEnum<
  typeof SignatureVersionCrowdstrike
>;

export type PreprocessCrowdstrike = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type MetadatumCrowdstrike = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type CheckpointingCrowdstrike = {
  /**
   * Resume processing files after an interruption
   */
  enabled?: boolean | undefined;
  /**
   * The number of times to retry processing when a processing error occurs. If Skip file on error is enabled, this setting is ignored.
   */
  retries?: number | undefined;
};

export const TagAfterProcessingCrowdstrike = {
  False: "false",
  True: "true",
} as const;
export type TagAfterProcessingCrowdstrike = OpenEnum<
  typeof TagAfterProcessingCrowdstrike
>;

export type InputCrowdstrike = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeCrowdstrike;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCrowdstrike> | undefined;
  pq?: PqCrowdstrike | undefined;
  /**
   * The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
   */
  awsAccountId?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: AuthenticationMethodCrowdstrike | undefined;
  awsSecretKey?: string | undefined;
  /**
   * AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
   */
  region?: string | undefined;
  /**
   * S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing S3 requests
   */
  signatureVersion?: SignatureVersionCrowdstrike | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
   */
  maxMessages?: number | undefined;
  /**
   * After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
   */
  socketTimeout?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Attach SQS notification metadata to a __sqsMetadata field on each event
   */
  includeSqsMetadata?: boolean | undefined;
  /**
   * Use Assume Role credentials to access Amazon S3
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Use Assume Role credentials when accessing Amazon SQS
   */
  enableSQSAssumeRole?: boolean | undefined;
  preprocess?: PreprocessCrowdstrike | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCrowdstrike> | undefined;
  checkpointing?: CheckpointingCrowdstrike | undefined;
  /**
   * How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
   */
  pollTimeout?: number | undefined;
  /**
   * Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
   */
  encoding?: string | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  tagAfterProcessing?: TagAfterProcessingCrowdstrike | undefined;
  /**
   * The key for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagKey?: string | undefined;
  /**
   * The value for the S3 object tag applied after processing. This field accepts an expression for dynamic generation.
   */
  processedTagValue?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeWindowsMetrics = {
  WindowsMetrics: "windows_metrics",
} as const;
export type TypeWindowsMetrics = ClosedEnum<typeof TypeWindowsMetrics>;

export type ConnectionWindowsMetrics = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeWindowsMetrics = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeWindowsMetrics = OpenEnum<typeof PqModeWindowsMetrics>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionWindowsMetrics = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionWindowsMetrics = OpenEnum<
  typeof CompressionWindowsMetrics
>;

export type PqControlsWindowsMetrics = {};

export type PqWindowsMetrics = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeWindowsMetrics | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionWindowsMetrics | undefined;
  pqControls?: PqControlsWindowsMetrics | undefined;
};

/**
 * Select level of detail for host metrics
 */
export const HostModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select level of detail for host metrics
 */
export type HostModeWindowsMetrics = OpenEnum<typeof HostModeWindowsMetrics>;

/**
 * Select the level of details for system metrics
 */
export const SystemModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of details for system metrics
 */
export type SystemModeWindowsMetrics = OpenEnum<
  typeof SystemModeWindowsMetrics
>;

export type SystemWindowsMetrics = {
  /**
   * Select the level of details for system metrics
   */
  mode?: SystemModeWindowsMetrics | undefined;
  /**
   * Generate metrics for all system information
   */
  detail?: boolean | undefined;
};

/**
 * Select the level of details for CPU metrics
 */
export const CpuModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of details for CPU metrics
 */
export type CpuModeWindowsMetrics = OpenEnum<typeof CpuModeWindowsMetrics>;

export type CpuWindowsMetrics = {
  /**
   * Select the level of details for CPU metrics
   */
  mode?: CpuModeWindowsMetrics | undefined;
  /**
   * Generate metrics for each CPU
   */
  perCpu?: boolean | undefined;
  /**
   * Generate metrics for all CPU states
   */
  detail?: boolean | undefined;
  /**
   * Generate raw, monotonic CPU time counters
   */
  time?: boolean | undefined;
};

/**
 * Select the level of details for memory metrics
 */
export const MemoryModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of details for memory metrics
 */
export type MemoryModeWindowsMetrics = OpenEnum<
  typeof MemoryModeWindowsMetrics
>;

export type MemoryWindowsMetrics = {
  /**
   * Select the level of details for memory metrics
   */
  mode?: MemoryModeWindowsMetrics | undefined;
  /**
   * Generate metrics for all memory states
   */
  detail?: boolean | undefined;
};

/**
 * Select the level of details for network metrics
 */
export const NetworkModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of details for network metrics
 */
export type NetworkModeWindowsMetrics = OpenEnum<
  typeof NetworkModeWindowsMetrics
>;

export type NetworkWindowsMetrics = {
  /**
   * Select the level of details for network metrics
   */
  mode?: NetworkModeWindowsMetrics | undefined;
  /**
   * Generate full network metrics
   */
  detail?: boolean | undefined;
  /**
   * Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
   */
  protocols?: boolean | undefined;
  /**
   * Network interfaces to include/exclude. All interfaces are included if this list is empty.
   */
  devices?: Array<string> | undefined;
  /**
   * Generate separate metrics for each interface
   */
  perInterface?: boolean | undefined;
};

/**
 * Select the level of details for disk metrics
 */
export const DiskModeWindowsMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of details for disk metrics
 */
export type DiskModeWindowsMetrics = OpenEnum<typeof DiskModeWindowsMetrics>;

export type DiskWindowsMetrics = {
  /**
   * Select the level of details for disk metrics
   */
  mode?: DiskModeWindowsMetrics | undefined;
  /**
   * Generate separate metrics for each volume
   */
  perVolume?: boolean | undefined;
  /**
   * Generate full disk metrics
   */
  detail?: boolean | undefined;
  /**
   * Windows volumes to include/exclude. E.g.: C:, !E:, etc. Wildcards and ! (not) operators are supported. All volumes are included if this list is empty.
   */
  volumes?: Array<string> | undefined;
};

export type CustomWindowsMetrics = {
  system?: SystemWindowsMetrics | undefined;
  cpu?: CpuWindowsMetrics | undefined;
  memory?: MemoryWindowsMetrics | undefined;
  network?: NetworkWindowsMetrics | undefined;
  disk?: DiskWindowsMetrics | undefined;
};

export type HostWindowsMetrics = {
  /**
   * Select level of detail for host metrics
   */
  mode?: HostModeWindowsMetrics | undefined;
  custom?: CustomWindowsMetrics | undefined;
};

export type SetWindowsMetrics = {
  name: string;
  filter: string;
  includeChildren?: boolean | undefined;
};

export type ProcessWindowsMetrics = {
  /**
   * Configure sets to collect process metrics
   */
  sets?: Array<SetWindowsMetrics> | undefined;
};

export type MetadatumWindowsMetrics = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export const DataCompressionFormatWindowsMetrics = {
  None: "none",
  Gzip: "gzip",
} as const;
export type DataCompressionFormatWindowsMetrics = OpenEnum<
  typeof DataCompressionFormatWindowsMetrics
>;

export type PersistenceWindowsMetrics = {
  /**
   * Spool metrics to disk for Cribl Edge and Search
   */
  enable?: boolean | undefined;
  /**
   * Time span for each file bucket
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: DataCompressionFormatWindowsMetrics | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/windows_metrics
   */
  destPath?: string | undefined;
};

export type InputWindowsMetrics = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeWindowsMetrics;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionWindowsMetrics> | undefined;
  pq?: PqWindowsMetrics | undefined;
  /**
   * Time, in seconds, between consecutive metric collections. Default is 10 seconds.
   */
  interval?: number | undefined;
  host?: HostWindowsMetrics | undefined;
  process?: ProcessWindowsMetrics | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumWindowsMetrics> | undefined;
  persistence?: PersistenceWindowsMetrics | undefined;
  /**
   * Enable to use built-in tools (PowerShell) to collect metrics instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-metrics/#advanced-tab)
   */
  disableNativeModule?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeKubeEvents = {
  KubeEvents: "kube_events",
} as const;
export type TypeKubeEvents = ClosedEnum<typeof TypeKubeEvents>;

export type ConnectionKubeEvents = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeKubeEvents = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeKubeEvents = OpenEnum<typeof ModeKubeEvents>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionKubeEvents = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionKubeEvents = OpenEnum<typeof CompressionKubeEvents>;

export type PqControlsKubeEvents = {};

export type PqKubeEvents = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeKubeEvents | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionKubeEvents | undefined;
  pqControls?: PqControlsKubeEvents | undefined;
};

export type RuleKubeEvents = {
  /**
   * JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type MetadatumKubeEvents = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputKubeEvents = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeKubeEvents;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionKubeEvents> | undefined;
  pq?: PqKubeEvents | undefined;
  /**
   * Filtering on event fields
   */
  rules?: Array<RuleKubeEvents> | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumKubeEvents> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeKubeLogs = {
  KubeLogs: "kube_logs",
} as const;
export type TypeKubeLogs = ClosedEnum<typeof TypeKubeLogs>;

export type ConnectionKubeLogs = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeKubeLogs = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeKubeLogs = OpenEnum<typeof ModeKubeLogs>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionKubeLogs = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionKubeLogs = OpenEnum<typeof PqCompressionKubeLogs>;

export type PqControlsKubeLogs = {};

export type PqKubeLogs = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeKubeLogs | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionKubeLogs | undefined;
  pqControls?: PqControlsKubeLogs | undefined;
};

export type RuleKubeLogs = {
  /**
   * JavaScript expression applied to Pod objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type MetadatumKubeLogs = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Data compression format. Default is gzip.
 */
export const PersistenceCompressionKubeLogs = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format. Default is gzip.
 */
export type PersistenceCompressionKubeLogs = OpenEnum<
  typeof PersistenceCompressionKubeLogs
>;

export type DiskSpoolingKubeLogs = {
  /**
   * Spool events on disk for Cribl Edge and Search. Default is disabled.
   */
  enable?: boolean | undefined;
  /**
   * Time period for grouping spooled events. Default is 10m.
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
   */
  maxDataTime?: string | undefined;
  /**
   * Data compression format. Default is gzip.
   */
  compress?: PersistenceCompressionKubeLogs | undefined;
};

export type InputKubeLogs = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeKubeLogs;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionKubeLogs> | undefined;
  pq?: PqKubeLogs | undefined;
  /**
   * Time, in seconds, between checks for new containers. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
   */
  rules?: Array<RuleKubeLogs> | undefined;
  /**
   * For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
   */
  timestamps?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumKubeLogs> | undefined;
  persistence?: DiskSpoolingKubeLogs | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeKubeMetrics = {
  KubeMetrics: "kube_metrics",
} as const;
export type TypeKubeMetrics = ClosedEnum<typeof TypeKubeMetrics>;

export type ConnectionKubeMetrics = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeKubeMetrics = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeKubeMetrics = OpenEnum<typeof ModeKubeMetrics>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionKubeMetrics = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionKubeMetrics = OpenEnum<typeof CompressionKubeMetrics>;

export type PqControlsKubeMetrics = {};

export type PqKubeMetrics = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeKubeMetrics | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionKubeMetrics | undefined;
  pqControls?: PqControlsKubeMetrics | undefined;
};

export type RuleKubeMetrics = {
  /**
   * JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type MetadatumKubeMetrics = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export const DataCompressionFormatKubeMetrics = {
  None: "none",
  Gzip: "gzip",
} as const;
export type DataCompressionFormatKubeMetrics = OpenEnum<
  typeof DataCompressionFormatKubeMetrics
>;

export type PersistenceKubeMetrics = {
  /**
   * Spool metrics on disk for Cribl Search
   */
  enable?: boolean | undefined;
  /**
   * Time span for each file bucket
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: DataCompressionFormatKubeMetrics | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
   */
  destPath?: string | undefined;
};

export type InputKubeMetrics = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeKubeMetrics;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionKubeMetrics> | undefined;
  pq?: PqKubeMetrics | undefined;
  /**
   * Time, in seconds, between consecutive metrics collections. Default is 15 secs.
   */
  interval?: number | undefined;
  /**
   * Add rules to decide which Kubernetes objects to generate metrics for. Events are generated if no rules are given or of all the rules' expressions evaluate to true.
   */
  rules?: Array<RuleKubeMetrics> | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumKubeMetrics> | undefined;
  persistence?: PersistenceKubeMetrics | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSystemState = {
  SystemState: "system_state",
} as const;
export type TypeSystemState = ClosedEnum<typeof TypeSystemState>;

export type ConnectionSystemState = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeSystemState = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeSystemState = OpenEnum<typeof ModeSystemState>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSystemState = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSystemState = OpenEnum<typeof CompressionSystemState>;

export type PqControlsSystemState = {};

export type PqSystemState = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeSystemState | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionSystemState | undefined;
  pqControls?: PqControlsSystemState | undefined;
};

export type MetadatumSystemState = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Creates events based on entries collected from the hosts file
 */
export type HostsFile = {
  enable?: boolean | undefined;
};

/**
 * Creates events for each of the hosts network interfaces
 */
export type Interfaces = {
  enable?: boolean | undefined;
};

/**
 * Creates events for physical disks, partitions, and file systems
 */
export type DisksAndFileSystems = {
  enable?: boolean | undefined;
};

/**
 * Creates events based on the host systems current state
 */
export type HostInfo = {
  enable?: boolean | undefined;
};

/**
 * Creates events based on entries collected from the hosts network routes
 */
export type InputRoutes = {
  enable?: boolean | undefined;
};

/**
 * Creates events for DNS resolvers and search entries
 */
export type Dns = {
  enable?: boolean | undefined;
};

/**
 * Creates events for local users and groups
 */
export type UsersAndGroups = {
  enable?: boolean | undefined;
};

/**
 * Creates events for Firewall rules entries
 */
export type Firewall = {
  enable?: boolean | undefined;
};

/**
 * Creates events from the list of services
 */
export type Services = {
  enable?: boolean | undefined;
};

/**
 * Creates events from list of listening ports
 */
export type ListeningPorts = {
  enable?: boolean | undefined;
};

/**
 * Creates events from list of logged-in users
 */
export type LoggedInUsers = {
  enable?: boolean | undefined;
};

export type Collectors = {
  /**
   * Creates events based on entries collected from the hosts file
   */
  hostsfile?: HostsFile | undefined;
  /**
   * Creates events for each of the hosts network interfaces
   */
  interfaces?: Interfaces | undefined;
  /**
   * Creates events for physical disks, partitions, and file systems
   */
  disk?: DisksAndFileSystems | undefined;
  /**
   * Creates events based on the host systems current state
   */
  metadata?: HostInfo | undefined;
  /**
   * Creates events based on entries collected from the hosts network routes
   */
  routes?: InputRoutes | undefined;
  /**
   * Creates events for DNS resolvers and search entries
   */
  dns?: Dns | undefined;
  /**
   * Creates events for local users and groups
   */
  user?: UsersAndGroups | undefined;
  /**
   * Creates events for Firewall rules entries
   */
  firewall?: Firewall | undefined;
  /**
   * Creates events from the list of services
   */
  services?: Services | undefined;
  /**
   * Creates events from list of listening ports
   */
  ports?: ListeningPorts | undefined;
  /**
   * Creates events from list of logged-in users
   */
  loginUsers?: LoggedInUsers | undefined;
};

export const DataCompressionFormatSystemState = {
  None: "none",
  Gzip: "gzip",
} as const;
export type DataCompressionFormatSystemState = OpenEnum<
  typeof DataCompressionFormatSystemState
>;

export type PersistenceSystemState = {
  /**
   * Spool metrics to disk for Cribl Edge and Search
   */
  enable?: boolean | undefined;
  /**
   * Time span for each file bucket
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: DataCompressionFormatSystemState | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state
   */
  destPath?: string | undefined;
};

export type InputSystemState = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeSystemState;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSystemState> | undefined;
  pq?: PqSystemState | undefined;
  /**
   * Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes).
   */
  interval?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSystemState> | undefined;
  collectors?: Collectors | undefined;
  persistence?: PersistenceSystemState | undefined;
  /**
   * Enable to use built-in tools (PowerShell) to collect events instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)
   */
  disableNativeModule?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSystemMetrics = {
  SystemMetrics: "system_metrics",
} as const;
export type TypeSystemMetrics = ClosedEnum<typeof TypeSystemMetrics>;

export type ConnectionSystemMetrics = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeSystemMetrics = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeSystemMetrics = OpenEnum<typeof PqModeSystemMetrics>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSystemMetrics = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSystemMetrics = OpenEnum<
  typeof CompressionSystemMetrics
>;

export type PqControlsSystemMetrics = {};

export type PqSystemMetrics = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeSystemMetrics | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionSystemMetrics | undefined;
  pqControls?: PqControlsSystemMetrics | undefined;
};

/**
 * Select level of detail for host metrics
 */
export const HostModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select level of detail for host metrics
 */
export type HostModeSystemMetrics = OpenEnum<typeof HostModeSystemMetrics>;

/**
 * Select the level of detail for system metrics
 */
export const SystemModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for system metrics
 */
export type SystemModeSystemMetrics = OpenEnum<typeof SystemModeSystemMetrics>;

export type SystemSystemMetrics = {
  /**
   * Select the level of detail for system metrics
   */
  mode?: SystemModeSystemMetrics | undefined;
  /**
   * Generate metrics for the numbers of processes in various states
   */
  processes?: boolean | undefined;
};

/**
 * Select the level of detail for CPU metrics
 */
export const CpuModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for CPU metrics
 */
export type CpuModeSystemMetrics = OpenEnum<typeof CpuModeSystemMetrics>;

export type CpuSystemMetrics = {
  /**
   * Select the level of detail for CPU metrics
   */
  mode?: CpuModeSystemMetrics | undefined;
  /**
   * Generate metrics for each CPU
   */
  perCpu?: boolean | undefined;
  /**
   * Generate metrics for all CPU states
   */
  detail?: boolean | undefined;
  /**
   * Generate raw, monotonic CPU time counters
   */
  time?: boolean | undefined;
};

/**
 * Select the level of detail for memory metrics
 */
export const MemoryModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for memory metrics
 */
export type MemoryModeSystemMetrics = OpenEnum<typeof MemoryModeSystemMetrics>;

export type MemorySystemMetrics = {
  /**
   * Select the level of detail for memory metrics
   */
  mode?: MemoryModeSystemMetrics | undefined;
  /**
   * Generate metrics for all memory states
   */
  detail?: boolean | undefined;
};

/**
 * Select the level of detail for network metrics
 */
export const NetworkModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for network metrics
 */
export type NetworkModeSystemMetrics = OpenEnum<
  typeof NetworkModeSystemMetrics
>;

export type NetworkSystemMetrics = {
  /**
   * Select the level of detail for network metrics
   */
  mode?: NetworkModeSystemMetrics | undefined;
  /**
   * Generate full network metrics
   */
  detail?: boolean | undefined;
  /**
   * Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite
   */
  protocols?: boolean | undefined;
  /**
   * Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty.
   */
  devices?: Array<string> | undefined;
  /**
   * Generate separate metrics for each interface
   */
  perInterface?: boolean | undefined;
};

/**
 * Select the level of detail for disk metrics
 */
export const DiskModeSystemMetrics = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for disk metrics
 */
export type DiskModeSystemMetrics = OpenEnum<typeof DiskModeSystemMetrics>;

export type DiskSystemMetrics = {
  /**
   * Select the level of detail for disk metrics
   */
  mode?: DiskModeSystemMetrics | undefined;
  /**
   * Generate full disk metrics
   */
  detail?: boolean | undefined;
  /**
   * Generate filesystem inode metrics
   */
  inodes?: boolean | undefined;
  /**
   * Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty.
   */
  devices?: Array<string> | undefined;
  /**
   * Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty.
   */
  mountpoints?: Array<string> | undefined;
  /**
   * Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty.
   */
  fstypes?: Array<string> | undefined;
  /**
   * Generate separate metrics for each device
   */
  perDevice?: boolean | undefined;
};

export type CustomSystemMetrics = {
  system?: SystemSystemMetrics | undefined;
  cpu?: CpuSystemMetrics | undefined;
  memory?: MemorySystemMetrics | undefined;
  network?: NetworkSystemMetrics | undefined;
  disk?: DiskSystemMetrics | undefined;
};

export type HostSystemMetrics = {
  /**
   * Select level of detail for host metrics
   */
  mode?: HostModeSystemMetrics | undefined;
  custom?: CustomSystemMetrics | undefined;
};

export type SetSystemMetrics = {
  name: string;
  filter: string;
  includeChildren?: boolean | undefined;
};

export type ProcessSystemMetrics = {
  /**
   * Configure sets to collect process metrics
   */
  sets?: Array<SetSystemMetrics> | undefined;
};

/**
 * Select the level of detail for container metrics
 */
export const ContainerMode = {
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * All
   */
  All: "all",
  /**
   * Custom
   */
  Custom: "custom",
  /**
   * Disabled
   */
  Disabled: "disabled",
} as const;
/**
 * Select the level of detail for container metrics
 */
export type ContainerMode = OpenEnum<typeof ContainerMode>;

export type ContainerFilter = {
  expr: string;
};

export type Container = {
  /**
   * Select the level of detail for container metrics
   */
  mode?: ContainerMode | undefined;
  /**
   * Full paths for Docker's UNIX-domain socket
   */
  dockerSocket?: Array<string> | undefined;
  /**
   * Timeout, in seconds, for the Docker API
   */
  dockerTimeout?: number | undefined;
  /**
   * Containers matching any of these will be included. All are included if no filters are added.
   */
  filters?: Array<ContainerFilter> | undefined;
  /**
   * Include stopped and paused containers
   */
  allContainers?: boolean | undefined;
  /**
   * Generate separate metrics for each device
   */
  perDevice?: boolean | undefined;
  /**
   * Generate full container metrics
   */
  detail?: boolean | undefined;
};

export type MetadatumSystemMetrics = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export const DataCompressionFormatSystemMetrics = {
  None: "none",
  Gzip: "gzip",
} as const;
export type DataCompressionFormatSystemMetrics = OpenEnum<
  typeof DataCompressionFormatSystemMetrics
>;

export type PersistenceSystemMetrics = {
  /**
   * Spool metrics to disk for Cribl Edge and Search
   */
  enable?: boolean | undefined;
  /**
   * Time span for each file bucket
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
   */
  maxDataTime?: string | undefined;
  compress?: DataCompressionFormatSystemMetrics | undefined;
  /**
   * Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics
   */
  destPath?: string | undefined;
};

export type InputSystemMetrics = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeSystemMetrics;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSystemMetrics> | undefined;
  pq?: PqSystemMetrics | undefined;
  /**
   * Time, in seconds, between consecutive metric collections. Default is 10 seconds.
   */
  interval?: number | undefined;
  host?: HostSystemMetrics | undefined;
  process?: ProcessSystemMetrics | undefined;
  container?: Container | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSystemMetrics> | undefined;
  persistence?: PersistenceSystemMetrics | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeTcpjson = {
  Tcpjson: "tcpjson",
} as const;
export type InputTypeTcpjson = ClosedEnum<typeof InputTypeTcpjson>;

export type ConnectionTcpjson = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeTcpjson = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeTcpjson = OpenEnum<typeof PqModeTcpjson>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionTcpjson = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionTcpjson = OpenEnum<typeof PqCompressionTcpjson>;

export type InputPqControlsTcpjson = {};

export type PqTcpjson = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeTcpjson | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionTcpjson | undefined;
  pqControls?: InputPqControlsTcpjson | undefined;
};

export const InputMinimumTLSVersionTcpjson = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionTcpjson = OpenEnum<
  typeof InputMinimumTLSVersionTcpjson
>;

export const InputMaximumTLSVersionTcpjson = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionTcpjson = OpenEnum<
  typeof InputMaximumTLSVersionTcpjson
>;

export type TLSSettingsServerSideTcpjson = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionTcpjson | undefined;
  maxVersion?: InputMaximumTLSVersionTcpjson | undefined;
};

export type MetadatumTcpjson = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const InputAuthenticationMethodTcpjson = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type InputAuthenticationMethodTcpjson = OpenEnum<
  typeof InputAuthenticationMethodTcpjson
>;

export type InputTcpjson = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeTcpjson;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionTcpjson> | undefined;
  pq?: PqTcpjson | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideTcpjson | undefined;
  /**
   * Regex matching IP addresses that are allowed to establish a connection
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  /**
   * Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumTcpjson> | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: InputAuthenticationMethodTcpjson | undefined;
  description?: string | undefined;
  /**
   * Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
   */
  authToken?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCriblLakeHTTP = {
  CriblLakeHttp: "cribl_lake_http",
} as const;
export type TypeCriblLakeHTTP = ClosedEnum<typeof TypeCriblLakeHTTP>;

export type ConnectionCriblLakeHTTP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCriblLakeHTTP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCriblLakeHTTP = OpenEnum<typeof ModeCriblLakeHTTP>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCriblLakeHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCriblLakeHTTP = OpenEnum<
  typeof CompressionCriblLakeHTTP
>;

export type PqControlsCriblLakeHTTP = {};

export type PqCriblLakeHTTP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCriblLakeHTTP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCriblLakeHTTP | undefined;
  pqControls?: PqControlsCriblLakeHTTP | undefined;
};

export const MinimumTLSVersionCriblLakeHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionCriblLakeHTTP = OpenEnum<
  typeof MinimumTLSVersionCriblLakeHTTP
>;

export const MaximumTLSVersionCriblLakeHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionCriblLakeHTTP = OpenEnum<
  typeof MaximumTLSVersionCriblLakeHTTP
>;

export type TLSSettingsServerSideCriblLakeHTTP = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionCriblLakeHTTP | undefined;
  maxVersion?: MaximumTLSVersionCriblLakeHTTP | undefined;
};

export type MetadatumCriblLakeHTTP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtMetadatumCriblLakeHTTP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type SplunkHecMetadata = {
  enabled?: boolean | undefined;
};

export type ElasticsearchMetadata = {
  enabled?: boolean | undefined;
};

export type AuthTokensExtCriblLakeHTTP = {
  token: string;
  description?: string | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokensExtMetadatumCriblLakeHTTP> | undefined;
  splunkHecMetadata?: SplunkHecMetadata | undefined;
  elasticsearchMetadata?: ElasticsearchMetadata | undefined;
};

export type InputCriblLakeHttp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeCriblLakeHTTP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCriblLakeHTTP> | undefined;
  pq?: PqCriblLakeHTTP | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideCriblLakeHTTP | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
   */
  criblAPI?: string | undefined;
  /**
   * Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
   */
  elasticAPI?: string | undefined;
  /**
   * Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
   */
  splunkHecAPI?: string | undefined;
  splunkHecAcks?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCriblLakeHTTP> | undefined;
  authTokensExt?: Array<AuthTokensExtCriblLakeHTTP> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeCriblHTTP = {
  CriblHttp: "cribl_http",
} as const;
export type InputTypeCriblHTTP = ClosedEnum<typeof InputTypeCriblHTTP>;

export type ConnectionCriblHTTP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeCriblHTTP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeCriblHTTP = OpenEnum<typeof PqModeCriblHTTP>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionCriblHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionCriblHTTP = OpenEnum<typeof PqCompressionCriblHTTP>;

export type InputPqControlsCriblHTTP = {};

export type PqCriblHTTP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeCriblHTTP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionCriblHTTP | undefined;
  pqControls?: InputPqControlsCriblHTTP | undefined;
};

export type InputAuthTokenCriblHTTP = {
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  enabled?: boolean | undefined;
  /**
   * Optional token description
   */
  description?: string | undefined;
};

export const InputMinimumTLSVersionCriblHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionCriblHTTP = OpenEnum<
  typeof InputMinimumTLSVersionCriblHTTP
>;

export const InputMaximumTLSVersionCriblHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionCriblHTTP = OpenEnum<
  typeof InputMaximumTLSVersionCriblHTTP
>;

export type TLSSettingsServerSideCriblHTTP = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionCriblHTTP | undefined;
  maxVersion?: InputMaximumTLSVersionCriblHTTP | undefined;
};

export type MetadatumCriblHTTP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputCriblHttp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeCriblHTTP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCriblHTTP> | undefined;
  pq?: PqCriblHTTP | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl HTTP destinations in connected environments.
   */
  authTokens?: Array<InputAuthTokenCriblHTTP> | undefined;
  tls?: TLSSettingsServerSideCriblHTTP | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCriblHTTP> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeCriblTCP = {
  CriblTcp: "cribl_tcp",
} as const;
export type InputTypeCriblTCP = ClosedEnum<typeof InputTypeCriblTCP>;

export type ConnectionCriblTCP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeCriblTCP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeCriblTCP = OpenEnum<typeof PqModeCriblTCP>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionCriblTCP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionCriblTCP = OpenEnum<typeof PqCompressionCriblTCP>;

export type InputPqControlsCriblTCP = {};

export type PqCriblTCP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeCriblTCP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionCriblTCP | undefined;
  pqControls?: InputPqControlsCriblTCP | undefined;
};

export const InputMinimumTLSVersionCriblTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionCriblTCP = OpenEnum<
  typeof InputMinimumTLSVersionCriblTCP
>;

export const InputMaximumTLSVersionCriblTCP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionCriblTCP = OpenEnum<
  typeof InputMaximumTLSVersionCriblTCP
>;

export type TLSSettingsServerSideCriblTCP = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionCriblTCP | undefined;
  maxVersion?: InputMaximumTLSVersionCriblTCP | undefined;
};

export type MetadatumCriblTCP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputAuthTokenCriblTCP = {
  /**
   * Select or create a stored text secret
   */
  tokenSecret: string;
  enabled?: boolean | undefined;
  /**
   * Optional token description
   */
  description?: string | undefined;
};

export type InputCriblTcp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeCriblTCP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCriblTCP> | undefined;
  pq?: PqCriblTCP | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideCriblTCP | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  /**
   * Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCriblTCP> | undefined;
  /**
   * Load balance traffic across all Worker Processes
   */
  enableLoadBalancing?: boolean | undefined;
  /**
   * Shared secrets to be used by connected environments to authorize connections. These tokens should be installed in Cribl TCP destinations in connected environments.
   */
  authTokens?: Array<InputAuthTokenCriblTCP> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeCribl = {
  Cribl: "cribl",
} as const;
export type TypeCribl = ClosedEnum<typeof TypeCribl>;

export type ConnectionCribl = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCribl = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCribl = OpenEnum<typeof ModeCribl>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCribl = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCribl = OpenEnum<typeof CompressionCribl>;

export type PqControlsCribl = {};

export type PqCribl = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCribl | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCribl | undefined;
  pqControls?: PqControlsCribl | undefined;
};

export type MetadatumCribl = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputCribl = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeCribl;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCribl> | undefined;
  pq?: PqCribl | undefined;
  filter?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCribl> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeGooglePubsub = {
  GooglePubsub: "google_pubsub",
} as const;
export type InputTypeGooglePubsub = ClosedEnum<typeof InputTypeGooglePubsub>;

export type ConnectionGooglePubsub = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeGooglePubsub = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeGooglePubsub = OpenEnum<typeof PqModeGooglePubsub>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionGooglePubsub = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionGooglePubsub = OpenEnum<
  typeof PqCompressionGooglePubsub
>;

export type InputPqControlsGooglePubsub = {};

export type PqGooglePubsub = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeGooglePubsub | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionGooglePubsub | undefined;
  pqControls?: InputPqControlsGooglePubsub | undefined;
};

/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export const InputGoogleAuthenticationMethod = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret
   */
  Secret: "secret",
} as const;
/**
 * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
 */
export type InputGoogleAuthenticationMethod = OpenEnum<
  typeof InputGoogleAuthenticationMethod
>;

export type MetadatumGooglePubsub = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputGooglePubsub = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeGooglePubsub;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionGooglePubsub> | undefined;
  pq?: PqGooglePubsub | undefined;
  /**
   * ID of the topic to receive events from. When Monitor subscription is enabled, any value may be entered.
   */
  topicName?: string | undefined;
  /**
   * ID of the subscription to use when receiving events. When Monitor subscription is enabled, the fully qualified subscription name must be entered. Example: projects/myProject/subscriptions/mySubscription
   */
  subscriptionName: string;
  /**
   * Use when the subscription is not created by this Source and topic is not known
   */
  monitorSubscription?: boolean | undefined;
  /**
   * Create topic if it does not exist
   */
  createTopic?: boolean | undefined;
  /**
   * Create subscription if it does not exist
   */
  createSubscription?: boolean | undefined;
  /**
   * Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
   */
  region?: string | undefined;
  /**
   * Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
   */
  googleAuthMethod?: InputGoogleAuthenticationMethod | undefined;
  /**
   * Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
   */
  serviceAccountCredentials?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  secret?: string | undefined;
  /**
   * If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events
   */
  maxBacklog?: number | undefined;
  /**
   * How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
   */
  concurrency?: number | undefined;
  /**
   * Pull request timeout, in milliseconds
   */
  requestTimeout?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumGooglePubsub> | undefined;
  description?: string | undefined;
  /**
   * Receive events in the order they were added to the queue. The process sending events must have ordering enabled.
   */
  orderedDelivery?: boolean | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeFirehose = {
  Firehose: "firehose",
} as const;
export type TypeFirehose = ClosedEnum<typeof TypeFirehose>;

export type ConnectionFirehose = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeFirehose = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeFirehose = OpenEnum<typeof ModeFirehose>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionFirehose = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionFirehose = OpenEnum<typeof CompressionFirehose>;

export type PqControlsFirehose = {};

export type PqFirehose = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeFirehose | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionFirehose | undefined;
  pqControls?: PqControlsFirehose | undefined;
};

export const MinimumTLSVersionFirehose = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionFirehose = OpenEnum<
  typeof MinimumTLSVersionFirehose
>;

export const MaximumTLSVersionFirehose = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionFirehose = OpenEnum<
  typeof MaximumTLSVersionFirehose
>;

export type TLSSettingsServerSideFirehose = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionFirehose | undefined;
  maxVersion?: MaximumTLSVersionFirehose | undefined;
};

export type MetadatumFirehose = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputFirehose = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeFirehose;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionFirehose> | undefined;
  pq?: PqFirehose | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideFirehose | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumFirehose> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputExecType = {
  Exec: "exec",
} as const;
export type InputExecType = ClosedEnum<typeof InputExecType>;

export type InputExecConnection = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputExecMode = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputExecMode = OpenEnum<typeof InputExecMode>;

/**
 * Codec to use to compress the persisted data
 */
export const InputExecCompression = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputExecCompression = OpenEnum<typeof InputExecCompression>;

export type InputExecPqControls = {};

export type InputExecPq = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputExecMode | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputExecCompression | undefined;
  pqControls?: InputExecPqControls | undefined;
};

/**
 * Select a schedule type; either an interval (in seconds) or a cron-style schedule.
 */
export const ScheduleType = {
  Interval: "interval",
  CronSchedule: "cronSchedule",
} as const;
/**
 * Select a schedule type; either an interval (in seconds) or a cron-style schedule.
 */
export type ScheduleType = OpenEnum<typeof ScheduleType>;

export type InputExecMetadatum = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputExec = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputExecType;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputExecConnection> | undefined;
  pq?: InputExecPq | undefined;
  /**
   * Command to execute; supports Bourne shell (or CMD on Windows) syntax
   */
  command: string;
  /**
   * Maximum number of retry attempts in the event that the command fails
   */
  retries?: number | undefined;
  /**
   * Select a schedule type; either an interval (in seconds) or a cron-style schedule.
   */
  scheduleType?: ScheduleType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputExecMetadatum> | undefined;
  description?: string | undefined;
  /**
   * Interval between command executions in seconds.
   */
  interval?: number | undefined;
  /**
   * Cron schedule to execute the command on.
   */
  cronSchedule?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeEventhub = {
  Eventhub: "eventhub",
} as const;
export type TypeEventhub = ClosedEnum<typeof TypeEventhub>;

export type ConnectionEventhub = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeEventhub = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeEventhub = OpenEnum<typeof ModeEventhub>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionEventhub = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionEventhub = OpenEnum<typeof CompressionEventhub>;

export type PqControlsEventhub = {};

export type PqEventhub = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeEventhub | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionEventhub | undefined;
  pqControls?: PqControlsEventhub | undefined;
};

/**
 * Enter password directly, or select a stored secret
 */
export const AuthTypeAuthenticationMethodEventhub = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter password directly, or select a stored secret
 */
export type AuthTypeAuthenticationMethodEventhub = OpenEnum<
  typeof AuthTypeAuthenticationMethodEventhub
>;

export const SASLMechanismEventhub = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * OAUTHBEARER
   */
  Oauthbearer: "oauthbearer",
} as const;
export type SASLMechanismEventhub = OpenEnum<typeof SASLMechanismEventhub>;

export const ClientSecretAuthTypeAuthenticationMethodEventhub = {
  Manual: "manual",
  Secret: "secret",
  Certificate: "certificate",
} as const;
export type ClientSecretAuthTypeAuthenticationMethodEventhub = OpenEnum<
  typeof ClientSecretAuthTypeAuthenticationMethodEventhub
>;

/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export const InputMicrosoftEntraIDAuthenticationEndpoint = {
  HttpsLoginMicrosoftonlineCom: "https://login.microsoftonline.com",
  HttpsLoginMicrosoftonlineUs: "https://login.microsoftonline.us",
  HttpsLoginPartnerMicrosoftonlineCn:
    "https://login.partner.microsoftonline.cn",
} as const;
/**
 * Endpoint used to acquire authentication tokens from Azure
 */
export type InputMicrosoftEntraIDAuthenticationEndpoint = OpenEnum<
  typeof InputMicrosoftEntraIDAuthenticationEndpoint
>;

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type AuthenticationEventhub = {
  disabled?: boolean | undefined;
  /**
   * Enter password directly, or select a stored secret
   */
  authType?: AuthTypeAuthenticationMethodEventhub | undefined;
  /**
   * Connection-string primary key, or connection-string secondary key, from the Event Hubs workspace
   */
  password?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  mechanism?: SASLMechanismEventhub | undefined;
  /**
   * The username for authentication. For Event Hubs, this should always be $ConnectionString.
   */
  username?: string | undefined;
  clientSecretAuthType?:
    | ClientSecretAuthTypeAuthenticationMethodEventhub
    | undefined;
  /**
   * client_secret to pass in the OAuth request parameter
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Select or create a stored certificate
   */
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  /**
   * Endpoint used to acquire authentication tokens from Azure
   */
  oauthEndpoint?: InputMicrosoftEntraIDAuthenticationEndpoint | undefined;
  /**
   * client_id to pass in the OAuth request parameter
   */
  clientId?: string | undefined;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory
   */
  tenantId?: string | undefined;
  /**
   * Scope to pass in the OAuth request parameter
   */
  scope?: string | undefined;
};

export type TLSSettingsClientSideEventhub = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
};

export type MetadatumEventhub = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputEventhub = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeEventhub;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionEventhub> | undefined;
  pq?: PqEventhub | undefined;
  /**
   * List of Event Hubs Kafka brokers to connect to (example: yourdomain.servicebus.windows.net:9093). The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
   */
  brokers: Array<string>;
  /**
   * The name of the Event Hub (Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
   */
  topics: Array<string>;
  /**
   * The consumer group this instance belongs to. Default is 'Cribl'.
   */
  groupId?: string | undefined;
  /**
   * Start reading from earliest available data; relevant only during initial subscription
   */
  fromBeginning?: boolean | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: AuthenticationEventhub | undefined;
  tls?: TLSSettingsClientSideEventhub | undefined;
  /**
   *       Timeout (session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group-management facilities.
   *
   * @remarks
   *       If the client sends no heartbeats to the broker before the timeout expires, the broker will remove the client from the group and initiate a rebalance.
   *       Value must be lower than rebalanceTimeout.
   *       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  sessionTimeout?: number | undefined;
  /**
   *       Maximum allowed time (rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance begins.
   *
   * @remarks
   *       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
   *       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  rebalanceTimeout?: number | undefined;
  /**
   *       Expected time (heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
   *
   * @remarks
   *       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
   *       See [Recommended configurations](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
   */
  heartbeatInterval?: number | undefined;
  /**
   * How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitInterval?: number | undefined;
  /**
   * How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitThreshold?: number | undefined;
  /**
   * Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
   */
  maxBytesPerPartition?: number | undefined;
  /**
   * Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
   */
  maxBytes?: number | undefined;
  /**
   * Maximum number of network errors before the consumer re-creates a socket
   */
  maxSocketErrors?: number | undefined;
  /**
   * Minimize duplicate events by starting only one consumer for each topic partition
   */
  minimizeDuplicates?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumEventhub> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeOffice365MsgTrace = {
  Office365MsgTrace: "office365_msg_trace",
} as const;
export type TypeOffice365MsgTrace = ClosedEnum<typeof TypeOffice365MsgTrace>;

export type ConnectionOffice365MsgTrace = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeOffice365MsgTrace = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeOffice365MsgTrace = OpenEnum<typeof ModeOffice365MsgTrace>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionOffice365MsgTrace = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionOffice365MsgTrace = OpenEnum<
  typeof CompressionOffice365MsgTrace
>;

export type PqControlsOffice365MsgTrace = {};

export type PqOffice365MsgTrace = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeOffice365MsgTrace | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionOffice365MsgTrace | undefined;
  pqControls?: PqControlsOffice365MsgTrace | undefined;
};

/**
 * Select authentication method.
 */
export const AuthenticationMethodOffice365MsgTrace = {
  Manual: "manual",
  Secret: "secret",
  Oauth: "oauth",
  OauthSecret: "oauthSecret",
  OauthCert: "oauthCert",
} as const;
/**
 * Select authentication method.
 */
export type AuthenticationMethodOffice365MsgTrace = OpenEnum<
  typeof AuthenticationMethodOffice365MsgTrace
>;

/**
 * Log Level (verbosity) for collection runtime behavior.
 */
export const LogLevelOffice365MsgTrace = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
  Silly: "silly",
} as const;
/**
 * Log Level (verbosity) for collection runtime behavior.
 */
export type LogLevelOffice365MsgTrace = OpenEnum<
  typeof LogLevelOffice365MsgTrace
>;

export type MetadatumOffice365MsgTrace = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * The algorithm to use when performing HTTP retries
 */
export const RetryTypeOffice365MsgTrace = {
  /**
   * Disabled
   */
  None: "none",
  /**
   * Backoff
   */
  Backoff: "backoff",
  /**
   * Static
   */
  Static: "static",
} as const;
/**
 * The algorithm to use when performing HTTP retries
 */
export type RetryTypeOffice365MsgTrace = OpenEnum<
  typeof RetryTypeOffice365MsgTrace
>;

export type RetryRulesOffice365MsgTrace = {
  /**
   * The algorithm to use when performing HTTP retries
   */
  type?: RetryTypeOffice365MsgTrace | undefined;
  /**
   * Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
   */
  interval?: number | undefined;
  /**
   * The maximum number of times to retry a failed HTTP request
   */
  limit?: number | undefined;
  /**
   * Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
   */
  multiplier?: number | undefined;
  /**
   * List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
   */
  codes?: Array<number> | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
   */
  enableHeader?: boolean | undefined;
  /**
   * Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
   */
  retryConnectTimeout?: boolean | undefined;
  /**
   * Retry request when a connection reset (ECONNRESET) error occurs
   */
  retryConnectReset?: boolean | undefined;
};

/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export const SubscriptionPlanOffice365MsgTrace = {
  /**
   * Office 365 Enterprise
   */
  EnterpriseGcc: "enterprise_gcc",
  /**
   * Office 365 GCC
   */
  Gcc: "gcc",
  /**
   * Office 365 GCC High
   */
  GccHigh: "gcc_high",
  /**
   * Office 365 DoD
   */
  Dod: "dod",
} as const;
/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export type SubscriptionPlanOffice365MsgTrace = OpenEnum<
  typeof SubscriptionPlanOffice365MsgTrace
>;

export type CertOptions = {
  /**
   * The name of the predefined certificate.
   */
  certificateName?: string | undefined;
  /**
   * Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
   */
  privKeyPath: string;
  /**
   * Passphrase to use to decrypt the private key.
   */
  passphrase?: string | undefined;
  /**
   * Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
   */
  certPath: string;
};

export type InputOffice365MsgTrace = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeOffice365MsgTrace;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionOffice365MsgTrace> | undefined;
  pq?: PqOffice365MsgTrace | undefined;
  /**
   * URL to use when retrieving report data.
   */
  url?: string | undefined;
  /**
   * How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
   */
  interval?: number | undefined;
  /**
   * Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
   */
  startDate?: string | undefined;
  /**
   * Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
   */
  endDate?: string | undefined;
  /**
   * HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
   */
  timeout?: number | undefined;
  /**
   * Disables time filtering of events when a date range is specified.
   */
  disableTimeFilter?: boolean | undefined;
  /**
   * Select authentication method.
   */
  authType?: AuthenticationMethodOffice365MsgTrace | undefined;
  /**
   * Reschedule tasks that failed with non-fatal errors
   */
  rescheduleDroppedTasks?: boolean | undefined;
  /**
   * Maximum number of times a task can be rescheduled
   */
  maxTaskReschedule?: number | undefined;
  /**
   * Log Level (verbosity) for collection runtime behavior.
   */
  logLevel?: LogLevelOffice365MsgTrace | undefined;
  /**
   * Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumOffice365MsgTrace> | undefined;
  retryRules?: RetryRulesOffice365MsgTrace | undefined;
  description?: string | undefined;
  /**
   * Username to run Message Trace API call.
   */
  username?: string | undefined;
  /**
   * Password to run Message Trace API call.
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials.
   */
  credentialsSecret?: string | undefined;
  /**
   * client_secret to pass in the OAuth request parameter.
   */
  clientSecret?: string | undefined;
  /**
   * Directory ID (tenant identifier) in Azure Active Directory.
   */
  tenantId?: string | undefined;
  /**
   * client_id to pass in the OAuth request parameter.
   */
  clientId?: string | undefined;
  /**
   * Resource to pass in the OAuth request parameter.
   */
  resource?: string | undefined;
  /**
   * Office 365 subscription plan for your organization, typically Office 365 Enterprise
   */
  planType?: SubscriptionPlanOffice365MsgTrace | undefined;
  /**
   * Select or create a secret that references your client_secret to pass in the OAuth request parameter.
   */
  textSecret?: string | undefined;
  certOptions?: CertOptions | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeOffice365Service = {
  Office365Service: "office365_service",
} as const;
export type TypeOffice365Service = ClosedEnum<typeof TypeOffice365Service>;

export type ConnectionOffice365Service = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeOffice365Service = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeOffice365Service = OpenEnum<typeof ModeOffice365Service>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionOffice365Service = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionOffice365Service = OpenEnum<
  typeof CompressionOffice365Service
>;

export type PqControlsOffice365Service = {};

export type PqOffice365Service = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeOffice365Service | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionOffice365Service | undefined;
  pqControls?: PqControlsOffice365Service | undefined;
};

/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export const SubscriptionPlanOffice365Service = {
  /**
   * Office 365 Enterprise
   */
  EnterpriseGcc: "enterprise_gcc",
  /**
   * Office 365 GCC
   */
  Gcc: "gcc",
  /**
   * Office 365 GCC High
   */
  GccHigh: "gcc_high",
  /**
   * Office 365 DoD
   */
  Dod: "dod",
} as const;
/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export type SubscriptionPlanOffice365Service = OpenEnum<
  typeof SubscriptionPlanOffice365Service
>;

export type MetadatumOffice365Service = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Collector runtime Log Level
 */
export const LogLevelOffice365Service = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
} as const;
/**
 * Collector runtime Log Level
 */
export type LogLevelOffice365Service = OpenEnum<
  typeof LogLevelOffice365Service
>;

export type ContentConfigOffice365Service = {
  /**
   * Office 365 Services API Content Type
   */
  contentType?: string | undefined;
  /**
   * If interval type is minutes the value entered must evenly divisible by 60 or save will fail
   */
  description?: string | undefined;
  interval?: number | undefined;
  /**
   * Collector runtime Log Level
   */
  logLevel?: LogLevelOffice365Service | undefined;
  enabled?: boolean | undefined;
};

/**
 * The algorithm to use when performing HTTP retries
 */
export const RetryTypeOffice365Service = {
  /**
   * Disabled
   */
  None: "none",
  /**
   * Backoff
   */
  Backoff: "backoff",
  /**
   * Static
   */
  Static: "static",
} as const;
/**
 * The algorithm to use when performing HTTP retries
 */
export type RetryTypeOffice365Service = OpenEnum<
  typeof RetryTypeOffice365Service
>;

export type RetryRulesOffice365Service = {
  /**
   * The algorithm to use when performing HTTP retries
   */
  type?: RetryTypeOffice365Service | undefined;
  /**
   * Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
   */
  interval?: number | undefined;
  /**
   * The maximum number of times to retry a failed HTTP request
   */
  limit?: number | undefined;
  /**
   * Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
   */
  multiplier?: number | undefined;
  /**
   * List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
   */
  codes?: Array<number> | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
   */
  enableHeader?: boolean | undefined;
  /**
   * Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
   */
  retryConnectTimeout?: boolean | undefined;
  /**
   * Retry request when a connection reset (ECONNRESET) error occurs
   */
  retryConnectReset?: boolean | undefined;
};

/**
 * Enter client secret directly, or select a stored secret
 */
export const AuthenticationMethodOffice365Service = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter client secret directly, or select a stored secret
 */
export type AuthenticationMethodOffice365Service = OpenEnum<
  typeof AuthenticationMethodOffice365Service
>;

export type InputOffice365Service = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeOffice365Service;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionOffice365Service> | undefined;
  pq?: PqOffice365Service | undefined;
  /**
   * Office 365 subscription plan for your organization, typically Office 365 Enterprise
   */
  planType?: SubscriptionPlanOffice365Service | undefined;
  /**
   * Office 365 Azure Tenant ID
   */
  tenantId: string;
  /**
   * Office 365 Azure Application ID
   */
  appId: string;
  /**
   * HTTP request inactivity timeout, use 0 to disable
   */
  timeout?: number | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumOffice365Service> | undefined;
  /**
   * Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: * /${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
   */
  contentConfig?: Array<ContentConfigOffice365Service> | undefined;
  retryRules?: RetryRulesOffice365Service | undefined;
  /**
   * Enter client secret directly, or select a stored secret
   */
  authType?: AuthenticationMethodOffice365Service | undefined;
  description?: string | undefined;
  /**
   * Office 365 Azure client secret
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeOffice365Mgmt = {
  Office365Mgmt: "office365_mgmt",
} as const;
export type TypeOffice365Mgmt = ClosedEnum<typeof TypeOffice365Mgmt>;

export type ConnectionOffice365Mgmt = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeOffice365Mgmt = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeOffice365Mgmt = OpenEnum<typeof ModeOffice365Mgmt>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionOffice365Mgmt = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionOffice365Mgmt = OpenEnum<
  typeof CompressionOffice365Mgmt
>;

export type PqControlsOffice365Mgmt = {};

export type PqOffice365Mgmt = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeOffice365Mgmt | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionOffice365Mgmt | undefined;
  pqControls?: PqControlsOffice365Mgmt | undefined;
};

/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export const SubscriptionPlanOffice365Mgmt = {
  /**
   * Office 365 Enterprise
   */
  EnterpriseGcc: "enterprise_gcc",
  /**
   * Office 365 GCC
   */
  Gcc: "gcc",
  /**
   * Office 365 GCC High
   */
  GccHigh: "gcc_high",
  /**
   * Office 365 DoD
   */
  Dod: "dod",
} as const;
/**
 * Office 365 subscription plan for your organization, typically Office 365 Enterprise
 */
export type SubscriptionPlanOffice365Mgmt = OpenEnum<
  typeof SubscriptionPlanOffice365Mgmt
>;

export type MetadatumOffice365Mgmt = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Collector runtime Log Level
 */
export const LogLevelOffice365Mgmt = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
} as const;
/**
 * Collector runtime Log Level
 */
export type LogLevelOffice365Mgmt = OpenEnum<typeof LogLevelOffice365Mgmt>;

export type ContentConfigOffice365Mgmt = {
  /**
   * Office 365 Management Activity API Content Type
   */
  contentType?: string | undefined;
  /**
   * If interval type is minutes the value entered must evenly divisible by 60 or save will fail
   */
  description?: string | undefined;
  interval?: number | undefined;
  /**
   * Collector runtime Log Level
   */
  logLevel?: LogLevelOffice365Mgmt | undefined;
  enabled?: boolean | undefined;
};

/**
 * The algorithm to use when performing HTTP retries
 */
export const RetryTypeOffice365Mgmt = {
  /**
   * Disabled
   */
  None: "none",
  /**
   * Backoff
   */
  Backoff: "backoff",
  /**
   * Static
   */
  Static: "static",
} as const;
/**
 * The algorithm to use when performing HTTP retries
 */
export type RetryTypeOffice365Mgmt = OpenEnum<typeof RetryTypeOffice365Mgmt>;

export type RetryRulesOffice365Mgmt = {
  /**
   * The algorithm to use when performing HTTP retries
   */
  type?: RetryTypeOffice365Mgmt | undefined;
  /**
   * Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
   */
  interval?: number | undefined;
  /**
   * The maximum number of times to retry a failed HTTP request
   */
  limit?: number | undefined;
  /**
   * Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
   */
  multiplier?: number | undefined;
  /**
   * List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
   */
  codes?: Array<number> | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
   */
  enableHeader?: boolean | undefined;
  /**
   * Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
   */
  retryConnectTimeout?: boolean | undefined;
  /**
   * Retry request when a connection reset (ECONNRESET) error occurs
   */
  retryConnectReset?: boolean | undefined;
};

/**
 * Enter client secret directly, or select a stored secret
 */
export const AuthenticationMethodOffice365Mgmt = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter client secret directly, or select a stored secret
 */
export type AuthenticationMethodOffice365Mgmt = OpenEnum<
  typeof AuthenticationMethodOffice365Mgmt
>;

export type InputOffice365Mgmt = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeOffice365Mgmt;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionOffice365Mgmt> | undefined;
  pq?: PqOffice365Mgmt | undefined;
  /**
   * Office 365 subscription plan for your organization, typically Office 365 Enterprise
   */
  planType?: SubscriptionPlanOffice365Mgmt | undefined;
  /**
   * Office 365 Azure Tenant ID
   */
  tenantId: string;
  /**
   * Office 365 Azure Application ID
   */
  appId: string;
  /**
   * HTTP request inactivity timeout, use 0 to disable
   */
  timeout?: number | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumOffice365Mgmt> | undefined;
  /**
   * Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
   */
  publisherIdentifier?: string | undefined;
  /**
   * Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: * /${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
   */
  contentConfig?: Array<ContentConfigOffice365Mgmt> | undefined;
  /**
   * Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
   */
  ingestionLag?: number | undefined;
  retryRules?: RetryRulesOffice365Mgmt | undefined;
  /**
   * Enter client secret directly, or select a stored secret
   */
  authType?: AuthenticationMethodOffice365Mgmt | undefined;
  description?: string | undefined;
  /**
   * Office 365 Azure client secret
   */
  clientSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeEdgePrometheus = {
  EdgePrometheus: "edge_prometheus",
} as const;
export type TypeEdgePrometheus = ClosedEnum<typeof TypeEdgePrometheus>;

export type ConnectionEdgePrometheus = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeEdgePrometheus = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeEdgePrometheus = OpenEnum<typeof ModeEdgePrometheus>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionEdgePrometheus = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionEdgePrometheus = OpenEnum<
  typeof PqCompressionEdgePrometheus
>;

export type PqControlsEdgePrometheus = {};

export type PqEdgePrometheus = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeEdgePrometheus | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionEdgePrometheus | undefined;
  pqControls?: PqControlsEdgePrometheus | undefined;
};

/**
 * Target discovery mechanism. Use static to manually enter a list of targets.
 */
export const DiscoveryTypeEdgePrometheus = {
  /**
   * Static
   */
  Static: "static",
  /**
   * DNS
   */
  Dns: "dns",
  /**
   * AWS EC2
   */
  Ec2: "ec2",
  /**
   * Kubernetes Node
   */
  K8sNode: "k8s-node",
  /**
   * Kubernetes Pods
   */
  K8sPods: "k8s-pods",
} as const;
/**
 * Target discovery mechanism. Use static to manually enter a list of targets.
 */
export type DiscoveryTypeEdgePrometheus = OpenEnum<
  typeof DiscoveryTypeEdgePrometheus
>;

/**
 * Data compression format. Default is gzip.
 */
export const PersistenceCompressionEdgePrometheus = {
  None: "none",
  Gzip: "gzip",
} as const;
/**
 * Data compression format. Default is gzip.
 */
export type PersistenceCompressionEdgePrometheus = OpenEnum<
  typeof PersistenceCompressionEdgePrometheus
>;

export type DiskSpoolingEdgePrometheus = {
  /**
   * Spool events on disk for Cribl Edge and Search. Default is disabled.
   */
  enable?: boolean | undefined;
  /**
   * Time period for grouping spooled events. Default is 10m.
   */
  timeWindow?: string | undefined;
  /**
   * Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
   */
  maxDataSize?: string | undefined;
  /**
   * Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
   */
  maxDataTime?: string | undefined;
  /**
   * Data compression format. Default is gzip.
   */
  compress?: PersistenceCompressionEdgePrometheus | undefined;
};

export type MetadatumEdgePrometheus = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const AuthTypeAuthenticationMethodEdgePrometheus = {
  Manual: "manual",
  Secret: "secret",
  Kubernetes: "kubernetes",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type AuthTypeAuthenticationMethodEdgePrometheus = OpenEnum<
  typeof AuthTypeAuthenticationMethodEdgePrometheus
>;

/**
 * Protocol to use when collecting metrics
 */
export const TargetProtocol = {
  Http: "http",
  Https: "https",
} as const;
/**
 * Protocol to use when collecting metrics
 */
export type TargetProtocol = OpenEnum<typeof TargetProtocol>;

export type Target = {
  /**
   * Protocol to use when collecting metrics
   */
  protocol?: TargetProtocol | undefined;
  /**
   * Name of host from which to pull metrics.
   */
  host: string;
  /**
   * The port number in the metrics URL for discovered targets.
   */
  port?: number | undefined;
  /**
   * Path to use when collecting metrics from discovered targets
   */
  path?: string | undefined;
};

/**
 * DNS Record type to resolve
 */
export const RecordTypeEdgePrometheus = {
  Srv: "SRV",
  A: "A",
  Aaaa: "AAAA",
} as const;
/**
 * DNS Record type to resolve
 */
export type RecordTypeEdgePrometheus = OpenEnum<
  typeof RecordTypeEdgePrometheus
>;

/**
 * Protocol to use when collecting metrics
 */
export const ScrapeProtocolProtocol = {
  Http: "http",
  Https: "https",
} as const;
/**
 * Protocol to use when collecting metrics
 */
export type ScrapeProtocolProtocol = OpenEnum<typeof ScrapeProtocolProtocol>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AwsAuthenticationMethodAuthenticationMethodEdgePrometheus =
  OpenEnum<typeof AwsAuthenticationMethodAuthenticationMethodEdgePrometheus>;

export type SearchFilterEdgePrometheus = {
  /**
   * Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
   */
  name: string;
  /**
   * Search Filter Values, if empty only "running" EC2 instances will be returned
   */
  values: Array<string>;
};

/**
 * Signature version to use for signing EC2 requests
 */
export const SignatureVersionEdgePrometheus = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing EC2 requests
 */
export type SignatureVersionEdgePrometheus = OpenEnum<
  typeof SignatureVersionEdgePrometheus
>;

export type PodFilter = {
  /**
   * JavaScript expression applied to pods objects. Return 'true' to include it.
   */
  filter: string;
  /**
   * Optional description of this rule's purpose
   */
  description?: string | undefined;
};

export type InputEdgePrometheus = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeEdgePrometheus;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionEdgePrometheus> | undefined;
  pq?: PqEdgePrometheus | undefined;
  /**
   * Other dimensions to include in events
   */
  dimensionList?: Array<string> | undefined;
  /**
   * Target discovery mechanism. Use static to manually enter a list of targets.
   */
  discoveryType?: DiscoveryTypeEdgePrometheus | undefined;
  /**
   * How often in seconds to scrape targets for metrics.
   */
  interval?: number | undefined;
  /**
   * Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
   */
  timeout?: number | undefined;
  persistence?: DiskSpoolingEdgePrometheus | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumEdgePrometheus> | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: AuthTypeAuthenticationMethodEdgePrometheus | undefined;
  description?: string | undefined;
  targets?: Array<Target> | undefined;
  /**
   * DNS Record type to resolve
   */
  recordType?: RecordTypeEdgePrometheus | undefined;
  /**
   * The port number in the metrics URL for discovered targets.
   */
  scrapePort?: number | undefined;
  /**
   * List of DNS names to resolve
   */
  nameList?: Array<string> | undefined;
  /**
   * Protocol to use when collecting metrics
   */
  scrapeProtocol?: ScrapeProtocolProtocol | undefined;
  /**
   * Path to use when collecting metrics from discovered targets
   */
  scrapePath?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?:
    | AwsAuthenticationMethodAuthenticationMethodEdgePrometheus
    | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Use public IP address for discovered targets. Set to false if the private IP address should be used.
   */
  usePublicIp?: boolean | undefined;
  /**
   * EC2 Instance Search Filter
   */
  searchFilter?: Array<SearchFilterEdgePrometheus> | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the EC2 is located
   */
  region?: string | undefined;
  /**
   * EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing EC2 requests
   */
  signatureVersion?: SignatureVersionEdgePrometheus | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access EC2
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Protocol to use when collecting metrics
   */
  scrapeProtocolExpr?: string | undefined;
  /**
   * The port number in the metrics URL for discovered targets.
   */
  scrapePortExpr?: string | undefined;
  /**
   * Path to use when collecting metrics from discovered targets
   */
  scrapePathExpr?: string | undefined;
  /**
   *   Add rules to decide which pods to discover for metrics.
   *
   * @remarks
   *   Pods are searched if no rules are given or of all the rules'
   *   expressions evaluate to true.
   */
  podFilter?: Array<PodFilter> | undefined;
  /**
   * Username for Prometheus Basic authentication
   */
  username?: string | undefined;
  /**
   * Password for Prometheus Basic authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypePrometheus = {
  Prometheus: "prometheus",
} as const;
export type InputTypePrometheus = ClosedEnum<typeof InputTypePrometheus>;

export type ConnectionPrometheus = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModePrometheus = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModePrometheus = OpenEnum<typeof PqModePrometheus>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionPrometheus = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionPrometheus = OpenEnum<typeof PqCompressionPrometheus>;

export type InputPqControlsPrometheus = {};

export type PqPrometheus = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModePrometheus | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionPrometheus | undefined;
  pqControls?: InputPqControlsPrometheus | undefined;
};

/**
 * Target discovery mechanism. Use static to manually enter a list of targets.
 */
export const DiscoveryTypePrometheus = {
  /**
   * Static
   */
  Static: "static",
  /**
   * DNS
   */
  Dns: "dns",
  /**
   * AWS EC2
   */
  Ec2: "ec2",
} as const;
/**
 * Target discovery mechanism. Use static to manually enter a list of targets.
 */
export type DiscoveryTypePrometheus = OpenEnum<typeof DiscoveryTypePrometheus>;

/**
 * Collector runtime Log Level
 */
export const LogLevelPrometheus = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
} as const;
/**
 * Collector runtime Log Level
 */
export type LogLevelPrometheus = OpenEnum<typeof LogLevelPrometheus>;

export type MetadatumPrometheus = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const AuthTypeAuthenticationMethodPrometheus = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type AuthTypeAuthenticationMethodPrometheus = OpenEnum<
  typeof AuthTypeAuthenticationMethodPrometheus
>;

/**
 * DNS Record type to resolve
 */
export const RecordTypePrometheus = {
  Srv: "SRV",
  A: "A",
  Aaaa: "AAAA",
} as const;
/**
 * DNS Record type to resolve
 */
export type RecordTypePrometheus = OpenEnum<typeof RecordTypePrometheus>;

/**
 * Protocol to use when collecting metrics
 */
export const MetricsProtocol = {
  Http: "http",
  Https: "https",
} as const;
/**
 * Protocol to use when collecting metrics
 */
export type MetricsProtocol = OpenEnum<typeof MetricsProtocol>;

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const AwsAuthenticationMethodAuthenticationMethodPrometheus = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type AwsAuthenticationMethodAuthenticationMethodPrometheus = OpenEnum<
  typeof AwsAuthenticationMethodAuthenticationMethodPrometheus
>;

export type SearchFilterPrometheus = {
  /**
   * Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
   */
  name: string;
  /**
   * Search Filter Values, if empty only "running" EC2 instances will be returned
   */
  values: Array<string>;
};

/**
 * Signature version to use for signing EC2 requests
 */
export const SignatureVersionPrometheus = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing EC2 requests
 */
export type SignatureVersionPrometheus = OpenEnum<
  typeof SignatureVersionPrometheus
>;

export type InputPrometheus = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypePrometheus;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionPrometheus> | undefined;
  pq?: PqPrometheus | undefined;
  /**
   * Other dimensions to include in events
   */
  dimensionList?: Array<string> | undefined;
  /**
   * Target discovery mechanism. Use static to manually enter a list of targets.
   */
  discoveryType?: DiscoveryTypePrometheus | undefined;
  /**
   * How often in minutes to scrape targets for metrics, 60 must be evenly divisible by the value or save will fail.
   */
  interval?: number | undefined;
  /**
   * Collector runtime Log Level
   */
  logLevel?: LogLevelPrometheus | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumPrometheus> | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: AuthTypeAuthenticationMethodPrometheus | undefined;
  description?: string | undefined;
  /**
   * List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
   */
  targetList?: Array<string> | undefined;
  /**
   * DNS Record type to resolve
   */
  recordType?: RecordTypePrometheus | undefined;
  /**
   * The port number in the metrics URL for discovered targets.
   */
  scrapePort?: number | undefined;
  /**
   * List of DNS names to resolve
   */
  nameList?: Array<string> | undefined;
  /**
   * Protocol to use when collecting metrics
   */
  scrapeProtocol?: MetricsProtocol | undefined;
  /**
   * Path to use when collecting metrics from discovered targets
   */
  scrapePath?: string | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?:
    | AwsAuthenticationMethodAuthenticationMethodPrometheus
    | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  /**
   * Use public IP address for discovered targets. Set to false if the private IP address should be used.
   */
  usePublicIp?: boolean | undefined;
  /**
   * EC2 Instance Search Filter
   */
  searchFilter?: Array<SearchFilterPrometheus> | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the EC2 is located
   */
  region?: string | undefined;
  /**
   * EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing EC2 requests
   */
  signatureVersion?: SignatureVersionPrometheus | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Use Assume Role credentials to access EC2
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  /**
   * Username for Prometheus Basic authentication
   */
  username?: string | undefined;
  /**
   * Password for Prometheus Basic authentication
   */
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypePrometheusRw = {
  PrometheusRw: "prometheus_rw",
} as const;
export type TypePrometheusRw = ClosedEnum<typeof TypePrometheusRw>;

export type ConnectionPrometheusRw = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModePrometheusRw = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModePrometheusRw = OpenEnum<typeof ModePrometheusRw>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionPrometheusRw = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionPrometheusRw = OpenEnum<typeof CompressionPrometheusRw>;

export type PqControlsPrometheusRw = {};

export type PqPrometheusRw = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModePrometheusRw | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionPrometheusRw | undefined;
  pqControls?: PqControlsPrometheusRw | undefined;
};

export const MinimumTLSVersionPrometheusRw = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionPrometheusRw = OpenEnum<
  typeof MinimumTLSVersionPrometheusRw
>;

export const MaximumTLSVersionPrometheusRw = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionPrometheusRw = OpenEnum<
  typeof MaximumTLSVersionPrometheusRw
>;

export type TLSSettingsServerSidePrometheusRw = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionPrometheusRw | undefined;
  maxVersion?: MaximumTLSVersionPrometheusRw | undefined;
};

/**
 * Remote Write authentication type
 */
export const AuthenticationTypePrometheusRw = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Remote Write authentication type
 */
export type AuthenticationTypePrometheusRw = OpenEnum<
  typeof AuthenticationTypePrometheusRw
>;

export type MetadatumPrometheusRw = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type OauthParamPrometheusRw = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderPrometheusRw = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputPrometheusRw = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypePrometheusRw;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionPrometheusRw> | undefined;
  pq?: PqPrometheusRw | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSidePrometheusRw | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<yourupstreamURL>:<yourport>/write.
   */
  prometheusAPI?: string | undefined;
  /**
   * Remote Write authentication type
   */
  authType?: AuthenticationTypePrometheusRw | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumPrometheusRw> | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamPrometheusRw> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderPrometheusRw> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeLoki = {
  Loki: "loki",
} as const;
export type InputTypeLoki = ClosedEnum<typeof InputTypeLoki>;

export type ConnectionLoki = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeLoki = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeLoki = OpenEnum<typeof PqModeLoki>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionLoki = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionLoki = OpenEnum<typeof PqCompressionLoki>;

export type InputPqControlsLoki = {};

export type PqLoki = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeLoki | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionLoki | undefined;
  pqControls?: InputPqControlsLoki | undefined;
};

export const MinimumTLSVersionLoki = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionLoki = OpenEnum<typeof MinimumTLSVersionLoki>;

export const MaximumTLSVersionLoki = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionLoki = OpenEnum<typeof MaximumTLSVersionLoki>;

export type TLSSettingsServerSideLoki = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionLoki | undefined;
  maxVersion?: MaximumTLSVersionLoki | undefined;
};

/**
 * Loki logs authentication type
 */
export const InputAuthenticationTypeLoki = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Loki logs authentication type
 */
export type InputAuthenticationTypeLoki = OpenEnum<
  typeof InputAuthenticationTypeLoki
>;

export type MetadatumLoki = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type OauthParamLoki = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderLoki = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputLoki = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeLoki;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionLoki> | undefined;
  pq?: PqLoki | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideLoki | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'.
   */
  lokiAPI?: string | undefined;
  /**
   * Loki logs authentication type
   */
  authType?: InputAuthenticationTypeLoki | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumLoki> | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamLoki> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderLoki> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputGrafanaType2 = {
  Grafana: "grafana",
} as const;
export type InputGrafanaType2 = ClosedEnum<typeof InputGrafanaType2>;

export type InputGrafanaConnection2 = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputGrafanaMode2 = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputGrafanaMode2 = OpenEnum<typeof InputGrafanaMode2>;

/**
 * Codec to use to compress the persisted data
 */
export const InputGrafanaCompression2 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputGrafanaCompression2 = OpenEnum<
  typeof InputGrafanaCompression2
>;

export type InputGrafanaPqControls2 = {};

export type InputGrafanaPq2 = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputGrafanaMode2 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputGrafanaCompression2 | undefined;
  pqControls?: InputGrafanaPqControls2 | undefined;
};

export const InputGrafanaMinimumTLSVersion2 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputGrafanaMinimumTLSVersion2 = OpenEnum<
  typeof InputGrafanaMinimumTLSVersion2
>;

export const InputGrafanaMaximumTLSVersion2 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputGrafanaMaximumTLSVersion2 = OpenEnum<
  typeof InputGrafanaMaximumTLSVersion2
>;

export type InputGrafanaTLSSettingsServerSide2 = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputGrafanaMinimumTLSVersion2 | undefined;
  maxVersion?: InputGrafanaMaximumTLSVersion2 | undefined;
};

/**
 * Remote Write authentication type
 */
export const InputGrafanaPrometheusAuthAuthenticationType2 = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Remote Write authentication type
 */
export type InputGrafanaPrometheusAuthAuthenticationType2 = OpenEnum<
  typeof InputGrafanaPrometheusAuthAuthenticationType2
>;

export type PrometheusAuthOauthParam2 = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type PrometheusAuthOauthHeader2 = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputPrometheusAuth2 = {
  /**
   * Remote Write authentication type
   */
  authType?: InputGrafanaPrometheusAuthAuthenticationType2 | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<PrometheusAuthOauthParam2> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<PrometheusAuthOauthHeader2> | undefined;
};

/**
 * Loki logs authentication type
 */
export const InputGrafanaLokiAuthAuthenticationType2 = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Loki logs authentication type
 */
export type InputGrafanaLokiAuthAuthenticationType2 = OpenEnum<
  typeof InputGrafanaLokiAuthAuthenticationType2
>;

export type LokiAuthOauthParam2 = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type LokiAuthOauthHeader2 = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputLokiAuth2 = {
  /**
   * Loki logs authentication type
   */
  authType?: InputGrafanaLokiAuthAuthenticationType2 | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<LokiAuthOauthParam2> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<LokiAuthOauthHeader2> | undefined;
};

export type InputGrafanaMetadatum2 = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputGrafanaGrafana2 = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputGrafanaType2;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputGrafanaConnection2> | undefined;
  pq?: InputGrafanaPq2 | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: InputGrafanaTLSSettingsServerSide2 | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
   */
  prometheusAPI?: string | undefined;
  /**
   * Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
   */
  lokiAPI?: string | undefined;
  prometheusAuth?: InputPrometheusAuth2 | undefined;
  lokiAuth?: InputLokiAuth2 | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputGrafanaMetadatum2> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputGrafanaType1 = {
  Grafana: "grafana",
} as const;
export type InputGrafanaType1 = ClosedEnum<typeof InputGrafanaType1>;

export type InputGrafanaConnection1 = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const InputGrafanaMode1 = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type InputGrafanaMode1 = OpenEnum<typeof InputGrafanaMode1>;

/**
 * Codec to use to compress the persisted data
 */
export const InputGrafanaCompression1 = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type InputGrafanaCompression1 = OpenEnum<
  typeof InputGrafanaCompression1
>;

export type InputGrafanaPqControls1 = {};

export type InputGrafanaPq1 = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: InputGrafanaMode1 | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: InputGrafanaCompression1 | undefined;
  pqControls?: InputGrafanaPqControls1 | undefined;
};

export const InputGrafanaMinimumTLSVersion1 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputGrafanaMinimumTLSVersion1 = OpenEnum<
  typeof InputGrafanaMinimumTLSVersion1
>;

export const InputGrafanaMaximumTLSVersion1 = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputGrafanaMaximumTLSVersion1 = OpenEnum<
  typeof InputGrafanaMaximumTLSVersion1
>;

export type InputGrafanaTLSSettingsServerSide1 = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputGrafanaMinimumTLSVersion1 | undefined;
  maxVersion?: InputGrafanaMaximumTLSVersion1 | undefined;
};

/**
 * Remote Write authentication type
 */
export const InputGrafanaPrometheusAuthAuthenticationType1 = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Remote Write authentication type
 */
export type InputGrafanaPrometheusAuthAuthenticationType1 = OpenEnum<
  typeof InputGrafanaPrometheusAuthAuthenticationType1
>;

export type PrometheusAuthOauthParam1 = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type PrometheusAuthOauthHeader1 = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputPrometheusAuth1 = {
  /**
   * Remote Write authentication type
   */
  authType?: InputGrafanaPrometheusAuthAuthenticationType1 | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<PrometheusAuthOauthParam1> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<PrometheusAuthOauthHeader1> | undefined;
};

/**
 * Loki logs authentication type
 */
export const InputGrafanaLokiAuthAuthenticationType1 = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Loki logs authentication type
 */
export type InputGrafanaLokiAuthAuthenticationType1 = OpenEnum<
  typeof InputGrafanaLokiAuthAuthenticationType1
>;

export type LokiAuthOauthParam1 = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type LokiAuthOauthHeader1 = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputLokiAuth1 = {
  /**
   * Loki logs authentication type
   */
  authType?: InputGrafanaLokiAuthAuthenticationType1 | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<LokiAuthOauthParam1> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<LokiAuthOauthHeader1> | undefined;
};

export type InputGrafanaMetadatum1 = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputGrafanaGrafana1 = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputGrafanaType1;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<InputGrafanaConnection1> | undefined;
  pq?: InputGrafanaPq1 | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: InputGrafanaTLSSettingsServerSide1 | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
   */
  prometheusAPI?: string | undefined;
  /**
   * Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
   */
  lokiAPI?: string | undefined;
  prometheusAuth?: InputPrometheusAuth1 | undefined;
  lokiAuth?: InputLokiAuth1 | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<InputGrafanaMetadatum1> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export type InputGrafana = InputGrafanaGrafana1 | InputGrafanaGrafana2;

export const InputTypeConfluentCloud = {
  ConfluentCloud: "confluent_cloud",
} as const;
export type InputTypeConfluentCloud = ClosedEnum<
  typeof InputTypeConfluentCloud
>;

export type ConnectionConfluentCloud = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeConfluentCloud = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeConfluentCloud = OpenEnum<typeof PqModeConfluentCloud>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionConfluentCloud = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionConfluentCloud = OpenEnum<
  typeof PqCompressionConfluentCloud
>;

export type InputPqControlsConfluentCloud = {};

export type PqConfluentCloud = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeConfluentCloud | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionConfluentCloud | undefined;
  pqControls?: InputPqControlsConfluentCloud | undefined;
};

export const InputMinimumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionConfluentCloud = OpenEnum<
  typeof InputMinimumTLSVersionConfluentCloud
>;

export const InputMaximumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionConfluentCloud = OpenEnum<
  typeof InputMaximumTLSVersionConfluentCloud
>;

export type InputTLSSettingsClientSideConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: InputMinimumTLSVersionConfluentCloud | undefined;
  maxVersion?: InputMaximumTLSVersionConfluentCloud | undefined;
};

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type InputAuthConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = OpenEnum<
  typeof InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
>;

export const InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = OpenEnum<
  typeof InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
>;

export type InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?:
    | InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
    | undefined;
  maxVersion?:
    | InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
    | undefined;
};

export type InputKafkaSchemaRegistryAuthenticationConfluentCloud = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: InputAuthConfluentCloud | undefined;
  tls?: InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud | undefined;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const InputAuthenticationMethodConfluentCloud = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type InputAuthenticationMethodConfluentCloud = OpenEnum<
  typeof InputAuthenticationMethodConfluentCloud
>;

export const InputSASLMechanismConfluentCloud = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * SCRAM-SHA-256
   */
  ScramSha256: "scram-sha-256",
  /**
   * SCRAM-SHA-512
   */
  ScramSha512: "scram-sha-512",
  /**
   * GSSAPI/Kerberos
   */
  Kerberos: "kerberos",
} as const;
export type InputSASLMechanismConfluentCloud = OpenEnum<
  typeof InputSASLMechanismConfluentCloud
>;

export type InputOauthParamConfluentCloud = {
  name: string;
  value: string;
};

export type InputSaslExtensionConfluentCloud = {
  name: string;
  value: string;
};

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type InputAuthenticationConfluentCloud = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: InputAuthenticationMethodConfluentCloud | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  mechanism?: InputSASLMechanismConfluentCloud | undefined;
  /**
   * Location of keytab file for authentication principal
   */
  keytabLocation?: string | undefined;
  /**
   * Authentication principal, such as `kafka_user@example.com`
   */
  principal?: string | undefined;
  /**
   * Kerberos service class for Kafka brokers, such as `kafka`
   */
  brokerServiceClass?: string | undefined;
  /**
   * Enable OAuth authentication
   */
  oauthEnabled?: boolean | undefined;
  /**
   * URL of the token endpoint to use for OAuth authentication
   */
  tokenUrl?: string | undefined;
  /**
   * Client ID to use for OAuth authentication
   */
  clientId?: string | undefined;
  oauthSecretType?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Additional fields to send to the token endpoint, such as scope or audience
   */
  oauthParams?: Array<InputOauthParamConfluentCloud> | undefined;
  /**
   * Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
   */
  saslExtensions?: Array<InputSaslExtensionConfluentCloud> | undefined;
};

export type MetadatumConfluentCloud = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputConfluentCloud = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeConfluentCloud;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionConfluentCloud> | undefined;
  pq?: PqConfluentCloud | undefined;
  /**
   * List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
   */
  brokers: Array<string>;
  tls?: InputTLSSettingsClientSideConfluentCloud | undefined;
  /**
   * Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
   */
  topics: Array<string>;
  /**
   * The consumer group to which this instance belongs. Defaults to 'Cribl'.
   */
  groupId?: string | undefined;
  /**
   * Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
   */
  fromBeginning?: boolean | undefined;
  kafkaSchemaRegistry?:
    | InputKafkaSchemaRegistryAuthenticationConfluentCloud
    | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: InputAuthenticationConfluentCloud | undefined;
  /**
   *       Timeout used to detect client failures when using Kafka's group-management facilities.
   *
   * @remarks
   *       If the client sends no heartbeats to the broker before the timeout expires,
   *       the broker will remove the client from the group and initiate a rebalance.
   *       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
   */
  sessionTimeout?: number | undefined;
  /**
   *       Maximum allowed time for each worker to join the group after a rebalance begins.
   *
   * @remarks
   *       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
   */
  rebalanceTimeout?: number | undefined;
  /**
   *       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
   *
   * @remarks
   *       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
   */
  heartbeatInterval?: number | undefined;
  /**
   * How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitInterval?: number | undefined;
  /**
   * How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitThreshold?: number | undefined;
  /**
   * Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
   */
  maxBytesPerPartition?: number | undefined;
  /**
   * Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
   */
  maxBytes?: number | undefined;
  /**
   * Maximum number of network errors before the consumer re-creates a socket
   */
  maxSocketErrors?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumConfluentCloud> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeElastic = {
  Elastic: "elastic",
} as const;
export type InputTypeElastic = ClosedEnum<typeof InputTypeElastic>;

export type ConnectionElastic = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeElastic = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeElastic = OpenEnum<typeof PqModeElastic>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionElastic = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionElastic = OpenEnum<typeof PqCompressionElastic>;

export type InputPqControlsElastic = {};

export type PqElastic = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeElastic | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionElastic | undefined;
  pqControls?: InputPqControlsElastic | undefined;
};

export const MinimumTLSVersionElastic = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionElastic = OpenEnum<
  typeof MinimumTLSVersionElastic
>;

export const MaximumTLSVersionElastic = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionElastic = OpenEnum<
  typeof MaximumTLSVersionElastic
>;

export type TLSSettingsServerSideElastic = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionElastic | undefined;
  maxVersion?: MaximumTLSVersionElastic | undefined;
};

export const AuthenticationTypeElastic = {
  /**
   * None
   */
  None: "none",
  /**
   * Basic
   */
  Basic: "basic",
  /**
   * Basic (credentials secret)
   */
  CredentialsSecret: "credentialsSecret",
  /**
   * Auth Tokens
   */
  AuthTokens: "authTokens",
} as const;
export type AuthenticationTypeElastic = OpenEnum<
  typeof AuthenticationTypeElastic
>;

/**
 * The API version to use for communicating with the server
 */
export const InputAPIVersion = {
  /**
   * 6.8.4
   */
  SixDot8Dot4: "6.8.4",
  /**
   * 8.3.2
   */
  EightDot3Dot2: "8.3.2",
  /**
   * Custom
   */
  Custom: "custom",
} as const;
/**
 * The API version to use for communicating with the server
 */
export type InputAPIVersion = OpenEnum<typeof InputAPIVersion>;

export type InputExtraHttpHeader = {
  name?: string | undefined;
  value: string;
};

export type MetadatumElastic = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const ProxyModeAuthenticationMethod = {
  None: "none",
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type ProxyModeAuthenticationMethod = OpenEnum<
  typeof ProxyModeAuthenticationMethod
>;

export type ProxyModeElastic = {
  /**
   * Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications. See [Cribl Docs](https://docs.cribl.io/stream/sources-elastic/#proxy-mode) for more details.
   */
  enabled?: boolean | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: ProxyModeAuthenticationMethod | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * URL of the Elastic server to proxy non-bulk requests to, such as http://elastic:9200
   */
  url?: string | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * List of headers to remove from the request to proxy
   */
  removeHeaders?: Array<string> | undefined;
  /**
   * Amount of time, in seconds, to wait for a proxy request to complete before canceling it
   */
  timeoutSec?: number | undefined;
};

export type InputElastic = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeElastic;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionElastic> | undefined;
  pq?: PqElastic | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideElastic | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically. For example, /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
   */
  elasticAPI?: string | undefined;
  authType?: AuthenticationTypeElastic | undefined;
  /**
   * The API version to use for communicating with the server
   */
  apiVersion?: InputAPIVersion | undefined;
  /**
   * Headers to add to all events
   */
  extraHttpHeaders?: Array<InputExtraHttpHeader> | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumElastic> | undefined;
  proxyMode?: ProxyModeElastic | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Bearer tokens to include in the authorization header
   */
  authTokens?: Array<string> | undefined;
  /**
   * Custom version information to respond to requests
   */
  customAPIVersion?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeAzureBlob = {
  AzureBlob: "azure_blob",
} as const;
export type InputTypeAzureBlob = ClosedEnum<typeof InputTypeAzureBlob>;

export type ConnectionAzureBlob = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeAzureBlob = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeAzureBlob = OpenEnum<typeof ModeAzureBlob>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionAzureBlob = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionAzureBlob = OpenEnum<typeof PqCompressionAzureBlob>;

export type PqControlsAzureBlob = {};

export type PqAzureBlob = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeAzureBlob | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionAzureBlob | undefined;
  pqControls?: PqControlsAzureBlob | undefined;
};

export type MetadatumAzureBlob = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export const InputAuthenticationMethodAzureBlob = {
  Manual: "manual",
  Secret: "secret",
  ClientSecret: "clientSecret",
  ClientCert: "clientCert",
} as const;
export type InputAuthenticationMethodAzureBlob = OpenEnum<
  typeof InputAuthenticationMethodAzureBlob
>;

export type InputCertificate = {
  /**
   * The certificate you registered as credentials for your app in the Azure portal
   */
  certificateName: string;
};

export type InputAzureBlob = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeAzureBlob;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionAzureBlob> | undefined;
  pq?: PqAzureBlob | undefined;
  /**
   * The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
   */
  queueName: string;
  /**
   * Regex matching file names to download and process. Defaults to: .*
   */
  fileFilter?: string | undefined;
  /**
   * The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
   */
  visibilityTimeout?: number | undefined;
  /**
   * How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
   */
  numReceivers?: number | undefined;
  /**
   * The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
   */
  maxMessages?: number | undefined;
  /**
   * The duration (in seconds) which pollers should be validated and restarted if exited
   */
  servicePeriodSecs?: number | undefined;
  /**
   * Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
   */
  skipOnError?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumAzureBlob> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Maximum file size for each Parquet chunk
   */
  parquetChunkSizeMB?: number | undefined;
  /**
   * The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
   */
  parquetChunkDownloadTimeout?: number | undefined;
  authType?: InputAuthenticationMethodAzureBlob | undefined;
  description?: string | undefined;
  /**
   * Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
   */
  connectionString?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * The name of your Azure storage account
   */
  storageAccountName?: string | undefined;
  /**
   * The service principal's tenant ID
   */
  tenantId?: string | undefined;
  /**
   * The service principal's client ID
   */
  clientId?: string | undefined;
  /**
   * The Azure cloud to use. Defaults to Azure Public Cloud.
   */
  azureCloud?: string | undefined;
  /**
   * Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
   */
  endpointSuffix?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  certificate?: InputCertificate | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeSplunkHec = {
  SplunkHec: "splunk_hec",
} as const;
export type InputTypeSplunkHec = ClosedEnum<typeof InputTypeSplunkHec>;

export type ConnectionSplunkHec = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeSplunkHec = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeSplunkHec = OpenEnum<typeof PqModeSplunkHec>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionSplunkHec = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionSplunkHec = OpenEnum<typeof PqCompressionSplunkHec>;

export type InputPqControlsSplunkHec = {};

export type PqSplunkHec = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeSplunkHec | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionSplunkHec | undefined;
  pqControls?: InputPqControlsSplunkHec | undefined;
};

/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export const AuthTokenAuthenticationMethodSplunkHec = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
 */
export type AuthTokenAuthenticationMethodSplunkHec = OpenEnum<
  typeof AuthTokenAuthenticationMethodSplunkHec
>;

export type AuthTokenMetadatumSplunkHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokenSplunkHec = {
  /**
   * Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
   */
  authType?: AuthTokenAuthenticationMethodSplunkHec | undefined;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled?: boolean | undefined;
  /**
   * Optional token description
   */
  description?: string | undefined;
  /**
   * Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
   */
  allowedIndexesAtToken?: Array<string> | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokenMetadatumSplunkHec> | undefined;
};

export const InputMinimumTLSVersionSplunkHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionSplunkHec = OpenEnum<
  typeof InputMinimumTLSVersionSplunkHec
>;

export const InputMaximumTLSVersionSplunkHec = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionSplunkHec = OpenEnum<
  typeof InputMaximumTLSVersionSplunkHec
>;

export type TLSSettingsServerSideSplunkHec = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionSplunkHec | undefined;
  maxVersion?: InputMaximumTLSVersionSplunkHec | undefined;
};

export type MetadatumSplunkHec = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputInputSplunkHec = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeSplunkHec;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSplunkHec> | undefined;
  pq?: PqSplunkHec | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<AuthTokenSplunkHec> | undefined;
  tls?: TLSSettingsServerSideSplunkHec | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  enableHealthCheck?: any | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
   */
  splunkHecAPI?: string | undefined;
  /**
   * Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
   */
  metadata?: Array<MetadatumSplunkHec> | undefined;
  /**
   * List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
   */
  allowedIndexes?: Array<string> | undefined;
  /**
   * Enable Splunk HEC acknowledgements
   */
  splunkHecAcks?: boolean | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
   */
  useFwdTimezone?: boolean | undefined;
  /**
   * Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
   */
  dropControlFields?: boolean | undefined;
  /**
   * Extract and process Splunk-generated metrics as Cribl metrics
   */
  extractMetrics?: boolean | undefined;
  /**
   * Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
   */
  accessControlAllowOrigin?: Array<string> | undefined;
  /**
   * Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
   */
  accessControlAllowHeaders?: Array<string> | undefined;
  /**
   * Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
   */
  emitTokenMetrics?: boolean | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeSplunkSearch = {
  SplunkSearch: "splunk_search",
} as const;
export type TypeSplunkSearch = ClosedEnum<typeof TypeSplunkSearch>;

export type ConnectionSplunkSearch = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeSplunkSearch = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeSplunkSearch = OpenEnum<typeof ModeSplunkSearch>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionSplunkSearch = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionSplunkSearch = OpenEnum<typeof CompressionSplunkSearch>;

export type PqControlsSplunkSearch = {};

export type PqSplunkSearch = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeSplunkSearch | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionSplunkSearch | undefined;
  pqControls?: PqControlsSplunkSearch | undefined;
};

/**
 * Format of the returned output
 */
export const OutputMode = {
  Csv: "csv",
  Json: "json",
} as const;
/**
 * Format of the returned output
 */
export type OutputMode = OpenEnum<typeof OutputMode>;

export type EndpointParam = {
  name: string;
  /**
   * JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
   */
  value: string;
};

export type EndpointHeader = {
  name: string;
  /**
   * JavaScript expression to compute the header's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
   */
  value: string;
};

/**
 * Collector runtime log level (verbosity)
 */
export const LogLevelSplunkSearch = {
  Error: "error",
  Warn: "warn",
  Info: "info",
  Debug: "debug",
} as const;
/**
 * Collector runtime log level (verbosity)
 */
export type LogLevelSplunkSearch = OpenEnum<typeof LogLevelSplunkSearch>;

export type MetadatumSplunkSearch = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * The algorithm to use when performing HTTP retries
 */
export const RetryTypeSplunkSearch = {
  /**
   * Disabled
   */
  None: "none",
  /**
   * Backoff
   */
  Backoff: "backoff",
  /**
   * Static
   */
  Static: "static",
} as const;
/**
 * The algorithm to use when performing HTTP retries
 */
export type RetryTypeSplunkSearch = OpenEnum<typeof RetryTypeSplunkSearch>;

export type RetryRulesSplunkSearch = {
  /**
   * The algorithm to use when performing HTTP retries
   */
  type?: RetryTypeSplunkSearch | undefined;
  /**
   * Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
   */
  interval?: number | undefined;
  /**
   * The maximum number of times to retry a failed HTTP request
   */
  limit?: number | undefined;
  /**
   * Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
   */
  multiplier?: number | undefined;
  /**
   * List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
   */
  codes?: Array<number> | undefined;
  /**
   * Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
   */
  enableHeader?: boolean | undefined;
  /**
   * Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
   */
  retryConnectTimeout?: boolean | undefined;
  /**
   * Retry request when a connection reset (ECONNRESET) error occurs
   */
  retryConnectReset?: boolean | undefined;
};

/**
 * Splunk Search authentication type
 */
export const AuthenticationTypeSplunkSearch = {
  None: "none",
  Basic: "basic",
  CredentialsSecret: "credentialsSecret",
  Token: "token",
  TextSecret: "textSecret",
  Oauth: "oauth",
} as const;
/**
 * Splunk Search authentication type
 */
export type AuthenticationTypeSplunkSearch = OpenEnum<
  typeof AuthenticationTypeSplunkSearch
>;

export type OauthParamSplunkSearch = {
  /**
   * OAuth parameter name
   */
  name: string;
  /**
   * OAuth parameter value
   */
  value: string;
};

export type OauthHeaderSplunkSearch = {
  /**
   * OAuth header name
   */
  name: string;
  /**
   * OAuth header value
   */
  value: string;
};

export type InputSplunkSearch = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeSplunkSearch;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSplunkSearch> | undefined;
  pq?: PqSplunkSearch | undefined;
  /**
   * Search head base URL. Can be an expression. Default is https://localhost:8089.
   */
  searchHead?: string | undefined;
  /**
   * Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
   */
  search: string;
  /**
   * The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
   */
  earliest?: string | undefined;
  /**
   * The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
   */
  latest?: string | undefined;
  /**
   * A cron schedule on which to run this job
   */
  cronSchedule?: string | undefined;
  /**
   * REST API used to create a search
   */
  endpoint?: string | undefined;
  /**
   * Format of the returned output
   */
  outputMode?: OutputMode | undefined;
  /**
   * Optional request parameters to send to the endpoint
   */
  endpointParams?: Array<EndpointParam> | undefined;
  /**
   * Optional request headers to send to the endpoint
   */
  endpointHeaders?: Array<EndpointHeader> | undefined;
  /**
   * Collector runtime log level (verbosity)
   */
  logLevel?: LogLevelSplunkSearch | undefined;
  /**
   * HTTP request inactivity timeout. Use 0 for no timeout.
   */
  requestTimeout?: number | undefined;
  /**
   * When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
   */
  useRoundRobinDns?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
   */
  encoding?: string | undefined;
  /**
   * How often workers should check in with the scheduler to keep job subscription alive
   */
  keepAliveTime?: number | undefined;
  /**
   * Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
   */
  jobTimeout?: string | undefined;
  /**
   * The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
   */
  maxMissedKeepAlives?: number | undefined;
  /**
   * Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
   */
  ttl?: string | undefined;
  /**
   * When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live.
   */
  ignoreGroupJobsLimit?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSplunkSearch> | undefined;
  retryRules?: RetryRulesSplunkSearch | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Splunk Search authentication type
   */
  authType?: AuthenticationTypeSplunkSearch | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Bearer token to include in the authorization header
   */
  token?: string | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  textSecret?: string | undefined;
  /**
   * URL for OAuth
   */
  loginUrl?: string | undefined;
  /**
   * Secret parameter name to pass in request body
   */
  secretParamName?: string | undefined;
  /**
   * Secret parameter value to pass in request body
   */
  secret?: string | undefined;
  /**
   * Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
   */
  tokenAttributeName?: string | undefined;
  /**
   * JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
   */
  authHeaderExpr?: string | undefined;
  /**
   * How often the OAuth token should be refreshed.
   */
  tokenTimeoutSecs?: number | undefined;
  /**
   * Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthParams?: Array<OauthParamSplunkSearch> | undefined;
  /**
   * Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
   */
  oauthHeaders?: Array<OauthHeaderSplunkSearch> | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeSplunk = {
  Splunk: "splunk",
} as const;
export type InputTypeSplunk = ClosedEnum<typeof InputTypeSplunk>;

export type ConnectionSplunk = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeSplunk = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeSplunk = OpenEnum<typeof PqModeSplunk>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionSplunk = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionSplunk = OpenEnum<typeof PqCompressionSplunk>;

export type InputPqControlsSplunk = {};

export type PqSplunk = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeSplunk | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionSplunk | undefined;
  pqControls?: InputPqControlsSplunk | undefined;
};

export const InputMinimumTLSVersionSplunk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionSplunk = OpenEnum<
  typeof InputMinimumTLSVersionSplunk
>;

export const InputMaximumTLSVersionSplunk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionSplunk = OpenEnum<
  typeof InputMaximumTLSVersionSplunk
>;

export type TLSSettingsServerSideSplunk = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: InputMinimumTLSVersionSplunk | undefined;
  maxVersion?: InputMaximumTLSVersionSplunk | undefined;
};

export type MetadatumSplunk = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokenSplunk = {
  /**
   * Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
   */
  token: string;
  description?: string | undefined;
};

/**
 * The highest S2S protocol version to advertise during handshake
 */
export const InputMaxS2SVersion = {
  /**
   * v3
   */
  V3: "v3",
  /**
   * v4
   */
  V4: "v4",
} as const;
/**
 * The highest S2S protocol version to advertise during handshake
 */
export type InputMaxS2SVersion = OpenEnum<typeof InputMaxS2SVersion>;

/**
 * Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
 */
export const InputCompressionSplunk = {
  /**
   * Disabled
   */
  Disabled: "disabled",
  /**
   * Automatic
   */
  Auto: "auto",
  /**
   * Always
   */
  Always: "always",
} as const;
/**
 * Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
 */
export type InputCompressionSplunk = OpenEnum<typeof InputCompressionSplunk>;

export type InputSplunk = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeSplunk;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionSplunk> | undefined;
  pq?: PqSplunk | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  tls?: TLSSettingsServerSideSplunk | undefined;
  /**
   * Regex matching IP addresses that are allowed to establish a connection
   */
  ipWhitelistRegex?: string | undefined;
  /**
   * Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
   */
  maxActiveCxn?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
   */
  socketIdleTimeout?: number | undefined;
  /**
   * How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
   */
  socketEndingMaxWait?: number | undefined;
  /**
   * The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
   */
  socketMaxLifespan?: number | undefined;
  /**
   * Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumSplunk> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  /**
   * Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
   */
  authTokens?: Array<AuthTokenSplunk> | undefined;
  /**
   * The highest S2S protocol version to advertise during handshake
   */
  maxS2Sversion?: InputMaxS2SVersion | undefined;
  description?: string | undefined;
  /**
   * Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
   */
  useFwdTimezone?: boolean | undefined;
  /**
   * Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
   */
  dropControlFields?: boolean | undefined;
  /**
   * Extract and process Splunk-generated metrics as Cribl metrics
   */
  extractMetrics?: boolean | undefined;
  /**
   * Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
   */
  compress?: InputCompressionSplunk | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const TypeHTTP = {
  Http: "http",
} as const;
export type TypeHTTP = ClosedEnum<typeof TypeHTTP>;

export type ConnectionHTTP = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeHTTP = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeHTTP = OpenEnum<typeof ModeHTTP>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionHTTP = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionHTTP = OpenEnum<typeof CompressionHTTP>;

export type PqControlsHTTP = {};

export type PqHTTP = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeHTTP | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionHTTP | undefined;
  pqControls?: PqControlsHTTP | undefined;
};

export const MinimumTLSVersionHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MinimumTLSVersionHTTP = OpenEnum<typeof MinimumTLSVersionHTTP>;

export const MaximumTLSVersionHTTP = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type MaximumTLSVersionHTTP = OpenEnum<typeof MaximumTLSVersionHTTP>;

export type TLSSettingsServerSideHTTP = {
  disabled?: boolean | undefined;
  /**
   * Require clients to present their certificates. Used to perform client authentication using SSL certs.
   */
  requestCert?: boolean | undefined;
  /**
   * Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's)
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Regex matching allowable common names in peer certificates' subject attribute
   */
  commonNameRegex?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  /**
   * Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  minVersion?: MinimumTLSVersionHTTP | undefined;
  maxVersion?: MaximumTLSVersionHTTP | undefined;
};

export type MetadatumHTTP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtMetadatumHTTP = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type AuthTokensExtHTTP = {
  /**
   * Shared secret to be provided by any client (Authorization: <token>)
   */
  token: string;
  description?: string | undefined;
  /**
   * Fields to add to events referencing this token
   */
  metadata?: Array<AuthTokensExtMetadatumHTTP> | undefined;
};

export type InputHttp = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: TypeHTTP;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionHTTP> | undefined;
  pq?: PqHTTP | undefined;
  /**
   * Address to bind on. Defaults to 0.0.0.0 (all addresses).
   */
  host?: string | undefined;
  /**
   * Port to listen on
   */
  port: number;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideHTTP | undefined;
  /**
   * Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput.
   */
  maxActiveReq?: number | undefined;
  /**
   * Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
   */
  maxRequestsPerSocket?: number | undefined;
  /**
   * Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction.
   */
  enableProxyHeader?: boolean | undefined;
  /**
   * Add request headers to events, in the __headers field
   */
  captureHeaders?: boolean | undefined;
  /**
   * How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
   */
  activityLogSampleRate?: number | undefined;
  /**
   * How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
   */
  requestTimeout?: number | undefined;
  /**
   * How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
   */
  socketTimeout?: number | undefined;
  /**
   * After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes).
   */
  keepAliveTimeout?: number | undefined;
  /**
   * Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
   */
  enableHealthCheck?: boolean | undefined;
  /**
   * Messages from matched IP addresses will be processed, unless also matched by the denylist
   */
  ipAllowlistRegex?: string | undefined;
  /**
   * Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
   */
  ipDenylistRegex?: string | undefined;
  /**
   * Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
   */
  criblAPI?: string | undefined;
  /**
   * Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
   */
  elasticAPI?: string | undefined;
  /**
   * Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
   */
  splunkHecAPI?: string | undefined;
  splunkHecAcks?: boolean | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumHTTP> | undefined;
  /**
   * Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
   */
  authTokensExt?: Array<AuthTokensExtHTTP> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeMsk = {
  Msk: "msk",
} as const;
export type InputTypeMsk = ClosedEnum<typeof InputTypeMsk>;

export type ConnectionMsk = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeMsk = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeMsk = OpenEnum<typeof PqModeMsk>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionMsk = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionMsk = OpenEnum<typeof PqCompressionMsk>;

export type InputPqControlsMsk = {};

export type PqMsk = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeMsk | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionMsk | undefined;
  pqControls?: InputPqControlsMsk | undefined;
};

export type MetadatumMsk = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type InputAuthMsk = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const InputKafkaSchemaRegistryMinimumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMinimumTLSVersionMsk = OpenEnum<
  typeof InputKafkaSchemaRegistryMinimumTLSVersionMsk
>;

export const InputKafkaSchemaRegistryMaximumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMaximumTLSVersionMsk = OpenEnum<
  typeof InputKafkaSchemaRegistryMaximumTLSVersionMsk
>;

export type InputKafkaSchemaRegistryTLSSettingsClientSideMsk = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: InputKafkaSchemaRegistryMinimumTLSVersionMsk | undefined;
  maxVersion?: InputKafkaSchemaRegistryMaximumTLSVersionMsk | undefined;
};

export type InputKafkaSchemaRegistryAuthenticationMsk = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: InputAuthMsk | undefined;
  tls?: InputKafkaSchemaRegistryTLSSettingsClientSideMsk | undefined;
};

/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export const InputAuthenticationMethodMsk = {
  /**
   * Auto
   */
  Auto: "auto",
  /**
   * Manual
   */
  Manual: "manual",
  /**
   * Secret Key pair
   */
  Secret: "secret",
} as const;
/**
 * AWS authentication method. Choose Auto to use IAM roles.
 */
export type InputAuthenticationMethodMsk = OpenEnum<
  typeof InputAuthenticationMethodMsk
>;

/**
 * Signature version to use for signing MSK cluster requests
 */
export const InputSignatureVersionMsk = {
  V2: "v2",
  V4: "v4",
} as const;
/**
 * Signature version to use for signing MSK cluster requests
 */
export type InputSignatureVersionMsk = OpenEnum<
  typeof InputSignatureVersionMsk
>;

export const InputMinimumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionMsk = OpenEnum<
  typeof InputMinimumTLSVersionMsk
>;

export const InputMaximumTLSVersionMsk = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionMsk = OpenEnum<
  typeof InputMaximumTLSVersionMsk
>;

export type InputTLSSettingsClientSideMsk = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: InputMinimumTLSVersionMsk | undefined;
  maxVersion?: InputMaximumTLSVersionMsk | undefined;
};

export type InputMsk = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeMsk;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionMsk> | undefined;
  pq?: PqMsk | undefined;
  /**
   * Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
   */
  brokers: Array<string>;
  /**
   * Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
   */
  topics: Array<string>;
  /**
   * The consumer group to which this instance belongs. Defaults to 'Cribl'.
   */
  groupId?: string | undefined;
  /**
   * Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
   */
  fromBeginning?: boolean | undefined;
  /**
   *       Timeout used to detect client failures when using Kafka's group-management facilities.
   *
   * @remarks
   *       If the client sends no heartbeats to the broker before the timeout expires,
   *       the broker will remove the client from the group and initiate a rebalance.
   *       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
   */
  sessionTimeout?: number | undefined;
  /**
   *       Maximum allowed time for each worker to join the group after a rebalance begins.
   *
   * @remarks
   *       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
   */
  rebalanceTimeout?: number | undefined;
  /**
   *       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
   *
   * @remarks
   *       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
   */
  heartbeatInterval?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumMsk> | undefined;
  kafkaSchemaRegistry?: InputKafkaSchemaRegistryAuthenticationMsk | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * AWS authentication method. Choose Auto to use IAM roles.
   */
  awsAuthenticationMethod?: InputAuthenticationMethodMsk | undefined;
  awsSecretKey?: string | undefined;
  /**
   * Region where the MSK cluster is located
   */
  region: string;
  /**
   * MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
   */
  endpoint?: string | undefined;
  /**
   * Signature version to use for signing MSK cluster requests
   */
  signatureVersion?: InputSignatureVersionMsk | undefined;
  /**
   * Reuse connections between requests, which can improve performance
   */
  reuseConnections?: boolean | undefined;
  /**
   * Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Use Assume Role credentials to access MSK
   */
  enableAssumeRole?: boolean | undefined;
  /**
   * Amazon Resource Name (ARN) of the role to assume
   */
  assumeRoleArn?: string | undefined;
  /**
   * External ID to use when assuming role
   */
  assumeRoleExternalId?: string | undefined;
  /**
   * Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
   */
  durationSeconds?: number | undefined;
  tls?: InputTLSSettingsClientSideMsk | undefined;
  /**
   * How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitInterval?: number | undefined;
  /**
   * How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitThreshold?: number | undefined;
  /**
   * Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
   */
  maxBytesPerPartition?: number | undefined;
  /**
   * Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
   */
  maxBytes?: number | undefined;
  /**
   * Maximum number of network errors before the consumer re-creates a socket
   */
  maxSocketErrors?: number | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  /**
   * Select or create a stored secret that references your access key and secret key
   */
  awsSecret?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeKafka = {
  Kafka: "kafka",
} as const;
export type InputTypeKafka = ClosedEnum<typeof InputTypeKafka>;

export type ConnectionKafka = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const PqModeKafka = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type PqModeKafka = OpenEnum<typeof PqModeKafka>;

/**
 * Codec to use to compress the persisted data
 */
export const PqCompressionKafka = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type PqCompressionKafka = OpenEnum<typeof PqCompressionKafka>;

export type InputPqControlsKafka = {};

export type PqKafka = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: PqModeKafka | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: PqCompressionKafka | undefined;
  pqControls?: InputPqControlsKafka | undefined;
};

/**
 * Credentials to use when authenticating with the schema registry using basic HTTP authentication
 */
export type InputAuthKafka = {
  disabled?: boolean | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
};

export const InputKafkaSchemaRegistryMinimumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMinimumTLSVersionKafka = OpenEnum<
  typeof InputKafkaSchemaRegistryMinimumTLSVersionKafka
>;

export const InputKafkaSchemaRegistryMaximumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputKafkaSchemaRegistryMaximumTLSVersionKafka = OpenEnum<
  typeof InputKafkaSchemaRegistryMaximumTLSVersionKafka
>;

export type InputKafkaSchemaRegistryTLSSettingsClientSideKafka = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: InputKafkaSchemaRegistryMinimumTLSVersionKafka | undefined;
  maxVersion?: InputKafkaSchemaRegistryMaximumTLSVersionKafka | undefined;
};

export type InputKafkaSchemaRegistryAuthenticationKafka = {
  disabled?: boolean | undefined;
  /**
   * URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
   */
  schemaRegistryURL?: string | undefined;
  /**
   * Maximum time to wait for a Schema Registry connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for the Schema Registry to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * Maximum number of times to try fetching schemas from the Schema Registry
   */
  maxRetries?: number | undefined;
  /**
   * Credentials to use when authenticating with the schema registry using basic HTTP authentication
   */
  auth?: InputAuthKafka | undefined;
  tls?: InputKafkaSchemaRegistryTLSSettingsClientSideKafka | undefined;
};

/**
 * Enter credentials directly, or select a stored secret
 */
export const InputAuthenticationMethodKafka = {
  Manual: "manual",
  Secret: "secret",
} as const;
/**
 * Enter credentials directly, or select a stored secret
 */
export type InputAuthenticationMethodKafka = OpenEnum<
  typeof InputAuthenticationMethodKafka
>;

export const InputSASLMechanismKafka = {
  /**
   * PLAIN
   */
  Plain: "plain",
  /**
   * SCRAM-SHA-256
   */
  ScramSha256: "scram-sha-256",
  /**
   * SCRAM-SHA-512
   */
  ScramSha512: "scram-sha-512",
  /**
   * GSSAPI/Kerberos
   */
  Kerberos: "kerberos",
} as const;
export type InputSASLMechanismKafka = OpenEnum<typeof InputSASLMechanismKafka>;

export type InputOauthParamKafka = {
  name: string;
  value: string;
};

export type InputSaslExtensionKafka = {
  name: string;
  value: string;
};

/**
 * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
 */
export type InputAuthenticationKafka = {
  disabled?: boolean | undefined;
  username?: string | undefined;
  password?: string | undefined;
  /**
   * Enter credentials directly, or select a stored secret
   */
  authType?: InputAuthenticationMethodKafka | undefined;
  /**
   * Select or create a secret that references your credentials
   */
  credentialsSecret?: string | undefined;
  mechanism?: InputSASLMechanismKafka | undefined;
  /**
   * Location of keytab file for authentication principal
   */
  keytabLocation?: string | undefined;
  /**
   * Authentication principal, such as `kafka_user@example.com`
   */
  principal?: string | undefined;
  /**
   * Kerberos service class for Kafka brokers, such as `kafka`
   */
  brokerServiceClass?: string | undefined;
  /**
   * Enable OAuth authentication
   */
  oauthEnabled?: boolean | undefined;
  /**
   * URL of the token endpoint to use for OAuth authentication
   */
  tokenUrl?: string | undefined;
  /**
   * Client ID to use for OAuth authentication
   */
  clientId?: string | undefined;
  oauthSecretType?: string | undefined;
  /**
   * Select or create a stored text secret
   */
  clientTextSecret?: string | undefined;
  /**
   * Additional fields to send to the token endpoint, such as scope or audience
   */
  oauthParams?: Array<InputOauthParamKafka> | undefined;
  /**
   * Additional SASL extension fields, such as Confluent's logicalCluster or identityPoolId
   */
  saslExtensions?: Array<InputSaslExtensionKafka> | undefined;
};

export const InputMinimumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMinimumTLSVersionKafka = OpenEnum<
  typeof InputMinimumTLSVersionKafka
>;

export const InputMaximumTLSVersionKafka = {
  TLSv1: "TLSv1",
  TLSv11: "TLSv1.1",
  TLSv12: "TLSv1.2",
  TLSv13: "TLSv1.3",
} as const;
export type InputMaximumTLSVersionKafka = OpenEnum<
  typeof InputMaximumTLSVersionKafka
>;

export type InputTLSSettingsClientSideKafka = {
  disabled?: boolean | undefined;
  /**
   * Reject certificates that are not authorized by a CA in the CA certificate path, or by another
   *
   * @remarks
   *                     trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
   */
  rejectUnauthorized?: boolean | undefined;
  /**
   * Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
   */
  servername?: string | undefined;
  /**
   * The name of the predefined certificate
   */
  certificateName?: string | undefined;
  /**
   * Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
   */
  caPath?: string | undefined;
  /**
   * Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
   */
  privKeyPath?: string | undefined;
  /**
   * Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
   */
  certPath?: string | undefined;
  /**
   * Passphrase to use to decrypt private key
   */
  passphrase?: string | undefined;
  minVersion?: InputMinimumTLSVersionKafka | undefined;
  maxVersion?: InputMaximumTLSVersionKafka | undefined;
};

export type MetadatumKafka = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputKafka = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type: InputTypeKafka;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process data from this Source before sending it through the Routes
   */
  pipeline?: string | undefined;
  /**
   * Select whether to send data to Routes, or directly to Destinations.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionKafka> | undefined;
  pq?: PqKafka | undefined;
  /**
   * Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
   */
  brokers: Array<string>;
  /**
   * Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to a single topic only.
   */
  topics: Array<string>;
  /**
   * The consumer group to which this instance belongs. Defaults to 'Cribl'.
   */
  groupId?: string | undefined;
  /**
   * Leave enabled if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
   */
  fromBeginning?: boolean | undefined;
  kafkaSchemaRegistry?: InputKafkaSchemaRegistryAuthenticationKafka | undefined;
  /**
   * Maximum time to wait for a connection to complete successfully
   */
  connectionTimeout?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to a request
   */
  requestTimeout?: number | undefined;
  /**
   * If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
   */
  maxRetries?: number | undefined;
  /**
   * The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
   */
  maxBackOff?: number | undefined;
  /**
   * Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
   */
  initialBackoff?: number | undefined;
  /**
   * Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
   */
  backoffRate?: number | undefined;
  /**
   * Maximum time to wait for Kafka to respond to an authentication request
   */
  authenticationTimeout?: number | undefined;
  /**
   * Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
   */
  reauthenticationThreshold?: number | undefined;
  /**
   * Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
   */
  sasl?: InputAuthenticationKafka | undefined;
  tls?: InputTLSSettingsClientSideKafka | undefined;
  /**
   *       Timeout used to detect client failures when using Kafka's group-management facilities.
   *
   * @remarks
   *       If the client sends no heartbeats to the broker before the timeout expires,
   *       the broker will remove the client from the group and initiate a rebalance.
   *       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms) for details.
   */
  sessionTimeout?: number | undefined;
  /**
   *       Maximum allowed time for each worker to join the group after a rebalance begins.
   *
   * @remarks
   *       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms) for details.
   */
  rebalanceTimeout?: number | undefined;
  /**
   *       Expected time between heartbeats to the consumer coordinator when using Kafka's group-management facilities.
   *
   * @remarks
   *       Value must be lower than sessionTimeout and typically should not exceed 1/3 of the sessionTimeout value.
   *       See [Kafka's documentation](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms) for details.
   */
  heartbeatInterval?: number | undefined;
  /**
   * How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitInterval?: number | undefined;
  /**
   * How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
   */
  autoCommitThreshold?: number | undefined;
  /**
   * Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
   */
  maxBytesPerPartition?: number | undefined;
  /**
   * Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
   */
  maxBytes?: number | undefined;
  /**
   * Maximum number of network errors before the consumer re-creates a socket
   */
  maxSocketErrors?: number | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumKafka> | undefined;
  description?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export const InputTypeCollection = {
  Collection: "collection",
} as const;
export type InputTypeCollection = ClosedEnum<typeof InputTypeCollection>;

export type ConnectionCollection = {
  pipeline?: string | undefined;
  output: string;
};

/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export const ModeCollection = {
  /**
   * Smart
   */
  Smart: "smart",
  /**
   * Always On
   */
  Always: "always",
} as const;
/**
 * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
 */
export type ModeCollection = OpenEnum<typeof ModeCollection>;

/**
 * Codec to use to compress the persisted data
 */
export const CompressionCollection = {
  /**
   * None
   */
  None: "none",
  /**
   * Gzip
   */
  Gzip: "gzip",
} as const;
/**
 * Codec to use to compress the persisted data
 */
export type CompressionCollection = OpenEnum<typeof CompressionCollection>;

export type PqControlsCollection = {};

export type PqCollection = {
  /**
   * With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
   */
  mode?: ModeCollection | undefined;
  /**
   * The maximum number of events to hold in memory before writing the events to disk
   */
  maxBufferSize?: number | undefined;
  /**
   * The number of events to send downstream before committing that Stream has read them
   */
  commitFrequency?: number | undefined;
  /**
   * The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
   */
  maxFileSize?: string | undefined;
  /**
   * The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
   */
  maxSize?: string | undefined;
  /**
   * The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
   */
  path?: string | undefined;
  /**
   * Codec to use to compress the persisted data
   */
  compress?: CompressionCollection | undefined;
  pqControls?: PqControlsCollection | undefined;
};

export type PreprocessCollection = {
  disabled?: boolean | undefined;
  /**
   * Command to feed the data through (via stdin) and process its output (stdout)
   */
  command?: string | undefined;
  /**
   * Arguments to be added to the custom command
   */
  args?: Array<string> | undefined;
};

export type MetadatumCollection = {
  name: string;
  /**
   * JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
   */
  value: string;
};

export type InputCollection = {
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputTypeCollection | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionCollection> | undefined;
  pq?: PqCollection | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessCollection | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<MetadatumCollection> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
  additionalProperties?: { [k: string]: any } | undefined;
};

export type Input =
  | (InputMsk & { type: "msk" })
  | (InputWiz & { type: "wiz" })
  | (InputKafka & { type: "kafka" })
  | (InputConfluentCloud & { type: "confluent_cloud" })
  | (InputOffice365Mgmt & { type: "office365_mgmt" })
  | (InputOffice365Service & { type: "office365_service" })
  | (InputEventhub & { type: "eventhub" })
  | (InputKinesis & { type: "kinesis" })
  | (InputSqs & { type: "sqs" })
  | (InputJournalFiles & { type: "journal_files" })
  | (InputCloudflareHec & { type: "cloudflare_hec" })
  | (InputHttp & { type: "http" })
  | (InputSplunk & { type: "splunk" })
  | (InputSplunkSearch & { type: "splunk_search" })
  | (InputInputSplunkHec & { type: "splunk_hec" })
  | (InputAzureBlob & { type: "azure_blob" })
  | (InputElastic & { type: "elastic" })
  | (InputLoki & { type: "loki" })
  | (InputPrometheusRw & { type: "prometheus_rw" })
  | (InputExec & { type: "exec" })
  | (InputFirehose & { type: "firehose" })
  | (InputGooglePubsub & { type: "google_pubsub" })
  | (InputCriblTcp & { type: "cribl_tcp" })
  | (InputCriblHttp & { type: "cribl_http" })
  | (InputCriblLakeHttp & { type: "cribl_lake_http" })
  | (InputTcpjson & { type: "tcpjson" })
  | (InputCrowdstrike & { type: "crowdstrike" })
  | (InputDatadogAgent & { type: "datadog_agent" })
  | (InputDatagen & { type: "datagen" })
  | (InputHttpRaw & { type: "http_raw" })
  | (InputS3 & { type: "s3" })
  | (InputS3Inventory & { type: "s3_inventory" })
  | (InputTcp & { type: "tcp" })
  | (InputWef & { type: "wef" })
  | (InputWinEventLogs & { type: "win_event_logs" })
  | (InputRawUdp & { type: "raw_udp" })
  | (InputWizWebhook & { type: "wiz_webhook" })
  | (InputSecurityLake & { type: "security_lake" })
  | (InputZscalerHec & { type: "zscaler_hec" })
  | (InputPrometheus & { type: "prometheus" })
  | (InputEdgePrometheus & { type: "edge_prometheus" })
  | (InputOffice365MsgTrace & { type: "office365_msg_trace" })
  | (InputCribl & { type: "cribl" })
  | (InputSystemMetrics & { type: "system_metrics" })
  | (InputSystemState & { type: "system_state" })
  | (InputKubeMetrics & { type: "kube_metrics" })
  | (InputKubeLogs & { type: "kube_logs" })
  | (InputKubeEvents & { type: "kube_events" })
  | (InputWindowsMetrics & { type: "windows_metrics" })
  | (InputCriblmetrics & { type: "criblmetrics" })
  | (InputMetrics & { type: "metrics" })
  | (InputSnmp & { type: "snmp" })
  | (InputOpenTelemetry & { type: "open_telemetry" })
  | (InputModelDrivenTelemetry & { type: "model_driven_telemetry" })
  | (InputFile & { type: "file" })
  | (InputAppscope & { type: "appscope" })
  | (InputNetflow & { type: "netflow" })
  | (InputCollection & { type: "collection" })
  | (InputGrafanaGrafana1 | InputGrafanaGrafana2 & { type: "grafana" })
  | (InputSyslogSyslog1 | InputSyslogSyslog2 & { type: "syslog" });

/** @internal */
export const TypeCloudflareHec$inboundSchema: z.ZodNativeEnum<
  typeof TypeCloudflareHec
> = z.nativeEnum(TypeCloudflareHec);
/** @internal */
export const TypeCloudflareHec$outboundSchema: z.ZodNativeEnum<
  typeof TypeCloudflareHec
> = TypeCloudflareHec$inboundSchema;

/** @internal */
export const ConnectionCloudflareHec$inboundSchema: z.ZodType<
  ConnectionCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCloudflareHec$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCloudflareHec$outboundSchema: z.ZodType<
  ConnectionCloudflareHec$Outbound,
  z.ZodTypeDef,
  ConnectionCloudflareHec
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCloudflareHecToJSON(
  connectionCloudflareHec: ConnectionCloudflareHec,
): string {
  return JSON.stringify(
    ConnectionCloudflareHec$outboundSchema.parse(connectionCloudflareHec),
  );
}
export function connectionCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCloudflareHec' from JSON`,
  );
}

/** @internal */
export const ModeCloudflareHec$inboundSchema: z.ZodType<
  ModeCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCloudflareHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCloudflareHec$outboundSchema: z.ZodType<
  ModeCloudflareHec,
  z.ZodTypeDef,
  ModeCloudflareHec
> = z.union([
  z.nativeEnum(ModeCloudflareHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCloudflareHec$inboundSchema: z.ZodType<
  CompressionCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCloudflareHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCloudflareHec$outboundSchema: z.ZodType<
  CompressionCloudflareHec,
  z.ZodTypeDef,
  CompressionCloudflareHec
> = z.union([
  z.nativeEnum(CompressionCloudflareHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCloudflareHec$inboundSchema: z.ZodType<
  PqControlsCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCloudflareHec$Outbound = {};

/** @internal */
export const PqControlsCloudflareHec$outboundSchema: z.ZodType<
  PqControlsCloudflareHec$Outbound,
  z.ZodTypeDef,
  PqControlsCloudflareHec
> = z.object({});

export function pqControlsCloudflareHecToJSON(
  pqControlsCloudflareHec: PqControlsCloudflareHec,
): string {
  return JSON.stringify(
    PqControlsCloudflareHec$outboundSchema.parse(pqControlsCloudflareHec),
  );
}
export function pqControlsCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCloudflareHec' from JSON`,
  );
}

/** @internal */
export const PqCloudflareHec$inboundSchema: z.ZodType<
  PqCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeCloudflareHec$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCloudflareHec$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCloudflareHec$inboundSchema).optional(),
});
/** @internal */
export type PqCloudflareHec$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCloudflareHec$Outbound | undefined;
};

/** @internal */
export const PqCloudflareHec$outboundSchema: z.ZodType<
  PqCloudflareHec$Outbound,
  z.ZodTypeDef,
  PqCloudflareHec
> = z.object({
  mode: ModeCloudflareHec$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCloudflareHec$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCloudflareHec$outboundSchema).optional(),
});

export function pqCloudflareHecToJSON(
  pqCloudflareHec: PqCloudflareHec,
): string {
  return JSON.stringify(PqCloudflareHec$outboundSchema.parse(pqCloudflareHec));
}
export function pqCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<PqCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCloudflareHec' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodCloudflareHec$inboundSchema: z.ZodType<
  AuthenticationMethodCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodCloudflareHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodCloudflareHec$outboundSchema: z.ZodType<
  AuthenticationMethodCloudflareHec,
  z.ZodTypeDef,
  AuthenticationMethodCloudflareHec
> = z.union([
  z.nativeEnum(AuthenticationMethodCloudflareHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthTokenMetadatumCloudflareHec$inboundSchema: z.ZodType<
  AuthTokenMetadatumCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokenMetadatumCloudflareHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokenMetadatumCloudflareHec$outboundSchema: z.ZodType<
  AuthTokenMetadatumCloudflareHec$Outbound,
  z.ZodTypeDef,
  AuthTokenMetadatumCloudflareHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokenMetadatumCloudflareHecToJSON(
  authTokenMetadatumCloudflareHec: AuthTokenMetadatumCloudflareHec,
): string {
  return JSON.stringify(
    AuthTokenMetadatumCloudflareHec$outboundSchema.parse(
      authTokenMetadatumCloudflareHec,
    ),
  );
}
export function authTokenMetadatumCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenMetadatumCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenMetadatumCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenMetadatumCloudflareHec' from JSON`,
  );
}

/** @internal */
export const AuthTokenCloudflareHec$inboundSchema: z.ZodType<
  AuthTokenCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: AuthenticationMethodCloudflareHec$inboundSchema.default("secret"),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(z.lazy(() => AuthTokenMetadatumCloudflareHec$inboundSchema))
    .optional(),
});
/** @internal */
export type AuthTokenCloudflareHec$Outbound = {
  authType: string;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled: boolean;
  description?: string | undefined;
  allowedIndexesAtToken?: Array<string> | undefined;
  metadata?: Array<AuthTokenMetadatumCloudflareHec$Outbound> | undefined;
};

/** @internal */
export const AuthTokenCloudflareHec$outboundSchema: z.ZodType<
  AuthTokenCloudflareHec$Outbound,
  z.ZodTypeDef,
  AuthTokenCloudflareHec
> = z.object({
  authType: AuthenticationMethodCloudflareHec$outboundSchema.default("secret"),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(
    z.lazy(() => AuthTokenMetadatumCloudflareHec$outboundSchema),
  ).optional(),
});

export function authTokenCloudflareHecToJSON(
  authTokenCloudflareHec: AuthTokenCloudflareHec,
): string {
  return JSON.stringify(
    AuthTokenCloudflareHec$outboundSchema.parse(authTokenCloudflareHec),
  );
}
export function authTokenCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenCloudflareHec' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionCloudflareHec$inboundSchema: z.ZodType<
  MinimumTLSVersionCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionCloudflareHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionCloudflareHec$outboundSchema: z.ZodType<
  MinimumTLSVersionCloudflareHec,
  z.ZodTypeDef,
  MinimumTLSVersionCloudflareHec
> = z.union([
  z.nativeEnum(MinimumTLSVersionCloudflareHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionCloudflareHec$inboundSchema: z.ZodType<
  MaximumTLSVersionCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionCloudflareHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionCloudflareHec$outboundSchema: z.ZodType<
  MaximumTLSVersionCloudflareHec,
  z.ZodTypeDef,
  MaximumTLSVersionCloudflareHec
> = z.union([
  z.nativeEnum(MaximumTLSVersionCloudflareHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideCloudflareHec$inboundSchema: z.ZodType<
  TLSSettingsServerSideCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionCloudflareHec$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionCloudflareHec$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideCloudflareHec$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideCloudflareHec$outboundSchema: z.ZodType<
  TLSSettingsServerSideCloudflareHec$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideCloudflareHec
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionCloudflareHec$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionCloudflareHec$outboundSchema.optional(),
});

export function tlsSettingsServerSideCloudflareHecToJSON(
  tlsSettingsServerSideCloudflareHec: TLSSettingsServerSideCloudflareHec,
): string {
  return JSON.stringify(
    TLSSettingsServerSideCloudflareHec$outboundSchema.parse(
      tlsSettingsServerSideCloudflareHec,
    ),
  );
}
export function tlsSettingsServerSideCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsServerSideCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideCloudflareHec' from JSON`,
  );
}

/** @internal */
export const MetadatumCloudflareHec$inboundSchema: z.ZodType<
  MetadatumCloudflareHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCloudflareHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCloudflareHec$outboundSchema: z.ZodType<
  MetadatumCloudflareHec$Outbound,
  z.ZodTypeDef,
  MetadatumCloudflareHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCloudflareHecToJSON(
  metadatumCloudflareHec: MetadatumCloudflareHec,
): string {
  return JSON.stringify(
    MetadatumCloudflareHec$outboundSchema.parse(metadatumCloudflareHec),
  );
}
export function metadatumCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCloudflareHec' from JSON`,
  );
}

/** @internal */
export const InputCloudflareHec$inboundSchema: z.ZodType<
  InputCloudflareHec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCloudflareHec$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCloudflareHec$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCloudflareHec$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.lazy(() => AuthTokenCloudflareHec$inboundSchema))
      .optional(),
    tls: z.lazy(() => TLSSettingsServerSideCloudflareHec$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.any().optional(),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    hecAPI: z.string(),
    metadata: z.array(z.lazy(() => MetadatumCloudflareHec$inboundSchema))
      .optional(),
    allowedIndexes: z.array(z.string()).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    accessControlAllowOrigin: z.array(z.string()).optional(),
    accessControlAllowHeaders: z.array(z.string()).optional(),
    emitTokenMetrics: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCloudflareHec$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCloudflareHec$Outbound> | undefined;
  pq?: PqCloudflareHec$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<AuthTokenCloudflareHec$Outbound> | undefined;
  tls?: TLSSettingsServerSideCloudflareHec$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck?: any | undefined;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  hecAPI: string;
  metadata?: Array<MetadatumCloudflareHec$Outbound> | undefined;
  allowedIndexes?: Array<string> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  accessControlAllowOrigin?: Array<string> | undefined;
  accessControlAllowHeaders?: Array<string> | undefined;
  emitTokenMetrics: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCloudflareHec$outboundSchema: z.ZodType<
  InputCloudflareHec$Outbound,
  z.ZodTypeDef,
  InputCloudflareHec
> = z.object({
  id: z.string().optional(),
  type: TypeCloudflareHec$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCloudflareHec$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCloudflareHec$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.lazy(() => AuthTokenCloudflareHec$outboundSchema))
    .optional(),
  tls: z.lazy(() => TLSSettingsServerSideCloudflareHec$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.any().optional(),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  hecAPI: z.string(),
  metadata: z.array(z.lazy(() => MetadatumCloudflareHec$outboundSchema))
    .optional(),
  allowedIndexes: z.array(z.string()).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  accessControlAllowOrigin: z.array(z.string()).optional(),
  accessControlAllowHeaders: z.array(z.string()).optional(),
  emitTokenMetrics: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCloudflareHecToJSON(
  inputCloudflareHec: InputCloudflareHec,
): string {
  return JSON.stringify(
    InputCloudflareHec$outboundSchema.parse(inputCloudflareHec),
  );
}
export function inputCloudflareHecFromJSON(
  jsonString: string,
): SafeParseResult<InputCloudflareHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCloudflareHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCloudflareHec' from JSON`,
  );
}

/** @internal */
export const TypeZscalerHec$inboundSchema: z.ZodNativeEnum<
  typeof TypeZscalerHec
> = z.nativeEnum(TypeZscalerHec);
/** @internal */
export const TypeZscalerHec$outboundSchema: z.ZodNativeEnum<
  typeof TypeZscalerHec
> = TypeZscalerHec$inboundSchema;

/** @internal */
export const ConnectionZscalerHec$inboundSchema: z.ZodType<
  ConnectionZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionZscalerHec$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionZscalerHec$outboundSchema: z.ZodType<
  ConnectionZscalerHec$Outbound,
  z.ZodTypeDef,
  ConnectionZscalerHec
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionZscalerHecToJSON(
  connectionZscalerHec: ConnectionZscalerHec,
): string {
  return JSON.stringify(
    ConnectionZscalerHec$outboundSchema.parse(connectionZscalerHec),
  );
}
export function connectionZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionZscalerHec' from JSON`,
  );
}

/** @internal */
export const ModeZscalerHec$inboundSchema: z.ZodType<
  ModeZscalerHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeZscalerHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeZscalerHec$outboundSchema: z.ZodType<
  ModeZscalerHec,
  z.ZodTypeDef,
  ModeZscalerHec
> = z.union([
  z.nativeEnum(ModeZscalerHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionZscalerHec$inboundSchema: z.ZodType<
  CompressionZscalerHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionZscalerHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionZscalerHec$outboundSchema: z.ZodType<
  CompressionZscalerHec,
  z.ZodTypeDef,
  CompressionZscalerHec
> = z.union([
  z.nativeEnum(CompressionZscalerHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsZscalerHec$inboundSchema: z.ZodType<
  PqControlsZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsZscalerHec$Outbound = {};

/** @internal */
export const PqControlsZscalerHec$outboundSchema: z.ZodType<
  PqControlsZscalerHec$Outbound,
  z.ZodTypeDef,
  PqControlsZscalerHec
> = z.object({});

export function pqControlsZscalerHecToJSON(
  pqControlsZscalerHec: PqControlsZscalerHec,
): string {
  return JSON.stringify(
    PqControlsZscalerHec$outboundSchema.parse(pqControlsZscalerHec),
  );
}
export function pqControlsZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsZscalerHec' from JSON`,
  );
}

/** @internal */
export const PqZscalerHec$inboundSchema: z.ZodType<
  PqZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeZscalerHec$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionZscalerHec$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsZscalerHec$inboundSchema).optional(),
});
/** @internal */
export type PqZscalerHec$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsZscalerHec$Outbound | undefined;
};

/** @internal */
export const PqZscalerHec$outboundSchema: z.ZodType<
  PqZscalerHec$Outbound,
  z.ZodTypeDef,
  PqZscalerHec
> = z.object({
  mode: ModeZscalerHec$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionZscalerHec$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsZscalerHec$outboundSchema).optional(),
});

export function pqZscalerHecToJSON(pqZscalerHec: PqZscalerHec): string {
  return JSON.stringify(PqZscalerHec$outboundSchema.parse(pqZscalerHec));
}
export function pqZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<PqZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqZscalerHec' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodZscalerHec$inboundSchema: z.ZodType<
  AuthenticationMethodZscalerHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodZscalerHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodZscalerHec$outboundSchema: z.ZodType<
  AuthenticationMethodZscalerHec,
  z.ZodTypeDef,
  AuthenticationMethodZscalerHec
> = z.union([
  z.nativeEnum(AuthenticationMethodZscalerHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthTokenMetadatumZscalerHec$inboundSchema: z.ZodType<
  AuthTokenMetadatumZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokenMetadatumZscalerHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokenMetadatumZscalerHec$outboundSchema: z.ZodType<
  AuthTokenMetadatumZscalerHec$Outbound,
  z.ZodTypeDef,
  AuthTokenMetadatumZscalerHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokenMetadatumZscalerHecToJSON(
  authTokenMetadatumZscalerHec: AuthTokenMetadatumZscalerHec,
): string {
  return JSON.stringify(
    AuthTokenMetadatumZscalerHec$outboundSchema.parse(
      authTokenMetadatumZscalerHec,
    ),
  );
}
export function authTokenMetadatumZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenMetadatumZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenMetadatumZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenMetadatumZscalerHec' from JSON`,
  );
}

/** @internal */
export const AuthTokenZscalerHec$inboundSchema: z.ZodType<
  AuthTokenZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: AuthenticationMethodZscalerHec$inboundSchema.default("manual"),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(z.lazy(() => AuthTokenMetadatumZscalerHec$inboundSchema))
    .optional(),
});
/** @internal */
export type AuthTokenZscalerHec$Outbound = {
  authType: string;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled: boolean;
  description?: string | undefined;
  allowedIndexesAtToken?: Array<string> | undefined;
  metadata?: Array<AuthTokenMetadatumZscalerHec$Outbound> | undefined;
};

/** @internal */
export const AuthTokenZscalerHec$outboundSchema: z.ZodType<
  AuthTokenZscalerHec$Outbound,
  z.ZodTypeDef,
  AuthTokenZscalerHec
> = z.object({
  authType: AuthenticationMethodZscalerHec$outboundSchema.default("manual"),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(z.lazy(() => AuthTokenMetadatumZscalerHec$outboundSchema))
    .optional(),
});

export function authTokenZscalerHecToJSON(
  authTokenZscalerHec: AuthTokenZscalerHec,
): string {
  return JSON.stringify(
    AuthTokenZscalerHec$outboundSchema.parse(authTokenZscalerHec),
  );
}
export function authTokenZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenZscalerHec' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionZscalerHec$inboundSchema: z.ZodType<
  MinimumTLSVersionZscalerHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionZscalerHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionZscalerHec$outboundSchema: z.ZodType<
  MinimumTLSVersionZscalerHec,
  z.ZodTypeDef,
  MinimumTLSVersionZscalerHec
> = z.union([
  z.nativeEnum(MinimumTLSVersionZscalerHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionZscalerHec$inboundSchema: z.ZodType<
  MaximumTLSVersionZscalerHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionZscalerHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionZscalerHec$outboundSchema: z.ZodType<
  MaximumTLSVersionZscalerHec,
  z.ZodTypeDef,
  MaximumTLSVersionZscalerHec
> = z.union([
  z.nativeEnum(MaximumTLSVersionZscalerHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideZscalerHec$inboundSchema: z.ZodType<
  TLSSettingsServerSideZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionZscalerHec$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionZscalerHec$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideZscalerHec$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideZscalerHec$outboundSchema: z.ZodType<
  TLSSettingsServerSideZscalerHec$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideZscalerHec
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionZscalerHec$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionZscalerHec$outboundSchema.optional(),
});

export function tlsSettingsServerSideZscalerHecToJSON(
  tlsSettingsServerSideZscalerHec: TLSSettingsServerSideZscalerHec,
): string {
  return JSON.stringify(
    TLSSettingsServerSideZscalerHec$outboundSchema.parse(
      tlsSettingsServerSideZscalerHec,
    ),
  );
}
export function tlsSettingsServerSideZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideZscalerHec' from JSON`,
  );
}

/** @internal */
export const MetadatumZscalerHec$inboundSchema: z.ZodType<
  MetadatumZscalerHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumZscalerHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumZscalerHec$outboundSchema: z.ZodType<
  MetadatumZscalerHec$Outbound,
  z.ZodTypeDef,
  MetadatumZscalerHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumZscalerHecToJSON(
  metadatumZscalerHec: MetadatumZscalerHec,
): string {
  return JSON.stringify(
    MetadatumZscalerHec$outboundSchema.parse(metadatumZscalerHec),
  );
}
export function metadatumZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumZscalerHec' from JSON`,
  );
}

/** @internal */
export const InputZscalerHec$inboundSchema: z.ZodType<
  InputZscalerHec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeZscalerHec$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionZscalerHec$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqZscalerHec$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.lazy(() => AuthTokenZscalerHec$inboundSchema))
      .optional(),
    tls: z.lazy(() => TLSSettingsServerSideZscalerHec$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.any().optional(),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    hecAPI: z.string().default("/services/collector"),
    metadata: z.array(z.lazy(() => MetadatumZscalerHec$inboundSchema))
      .optional(),
    allowedIndexes: z.array(z.string()).optional(),
    hecAcks: z.boolean().default(false),
    accessControlAllowOrigin: z.array(z.string()).optional(),
    accessControlAllowHeaders: z.array(z.string()).optional(),
    emitTokenMetrics: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputZscalerHec$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionZscalerHec$Outbound> | undefined;
  pq?: PqZscalerHec$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<AuthTokenZscalerHec$Outbound> | undefined;
  tls?: TLSSettingsServerSideZscalerHec$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck?: any | undefined;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  hecAPI: string;
  metadata?: Array<MetadatumZscalerHec$Outbound> | undefined;
  allowedIndexes?: Array<string> | undefined;
  hecAcks: boolean;
  accessControlAllowOrigin?: Array<string> | undefined;
  accessControlAllowHeaders?: Array<string> | undefined;
  emitTokenMetrics: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputZscalerHec$outboundSchema: z.ZodType<
  InputZscalerHec$Outbound,
  z.ZodTypeDef,
  InputZscalerHec
> = z.object({
  id: z.string().optional(),
  type: TypeZscalerHec$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionZscalerHec$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqZscalerHec$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.lazy(() => AuthTokenZscalerHec$outboundSchema))
    .optional(),
  tls: z.lazy(() => TLSSettingsServerSideZscalerHec$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.any().optional(),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  hecAPI: z.string().default("/services/collector"),
  metadata: z.array(z.lazy(() => MetadatumZscalerHec$outboundSchema))
    .optional(),
  allowedIndexes: z.array(z.string()).optional(),
  hecAcks: z.boolean().default(false),
  accessControlAllowOrigin: z.array(z.string()).optional(),
  accessControlAllowHeaders: z.array(z.string()).optional(),
  emitTokenMetrics: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputZscalerHecToJSON(
  inputZscalerHec: InputZscalerHec,
): string {
  return JSON.stringify(InputZscalerHec$outboundSchema.parse(inputZscalerHec));
}
export function inputZscalerHecFromJSON(
  jsonString: string,
): SafeParseResult<InputZscalerHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputZscalerHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputZscalerHec' from JSON`,
  );
}

/** @internal */
export const InputTypeSecurityLake$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeSecurityLake
> = z.nativeEnum(InputTypeSecurityLake);
/** @internal */
export const InputTypeSecurityLake$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeSecurityLake
> = InputTypeSecurityLake$inboundSchema;

/** @internal */
export const ConnectionSecurityLake$inboundSchema: z.ZodType<
  ConnectionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSecurityLake$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSecurityLake$outboundSchema: z.ZodType<
  ConnectionSecurityLake$Outbound,
  z.ZodTypeDef,
  ConnectionSecurityLake
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSecurityLakeToJSON(
  connectionSecurityLake: ConnectionSecurityLake,
): string {
  return JSON.stringify(
    ConnectionSecurityLake$outboundSchema.parse(connectionSecurityLake),
  );
}
export function connectionSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSecurityLake' from JSON`,
  );
}

/** @internal */
export const ModeSecurityLake$inboundSchema: z.ZodType<
  ModeSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSecurityLake$outboundSchema: z.ZodType<
  ModeSecurityLake,
  z.ZodTypeDef,
  ModeSecurityLake
> = z.union([
  z.nativeEnum(ModeSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSecurityLake$inboundSchema: z.ZodType<
  CompressionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSecurityLake$outboundSchema: z.ZodType<
  CompressionSecurityLake,
  z.ZodTypeDef,
  CompressionSecurityLake
> = z.union([
  z.nativeEnum(CompressionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSecurityLake$inboundSchema: z.ZodType<
  PqControlsSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSecurityLake$Outbound = {};

/** @internal */
export const PqControlsSecurityLake$outboundSchema: z.ZodType<
  PqControlsSecurityLake$Outbound,
  z.ZodTypeDef,
  PqControlsSecurityLake
> = z.object({});

export function pqControlsSecurityLakeToJSON(
  pqControlsSecurityLake: PqControlsSecurityLake,
): string {
  return JSON.stringify(
    PqControlsSecurityLake$outboundSchema.parse(pqControlsSecurityLake),
  );
}
export function pqControlsSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSecurityLake' from JSON`,
  );
}

/** @internal */
export const PqSecurityLake$inboundSchema: z.ZodType<
  PqSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeSecurityLake$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSecurityLake$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSecurityLake$inboundSchema).optional(),
});
/** @internal */
export type PqSecurityLake$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsSecurityLake$Outbound | undefined;
};

/** @internal */
export const PqSecurityLake$outboundSchema: z.ZodType<
  PqSecurityLake$Outbound,
  z.ZodTypeDef,
  PqSecurityLake
> = z.object({
  mode: ModeSecurityLake$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSecurityLake$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSecurityLake$outboundSchema).optional(),
});

export function pqSecurityLakeToJSON(pqSecurityLake: PqSecurityLake): string {
  return JSON.stringify(PqSecurityLake$outboundSchema.parse(pqSecurityLake));
}
export function pqSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<PqSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSecurityLake' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodSecurityLake$inboundSchema: z.ZodType<
  InputAuthenticationMethodSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodSecurityLake$outboundSchema: z.ZodType<
  InputAuthenticationMethodSecurityLake,
  z.ZodTypeDef,
  InputAuthenticationMethodSecurityLake
> = z.union([
  z.nativeEnum(InputAuthenticationMethodSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSignatureVersionSecurityLake$inboundSchema: z.ZodType<
  InputSignatureVersionSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSignatureVersionSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSignatureVersionSecurityLake$outboundSchema: z.ZodType<
  InputSignatureVersionSecurityLake,
  z.ZodTypeDef,
  InputSignatureVersionSecurityLake
> = z.union([
  z.nativeEnum(InputSignatureVersionSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PreprocessSecurityLake$inboundSchema: z.ZodType<
  PreprocessSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessSecurityLake$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessSecurityLake$outboundSchema: z.ZodType<
  PreprocessSecurityLake$Outbound,
  z.ZodTypeDef,
  PreprocessSecurityLake
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessSecurityLakeToJSON(
  preprocessSecurityLake: PreprocessSecurityLake,
): string {
  return JSON.stringify(
    PreprocessSecurityLake$outboundSchema.parse(preprocessSecurityLake),
  );
}
export function preprocessSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<PreprocessSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessSecurityLake' from JSON`,
  );
}

/** @internal */
export const MetadatumSecurityLake$inboundSchema: z.ZodType<
  MetadatumSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSecurityLake$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSecurityLake$outboundSchema: z.ZodType<
  MetadatumSecurityLake$Outbound,
  z.ZodTypeDef,
  MetadatumSecurityLake
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSecurityLakeToJSON(
  metadatumSecurityLake: MetadatumSecurityLake,
): string {
  return JSON.stringify(
    MetadatumSecurityLake$outboundSchema.parse(metadatumSecurityLake),
  );
}
export function metadatumSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSecurityLake' from JSON`,
  );
}

/** @internal */
export const CheckpointingSecurityLake$inboundSchema: z.ZodType<
  CheckpointingSecurityLake,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});
/** @internal */
export type CheckpointingSecurityLake$Outbound = {
  enabled: boolean;
  retries: number;
};

/** @internal */
export const CheckpointingSecurityLake$outboundSchema: z.ZodType<
  CheckpointingSecurityLake$Outbound,
  z.ZodTypeDef,
  CheckpointingSecurityLake
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});

export function checkpointingSecurityLakeToJSON(
  checkpointingSecurityLake: CheckpointingSecurityLake,
): string {
  return JSON.stringify(
    CheckpointingSecurityLake$outboundSchema.parse(checkpointingSecurityLake),
  );
}
export function checkpointingSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<CheckpointingSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CheckpointingSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CheckpointingSecurityLake' from JSON`,
  );
}

/** @internal */
export const TagAfterProcessingSecurityLake$inboundSchema: z.ZodType<
  TagAfterProcessingSecurityLake,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TagAfterProcessingSecurityLake),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TagAfterProcessingSecurityLake$outboundSchema: z.ZodType<
  TagAfterProcessingSecurityLake,
  z.ZodTypeDef,
  TagAfterProcessingSecurityLake
> = z.union([
  z.nativeEnum(TagAfterProcessingSecurityLake),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSecurityLake$inboundSchema: z.ZodType<
  InputSecurityLake,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeSecurityLake$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSecurityLake$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSecurityLake$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    awsAccountId: z.string().optional(),
    awsAuthenticationMethod: InputAuthenticationMethodSecurityLake$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: InputSignatureVersionSecurityLake$inboundSchema.default(
      "v4",
    ),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    maxMessages: z.number().default(1),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    socketTimeout: z.number().default(300),
    skipOnError: z.boolean().default(false),
    includeSqsMetadata: z.boolean().default(false),
    enableAssumeRole: z.boolean().default(true),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    enableSQSAssumeRole: z.boolean().default(false),
    preprocess: z.lazy(() => PreprocessSecurityLake$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumSecurityLake$inboundSchema))
      .optional(),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    checkpointing: z.lazy(() => CheckpointingSecurityLake$inboundSchema)
      .optional(),
    pollTimeout: z.number().default(10),
    encoding: z.string().optional(),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    tagAfterProcessing: TagAfterProcessingSecurityLake$inboundSchema.optional(),
    processedTagKey: z.string().optional(),
    processedTagValue: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSecurityLake$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSecurityLake$Outbound> | undefined;
  pq?: PqSecurityLake$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  awsAccountId?: string | undefined;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  maxMessages: number;
  visibilityTimeout: number;
  numReceivers: number;
  socketTimeout: number;
  skipOnError: boolean;
  includeSqsMetadata: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  enableSQSAssumeRole: boolean;
  preprocess?: PreprocessSecurityLake$Outbound | undefined;
  metadata?: Array<MetadatumSecurityLake$Outbound> | undefined;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  checkpointing?: CheckpointingSecurityLake$Outbound | undefined;
  pollTimeout: number;
  encoding?: string | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  tagAfterProcessing?: string | undefined;
  processedTagKey?: string | undefined;
  processedTagValue?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSecurityLake$outboundSchema: z.ZodType<
  InputSecurityLake$Outbound,
  z.ZodTypeDef,
  InputSecurityLake
> = z.object({
  id: z.string().optional(),
  type: InputTypeSecurityLake$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSecurityLake$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSecurityLake$outboundSchema).optional(),
  queueName: z.string(),
  fileFilter: z.string().default("/.*/"),
  awsAccountId: z.string().optional(),
  awsAuthenticationMethod: InputAuthenticationMethodSecurityLake$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: InputSignatureVersionSecurityLake$outboundSchema.default(
    "v4",
  ),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  maxMessages: z.number().default(1),
  visibilityTimeout: z.number().default(600),
  numReceivers: z.number().default(1),
  socketTimeout: z.number().default(300),
  skipOnError: z.boolean().default(false),
  includeSqsMetadata: z.boolean().default(false),
  enableAssumeRole: z.boolean().default(true),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  enableSQSAssumeRole: z.boolean().default(false),
  preprocess: z.lazy(() => PreprocessSecurityLake$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumSecurityLake$outboundSchema))
    .optional(),
  parquetChunkSizeMB: z.number().default(5),
  parquetChunkDownloadTimeout: z.number().default(600),
  checkpointing: z.lazy(() => CheckpointingSecurityLake$outboundSchema)
    .optional(),
  pollTimeout: z.number().default(10),
  encoding: z.string().optional(),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  tagAfterProcessing: TagAfterProcessingSecurityLake$outboundSchema.optional(),
  processedTagKey: z.string().optional(),
  processedTagValue: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSecurityLakeToJSON(
  inputSecurityLake: InputSecurityLake,
): string {
  return JSON.stringify(
    InputSecurityLake$outboundSchema.parse(inputSecurityLake),
  );
}
export function inputSecurityLakeFromJSON(
  jsonString: string,
): SafeParseResult<InputSecurityLake, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSecurityLake$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSecurityLake' from JSON`,
  );
}

/** @internal */
export const InputTypeNetflow$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeNetflow
> = z.nativeEnum(InputTypeNetflow);
/** @internal */
export const InputTypeNetflow$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeNetflow
> = InputTypeNetflow$inboundSchema;

/** @internal */
export const ConnectionNetflow$inboundSchema: z.ZodType<
  ConnectionNetflow,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionNetflow$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionNetflow$outboundSchema: z.ZodType<
  ConnectionNetflow$Outbound,
  z.ZodTypeDef,
  ConnectionNetflow
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionNetflowToJSON(
  connectionNetflow: ConnectionNetflow,
): string {
  return JSON.stringify(
    ConnectionNetflow$outboundSchema.parse(connectionNetflow),
  );
}
export function connectionNetflowFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionNetflow' from JSON`,
  );
}

/** @internal */
export const ModeNetflow$inboundSchema: z.ZodType<
  ModeNetflow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeNetflow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeNetflow$outboundSchema: z.ZodType<
  ModeNetflow,
  z.ZodTypeDef,
  ModeNetflow
> = z.union([
  z.nativeEnum(ModeNetflow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionNetflow$inboundSchema: z.ZodType<
  CompressionNetflow,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionNetflow),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionNetflow$outboundSchema: z.ZodType<
  CompressionNetflow,
  z.ZodTypeDef,
  CompressionNetflow
> = z.union([
  z.nativeEnum(CompressionNetflow),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsNetflow$inboundSchema: z.ZodType<
  PqControlsNetflow,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsNetflow$Outbound = {};

/** @internal */
export const PqControlsNetflow$outboundSchema: z.ZodType<
  PqControlsNetflow$Outbound,
  z.ZodTypeDef,
  PqControlsNetflow
> = z.object({});

export function pqControlsNetflowToJSON(
  pqControlsNetflow: PqControlsNetflow,
): string {
  return JSON.stringify(
    PqControlsNetflow$outboundSchema.parse(pqControlsNetflow),
  );
}
export function pqControlsNetflowFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsNetflow' from JSON`,
  );
}

/** @internal */
export const PqNetflow$inboundSchema: z.ZodType<
  PqNetflow,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeNetflow$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionNetflow$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsNetflow$inboundSchema).optional(),
});
/** @internal */
export type PqNetflow$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsNetflow$Outbound | undefined;
};

/** @internal */
export const PqNetflow$outboundSchema: z.ZodType<
  PqNetflow$Outbound,
  z.ZodTypeDef,
  PqNetflow
> = z.object({
  mode: ModeNetflow$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionNetflow$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsNetflow$outboundSchema).optional(),
});

export function pqNetflowToJSON(pqNetflow: PqNetflow): string {
  return JSON.stringify(PqNetflow$outboundSchema.parse(pqNetflow));
}
export function pqNetflowFromJSON(
  jsonString: string,
): SafeParseResult<PqNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqNetflow' from JSON`,
  );
}

/** @internal */
export const MetadatumNetflow$inboundSchema: z.ZodType<
  MetadatumNetflow,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumNetflow$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumNetflow$outboundSchema: z.ZodType<
  MetadatumNetflow$Outbound,
  z.ZodTypeDef,
  MetadatumNetflow
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumNetflowToJSON(
  metadatumNetflow: MetadatumNetflow,
): string {
  return JSON.stringify(
    MetadatumNetflow$outboundSchema.parse(metadatumNetflow),
  );
}
export function metadatumNetflowFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumNetflow' from JSON`,
  );
}

/** @internal */
export const InputNetflow$inboundSchema: z.ZodType<
  InputNetflow,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeNetflow$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionNetflow$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqNetflow$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number().default(2055),
    enablePassThrough: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    udpSocketRxBufSize: z.number().optional(),
    templateCacheMinutes: z.number().default(30),
    v5Enabled: z.boolean().default(true),
    v9Enabled: z.boolean().default(true),
    ipfixEnabled: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumNetflow$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputNetflow$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionNetflow$Outbound> | undefined;
  pq?: PqNetflow$Outbound | undefined;
  host: string;
  port: number;
  enablePassThrough: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  udpSocketRxBufSize?: number | undefined;
  templateCacheMinutes: number;
  v5Enabled: boolean;
  v9Enabled: boolean;
  ipfixEnabled: boolean;
  metadata?: Array<MetadatumNetflow$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputNetflow$outboundSchema: z.ZodType<
  InputNetflow$Outbound,
  z.ZodTypeDef,
  InputNetflow
> = z.object({
  id: z.string().optional(),
  type: InputTypeNetflow$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionNetflow$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqNetflow$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number().default(2055),
  enablePassThrough: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  udpSocketRxBufSize: z.number().optional(),
  templateCacheMinutes: z.number().default(30),
  v5Enabled: z.boolean().default(true),
  v9Enabled: z.boolean().default(true),
  ipfixEnabled: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumNetflow$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputNetflowToJSON(inputNetflow: InputNetflow): string {
  return JSON.stringify(InputNetflow$outboundSchema.parse(inputNetflow));
}
export function inputNetflowFromJSON(
  jsonString: string,
): SafeParseResult<InputNetflow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputNetflow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputNetflow' from JSON`,
  );
}

/** @internal */
export const TypeWizWebhook$inboundSchema: z.ZodNativeEnum<
  typeof TypeWizWebhook
> = z.nativeEnum(TypeWizWebhook);
/** @internal */
export const TypeWizWebhook$outboundSchema: z.ZodNativeEnum<
  typeof TypeWizWebhook
> = TypeWizWebhook$inboundSchema;

/** @internal */
export const ConnectionWizWebhook$inboundSchema: z.ZodType<
  ConnectionWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionWizWebhook$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionWizWebhook$outboundSchema: z.ZodType<
  ConnectionWizWebhook$Outbound,
  z.ZodTypeDef,
  ConnectionWizWebhook
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionWizWebhookToJSON(
  connectionWizWebhook: ConnectionWizWebhook,
): string {
  return JSON.stringify(
    ConnectionWizWebhook$outboundSchema.parse(connectionWizWebhook),
  );
}
export function connectionWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionWizWebhook' from JSON`,
  );
}

/** @internal */
export const ModeWizWebhook$inboundSchema: z.ZodType<
  ModeWizWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeWizWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeWizWebhook$outboundSchema: z.ZodType<
  ModeWizWebhook,
  z.ZodTypeDef,
  ModeWizWebhook
> = z.union([
  z.nativeEnum(ModeWizWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionWizWebhook$inboundSchema: z.ZodType<
  CompressionWizWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWizWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWizWebhook$outboundSchema: z.ZodType<
  CompressionWizWebhook,
  z.ZodTypeDef,
  CompressionWizWebhook
> = z.union([
  z.nativeEnum(CompressionWizWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWizWebhook$inboundSchema: z.ZodType<
  PqControlsWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWizWebhook$Outbound = {};

/** @internal */
export const PqControlsWizWebhook$outboundSchema: z.ZodType<
  PqControlsWizWebhook$Outbound,
  z.ZodTypeDef,
  PqControlsWizWebhook
> = z.object({});

export function pqControlsWizWebhookToJSON(
  pqControlsWizWebhook: PqControlsWizWebhook,
): string {
  return JSON.stringify(
    PqControlsWizWebhook$outboundSchema.parse(pqControlsWizWebhook),
  );
}
export function pqControlsWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWizWebhook' from JSON`,
  );
}

/** @internal */
export const PqWizWebhook$inboundSchema: z.ZodType<
  PqWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeWizWebhook$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWizWebhook$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWizWebhook$inboundSchema).optional(),
});
/** @internal */
export type PqWizWebhook$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsWizWebhook$Outbound | undefined;
};

/** @internal */
export const PqWizWebhook$outboundSchema: z.ZodType<
  PqWizWebhook$Outbound,
  z.ZodTypeDef,
  PqWizWebhook
> = z.object({
  mode: ModeWizWebhook$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWizWebhook$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWizWebhook$outboundSchema).optional(),
});

export function pqWizWebhookToJSON(pqWizWebhook: PqWizWebhook): string {
  return JSON.stringify(PqWizWebhook$outboundSchema.parse(pqWizWebhook));
}
export function pqWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<PqWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqWizWebhook' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionWizWebhook$inboundSchema: z.ZodType<
  MinimumTLSVersionWizWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionWizWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionWizWebhook$outboundSchema: z.ZodType<
  MinimumTLSVersionWizWebhook,
  z.ZodTypeDef,
  MinimumTLSVersionWizWebhook
> = z.union([
  z.nativeEnum(MinimumTLSVersionWizWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionWizWebhook$inboundSchema: z.ZodType<
  MaximumTLSVersionWizWebhook,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionWizWebhook),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionWizWebhook$outboundSchema: z.ZodType<
  MaximumTLSVersionWizWebhook,
  z.ZodTypeDef,
  MaximumTLSVersionWizWebhook
> = z.union([
  z.nativeEnum(MaximumTLSVersionWizWebhook),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideWizWebhook$inboundSchema: z.ZodType<
  TLSSettingsServerSideWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionWizWebhook$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionWizWebhook$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideWizWebhook$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideWizWebhook$outboundSchema: z.ZodType<
  TLSSettingsServerSideWizWebhook$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideWizWebhook
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionWizWebhook$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionWizWebhook$outboundSchema.optional(),
});

export function tlsSettingsServerSideWizWebhookToJSON(
  tlsSettingsServerSideWizWebhook: TLSSettingsServerSideWizWebhook,
): string {
  return JSON.stringify(
    TLSSettingsServerSideWizWebhook$outboundSchema.parse(
      tlsSettingsServerSideWizWebhook,
    ),
  );
}
export function tlsSettingsServerSideWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideWizWebhook' from JSON`,
  );
}

/** @internal */
export const MetadatumWizWebhook$inboundSchema: z.ZodType<
  MetadatumWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumWizWebhook$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumWizWebhook$outboundSchema: z.ZodType<
  MetadatumWizWebhook$Outbound,
  z.ZodTypeDef,
  MetadatumWizWebhook
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumWizWebhookToJSON(
  metadatumWizWebhook: MetadatumWizWebhook,
): string {
  return JSON.stringify(
    MetadatumWizWebhook$outboundSchema.parse(metadatumWizWebhook),
  );
}
export function metadatumWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumWizWebhook' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtMetadatumWizWebhook$inboundSchema: z.ZodType<
  AuthTokensExtMetadatumWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokensExtMetadatumWizWebhook$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokensExtMetadatumWizWebhook$outboundSchema: z.ZodType<
  AuthTokensExtMetadatumWizWebhook$Outbound,
  z.ZodTypeDef,
  AuthTokensExtMetadatumWizWebhook
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokensExtMetadatumWizWebhookToJSON(
  authTokensExtMetadatumWizWebhook: AuthTokensExtMetadatumWizWebhook,
): string {
  return JSON.stringify(
    AuthTokensExtMetadatumWizWebhook$outboundSchema.parse(
      authTokensExtMetadatumWizWebhook,
    ),
  );
}
export function authTokensExtMetadatumWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtMetadatumWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtMetadatumWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtMetadatumWizWebhook' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtWizWebhook$inboundSchema: z.ZodType<
  AuthTokensExtWizWebhook,
  z.ZodTypeDef,
  unknown
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(
    z.lazy(() => AuthTokensExtMetadatumWizWebhook$inboundSchema),
  ).optional(),
});
/** @internal */
export type AuthTokensExtWizWebhook$Outbound = {
  token: string;
  description?: string | undefined;
  metadata?: Array<AuthTokensExtMetadatumWizWebhook$Outbound> | undefined;
};

/** @internal */
export const AuthTokensExtWizWebhook$outboundSchema: z.ZodType<
  AuthTokensExtWizWebhook$Outbound,
  z.ZodTypeDef,
  AuthTokensExtWizWebhook
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(
    z.lazy(() => AuthTokensExtMetadatumWizWebhook$outboundSchema),
  ).optional(),
});

export function authTokensExtWizWebhookToJSON(
  authTokensExtWizWebhook: AuthTokensExtWizWebhook,
): string {
  return JSON.stringify(
    AuthTokensExtWizWebhook$outboundSchema.parse(authTokensExtWizWebhook),
  );
}
export function authTokensExtWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtWizWebhook' from JSON`,
  );
}

/** @internal */
export const InputWizWebhook$inboundSchema: z.ZodType<
  InputWizWebhook,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWizWebhook$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionWizWebhook$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqWizWebhook$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.string()).optional(),
    tls: z.lazy(() => TLSSettingsServerSideWizWebhook$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    metadata: z.array(z.lazy(() => MetadatumWizWebhook$inboundSchema))
      .optional(),
    allowedPaths: z.array(z.string()).optional(),
    allowedMethods: z.array(z.string()).optional(),
    authTokensExt: z.array(z.lazy(() => AuthTokensExtWizWebhook$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputWizWebhook$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionWizWebhook$Outbound> | undefined;
  pq?: PqWizWebhook$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideWizWebhook$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  metadata?: Array<MetadatumWizWebhook$Outbound> | undefined;
  allowedPaths?: Array<string> | undefined;
  allowedMethods?: Array<string> | undefined;
  authTokensExt?: Array<AuthTokensExtWizWebhook$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputWizWebhook$outboundSchema: z.ZodType<
  InputWizWebhook$Outbound,
  z.ZodTypeDef,
  InputWizWebhook
> = z.object({
  id: z.string().optional(),
  type: TypeWizWebhook$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionWizWebhook$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqWizWebhook$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.string()).optional(),
  tls: z.lazy(() => TLSSettingsServerSideWizWebhook$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  metadata: z.array(z.lazy(() => MetadatumWizWebhook$outboundSchema))
    .optional(),
  allowedPaths: z.array(z.string()).optional(),
  allowedMethods: z.array(z.string()).optional(),
  authTokensExt: z.array(z.lazy(() => AuthTokensExtWizWebhook$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputWizWebhookToJSON(
  inputWizWebhook: InputWizWebhook,
): string {
  return JSON.stringify(InputWizWebhook$outboundSchema.parse(inputWizWebhook));
}
export function inputWizWebhookFromJSON(
  jsonString: string,
): SafeParseResult<InputWizWebhook, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputWizWebhook$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputWizWebhook' from JSON`,
  );
}

/** @internal */
export const TypeWiz$inboundSchema: z.ZodNativeEnum<typeof TypeWiz> = z
  .nativeEnum(TypeWiz);
/** @internal */
export const TypeWiz$outboundSchema: z.ZodNativeEnum<typeof TypeWiz> =
  TypeWiz$inboundSchema;

/** @internal */
export const ConnectionWiz$inboundSchema: z.ZodType<
  ConnectionWiz,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionWiz$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionWiz$outboundSchema: z.ZodType<
  ConnectionWiz$Outbound,
  z.ZodTypeDef,
  ConnectionWiz
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionWizToJSON(connectionWiz: ConnectionWiz): string {
  return JSON.stringify(ConnectionWiz$outboundSchema.parse(connectionWiz));
}
export function connectionWizFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionWiz' from JSON`,
  );
}

/** @internal */
export const ModeWiz$inboundSchema: z.ZodType<ModeWiz, z.ZodTypeDef, unknown> =
  z
    .union([
      z.nativeEnum(ModeWiz),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ModeWiz$outboundSchema: z.ZodType<ModeWiz, z.ZodTypeDef, ModeWiz> =
  z.union([
    z.nativeEnum(ModeWiz),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const CompressionWiz$inboundSchema: z.ZodType<
  CompressionWiz,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWiz),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWiz$outboundSchema: z.ZodType<
  CompressionWiz,
  z.ZodTypeDef,
  CompressionWiz
> = z.union([
  z.nativeEnum(CompressionWiz),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWiz$inboundSchema: z.ZodType<
  PqControlsWiz,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWiz$Outbound = {};

/** @internal */
export const PqControlsWiz$outboundSchema: z.ZodType<
  PqControlsWiz$Outbound,
  z.ZodTypeDef,
  PqControlsWiz
> = z.object({});

export function pqControlsWizToJSON(pqControlsWiz: PqControlsWiz): string {
  return JSON.stringify(PqControlsWiz$outboundSchema.parse(pqControlsWiz));
}
export function pqControlsWizFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWiz' from JSON`,
  );
}

/** @internal */
export const PqWiz$inboundSchema: z.ZodType<PqWiz, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeWiz$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionWiz$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsWiz$inboundSchema).optional(),
  });
/** @internal */
export type PqWiz$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsWiz$Outbound | undefined;
};

/** @internal */
export const PqWiz$outboundSchema: z.ZodType<
  PqWiz$Outbound,
  z.ZodTypeDef,
  PqWiz
> = z.object({
  mode: ModeWiz$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWiz$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWiz$outboundSchema).optional(),
});

export function pqWizToJSON(pqWiz: PqWiz): string {
  return JSON.stringify(PqWiz$outboundSchema.parse(pqWiz));
}
export function pqWizFromJSON(
  jsonString: string,
): SafeParseResult<PqWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqWiz' from JSON`,
  );
}

/** @internal */
export const ContentConfigWiz$inboundSchema: z.ZodType<
  ContentConfigWiz,
  z.ZodTypeDef,
  unknown
> = z.object({
  contentType: z.string(),
  contentDescription: z.string().optional(),
  enabled: z.boolean().default(false),
});
/** @internal */
export type ContentConfigWiz$Outbound = {
  contentType: string;
  contentDescription?: string | undefined;
  enabled: boolean;
};

/** @internal */
export const ContentConfigWiz$outboundSchema: z.ZodType<
  ContentConfigWiz$Outbound,
  z.ZodTypeDef,
  ContentConfigWiz
> = z.object({
  contentType: z.string(),
  contentDescription: z.string().optional(),
  enabled: z.boolean().default(false),
});

export function contentConfigWizToJSON(
  contentConfigWiz: ContentConfigWiz,
): string {
  return JSON.stringify(
    ContentConfigWiz$outboundSchema.parse(contentConfigWiz),
  );
}
export function contentConfigWizFromJSON(
  jsonString: string,
): SafeParseResult<ContentConfigWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ContentConfigWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ContentConfigWiz' from JSON`,
  );
}

/** @internal */
export const MetadatumWiz$inboundSchema: z.ZodType<
  MetadatumWiz,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumWiz$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumWiz$outboundSchema: z.ZodType<
  MetadatumWiz$Outbound,
  z.ZodTypeDef,
  MetadatumWiz
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumWizToJSON(metadatumWiz: MetadatumWiz): string {
  return JSON.stringify(MetadatumWiz$outboundSchema.parse(metadatumWiz));
}
export function metadatumWizFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumWiz' from JSON`,
  );
}

/** @internal */
export const RetryTypeWiz$inboundSchema: z.ZodType<
  RetryTypeWiz,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RetryTypeWiz),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RetryTypeWiz$outboundSchema: z.ZodType<
  RetryTypeWiz,
  z.ZodTypeDef,
  RetryTypeWiz
> = z.union([
  z.nativeEnum(RetryTypeWiz),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RetryRulesWiz$inboundSchema: z.ZodType<
  RetryRulesWiz,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RetryTypeWiz$inboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});
/** @internal */
export type RetryRulesWiz$Outbound = {
  type: string;
  interval: number;
  limit: number;
  multiplier: number;
  codes?: Array<number> | undefined;
  enableHeader: boolean;
  retryConnectTimeout: boolean;
  retryConnectReset: boolean;
};

/** @internal */
export const RetryRulesWiz$outboundSchema: z.ZodType<
  RetryRulesWiz$Outbound,
  z.ZodTypeDef,
  RetryRulesWiz
> = z.object({
  type: RetryTypeWiz$outboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});

export function retryRulesWizToJSON(retryRulesWiz: RetryRulesWiz): string {
  return JSON.stringify(RetryRulesWiz$outboundSchema.parse(retryRulesWiz));
}
export function retryRulesWizFromJSON(
  jsonString: string,
): SafeParseResult<RetryRulesWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RetryRulesWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RetryRulesWiz' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodWiz$inboundSchema: z.ZodType<
  AuthenticationMethodWiz,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodWiz),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodWiz$outboundSchema: z.ZodType<
  AuthenticationMethodWiz,
  z.ZodTypeDef,
  AuthenticationMethodWiz
> = z.union([
  z.nativeEnum(AuthenticationMethodWiz),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputWiz$inboundSchema: z.ZodType<
  InputWiz,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWiz$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionWiz$inboundSchema)).optional(),
    pq: z.lazy(() => PqWiz$inboundSchema).optional(),
    endpoint: z.string().default("https://api.<region>.app.wiz.io/graphql"),
    authUrl: z.string(),
    authAudienceOverride: z.string().optional(),
    clientId: z.string(),
    contentConfig: z.array(z.lazy(() => ContentConfigWiz$inboundSchema)),
    requestTimeout: z.number().default(300),
    keepAliveTime: z.number().default(30),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumWiz$inboundSchema)).optional(),
    retryRules: z.lazy(() => RetryRulesWiz$inboundSchema).optional(),
    authType: AuthenticationMethodWiz$inboundSchema.default("manual"),
    description: z.string().optional(),
    clientSecret: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputWiz$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionWiz$Outbound> | undefined;
  pq?: PqWiz$Outbound | undefined;
  endpoint: string;
  authUrl: string;
  authAudienceOverride?: string | undefined;
  clientId: string;
  contentConfig: Array<ContentConfigWiz$Outbound>;
  requestTimeout: number;
  keepAliveTime: number;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumWiz$Outbound> | undefined;
  retryRules?: RetryRulesWiz$Outbound | undefined;
  authType: string;
  description?: string | undefined;
  clientSecret?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputWiz$outboundSchema: z.ZodType<
  InputWiz$Outbound,
  z.ZodTypeDef,
  InputWiz
> = z.object({
  id: z.string().optional(),
  type: TypeWiz$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionWiz$outboundSchema)).optional(),
  pq: z.lazy(() => PqWiz$outboundSchema).optional(),
  endpoint: z.string().default("https://api.<region>.app.wiz.io/graphql"),
  authUrl: z.string(),
  authAudienceOverride: z.string().optional(),
  clientId: z.string(),
  contentConfig: z.array(z.lazy(() => ContentConfigWiz$outboundSchema)),
  requestTimeout: z.number().default(300),
  keepAliveTime: z.number().default(30),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumWiz$outboundSchema)).optional(),
  retryRules: z.lazy(() => RetryRulesWiz$outboundSchema).optional(),
  authType: AuthenticationMethodWiz$outboundSchema.default("manual"),
  description: z.string().optional(),
  clientSecret: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputWizToJSON(inputWiz: InputWiz): string {
  return JSON.stringify(InputWiz$outboundSchema.parse(inputWiz));
}
export function inputWizFromJSON(
  jsonString: string,
): SafeParseResult<InputWiz, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputWiz$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputWiz' from JSON`,
  );
}

/** @internal */
export const InputJournalFilesType$inboundSchema: z.ZodNativeEnum<
  typeof InputJournalFilesType
> = z.nativeEnum(InputJournalFilesType);
/** @internal */
export const InputJournalFilesType$outboundSchema: z.ZodNativeEnum<
  typeof InputJournalFilesType
> = InputJournalFilesType$inboundSchema;

/** @internal */
export const InputJournalFilesConnection$inboundSchema: z.ZodType<
  InputJournalFilesConnection,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputJournalFilesConnection$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputJournalFilesConnection$outboundSchema: z.ZodType<
  InputJournalFilesConnection$Outbound,
  z.ZodTypeDef,
  InputJournalFilesConnection
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputJournalFilesConnectionToJSON(
  inputJournalFilesConnection: InputJournalFilesConnection,
): string {
  return JSON.stringify(
    InputJournalFilesConnection$outboundSchema.parse(
      inputJournalFilesConnection,
    ),
  );
}
export function inputJournalFilesConnectionFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFilesConnection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFilesConnection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFilesConnection' from JSON`,
  );
}

/** @internal */
export const InputJournalFilesMode$inboundSchema: z.ZodType<
  InputJournalFilesMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputJournalFilesMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputJournalFilesMode$outboundSchema: z.ZodType<
  InputJournalFilesMode,
  z.ZodTypeDef,
  InputJournalFilesMode
> = z.union([
  z.nativeEnum(InputJournalFilesMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputJournalFilesCompression$inboundSchema: z.ZodType<
  InputJournalFilesCompression,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputJournalFilesCompression),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputJournalFilesCompression$outboundSchema: z.ZodType<
  InputJournalFilesCompression,
  z.ZodTypeDef,
  InputJournalFilesCompression
> = z.union([
  z.nativeEnum(InputJournalFilesCompression),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputJournalFilesPqControls$inboundSchema: z.ZodType<
  InputJournalFilesPqControls,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputJournalFilesPqControls$Outbound = {};

/** @internal */
export const InputJournalFilesPqControls$outboundSchema: z.ZodType<
  InputJournalFilesPqControls$Outbound,
  z.ZodTypeDef,
  InputJournalFilesPqControls
> = z.object({});

export function inputJournalFilesPqControlsToJSON(
  inputJournalFilesPqControls: InputJournalFilesPqControls,
): string {
  return JSON.stringify(
    InputJournalFilesPqControls$outboundSchema.parse(
      inputJournalFilesPqControls,
    ),
  );
}
export function inputJournalFilesPqControlsFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFilesPqControls, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFilesPqControls$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFilesPqControls' from JSON`,
  );
}

/** @internal */
export const InputJournalFilesPq$inboundSchema: z.ZodType<
  InputJournalFilesPq,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputJournalFilesMode$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputJournalFilesCompression$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputJournalFilesPqControls$inboundSchema)
    .optional(),
});
/** @internal */
export type InputJournalFilesPq$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputJournalFilesPqControls$Outbound | undefined;
};

/** @internal */
export const InputJournalFilesPq$outboundSchema: z.ZodType<
  InputJournalFilesPq$Outbound,
  z.ZodTypeDef,
  InputJournalFilesPq
> = z.object({
  mode: InputJournalFilesMode$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputJournalFilesCompression$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputJournalFilesPqControls$outboundSchema)
    .optional(),
});

export function inputJournalFilesPqToJSON(
  inputJournalFilesPq: InputJournalFilesPq,
): string {
  return JSON.stringify(
    InputJournalFilesPq$outboundSchema.parse(inputJournalFilesPq),
  );
}
export function inputJournalFilesPqFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFilesPq, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFilesPq$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFilesPq' from JSON`,
  );
}

/** @internal */
export const InputJournalFilesRule$inboundSchema: z.ZodType<
  InputJournalFilesRule,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type InputJournalFilesRule$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const InputJournalFilesRule$outboundSchema: z.ZodType<
  InputJournalFilesRule$Outbound,
  z.ZodTypeDef,
  InputJournalFilesRule
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function inputJournalFilesRuleToJSON(
  inputJournalFilesRule: InputJournalFilesRule,
): string {
  return JSON.stringify(
    InputJournalFilesRule$outboundSchema.parse(inputJournalFilesRule),
  );
}
export function inputJournalFilesRuleFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFilesRule, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFilesRule$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFilesRule' from JSON`,
  );
}

/** @internal */
export const InputJournalFilesMetadatum$inboundSchema: z.ZodType<
  InputJournalFilesMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputJournalFilesMetadatum$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputJournalFilesMetadatum$outboundSchema: z.ZodType<
  InputJournalFilesMetadatum$Outbound,
  z.ZodTypeDef,
  InputJournalFilesMetadatum
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputJournalFilesMetadatumToJSON(
  inputJournalFilesMetadatum: InputJournalFilesMetadatum,
): string {
  return JSON.stringify(
    InputJournalFilesMetadatum$outboundSchema.parse(inputJournalFilesMetadatum),
  );
}
export function inputJournalFilesMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFilesMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFilesMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFilesMetadatum' from JSON`,
  );
}

/** @internal */
export const InputJournalFiles$inboundSchema: z.ZodType<
  InputJournalFiles,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputJournalFilesType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(
      z.lazy(() => InputJournalFilesConnection$inboundSchema),
    ).optional(),
    pq: z.lazy(() => InputJournalFilesPq$inboundSchema).optional(),
    path: z.string(),
    interval: z.number().default(10),
    journals: z.array(z.string()),
    rules: z.array(z.lazy(() => InputJournalFilesRule$inboundSchema))
      .optional(),
    currentBoot: z.boolean().default(false),
    maxAgeDur: z.string().optional(),
    metadata: z.array(z.lazy(() => InputJournalFilesMetadatum$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputJournalFiles$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputJournalFilesConnection$Outbound> | undefined;
  pq?: InputJournalFilesPq$Outbound | undefined;
  path: string;
  interval: number;
  journals: Array<string>;
  rules?: Array<InputJournalFilesRule$Outbound> | undefined;
  currentBoot: boolean;
  maxAgeDur?: string | undefined;
  metadata?: Array<InputJournalFilesMetadatum$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputJournalFiles$outboundSchema: z.ZodType<
  InputJournalFiles$Outbound,
  z.ZodTypeDef,
  InputJournalFiles
> = z.object({
  id: z.string().optional(),
  type: InputJournalFilesType$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputJournalFilesConnection$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputJournalFilesPq$outboundSchema).optional(),
  path: z.string(),
  interval: z.number().default(10),
  journals: z.array(z.string()),
  rules: z.array(z.lazy(() => InputJournalFilesRule$outboundSchema)).optional(),
  currentBoot: z.boolean().default(false),
  maxAgeDur: z.string().optional(),
  metadata: z.array(z.lazy(() => InputJournalFilesMetadatum$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputJournalFilesToJSON(
  inputJournalFiles: InputJournalFiles,
): string {
  return JSON.stringify(
    InputJournalFiles$outboundSchema.parse(inputJournalFiles),
  );
}
export function inputJournalFilesFromJSON(
  jsonString: string,
): SafeParseResult<InputJournalFiles, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputJournalFiles$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputJournalFiles' from JSON`,
  );
}

/** @internal */
export const TypeRawUDP$inboundSchema: z.ZodNativeEnum<typeof TypeRawUDP> = z
  .nativeEnum(TypeRawUDP);
/** @internal */
export const TypeRawUDP$outboundSchema: z.ZodNativeEnum<typeof TypeRawUDP> =
  TypeRawUDP$inboundSchema;

/** @internal */
export const ConnectionRawUDP$inboundSchema: z.ZodType<
  ConnectionRawUDP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionRawUDP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionRawUDP$outboundSchema: z.ZodType<
  ConnectionRawUDP$Outbound,
  z.ZodTypeDef,
  ConnectionRawUDP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionRawUDPToJSON(
  connectionRawUDP: ConnectionRawUDP,
): string {
  return JSON.stringify(
    ConnectionRawUDP$outboundSchema.parse(connectionRawUDP),
  );
}
export function connectionRawUDPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionRawUDP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionRawUDP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionRawUDP' from JSON`,
  );
}

/** @internal */
export const ModeRawUDP$inboundSchema: z.ZodType<
  ModeRawUDP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeRawUDP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeRawUDP$outboundSchema: z.ZodType<
  ModeRawUDP,
  z.ZodTypeDef,
  ModeRawUDP
> = z.union([
  z.nativeEnum(ModeRawUDP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionRawUDP$inboundSchema: z.ZodType<
  CompressionRawUDP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionRawUDP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionRawUDP$outboundSchema: z.ZodType<
  CompressionRawUDP,
  z.ZodTypeDef,
  CompressionRawUDP
> = z.union([
  z.nativeEnum(CompressionRawUDP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsRawUDP$inboundSchema: z.ZodType<
  PqControlsRawUDP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsRawUDP$Outbound = {};

/** @internal */
export const PqControlsRawUDP$outboundSchema: z.ZodType<
  PqControlsRawUDP$Outbound,
  z.ZodTypeDef,
  PqControlsRawUDP
> = z.object({});

export function pqControlsRawUDPToJSON(
  pqControlsRawUDP: PqControlsRawUDP,
): string {
  return JSON.stringify(
    PqControlsRawUDP$outboundSchema.parse(pqControlsRawUDP),
  );
}
export function pqControlsRawUDPFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsRawUDP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsRawUDP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsRawUDP' from JSON`,
  );
}

/** @internal */
export const PqRawUDP$inboundSchema: z.ZodType<
  PqRawUDP,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeRawUDP$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionRawUDP$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsRawUDP$inboundSchema).optional(),
});
/** @internal */
export type PqRawUDP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsRawUDP$Outbound | undefined;
};

/** @internal */
export const PqRawUDP$outboundSchema: z.ZodType<
  PqRawUDP$Outbound,
  z.ZodTypeDef,
  PqRawUDP
> = z.object({
  mode: ModeRawUDP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionRawUDP$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsRawUDP$outboundSchema).optional(),
});

export function pqRawUDPToJSON(pqRawUDP: PqRawUDP): string {
  return JSON.stringify(PqRawUDP$outboundSchema.parse(pqRawUDP));
}
export function pqRawUDPFromJSON(
  jsonString: string,
): SafeParseResult<PqRawUDP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqRawUDP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqRawUDP' from JSON`,
  );
}

/** @internal */
export const MetadatumRawUDP$inboundSchema: z.ZodType<
  MetadatumRawUDP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumRawUDP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumRawUDP$outboundSchema: z.ZodType<
  MetadatumRawUDP$Outbound,
  z.ZodTypeDef,
  MetadatumRawUDP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumRawUDPToJSON(
  metadatumRawUDP: MetadatumRawUDP,
): string {
  return JSON.stringify(MetadatumRawUDP$outboundSchema.parse(metadatumRawUDP));
}
export function metadatumRawUDPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumRawUDP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumRawUDP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumRawUDP' from JSON`,
  );
}

/** @internal */
export const InputRawUdp$inboundSchema: z.ZodType<
  InputRawUdp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeRawUDP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionRawUDP$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqRawUDP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    maxBufferSize: z.number().default(1000),
    ipWhitelistRegex: z.string().default("/.*/"),
    singleMsgUdpPackets: z.boolean().default(false),
    ingestRawBytes: z.boolean().default(false),
    udpSocketRxBufSize: z.number().optional(),
    metadata: z.array(z.lazy(() => MetadatumRawUDP$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputRawUdp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionRawUDP$Outbound> | undefined;
  pq?: PqRawUDP$Outbound | undefined;
  host: string;
  port: number;
  maxBufferSize: number;
  ipWhitelistRegex: string;
  singleMsgUdpPackets: boolean;
  ingestRawBytes: boolean;
  udpSocketRxBufSize?: number | undefined;
  metadata?: Array<MetadatumRawUDP$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputRawUdp$outboundSchema: z.ZodType<
  InputRawUdp$Outbound,
  z.ZodTypeDef,
  InputRawUdp
> = z.object({
  id: z.string().optional(),
  type: TypeRawUDP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionRawUDP$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqRawUDP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  maxBufferSize: z.number().default(1000),
  ipWhitelistRegex: z.string().default("/.*/"),
  singleMsgUdpPackets: z.boolean().default(false),
  ingestRawBytes: z.boolean().default(false),
  udpSocketRxBufSize: z.number().optional(),
  metadata: z.array(z.lazy(() => MetadatumRawUDP$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputRawUdpToJSON(inputRawUdp: InputRawUdp): string {
  return JSON.stringify(InputRawUdp$outboundSchema.parse(inputRawUdp));
}
export function inputRawUdpFromJSON(
  jsonString: string,
): SafeParseResult<InputRawUdp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputRawUdp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputRawUdp' from JSON`,
  );
}

/** @internal */
export const TypeWinEventLogs$inboundSchema: z.ZodNativeEnum<
  typeof TypeWinEventLogs
> = z.nativeEnum(TypeWinEventLogs);
/** @internal */
export const TypeWinEventLogs$outboundSchema: z.ZodNativeEnum<
  typeof TypeWinEventLogs
> = TypeWinEventLogs$inboundSchema;

/** @internal */
export const ConnectionWinEventLogs$inboundSchema: z.ZodType<
  ConnectionWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionWinEventLogs$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionWinEventLogs$outboundSchema: z.ZodType<
  ConnectionWinEventLogs$Outbound,
  z.ZodTypeDef,
  ConnectionWinEventLogs
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionWinEventLogsToJSON(
  connectionWinEventLogs: ConnectionWinEventLogs,
): string {
  return JSON.stringify(
    ConnectionWinEventLogs$outboundSchema.parse(connectionWinEventLogs),
  );
}
export function connectionWinEventLogsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionWinEventLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionWinEventLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionWinEventLogs' from JSON`,
  );
}

/** @internal */
export const ModeWinEventLogs$inboundSchema: z.ZodType<
  ModeWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeWinEventLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeWinEventLogs$outboundSchema: z.ZodType<
  ModeWinEventLogs,
  z.ZodTypeDef,
  ModeWinEventLogs
> = z.union([
  z.nativeEnum(ModeWinEventLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionWinEventLogs$inboundSchema: z.ZodType<
  CompressionWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWinEventLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWinEventLogs$outboundSchema: z.ZodType<
  CompressionWinEventLogs,
  z.ZodTypeDef,
  CompressionWinEventLogs
> = z.union([
  z.nativeEnum(CompressionWinEventLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWinEventLogs$inboundSchema: z.ZodType<
  PqControlsWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWinEventLogs$Outbound = {};

/** @internal */
export const PqControlsWinEventLogs$outboundSchema: z.ZodType<
  PqControlsWinEventLogs$Outbound,
  z.ZodTypeDef,
  PqControlsWinEventLogs
> = z.object({});

export function pqControlsWinEventLogsToJSON(
  pqControlsWinEventLogs: PqControlsWinEventLogs,
): string {
  return JSON.stringify(
    PqControlsWinEventLogs$outboundSchema.parse(pqControlsWinEventLogs),
  );
}
export function pqControlsWinEventLogsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWinEventLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWinEventLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWinEventLogs' from JSON`,
  );
}

/** @internal */
export const PqWinEventLogs$inboundSchema: z.ZodType<
  PqWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeWinEventLogs$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWinEventLogs$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWinEventLogs$inboundSchema).optional(),
});
/** @internal */
export type PqWinEventLogs$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsWinEventLogs$Outbound | undefined;
};

/** @internal */
export const PqWinEventLogs$outboundSchema: z.ZodType<
  PqWinEventLogs$Outbound,
  z.ZodTypeDef,
  PqWinEventLogs
> = z.object({
  mode: ModeWinEventLogs$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWinEventLogs$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWinEventLogs$outboundSchema).optional(),
});

export function pqWinEventLogsToJSON(pqWinEventLogs: PqWinEventLogs): string {
  return JSON.stringify(PqWinEventLogs$outboundSchema.parse(pqWinEventLogs));
}
export function pqWinEventLogsFromJSON(
  jsonString: string,
): SafeParseResult<PqWinEventLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqWinEventLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqWinEventLogs' from JSON`,
  );
}

/** @internal */
export const ReadMode$inboundSchema: z.ZodType<
  ReadMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ReadMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ReadMode$outboundSchema: z.ZodType<
  ReadMode,
  z.ZodTypeDef,
  ReadMode
> = z.union([
  z.nativeEnum(ReadMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const EventFormat$inboundSchema: z.ZodType<
  EventFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(EventFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const EventFormat$outboundSchema: z.ZodType<
  EventFormat,
  z.ZodTypeDef,
  EventFormat
> = z.union([
  z.nativeEnum(EventFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumWinEventLogs$inboundSchema: z.ZodType<
  MetadatumWinEventLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumWinEventLogs$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumWinEventLogs$outboundSchema: z.ZodType<
  MetadatumWinEventLogs$Outbound,
  z.ZodTypeDef,
  MetadatumWinEventLogs
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumWinEventLogsToJSON(
  metadatumWinEventLogs: MetadatumWinEventLogs,
): string {
  return JSON.stringify(
    MetadatumWinEventLogs$outboundSchema.parse(metadatumWinEventLogs),
  );
}
export function metadatumWinEventLogsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumWinEventLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumWinEventLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumWinEventLogs' from JSON`,
  );
}

/** @internal */
export const InputWinEventLogs$inboundSchema: z.ZodType<
  InputWinEventLogs,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWinEventLogs$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionWinEventLogs$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqWinEventLogs$inboundSchema).optional(),
    logNames: z.array(z.string()),
    readMode: ReadMode$inboundSchema.default("newest"),
    eventFormat: EventFormat$inboundSchema.default("json"),
    disableNativeModule: z.boolean().default(false),
    interval: z.number().default(10),
    batchSize: z.number().default(500),
    metadata: z.array(z.lazy(() => MetadatumWinEventLogs$inboundSchema))
      .optional(),
    maxEventBytes: z.number().default(51200),
    description: z.string().optional(),
    disableJsonRendering: z.boolean().default(false),
    disableXmlRendering: z.boolean().default(true),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputWinEventLogs$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionWinEventLogs$Outbound> | undefined;
  pq?: PqWinEventLogs$Outbound | undefined;
  logNames: Array<string>;
  readMode: string;
  eventFormat: string;
  disableNativeModule: boolean;
  interval: number;
  batchSize: number;
  metadata?: Array<MetadatumWinEventLogs$Outbound> | undefined;
  maxEventBytes: number;
  description?: string | undefined;
  disableJsonRendering: boolean;
  disableXmlRendering: boolean;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputWinEventLogs$outboundSchema: z.ZodType<
  InputWinEventLogs$Outbound,
  z.ZodTypeDef,
  InputWinEventLogs
> = z.object({
  id: z.string().optional(),
  type: TypeWinEventLogs$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionWinEventLogs$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqWinEventLogs$outboundSchema).optional(),
  logNames: z.array(z.string()),
  readMode: ReadMode$outboundSchema.default("newest"),
  eventFormat: EventFormat$outboundSchema.default("json"),
  disableNativeModule: z.boolean().default(false),
  interval: z.number().default(10),
  batchSize: z.number().default(500),
  metadata: z.array(z.lazy(() => MetadatumWinEventLogs$outboundSchema))
    .optional(),
  maxEventBytes: z.number().default(51200),
  description: z.string().optional(),
  disableJsonRendering: z.boolean().default(false),
  disableXmlRendering: z.boolean().default(true),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputWinEventLogsToJSON(
  inputWinEventLogs: InputWinEventLogs,
): string {
  return JSON.stringify(
    InputWinEventLogs$outboundSchema.parse(inputWinEventLogs),
  );
}
export function inputWinEventLogsFromJSON(
  jsonString: string,
): SafeParseResult<InputWinEventLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputWinEventLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputWinEventLogs' from JSON`,
  );
}

/** @internal */
export const TypeWef$inboundSchema: z.ZodNativeEnum<typeof TypeWef> = z
  .nativeEnum(TypeWef);
/** @internal */
export const TypeWef$outboundSchema: z.ZodNativeEnum<typeof TypeWef> =
  TypeWef$inboundSchema;

/** @internal */
export const ConnectionWef$inboundSchema: z.ZodType<
  ConnectionWef,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionWef$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionWef$outboundSchema: z.ZodType<
  ConnectionWef$Outbound,
  z.ZodTypeDef,
  ConnectionWef
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionWefToJSON(connectionWef: ConnectionWef): string {
  return JSON.stringify(ConnectionWef$outboundSchema.parse(connectionWef));
}
export function connectionWefFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionWef, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionWef$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionWef' from JSON`,
  );
}

/** @internal */
export const ModeWef$inboundSchema: z.ZodType<ModeWef, z.ZodTypeDef, unknown> =
  z
    .union([
      z.nativeEnum(ModeWef),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ModeWef$outboundSchema: z.ZodType<ModeWef, z.ZodTypeDef, ModeWef> =
  z.union([
    z.nativeEnum(ModeWef),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const CompressionWef$inboundSchema: z.ZodType<
  CompressionWef,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWef),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWef$outboundSchema: z.ZodType<
  CompressionWef,
  z.ZodTypeDef,
  CompressionWef
> = z.union([
  z.nativeEnum(CompressionWef),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWef$inboundSchema: z.ZodType<
  PqControlsWef,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWef$Outbound = {};

/** @internal */
export const PqControlsWef$outboundSchema: z.ZodType<
  PqControlsWef$Outbound,
  z.ZodTypeDef,
  PqControlsWef
> = z.object({});

export function pqControlsWefToJSON(pqControlsWef: PqControlsWef): string {
  return JSON.stringify(PqControlsWef$outboundSchema.parse(pqControlsWef));
}
export function pqControlsWefFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWef, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWef$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWef' from JSON`,
  );
}

/** @internal */
export const PqWef$inboundSchema: z.ZodType<PqWef, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeWef$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionWef$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsWef$inboundSchema).optional(),
  });
/** @internal */
export type PqWef$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsWef$Outbound | undefined;
};

/** @internal */
export const PqWef$outboundSchema: z.ZodType<
  PqWef$Outbound,
  z.ZodTypeDef,
  PqWef
> = z.object({
  mode: ModeWef$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWef$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWef$outboundSchema).optional(),
});

export function pqWefToJSON(pqWef: PqWef): string {
  return JSON.stringify(PqWef$outboundSchema.parse(pqWef));
}
export function pqWefFromJSON(
  jsonString: string,
): SafeParseResult<PqWef, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqWef$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqWef' from JSON`,
  );
}

/** @internal */
export const AuthMethodAuthenticationMethod$inboundSchema: z.ZodType<
  AuthMethodAuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthMethodAuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthMethodAuthenticationMethod$outboundSchema: z.ZodType<
  AuthMethodAuthenticationMethod,
  z.ZodTypeDef,
  AuthMethodAuthenticationMethod
> = z.union([
  z.nativeEnum(AuthMethodAuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MinimumTLSVersionWef$inboundSchema: z.ZodType<
  MinimumTLSVersionWef,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionWef),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionWef$outboundSchema: z.ZodType<
  MinimumTLSVersionWef,
  z.ZodTypeDef,
  MinimumTLSVersionWef
> = z.union([
  z.nativeEnum(MinimumTLSVersionWef),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionWef$inboundSchema: z.ZodType<
  MaximumTLSVersionWef,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionWef),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionWef$outboundSchema: z.ZodType<
  MaximumTLSVersionWef,
  z.ZodTypeDef,
  MaximumTLSVersionWef
> = z.union([
  z.nativeEnum(MaximumTLSVersionWef),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MTLSSettings$inboundSchema: z.ZodType<
  MTLSSettings,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  requestCert: z.boolean().default(true),
  certificateName: z.string().optional(),
  privKeyPath: z.string(),
  passphrase: z.string().optional(),
  certPath: z.string(),
  caPath: z.string(),
  commonNameRegex: z.string().default("/.*/"),
  minVersion: MinimumTLSVersionWef$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionWef$inboundSchema.optional(),
  ocspCheck: z.boolean().default(false),
  keytab: z.any().optional(),
  principal: z.any().optional(),
  ocspCheckFailClose: z.boolean().default(false),
});
/** @internal */
export type MTLSSettings$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  requestCert: boolean;
  certificateName?: string | undefined;
  privKeyPath: string;
  passphrase?: string | undefined;
  certPath: string;
  caPath: string;
  commonNameRegex: string;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
  ocspCheck: boolean;
  keytab?: any | undefined;
  principal?: any | undefined;
  ocspCheckFailClose: boolean;
};

/** @internal */
export const MTLSSettings$outboundSchema: z.ZodType<
  MTLSSettings$Outbound,
  z.ZodTypeDef,
  MTLSSettings
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  requestCert: z.boolean().default(true),
  certificateName: z.string().optional(),
  privKeyPath: z.string(),
  passphrase: z.string().optional(),
  certPath: z.string(),
  caPath: z.string(),
  commonNameRegex: z.string().default("/.*/"),
  minVersion: MinimumTLSVersionWef$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionWef$outboundSchema.optional(),
  ocspCheck: z.boolean().default(false),
  keytab: z.any().optional(),
  principal: z.any().optional(),
  ocspCheckFailClose: z.boolean().default(false),
});

export function mTLSSettingsToJSON(mtlsSettings: MTLSSettings): string {
  return JSON.stringify(MTLSSettings$outboundSchema.parse(mtlsSettings));
}
export function mTLSSettingsFromJSON(
  jsonString: string,
): SafeParseResult<MTLSSettings, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MTLSSettings$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MTLSSettings' from JSON`,
  );
}

/** @internal */
export const InputFormat$inboundSchema: z.ZodType<
  InputFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputFormat$outboundSchema: z.ZodType<
  InputFormat,
  z.ZodTypeDef,
  InputFormat
> = z.union([
  z.nativeEnum(InputFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const QueryBuilderMode$inboundSchema: z.ZodType<
  QueryBuilderMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(QueryBuilderMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const QueryBuilderMode$outboundSchema: z.ZodType<
  QueryBuilderMode,
  z.ZodTypeDef,
  QueryBuilderMode
> = z.union([
  z.nativeEnum(QueryBuilderMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SubscriptionMetadatum$inboundSchema: z.ZodType<
  SubscriptionMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type SubscriptionMetadatum$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const SubscriptionMetadatum$outboundSchema: z.ZodType<
  SubscriptionMetadatum$Outbound,
  z.ZodTypeDef,
  SubscriptionMetadatum
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function subscriptionMetadatumToJSON(
  subscriptionMetadatum: SubscriptionMetadatum,
): string {
  return JSON.stringify(
    SubscriptionMetadatum$outboundSchema.parse(subscriptionMetadatum),
  );
}
export function subscriptionMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<SubscriptionMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SubscriptionMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SubscriptionMetadatum' from JSON`,
  );
}

/** @internal */
export const Subscription$inboundSchema: z.ZodType<
  Subscription,
  z.ZodTypeDef,
  unknown
> = z.object({
  subscriptionName: z.string(),
  version: z.string().optional(),
  contentFormat: InputFormat$inboundSchema.default("Raw"),
  heartbeatInterval: z.number().default(60),
  batchTimeout: z.number().default(60),
  readExistingEvents: z.boolean().default(false),
  sendBookmarks: z.boolean().default(true),
  compress: z.boolean().default(true),
  targets: z.array(z.string()),
  locale: z.string().default("en-US"),
  querySelector: QueryBuilderMode$inboundSchema.default("simple"),
  metadata: z.array(z.lazy(() => SubscriptionMetadatum$inboundSchema))
    .optional(),
});
/** @internal */
export type Subscription$Outbound = {
  subscriptionName: string;
  version?: string | undefined;
  contentFormat: string;
  heartbeatInterval: number;
  batchTimeout: number;
  readExistingEvents: boolean;
  sendBookmarks: boolean;
  compress: boolean;
  targets: Array<string>;
  locale: string;
  querySelector: string;
  metadata?: Array<SubscriptionMetadatum$Outbound> | undefined;
};

/** @internal */
export const Subscription$outboundSchema: z.ZodType<
  Subscription$Outbound,
  z.ZodTypeDef,
  Subscription
> = z.object({
  subscriptionName: z.string(),
  version: z.string().optional(),
  contentFormat: InputFormat$outboundSchema.default("Raw"),
  heartbeatInterval: z.number().default(60),
  batchTimeout: z.number().default(60),
  readExistingEvents: z.boolean().default(false),
  sendBookmarks: z.boolean().default(true),
  compress: z.boolean().default(true),
  targets: z.array(z.string()),
  locale: z.string().default("en-US"),
  querySelector: QueryBuilderMode$outboundSchema.default("simple"),
  metadata: z.array(z.lazy(() => SubscriptionMetadatum$outboundSchema))
    .optional(),
});

export function subscriptionToJSON(subscription: Subscription): string {
  return JSON.stringify(Subscription$outboundSchema.parse(subscription));
}
export function subscriptionFromJSON(
  jsonString: string,
): SafeParseResult<Subscription, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Subscription$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Subscription' from JSON`,
  );
}

/** @internal */
export const MetadatumWef$inboundSchema: z.ZodType<
  MetadatumWef,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumWef$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumWef$outboundSchema: z.ZodType<
  MetadatumWef$Outbound,
  z.ZodTypeDef,
  MetadatumWef
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumWefToJSON(metadatumWef: MetadatumWef): string {
  return JSON.stringify(MetadatumWef$outboundSchema.parse(metadatumWef));
}
export function metadatumWefFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumWef, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumWef$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumWef' from JSON`,
  );
}

/** @internal */
export const InputWef$inboundSchema: z.ZodType<
  InputWef,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWef$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionWef$inboundSchema)).optional(),
    pq: z.lazy(() => PqWef$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number().default(5986),
    authMethod: AuthMethodAuthenticationMethod$inboundSchema.default(
      "clientCert",
    ),
    tls: z.lazy(() => MTLSSettings$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    keepAliveTimeout: z.number().default(90),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    socketTimeout: z.number().default(0),
    caFingerprint: z.string().optional(),
    keytab: z.string().optional(),
    principal: z.string().optional(),
    allowMachineIdMismatch: z.boolean().default(false),
    subscriptions: z.array(z.lazy(() => Subscription$inboundSchema)),
    metadata: z.array(z.lazy(() => MetadatumWef$inboundSchema)).optional(),
    description: z.string().optional(),
    logFingerprintMismatch: z.boolean().default(false),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputWef$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionWef$Outbound> | undefined;
  pq?: PqWef$Outbound | undefined;
  host: string;
  port: number;
  authMethod: string;
  tls?: MTLSSettings$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  socketTimeout: number;
  caFingerprint?: string | undefined;
  keytab?: string | undefined;
  principal?: string | undefined;
  allowMachineIdMismatch: boolean;
  subscriptions: Array<Subscription$Outbound>;
  metadata?: Array<MetadatumWef$Outbound> | undefined;
  description?: string | undefined;
  logFingerprintMismatch: boolean;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputWef$outboundSchema: z.ZodType<
  InputWef$Outbound,
  z.ZodTypeDef,
  InputWef
> = z.object({
  id: z.string().optional(),
  type: TypeWef$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionWef$outboundSchema)).optional(),
  pq: z.lazy(() => PqWef$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number().default(5986),
  authMethod: AuthMethodAuthenticationMethod$outboundSchema.default(
    "clientCert",
  ),
  tls: z.lazy(() => MTLSSettings$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  keepAliveTimeout: z.number().default(90),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  socketTimeout: z.number().default(0),
  caFingerprint: z.string().optional(),
  keytab: z.string().optional(),
  principal: z.string().optional(),
  allowMachineIdMismatch: z.boolean().default(false),
  subscriptions: z.array(z.lazy(() => Subscription$outboundSchema)),
  metadata: z.array(z.lazy(() => MetadatumWef$outboundSchema)).optional(),
  description: z.string().optional(),
  logFingerprintMismatch: z.boolean().default(false),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputWefToJSON(inputWef: InputWef): string {
  return JSON.stringify(InputWef$outboundSchema.parse(inputWef));
}
export function inputWefFromJSON(
  jsonString: string,
): SafeParseResult<InputWef, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputWef$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputWef' from JSON`,
  );
}

/** @internal */
export const TypeAppscope$inboundSchema: z.ZodNativeEnum<typeof TypeAppscope> =
  z.nativeEnum(TypeAppscope);
/** @internal */
export const TypeAppscope$outboundSchema: z.ZodNativeEnum<typeof TypeAppscope> =
  TypeAppscope$inboundSchema;

/** @internal */
export const ConnectionAppscope$inboundSchema: z.ZodType<
  ConnectionAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionAppscope$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionAppscope$outboundSchema: z.ZodType<
  ConnectionAppscope$Outbound,
  z.ZodTypeDef,
  ConnectionAppscope
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionAppscopeToJSON(
  connectionAppscope: ConnectionAppscope,
): string {
  return JSON.stringify(
    ConnectionAppscope$outboundSchema.parse(connectionAppscope),
  );
}
export function connectionAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionAppscope' from JSON`,
  );
}

/** @internal */
export const ModeAppscope$inboundSchema: z.ZodType<
  ModeAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeAppscope$outboundSchema: z.ZodType<
  ModeAppscope,
  z.ZodTypeDef,
  ModeAppscope
> = z.union([
  z.nativeEnum(ModeAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionAppscope$inboundSchema: z.ZodType<
  CompressionAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionAppscope$outboundSchema: z.ZodType<
  CompressionAppscope,
  z.ZodTypeDef,
  CompressionAppscope
> = z.union([
  z.nativeEnum(CompressionAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsAppscope$inboundSchema: z.ZodType<
  PqControlsAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsAppscope$Outbound = {};

/** @internal */
export const PqControlsAppscope$outboundSchema: z.ZodType<
  PqControlsAppscope$Outbound,
  z.ZodTypeDef,
  PqControlsAppscope
> = z.object({});

export function pqControlsAppscopeToJSON(
  pqControlsAppscope: PqControlsAppscope,
): string {
  return JSON.stringify(
    PqControlsAppscope$outboundSchema.parse(pqControlsAppscope),
  );
}
export function pqControlsAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsAppscope' from JSON`,
  );
}

/** @internal */
export const PqAppscope$inboundSchema: z.ZodType<
  PqAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeAppscope$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionAppscope$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsAppscope$inboundSchema).optional(),
});
/** @internal */
export type PqAppscope$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsAppscope$Outbound | undefined;
};

/** @internal */
export const PqAppscope$outboundSchema: z.ZodType<
  PqAppscope$Outbound,
  z.ZodTypeDef,
  PqAppscope
> = z.object({
  mode: ModeAppscope$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionAppscope$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsAppscope$outboundSchema).optional(),
});

export function pqAppscopeToJSON(pqAppscope: PqAppscope): string {
  return JSON.stringify(PqAppscope$outboundSchema.parse(pqAppscope));
}
export function pqAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<PqAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqAppscope' from JSON`,
  );
}

/** @internal */
export const MetadatumAppscope$inboundSchema: z.ZodType<
  MetadatumAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumAppscope$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumAppscope$outboundSchema: z.ZodType<
  MetadatumAppscope$Outbound,
  z.ZodTypeDef,
  MetadatumAppscope
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumAppscopeToJSON(
  metadatumAppscope: MetadatumAppscope,
): string {
  return JSON.stringify(
    MetadatumAppscope$outboundSchema.parse(metadatumAppscope),
  );
}
export function metadatumAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumAppscope' from JSON`,
  );
}

/** @internal */
export const Allow$inboundSchema: z.ZodType<Allow, z.ZodTypeDef, unknown> = z
  .object({
    procname: z.string(),
    arg: z.string().optional(),
    config: z.string(),
  });
/** @internal */
export type Allow$Outbound = {
  procname: string;
  arg?: string | undefined;
  config: string;
};

/** @internal */
export const Allow$outboundSchema: z.ZodType<
  Allow$Outbound,
  z.ZodTypeDef,
  Allow
> = z.object({
  procname: z.string(),
  arg: z.string().optional(),
  config: z.string(),
});

export function allowToJSON(allow: Allow): string {
  return JSON.stringify(Allow$outboundSchema.parse(allow));
}
export function allowFromJSON(
  jsonString: string,
): SafeParseResult<Allow, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Allow$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Allow' from JSON`,
  );
}

/** @internal */
export const FilterAppscope$inboundSchema: z.ZodType<
  FilterAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  allow: z.array(z.lazy(() => Allow$inboundSchema)).optional(),
  transportURL: z.string().optional(),
});
/** @internal */
export type FilterAppscope$Outbound = {
  allow?: Array<Allow$Outbound> | undefined;
  transportURL?: string | undefined;
};

/** @internal */
export const FilterAppscope$outboundSchema: z.ZodType<
  FilterAppscope$Outbound,
  z.ZodTypeDef,
  FilterAppscope
> = z.object({
  allow: z.array(z.lazy(() => Allow$outboundSchema)).optional(),
  transportURL: z.string().optional(),
});

export function filterAppscopeToJSON(filterAppscope: FilterAppscope): string {
  return JSON.stringify(FilterAppscope$outboundSchema.parse(filterAppscope));
}
export function filterAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<FilterAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => FilterAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'FilterAppscope' from JSON`,
  );
}

/** @internal */
export const DataCompressionFormatAppscope$inboundSchema: z.ZodType<
  DataCompressionFormatAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataCompressionFormatAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataCompressionFormatAppscope$outboundSchema: z.ZodType<
  DataCompressionFormatAppscope,
  z.ZodTypeDef,
  DataCompressionFormatAppscope
> = z.union([
  z.nativeEnum(DataCompressionFormatAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceAppscope$inboundSchema: z.ZodType<
  PersistenceAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatAppscope$inboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/appscope"),
});
/** @internal */
export type PersistenceAppscope$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath: string;
};

/** @internal */
export const PersistenceAppscope$outboundSchema: z.ZodType<
  PersistenceAppscope$Outbound,
  z.ZodTypeDef,
  PersistenceAppscope
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatAppscope$outboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/appscope"),
});

export function persistenceAppscopeToJSON(
  persistenceAppscope: PersistenceAppscope,
): string {
  return JSON.stringify(
    PersistenceAppscope$outboundSchema.parse(persistenceAppscope),
  );
}
export function persistenceAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<PersistenceAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PersistenceAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PersistenceAppscope' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodAppscope$inboundSchema: z.ZodType<
  AuthenticationMethodAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodAppscope$outboundSchema: z.ZodType<
  AuthenticationMethodAppscope,
  z.ZodTypeDef,
  AuthenticationMethodAppscope
> = z.union([
  z.nativeEnum(AuthenticationMethodAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MinimumTLSVersionAppscope$inboundSchema: z.ZodType<
  MinimumTLSVersionAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionAppscope$outboundSchema: z.ZodType<
  MinimumTLSVersionAppscope,
  z.ZodTypeDef,
  MinimumTLSVersionAppscope
> = z.union([
  z.nativeEnum(MinimumTLSVersionAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionAppscope$inboundSchema: z.ZodType<
  MaximumTLSVersionAppscope,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionAppscope),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionAppscope$outboundSchema: z.ZodType<
  MaximumTLSVersionAppscope,
  z.ZodTypeDef,
  MaximumTLSVersionAppscope
> = z.union([
  z.nativeEnum(MaximumTLSVersionAppscope),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideAppscope$inboundSchema: z.ZodType<
  TLSSettingsServerSideAppscope,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionAppscope$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionAppscope$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideAppscope$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideAppscope$outboundSchema: z.ZodType<
  TLSSettingsServerSideAppscope$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideAppscope
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionAppscope$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionAppscope$outboundSchema.optional(),
});

export function tlsSettingsServerSideAppscopeToJSON(
  tlsSettingsServerSideAppscope: TLSSettingsServerSideAppscope,
): string {
  return JSON.stringify(
    TLSSettingsServerSideAppscope$outboundSchema.parse(
      tlsSettingsServerSideAppscope,
    ),
  );
}
export function tlsSettingsServerSideAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideAppscope' from JSON`,
  );
}

/** @internal */
export const InputAppscope$inboundSchema: z.ZodType<
  InputAppscope,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeAppscope$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionAppscope$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqAppscope$inboundSchema).optional(),
    ipWhitelistRegex: z.string().default("/.*/"),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    enableProxyHeader: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumAppscope$inboundSchema)).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableUnixPath: z.boolean().default(false),
    filter: z.lazy(() => FilterAppscope$inboundSchema).optional(),
    persistence: z.lazy(() => PersistenceAppscope$inboundSchema).optional(),
    authType: AuthenticationMethodAppscope$inboundSchema.default("manual"),
    description: z.string().optional(),
    host: z.string().optional(),
    port: z.number().optional(),
    tls: z.lazy(() => TLSSettingsServerSideAppscope$inboundSchema).optional(),
    unixSocketPath: z.string().default("$CRIBL_HOME/state/appscope.sock"),
    unixSocketPerms: z.string().optional(),
    authToken: z.string().default(""),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputAppscope$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionAppscope$Outbound> | undefined;
  pq?: PqAppscope$Outbound | undefined;
  ipWhitelistRegex: string;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  enableProxyHeader: boolean;
  metadata?: Array<MetadatumAppscope$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableUnixPath: boolean;
  filter?: FilterAppscope$Outbound | undefined;
  persistence?: PersistenceAppscope$Outbound | undefined;
  authType: string;
  description?: string | undefined;
  host?: string | undefined;
  port?: number | undefined;
  tls?: TLSSettingsServerSideAppscope$Outbound | undefined;
  unixSocketPath: string;
  unixSocketPerms?: string | undefined;
  authToken: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputAppscope$outboundSchema: z.ZodType<
  InputAppscope$Outbound,
  z.ZodTypeDef,
  InputAppscope
> = z.object({
  id: z.string().optional(),
  type: TypeAppscope$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionAppscope$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqAppscope$outboundSchema).optional(),
  ipWhitelistRegex: z.string().default("/.*/"),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  enableProxyHeader: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumAppscope$outboundSchema)).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableUnixPath: z.boolean().default(false),
  filter: z.lazy(() => FilterAppscope$outboundSchema).optional(),
  persistence: z.lazy(() => PersistenceAppscope$outboundSchema).optional(),
  authType: AuthenticationMethodAppscope$outboundSchema.default("manual"),
  description: z.string().optional(),
  host: z.string().optional(),
  port: z.number().optional(),
  tls: z.lazy(() => TLSSettingsServerSideAppscope$outboundSchema).optional(),
  unixSocketPath: z.string().default("$CRIBL_HOME/state/appscope.sock"),
  unixSocketPerms: z.string().optional(),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputAppscopeToJSON(inputAppscope: InputAppscope): string {
  return JSON.stringify(InputAppscope$outboundSchema.parse(inputAppscope));
}
export function inputAppscopeFromJSON(
  jsonString: string,
): SafeParseResult<InputAppscope, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAppscope$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAppscope' from JSON`,
  );
}

/** @internal */
export const TypeTCP$inboundSchema: z.ZodNativeEnum<typeof TypeTCP> = z
  .nativeEnum(TypeTCP);
/** @internal */
export const TypeTCP$outboundSchema: z.ZodNativeEnum<typeof TypeTCP> =
  TypeTCP$inboundSchema;

/** @internal */
export const ConnectionTCP$inboundSchema: z.ZodType<
  ConnectionTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionTCP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionTCP$outboundSchema: z.ZodType<
  ConnectionTCP$Outbound,
  z.ZodTypeDef,
  ConnectionTCP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionTCPToJSON(connectionTCP: ConnectionTCP): string {
  return JSON.stringify(ConnectionTCP$outboundSchema.parse(connectionTCP));
}
export function connectionTCPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionTCP' from JSON`,
  );
}

/** @internal */
export const ModeTCP$inboundSchema: z.ZodType<ModeTCP, z.ZodTypeDef, unknown> =
  z
    .union([
      z.nativeEnum(ModeTCP),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ModeTCP$outboundSchema: z.ZodType<ModeTCP, z.ZodTypeDef, ModeTCP> =
  z.union([
    z.nativeEnum(ModeTCP),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const CompressionTCP$inboundSchema: z.ZodType<
  CompressionTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionTCP$outboundSchema: z.ZodType<
  CompressionTCP,
  z.ZodTypeDef,
  CompressionTCP
> = z.union([
  z.nativeEnum(CompressionTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsTCP$inboundSchema: z.ZodType<
  PqControlsTCP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsTCP$Outbound = {};

/** @internal */
export const PqControlsTCP$outboundSchema: z.ZodType<
  PqControlsTCP$Outbound,
  z.ZodTypeDef,
  PqControlsTCP
> = z.object({});

export function pqControlsTCPToJSON(pqControlsTCP: PqControlsTCP): string {
  return JSON.stringify(PqControlsTCP$outboundSchema.parse(pqControlsTCP));
}
export function pqControlsTCPFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsTCP' from JSON`,
  );
}

/** @internal */
export const PqTCP$inboundSchema: z.ZodType<PqTCP, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeTCP$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionTCP$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsTCP$inboundSchema).optional(),
  });
/** @internal */
export type PqTCP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsTCP$Outbound | undefined;
};

/** @internal */
export const PqTCP$outboundSchema: z.ZodType<
  PqTCP$Outbound,
  z.ZodTypeDef,
  PqTCP
> = z.object({
  mode: ModeTCP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionTCP$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsTCP$outboundSchema).optional(),
});

export function pqTCPToJSON(pqTCP: PqTCP): string {
  return JSON.stringify(PqTCP$outboundSchema.parse(pqTCP));
}
export function pqTCPFromJSON(
  jsonString: string,
): SafeParseResult<PqTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqTCP' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionTCP$inboundSchema: z.ZodType<
  MinimumTLSVersionTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionTCP$outboundSchema: z.ZodType<
  MinimumTLSVersionTCP,
  z.ZodTypeDef,
  MinimumTLSVersionTCP
> = z.union([
  z.nativeEnum(MinimumTLSVersionTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionTCP$inboundSchema: z.ZodType<
  MaximumTLSVersionTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionTCP$outboundSchema: z.ZodType<
  MaximumTLSVersionTCP,
  z.ZodTypeDef,
  MaximumTLSVersionTCP
> = z.union([
  z.nativeEnum(MaximumTLSVersionTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideTCP$inboundSchema: z.ZodType<
  TLSSettingsServerSideTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionTCP$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionTCP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideTCP$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideTCP$outboundSchema: z.ZodType<
  TLSSettingsServerSideTCP$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideTCP
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionTCP$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionTCP$outboundSchema.optional(),
});

export function tlsSettingsServerSideTCPToJSON(
  tlsSettingsServerSideTCP: TLSSettingsServerSideTCP,
): string {
  return JSON.stringify(
    TLSSettingsServerSideTCP$outboundSchema.parse(tlsSettingsServerSideTCP),
  );
}
export function tlsSettingsServerSideTCPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideTCP' from JSON`,
  );
}

/** @internal */
export const MetadatumTCP$inboundSchema: z.ZodType<
  MetadatumTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumTCP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumTCP$outboundSchema: z.ZodType<
  MetadatumTCP$Outbound,
  z.ZodTypeDef,
  MetadatumTCP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumTCPToJSON(metadatumTCP: MetadatumTCP): string {
  return JSON.stringify(MetadatumTCP$outboundSchema.parse(metadatumTCP));
}
export function metadatumTCPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumTCP' from JSON`,
  );
}

/** @internal */
export const PreprocessTCP$inboundSchema: z.ZodType<
  PreprocessTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessTCP$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessTCP$outboundSchema: z.ZodType<
  PreprocessTCP$Outbound,
  z.ZodTypeDef,
  PreprocessTCP
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessTCPToJSON(preprocessTCP: PreprocessTCP): string {
  return JSON.stringify(PreprocessTCP$outboundSchema.parse(preprocessTCP));
}
export function preprocessTCPFromJSON(
  jsonString: string,
): SafeParseResult<PreprocessTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessTCP' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodTCP$inboundSchema: z.ZodType<
  AuthenticationMethodTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodTCP$outboundSchema: z.ZodType<
  AuthenticationMethodTCP,
  z.ZodTypeDef,
  AuthenticationMethodTCP
> = z.union([
  z.nativeEnum(AuthenticationMethodTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputTcp$inboundSchema: z.ZodType<
  InputTcp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeTCP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionTCP$inboundSchema)).optional(),
    pq: z.lazy(() => PqTCP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideTCP$inboundSchema).optional(),
    ipWhitelistRegex: z.string().default("/.*/"),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    enableProxyHeader: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumTCP$inboundSchema)).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableHeader: z.boolean().default(false),
    preprocess: z.lazy(() => PreprocessTCP$inboundSchema).optional(),
    description: z.string().optional(),
    authToken: z.string().default(""),
    authType: AuthenticationMethodTCP$inboundSchema.default("manual"),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputTcp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionTCP$Outbound> | undefined;
  pq?: PqTCP$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideTCP$Outbound | undefined;
  ipWhitelistRegex: string;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  enableProxyHeader: boolean;
  metadata?: Array<MetadatumTCP$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableHeader: boolean;
  preprocess?: PreprocessTCP$Outbound | undefined;
  description?: string | undefined;
  authToken: string;
  authType: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputTcp$outboundSchema: z.ZodType<
  InputTcp$Outbound,
  z.ZodTypeDef,
  InputTcp
> = z.object({
  id: z.string().optional(),
  type: TypeTCP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionTCP$outboundSchema)).optional(),
  pq: z.lazy(() => PqTCP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideTCP$outboundSchema).optional(),
  ipWhitelistRegex: z.string().default("/.*/"),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  enableProxyHeader: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumTCP$outboundSchema)).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableHeader: z.boolean().default(false),
  preprocess: z.lazy(() => PreprocessTCP$outboundSchema).optional(),
  description: z.string().optional(),
  authToken: z.string().default(""),
  authType: AuthenticationMethodTCP$outboundSchema.default("manual"),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputTcpToJSON(inputTcp: InputTcp): string {
  return JSON.stringify(InputTcp$outboundSchema.parse(inputTcp));
}
export function inputTcpFromJSON(
  jsonString: string,
): SafeParseResult<InputTcp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputTcp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputTcp' from JSON`,
  );
}

/** @internal */
export const InputFileType$inboundSchema: z.ZodNativeEnum<
  typeof InputFileType
> = z.nativeEnum(InputFileType);
/** @internal */
export const InputFileType$outboundSchema: z.ZodNativeEnum<
  typeof InputFileType
> = InputFileType$inboundSchema;

/** @internal */
export const InputFileConnection$inboundSchema: z.ZodType<
  InputFileConnection,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputFileConnection$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputFileConnection$outboundSchema: z.ZodType<
  InputFileConnection$Outbound,
  z.ZodTypeDef,
  InputFileConnection
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputFileConnectionToJSON(
  inputFileConnection: InputFileConnection,
): string {
  return JSON.stringify(
    InputFileConnection$outboundSchema.parse(inputFileConnection),
  );
}
export function inputFileConnectionFromJSON(
  jsonString: string,
): SafeParseResult<InputFileConnection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFileConnection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFileConnection' from JSON`,
  );
}

/** @internal */
export const InputFilePqMode$inboundSchema: z.ZodType<
  InputFilePqMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputFilePqMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputFilePqMode$outboundSchema: z.ZodType<
  InputFilePqMode,
  z.ZodTypeDef,
  InputFilePqMode
> = z.union([
  z.nativeEnum(InputFilePqMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputFileCompression$inboundSchema: z.ZodType<
  InputFileCompression,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputFileCompression),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputFileCompression$outboundSchema: z.ZodType<
  InputFileCompression,
  z.ZodTypeDef,
  InputFileCompression
> = z.union([
  z.nativeEnum(InputFileCompression),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputFilePqControls$inboundSchema: z.ZodType<
  InputFilePqControls,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputFilePqControls$Outbound = {};

/** @internal */
export const InputFilePqControls$outboundSchema: z.ZodType<
  InputFilePqControls$Outbound,
  z.ZodTypeDef,
  InputFilePqControls
> = z.object({});

export function inputFilePqControlsToJSON(
  inputFilePqControls: InputFilePqControls,
): string {
  return JSON.stringify(
    InputFilePqControls$outboundSchema.parse(inputFilePqControls),
  );
}
export function inputFilePqControlsFromJSON(
  jsonString: string,
): SafeParseResult<InputFilePqControls, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFilePqControls$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFilePqControls' from JSON`,
  );
}

/** @internal */
export const InputFilePq$inboundSchema: z.ZodType<
  InputFilePq,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputFilePqMode$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputFileCompression$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputFilePqControls$inboundSchema).optional(),
});
/** @internal */
export type InputFilePq$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputFilePqControls$Outbound | undefined;
};

/** @internal */
export const InputFilePq$outboundSchema: z.ZodType<
  InputFilePq$Outbound,
  z.ZodTypeDef,
  InputFilePq
> = z.object({
  mode: InputFilePqMode$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputFileCompression$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputFilePqControls$outboundSchema).optional(),
});

export function inputFilePqToJSON(inputFilePq: InputFilePq): string {
  return JSON.stringify(InputFilePq$outboundSchema.parse(inputFilePq));
}
export function inputFilePqFromJSON(
  jsonString: string,
): SafeParseResult<InputFilePq, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFilePq$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFilePq' from JSON`,
  );
}

/** @internal */
export const InputFileMode$inboundSchema: z.ZodType<
  InputFileMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputFileMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputFileMode$outboundSchema: z.ZodType<
  InputFileMode,
  z.ZodTypeDef,
  InputFileMode
> = z.union([
  z.nativeEnum(InputFileMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputFileMetadatum$inboundSchema: z.ZodType<
  InputFileMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputFileMetadatum$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputFileMetadatum$outboundSchema: z.ZodType<
  InputFileMetadatum$Outbound,
  z.ZodTypeDef,
  InputFileMetadatum
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputFileMetadatumToJSON(
  inputFileMetadatum: InputFileMetadatum,
): string {
  return JSON.stringify(
    InputFileMetadatum$outboundSchema.parse(inputFileMetadatum),
  );
}
export function inputFileMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<InputFileMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFileMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFileMetadatum' from JSON`,
  );
}

/** @internal */
export const InputFile$inboundSchema: z.ZodType<
  InputFile,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputFileType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputFileConnection$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputFilePq$inboundSchema).optional(),
    mode: InputFileMode$inboundSchema.default("manual"),
    interval: z.number().default(10),
    filenames: z.array(z.string()).optional(),
    filterArchivedFiles: z.boolean().default(false),
    tailOnly: z.boolean().default(true),
    idleTimeout: z.number().default(300),
    minAgeDur: z.string().optional(),
    maxAgeDur: z.string().optional(),
    checkFileModTime: z.boolean().default(false),
    forceText: z.boolean().default(false),
    hashLen: z.number().default(256),
    metadata: z.array(z.lazy(() => InputFileMetadatum$inboundSchema))
      .optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    description: z.string().optional(),
    path: z.string().optional(),
    depth: z.number().optional(),
    suppressMissingPathErrors: z.boolean().default(false),
    deleteFiles: z.boolean().default(false),
    includeUnidentifiableBinary: z.boolean().default(false),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputFile$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputFileConnection$Outbound> | undefined;
  pq?: InputFilePq$Outbound | undefined;
  mode: string;
  interval: number;
  filenames?: Array<string> | undefined;
  filterArchivedFiles: boolean;
  tailOnly: boolean;
  idleTimeout: number;
  minAgeDur?: string | undefined;
  maxAgeDur?: string | undefined;
  checkFileModTime: boolean;
  forceText: boolean;
  hashLen: number;
  metadata?: Array<InputFileMetadatum$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  description?: string | undefined;
  path?: string | undefined;
  depth?: number | undefined;
  suppressMissingPathErrors: boolean;
  deleteFiles: boolean;
  includeUnidentifiableBinary: boolean;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputFile$outboundSchema: z.ZodType<
  InputFile$Outbound,
  z.ZodTypeDef,
  InputFile
> = z.object({
  id: z.string().optional(),
  type: InputFileType$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputFileConnection$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputFilePq$outboundSchema).optional(),
  mode: InputFileMode$outboundSchema.default("manual"),
  interval: z.number().default(10),
  filenames: z.array(z.string()).optional(),
  filterArchivedFiles: z.boolean().default(false),
  tailOnly: z.boolean().default(true),
  idleTimeout: z.number().default(300),
  minAgeDur: z.string().optional(),
  maxAgeDur: z.string().optional(),
  checkFileModTime: z.boolean().default(false),
  forceText: z.boolean().default(false),
  hashLen: z.number().default(256),
  metadata: z.array(z.lazy(() => InputFileMetadatum$outboundSchema)).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  description: z.string().optional(),
  path: z.string().optional(),
  depth: z.number().optional(),
  suppressMissingPathErrors: z.boolean().default(false),
  deleteFiles: z.boolean().default(false),
  includeUnidentifiableBinary: z.boolean().default(false),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputFileToJSON(inputFile: InputFile): string {
  return JSON.stringify(InputFile$outboundSchema.parse(inputFile));
}
export function inputFileFromJSON(
  jsonString: string,
): SafeParseResult<InputFile, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFile$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFile' from JSON`,
  );
}

/** @internal */
export const InputSyslogType2$inboundSchema: z.ZodNativeEnum<
  typeof InputSyslogType2
> = z.nativeEnum(InputSyslogType2);
/** @internal */
export const InputSyslogType2$outboundSchema: z.ZodNativeEnum<
  typeof InputSyslogType2
> = InputSyslogType2$inboundSchema;

/** @internal */
export const InputSyslogConnection2$inboundSchema: z.ZodType<
  InputSyslogConnection2,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputSyslogConnection2$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputSyslogConnection2$outboundSchema: z.ZodType<
  InputSyslogConnection2$Outbound,
  z.ZodTypeDef,
  InputSyslogConnection2
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputSyslogConnection2ToJSON(
  inputSyslogConnection2: InputSyslogConnection2,
): string {
  return JSON.stringify(
    InputSyslogConnection2$outboundSchema.parse(inputSyslogConnection2),
  );
}
export function inputSyslogConnection2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogConnection2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogConnection2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogConnection2' from JSON`,
  );
}

/** @internal */
export const InputSyslogMode2$inboundSchema: z.ZodType<
  InputSyslogMode2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMode2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMode2$outboundSchema: z.ZodType<
  InputSyslogMode2,
  z.ZodTypeDef,
  InputSyslogMode2
> = z.union([
  z.nativeEnum(InputSyslogMode2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogCompression2$inboundSchema: z.ZodType<
  InputSyslogCompression2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogCompression2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogCompression2$outboundSchema: z.ZodType<
  InputSyslogCompression2,
  z.ZodTypeDef,
  InputSyslogCompression2
> = z.union([
  z.nativeEnum(InputSyslogCompression2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogPqControls2$inboundSchema: z.ZodType<
  InputSyslogPqControls2,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputSyslogPqControls2$Outbound = {};

/** @internal */
export const InputSyslogPqControls2$outboundSchema: z.ZodType<
  InputSyslogPqControls2$Outbound,
  z.ZodTypeDef,
  InputSyslogPqControls2
> = z.object({});

export function inputSyslogPqControls2ToJSON(
  inputSyslogPqControls2: InputSyslogPqControls2,
): string {
  return JSON.stringify(
    InputSyslogPqControls2$outboundSchema.parse(inputSyslogPqControls2),
  );
}
export function inputSyslogPqControls2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogPqControls2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogPqControls2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogPqControls2' from JSON`,
  );
}

/** @internal */
export const InputSyslogPq2$inboundSchema: z.ZodType<
  InputSyslogPq2,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputSyslogMode2$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputSyslogCompression2$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputSyslogPqControls2$inboundSchema).optional(),
});
/** @internal */
export type InputSyslogPq2$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputSyslogPqControls2$Outbound | undefined;
};

/** @internal */
export const InputSyslogPq2$outboundSchema: z.ZodType<
  InputSyslogPq2$Outbound,
  z.ZodTypeDef,
  InputSyslogPq2
> = z.object({
  mode: InputSyslogMode2$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputSyslogCompression2$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputSyslogPqControls2$outboundSchema).optional(),
});

export function inputSyslogPq2ToJSON(inputSyslogPq2: InputSyslogPq2): string {
  return JSON.stringify(InputSyslogPq2$outboundSchema.parse(inputSyslogPq2));
}
export function inputSyslogPq2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogPq2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogPq2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogPq2' from JSON`,
  );
}

/** @internal */
export const InputSyslogMinimumTLSVersion2$inboundSchema: z.ZodType<
  InputSyslogMinimumTLSVersion2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMinimumTLSVersion2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMinimumTLSVersion2$outboundSchema: z.ZodType<
  InputSyslogMinimumTLSVersion2,
  z.ZodTypeDef,
  InputSyslogMinimumTLSVersion2
> = z.union([
  z.nativeEnum(InputSyslogMinimumTLSVersion2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogMaximumTLSVersion2$inboundSchema: z.ZodType<
  InputSyslogMaximumTLSVersion2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMaximumTLSVersion2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMaximumTLSVersion2$outboundSchema: z.ZodType<
  InputSyslogMaximumTLSVersion2,
  z.ZodTypeDef,
  InputSyslogMaximumTLSVersion2
> = z.union([
  z.nativeEnum(InputSyslogMaximumTLSVersion2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogTLSSettingsServerSide2$inboundSchema: z.ZodType<
  InputSyslogTLSSettingsServerSide2,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputSyslogMinimumTLSVersion2$inboundSchema.optional(),
  maxVersion: InputSyslogMaximumTLSVersion2$inboundSchema.optional(),
});
/** @internal */
export type InputSyslogTLSSettingsServerSide2$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputSyslogTLSSettingsServerSide2$outboundSchema: z.ZodType<
  InputSyslogTLSSettingsServerSide2$Outbound,
  z.ZodTypeDef,
  InputSyslogTLSSettingsServerSide2
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputSyslogMinimumTLSVersion2$outboundSchema.optional(),
  maxVersion: InputSyslogMaximumTLSVersion2$outboundSchema.optional(),
});

export function inputSyslogTLSSettingsServerSide2ToJSON(
  inputSyslogTLSSettingsServerSide2: InputSyslogTLSSettingsServerSide2,
): string {
  return JSON.stringify(
    InputSyslogTLSSettingsServerSide2$outboundSchema.parse(
      inputSyslogTLSSettingsServerSide2,
    ),
  );
}
export function inputSyslogTLSSettingsServerSide2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogTLSSettingsServerSide2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogTLSSettingsServerSide2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogTLSSettingsServerSide2' from JSON`,
  );
}

/** @internal */
export const InputSyslogMetadatum2$inboundSchema: z.ZodType<
  InputSyslogMetadatum2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputSyslogMetadatum2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputSyslogMetadatum2$outboundSchema: z.ZodType<
  InputSyslogMetadatum2$Outbound,
  z.ZodTypeDef,
  InputSyslogMetadatum2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputSyslogMetadatum2ToJSON(
  inputSyslogMetadatum2: InputSyslogMetadatum2,
): string {
  return JSON.stringify(
    InputSyslogMetadatum2$outboundSchema.parse(inputSyslogMetadatum2),
  );
}
export function inputSyslogMetadatum2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogMetadatum2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogMetadatum2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogMetadatum2' from JSON`,
  );
}

/** @internal */
export const InputSyslogSyslog2$inboundSchema: z.ZodType<
  InputSyslogSyslog2,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputSyslogType2$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputSyslogConnection2$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputSyslogPq2$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    udpPort: z.number().optional(),
    tcpPort: z.number(),
    maxBufferSize: z.number().default(1000),
    ipWhitelistRegex: z.string().default("/.*/"),
    timestampTimezone: z.string().default("local"),
    singleMsgUdpPackets: z.boolean().default(false),
    enableProxyHeader: z.boolean().default(false),
    keepFieldsList: z.array(z.string()).optional(),
    octetCounting: z.boolean().default(false),
    inferFraming: z.boolean().default(true),
    strictlyInferOctetCounting: z.boolean().default(true),
    allowNonStandardAppName: z.boolean().default(false),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    tls: z.lazy(() => InputSyslogTLSSettingsServerSide2$inboundSchema)
      .optional(),
    metadata: z.array(z.lazy(() => InputSyslogMetadatum2$inboundSchema))
      .optional(),
    udpSocketRxBufSize: z.number().optional(),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
    enableEnhancedProxyHeaderParsing: z.boolean().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSyslogSyslog2$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputSyslogConnection2$Outbound> | undefined;
  pq?: InputSyslogPq2$Outbound | undefined;
  host: string;
  udpPort?: number | undefined;
  tcpPort: number;
  maxBufferSize: number;
  ipWhitelistRegex: string;
  timestampTimezone: string;
  singleMsgUdpPackets: boolean;
  enableProxyHeader: boolean;
  keepFieldsList?: Array<string> | undefined;
  octetCounting: boolean;
  inferFraming: boolean;
  strictlyInferOctetCounting: boolean;
  allowNonStandardAppName: boolean;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  tls?: InputSyslogTLSSettingsServerSide2$Outbound | undefined;
  metadata?: Array<InputSyslogMetadatum2$Outbound> | undefined;
  udpSocketRxBufSize?: number | undefined;
  enableLoadBalancing: boolean;
  description?: string | undefined;
  enableEnhancedProxyHeaderParsing?: boolean | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSyslogSyslog2$outboundSchema: z.ZodType<
  InputSyslogSyslog2$Outbound,
  z.ZodTypeDef,
  InputSyslogSyslog2
> = z.object({
  id: z.string().optional(),
  type: InputSyslogType2$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputSyslogConnection2$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputSyslogPq2$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  udpPort: z.number().optional(),
  tcpPort: z.number(),
  maxBufferSize: z.number().default(1000),
  ipWhitelistRegex: z.string().default("/.*/"),
  timestampTimezone: z.string().default("local"),
  singleMsgUdpPackets: z.boolean().default(false),
  enableProxyHeader: z.boolean().default(false),
  keepFieldsList: z.array(z.string()).optional(),
  octetCounting: z.boolean().default(false),
  inferFraming: z.boolean().default(true),
  strictlyInferOctetCounting: z.boolean().default(true),
  allowNonStandardAppName: z.boolean().default(false),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  tls: z.lazy(() => InputSyslogTLSSettingsServerSide2$outboundSchema)
    .optional(),
  metadata: z.array(z.lazy(() => InputSyslogMetadatum2$outboundSchema))
    .optional(),
  udpSocketRxBufSize: z.number().optional(),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
  enableEnhancedProxyHeaderParsing: z.boolean().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSyslogSyslog2ToJSON(
  inputSyslogSyslog2: InputSyslogSyslog2,
): string {
  return JSON.stringify(
    InputSyslogSyslog2$outboundSchema.parse(inputSyslogSyslog2),
  );
}
export function inputSyslogSyslog2FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogSyslog2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogSyslog2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogSyslog2' from JSON`,
  );
}

/** @internal */
export const InputSyslogType1$inboundSchema: z.ZodNativeEnum<
  typeof InputSyslogType1
> = z.nativeEnum(InputSyslogType1);
/** @internal */
export const InputSyslogType1$outboundSchema: z.ZodNativeEnum<
  typeof InputSyslogType1
> = InputSyslogType1$inboundSchema;

/** @internal */
export const InputSyslogConnection1$inboundSchema: z.ZodType<
  InputSyslogConnection1,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputSyslogConnection1$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputSyslogConnection1$outboundSchema: z.ZodType<
  InputSyslogConnection1$Outbound,
  z.ZodTypeDef,
  InputSyslogConnection1
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputSyslogConnection1ToJSON(
  inputSyslogConnection1: InputSyslogConnection1,
): string {
  return JSON.stringify(
    InputSyslogConnection1$outboundSchema.parse(inputSyslogConnection1),
  );
}
export function inputSyslogConnection1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogConnection1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogConnection1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogConnection1' from JSON`,
  );
}

/** @internal */
export const InputSyslogMode1$inboundSchema: z.ZodType<
  InputSyslogMode1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMode1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMode1$outboundSchema: z.ZodType<
  InputSyslogMode1,
  z.ZodTypeDef,
  InputSyslogMode1
> = z.union([
  z.nativeEnum(InputSyslogMode1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogCompression1$inboundSchema: z.ZodType<
  InputSyslogCompression1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogCompression1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogCompression1$outboundSchema: z.ZodType<
  InputSyslogCompression1,
  z.ZodTypeDef,
  InputSyslogCompression1
> = z.union([
  z.nativeEnum(InputSyslogCompression1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogPqControls1$inboundSchema: z.ZodType<
  InputSyslogPqControls1,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputSyslogPqControls1$Outbound = {};

/** @internal */
export const InputSyslogPqControls1$outboundSchema: z.ZodType<
  InputSyslogPqControls1$Outbound,
  z.ZodTypeDef,
  InputSyslogPqControls1
> = z.object({});

export function inputSyslogPqControls1ToJSON(
  inputSyslogPqControls1: InputSyslogPqControls1,
): string {
  return JSON.stringify(
    InputSyslogPqControls1$outboundSchema.parse(inputSyslogPqControls1),
  );
}
export function inputSyslogPqControls1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogPqControls1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogPqControls1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogPqControls1' from JSON`,
  );
}

/** @internal */
export const InputSyslogPq1$inboundSchema: z.ZodType<
  InputSyslogPq1,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputSyslogMode1$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputSyslogCompression1$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputSyslogPqControls1$inboundSchema).optional(),
});
/** @internal */
export type InputSyslogPq1$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputSyslogPqControls1$Outbound | undefined;
};

/** @internal */
export const InputSyslogPq1$outboundSchema: z.ZodType<
  InputSyslogPq1$Outbound,
  z.ZodTypeDef,
  InputSyslogPq1
> = z.object({
  mode: InputSyslogMode1$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputSyslogCompression1$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputSyslogPqControls1$outboundSchema).optional(),
});

export function inputSyslogPq1ToJSON(inputSyslogPq1: InputSyslogPq1): string {
  return JSON.stringify(InputSyslogPq1$outboundSchema.parse(inputSyslogPq1));
}
export function inputSyslogPq1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogPq1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogPq1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogPq1' from JSON`,
  );
}

/** @internal */
export const InputSyslogMinimumTLSVersion1$inboundSchema: z.ZodType<
  InputSyslogMinimumTLSVersion1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMinimumTLSVersion1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMinimumTLSVersion1$outboundSchema: z.ZodType<
  InputSyslogMinimumTLSVersion1,
  z.ZodTypeDef,
  InputSyslogMinimumTLSVersion1
> = z.union([
  z.nativeEnum(InputSyslogMinimumTLSVersion1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogMaximumTLSVersion1$inboundSchema: z.ZodType<
  InputSyslogMaximumTLSVersion1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSyslogMaximumTLSVersion1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSyslogMaximumTLSVersion1$outboundSchema: z.ZodType<
  InputSyslogMaximumTLSVersion1,
  z.ZodTypeDef,
  InputSyslogMaximumTLSVersion1
> = z.union([
  z.nativeEnum(InputSyslogMaximumTLSVersion1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSyslogTLSSettingsServerSide1$inboundSchema: z.ZodType<
  InputSyslogTLSSettingsServerSide1,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputSyslogMinimumTLSVersion1$inboundSchema.optional(),
  maxVersion: InputSyslogMaximumTLSVersion1$inboundSchema.optional(),
});
/** @internal */
export type InputSyslogTLSSettingsServerSide1$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputSyslogTLSSettingsServerSide1$outboundSchema: z.ZodType<
  InputSyslogTLSSettingsServerSide1$Outbound,
  z.ZodTypeDef,
  InputSyslogTLSSettingsServerSide1
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputSyslogMinimumTLSVersion1$outboundSchema.optional(),
  maxVersion: InputSyslogMaximumTLSVersion1$outboundSchema.optional(),
});

export function inputSyslogTLSSettingsServerSide1ToJSON(
  inputSyslogTLSSettingsServerSide1: InputSyslogTLSSettingsServerSide1,
): string {
  return JSON.stringify(
    InputSyslogTLSSettingsServerSide1$outboundSchema.parse(
      inputSyslogTLSSettingsServerSide1,
    ),
  );
}
export function inputSyslogTLSSettingsServerSide1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogTLSSettingsServerSide1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogTLSSettingsServerSide1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogTLSSettingsServerSide1' from JSON`,
  );
}

/** @internal */
export const InputSyslogMetadatum1$inboundSchema: z.ZodType<
  InputSyslogMetadatum1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputSyslogMetadatum1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputSyslogMetadatum1$outboundSchema: z.ZodType<
  InputSyslogMetadatum1$Outbound,
  z.ZodTypeDef,
  InputSyslogMetadatum1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputSyslogMetadatum1ToJSON(
  inputSyslogMetadatum1: InputSyslogMetadatum1,
): string {
  return JSON.stringify(
    InputSyslogMetadatum1$outboundSchema.parse(inputSyslogMetadatum1),
  );
}
export function inputSyslogMetadatum1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogMetadatum1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogMetadatum1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogMetadatum1' from JSON`,
  );
}

/** @internal */
export const InputSyslogSyslog1$inboundSchema: z.ZodType<
  InputSyslogSyslog1,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputSyslogType1$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputSyslogConnection1$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputSyslogPq1$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    udpPort: z.number(),
    tcpPort: z.number().optional(),
    maxBufferSize: z.number().default(1000),
    ipWhitelistRegex: z.string().default("/.*/"),
    timestampTimezone: z.string().default("local"),
    singleMsgUdpPackets: z.boolean().default(false),
    enableProxyHeader: z.boolean().default(false),
    keepFieldsList: z.array(z.string()).optional(),
    octetCounting: z.boolean().default(false),
    inferFraming: z.boolean().default(true),
    strictlyInferOctetCounting: z.boolean().default(true),
    allowNonStandardAppName: z.boolean().default(false),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    tls: z.lazy(() => InputSyslogTLSSettingsServerSide1$inboundSchema)
      .optional(),
    metadata: z.array(z.lazy(() => InputSyslogMetadatum1$inboundSchema))
      .optional(),
    udpSocketRxBufSize: z.number().optional(),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
    enableEnhancedProxyHeaderParsing: z.boolean().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSyslogSyslog1$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputSyslogConnection1$Outbound> | undefined;
  pq?: InputSyslogPq1$Outbound | undefined;
  host: string;
  udpPort: number;
  tcpPort?: number | undefined;
  maxBufferSize: number;
  ipWhitelistRegex: string;
  timestampTimezone: string;
  singleMsgUdpPackets: boolean;
  enableProxyHeader: boolean;
  keepFieldsList?: Array<string> | undefined;
  octetCounting: boolean;
  inferFraming: boolean;
  strictlyInferOctetCounting: boolean;
  allowNonStandardAppName: boolean;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  tls?: InputSyslogTLSSettingsServerSide1$Outbound | undefined;
  metadata?: Array<InputSyslogMetadatum1$Outbound> | undefined;
  udpSocketRxBufSize?: number | undefined;
  enableLoadBalancing: boolean;
  description?: string | undefined;
  enableEnhancedProxyHeaderParsing?: boolean | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSyslogSyslog1$outboundSchema: z.ZodType<
  InputSyslogSyslog1$Outbound,
  z.ZodTypeDef,
  InputSyslogSyslog1
> = z.object({
  id: z.string().optional(),
  type: InputSyslogType1$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputSyslogConnection1$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputSyslogPq1$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  udpPort: z.number(),
  tcpPort: z.number().optional(),
  maxBufferSize: z.number().default(1000),
  ipWhitelistRegex: z.string().default("/.*/"),
  timestampTimezone: z.string().default("local"),
  singleMsgUdpPackets: z.boolean().default(false),
  enableProxyHeader: z.boolean().default(false),
  keepFieldsList: z.array(z.string()).optional(),
  octetCounting: z.boolean().default(false),
  inferFraming: z.boolean().default(true),
  strictlyInferOctetCounting: z.boolean().default(true),
  allowNonStandardAppName: z.boolean().default(false),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  tls: z.lazy(() => InputSyslogTLSSettingsServerSide1$outboundSchema)
    .optional(),
  metadata: z.array(z.lazy(() => InputSyslogMetadatum1$outboundSchema))
    .optional(),
  udpSocketRxBufSize: z.number().optional(),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
  enableEnhancedProxyHeaderParsing: z.boolean().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSyslogSyslog1ToJSON(
  inputSyslogSyslog1: InputSyslogSyslog1,
): string {
  return JSON.stringify(
    InputSyslogSyslog1$outboundSchema.parse(inputSyslogSyslog1),
  );
}
export function inputSyslogSyslog1FromJSON(
  jsonString: string,
): SafeParseResult<InputSyslogSyslog1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslogSyslog1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslogSyslog1' from JSON`,
  );
}

/** @internal */
export const InputSyslog$inboundSchema: z.ZodType<
  InputSyslog,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => InputSyslogSyslog1$inboundSchema),
  z.lazy(() => InputSyslogSyslog2$inboundSchema),
]);
/** @internal */
export type InputSyslog$Outbound =
  | InputSyslogSyslog1$Outbound
  | InputSyslogSyslog2$Outbound;

/** @internal */
export const InputSyslog$outboundSchema: z.ZodType<
  InputSyslog$Outbound,
  z.ZodTypeDef,
  InputSyslog
> = z.union([
  z.lazy(() => InputSyslogSyslog1$outboundSchema),
  z.lazy(() => InputSyslogSyslog2$outboundSchema),
]);

export function inputSyslogToJSON(inputSyslog: InputSyslog): string {
  return JSON.stringify(InputSyslog$outboundSchema.parse(inputSyslog));
}
export function inputSyslogFromJSON(
  jsonString: string,
): SafeParseResult<InputSyslog, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSyslog$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSyslog' from JSON`,
  );
}

/** @internal */
export const InputTypeSqs$inboundSchema: z.ZodNativeEnum<typeof InputTypeSqs> =
  z.nativeEnum(InputTypeSqs);
/** @internal */
export const InputTypeSqs$outboundSchema: z.ZodNativeEnum<typeof InputTypeSqs> =
  InputTypeSqs$inboundSchema;

/** @internal */
export const ConnectionSqs$inboundSchema: z.ZodType<
  ConnectionSqs,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSqs$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSqs$outboundSchema: z.ZodType<
  ConnectionSqs$Outbound,
  z.ZodTypeDef,
  ConnectionSqs
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSqsToJSON(connectionSqs: ConnectionSqs): string {
  return JSON.stringify(ConnectionSqs$outboundSchema.parse(connectionSqs));
}
export function connectionSqsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSqs' from JSON`,
  );
}

/** @internal */
export const PqModeSqs$inboundSchema: z.ZodType<
  PqModeSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeSqs$outboundSchema: z.ZodType<
  PqModeSqs,
  z.ZodTypeDef,
  PqModeSqs
> = z.union([
  z.nativeEnum(PqModeSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionSqs$inboundSchema: z.ZodType<
  PqCompressionSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionSqs$outboundSchema: z.ZodType<
  PqCompressionSqs,
  z.ZodTypeDef,
  PqCompressionSqs
> = z.union([
  z.nativeEnum(PqCompressionSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsSqs$inboundSchema: z.ZodType<
  InputPqControlsSqs,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsSqs$Outbound = {};

/** @internal */
export const InputPqControlsSqs$outboundSchema: z.ZodType<
  InputPqControlsSqs$Outbound,
  z.ZodTypeDef,
  InputPqControlsSqs
> = z.object({});

export function inputPqControlsSqsToJSON(
  inputPqControlsSqs: InputPqControlsSqs,
): string {
  return JSON.stringify(
    InputPqControlsSqs$outboundSchema.parse(inputPqControlsSqs),
  );
}
export function inputPqControlsSqsFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsSqs' from JSON`,
  );
}

/** @internal */
export const PqSqs$inboundSchema: z.ZodType<PqSqs, z.ZodTypeDef, unknown> = z
  .object({
    mode: PqModeSqs$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionSqs$inboundSchema.default("none"),
    pqControls: z.lazy(() => InputPqControlsSqs$inboundSchema).optional(),
  });
/** @internal */
export type PqSqs$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsSqs$Outbound | undefined;
};

/** @internal */
export const PqSqs$outboundSchema: z.ZodType<
  PqSqs$Outbound,
  z.ZodTypeDef,
  PqSqs
> = z.object({
  mode: PqModeSqs$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionSqs$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsSqs$outboundSchema).optional(),
});

export function pqSqsToJSON(pqSqs: PqSqs): string {
  return JSON.stringify(PqSqs$outboundSchema.parse(pqSqs));
}
export function pqSqsFromJSON(
  jsonString: string,
): SafeParseResult<PqSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSqs' from JSON`,
  );
}

/** @internal */
export const InputQueueType$inboundSchema: z.ZodType<
  InputQueueType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputQueueType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputQueueType$outboundSchema: z.ZodType<
  InputQueueType,
  z.ZodTypeDef,
  InputQueueType
> = z.union([
  z.nativeEnum(InputQueueType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputAuthenticationMethodSqs$inboundSchema: z.ZodType<
  InputAuthenticationMethodSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodSqs$outboundSchema: z.ZodType<
  InputAuthenticationMethodSqs,
  z.ZodTypeDef,
  InputAuthenticationMethodSqs
> = z.union([
  z.nativeEnum(InputAuthenticationMethodSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSignatureVersionSqs$inboundSchema: z.ZodType<
  InputSignatureVersionSqs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSignatureVersionSqs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSignatureVersionSqs$outboundSchema: z.ZodType<
  InputSignatureVersionSqs,
  z.ZodTypeDef,
  InputSignatureVersionSqs
> = z.union([
  z.nativeEnum(InputSignatureVersionSqs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumSqs$inboundSchema: z.ZodType<
  MetadatumSqs,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSqs$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSqs$outboundSchema: z.ZodType<
  MetadatumSqs$Outbound,
  z.ZodTypeDef,
  MetadatumSqs
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSqsToJSON(metadatumSqs: MetadatumSqs): string {
  return JSON.stringify(MetadatumSqs$outboundSchema.parse(metadatumSqs));
}
export function metadatumSqsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSqs' from JSON`,
  );
}

/** @internal */
export const InputSqs$inboundSchema: z.ZodType<
  InputSqs,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeSqs$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSqs$inboundSchema)).optional(),
    pq: z.lazy(() => PqSqs$inboundSchema).optional(),
    queueName: z.string(),
    queueType: InputQueueType$inboundSchema,
    awsAccountId: z.string().optional(),
    createQueue: z.boolean().default(false),
    awsAuthenticationMethod: InputAuthenticationMethodSqs$inboundSchema.default(
      "auto",
    ),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: InputSignatureVersionSqs$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    maxMessages: z.number().default(10),
    visibilityTimeout: z.number().default(600),
    metadata: z.array(z.lazy(() => MetadatumSqs$inboundSchema)).optional(),
    pollTimeout: z.number().default(10),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    numReceivers: z.number().default(3),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSqs$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSqs$Outbound> | undefined;
  pq?: PqSqs$Outbound | undefined;
  queueName: string;
  queueType: string;
  awsAccountId?: string | undefined;
  createQueue: boolean;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  maxMessages: number;
  visibilityTimeout: number;
  metadata?: Array<MetadatumSqs$Outbound> | undefined;
  pollTimeout: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  numReceivers: number;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSqs$outboundSchema: z.ZodType<
  InputSqs$Outbound,
  z.ZodTypeDef,
  InputSqs
> = z.object({
  id: z.string().optional(),
  type: InputTypeSqs$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSqs$outboundSchema)).optional(),
  pq: z.lazy(() => PqSqs$outboundSchema).optional(),
  queueName: z.string(),
  queueType: InputQueueType$outboundSchema,
  awsAccountId: z.string().optional(),
  createQueue: z.boolean().default(false),
  awsAuthenticationMethod: InputAuthenticationMethodSqs$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: InputSignatureVersionSqs$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  maxMessages: z.number().default(10),
  visibilityTimeout: z.number().default(600),
  metadata: z.array(z.lazy(() => MetadatumSqs$outboundSchema)).optional(),
  pollTimeout: z.number().default(10),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  numReceivers: z.number().default(3),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSqsToJSON(inputSqs: InputSqs): string {
  return JSON.stringify(InputSqs$outboundSchema.parse(inputSqs));
}
export function inputSqsFromJSON(
  jsonString: string,
): SafeParseResult<InputSqs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSqs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSqs' from JSON`,
  );
}

/** @internal */
export const TypeModelDrivenTelemetry$inboundSchema: z.ZodNativeEnum<
  typeof TypeModelDrivenTelemetry
> = z.nativeEnum(TypeModelDrivenTelemetry);
/** @internal */
export const TypeModelDrivenTelemetry$outboundSchema: z.ZodNativeEnum<
  typeof TypeModelDrivenTelemetry
> = TypeModelDrivenTelemetry$inboundSchema;

/** @internal */
export const ConnectionModelDrivenTelemetry$inboundSchema: z.ZodType<
  ConnectionModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionModelDrivenTelemetry$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionModelDrivenTelemetry$outboundSchema: z.ZodType<
  ConnectionModelDrivenTelemetry$Outbound,
  z.ZodTypeDef,
  ConnectionModelDrivenTelemetry
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionModelDrivenTelemetryToJSON(
  connectionModelDrivenTelemetry: ConnectionModelDrivenTelemetry,
): string {
  return JSON.stringify(
    ConnectionModelDrivenTelemetry$outboundSchema.parse(
      connectionModelDrivenTelemetry,
    ),
  );
}
export function connectionModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionModelDrivenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionModelDrivenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const ModeModelDrivenTelemetry$inboundSchema: z.ZodType<
  ModeModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeModelDrivenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeModelDrivenTelemetry$outboundSchema: z.ZodType<
  ModeModelDrivenTelemetry,
  z.ZodTypeDef,
  ModeModelDrivenTelemetry
> = z.union([
  z.nativeEnum(ModeModelDrivenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionModelDrivenTelemetry$inboundSchema: z.ZodType<
  CompressionModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionModelDrivenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionModelDrivenTelemetry$outboundSchema: z.ZodType<
  CompressionModelDrivenTelemetry,
  z.ZodTypeDef,
  CompressionModelDrivenTelemetry
> = z.union([
  z.nativeEnum(CompressionModelDrivenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsModelDrivenTelemetry$inboundSchema: z.ZodType<
  PqControlsModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsModelDrivenTelemetry$Outbound = {};

/** @internal */
export const PqControlsModelDrivenTelemetry$outboundSchema: z.ZodType<
  PqControlsModelDrivenTelemetry$Outbound,
  z.ZodTypeDef,
  PqControlsModelDrivenTelemetry
> = z.object({});

export function pqControlsModelDrivenTelemetryToJSON(
  pqControlsModelDrivenTelemetry: PqControlsModelDrivenTelemetry,
): string {
  return JSON.stringify(
    PqControlsModelDrivenTelemetry$outboundSchema.parse(
      pqControlsModelDrivenTelemetry,
    ),
  );
}
export function pqControlsModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsModelDrivenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsModelDrivenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const PqModelDrivenTelemetry$inboundSchema: z.ZodType<
  PqModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeModelDrivenTelemetry$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionModelDrivenTelemetry$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsModelDrivenTelemetry$inboundSchema)
    .optional(),
});
/** @internal */
export type PqModelDrivenTelemetry$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsModelDrivenTelemetry$Outbound | undefined;
};

/** @internal */
export const PqModelDrivenTelemetry$outboundSchema: z.ZodType<
  PqModelDrivenTelemetry$Outbound,
  z.ZodTypeDef,
  PqModelDrivenTelemetry
> = z.object({
  mode: ModeModelDrivenTelemetry$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionModelDrivenTelemetry$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsModelDrivenTelemetry$outboundSchema)
    .optional(),
});

export function pqModelDrivenTelemetryToJSON(
  pqModelDrivenTelemetry: PqModelDrivenTelemetry,
): string {
  return JSON.stringify(
    PqModelDrivenTelemetry$outboundSchema.parse(pqModelDrivenTelemetry),
  );
}
export function pqModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<PqModelDrivenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqModelDrivenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionModelDrivenTelemetry$inboundSchema: z.ZodType<
  MinimumTLSVersionModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionModelDrivenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionModelDrivenTelemetry$outboundSchema: z.ZodType<
  MinimumTLSVersionModelDrivenTelemetry,
  z.ZodTypeDef,
  MinimumTLSVersionModelDrivenTelemetry
> = z.union([
  z.nativeEnum(MinimumTLSVersionModelDrivenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionModelDrivenTelemetry$inboundSchema: z.ZodType<
  MaximumTLSVersionModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionModelDrivenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionModelDrivenTelemetry$outboundSchema: z.ZodType<
  MaximumTLSVersionModelDrivenTelemetry,
  z.ZodTypeDef,
  MaximumTLSVersionModelDrivenTelemetry
> = z.union([
  z.nativeEnum(MaximumTLSVersionModelDrivenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideModelDrivenTelemetry$inboundSchema: z.ZodType<
  TLSSettingsServerSideModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionModelDrivenTelemetry$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionModelDrivenTelemetry$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideModelDrivenTelemetry$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideModelDrivenTelemetry$outboundSchema:
  z.ZodType<
    TLSSettingsServerSideModelDrivenTelemetry$Outbound,
    z.ZodTypeDef,
    TLSSettingsServerSideModelDrivenTelemetry
  > = z.object({
    disabled: z.boolean().default(true),
    requestCert: z.boolean().default(false),
    rejectUnauthorized: z.boolean().default(true),
    commonNameRegex: z.string().default("/.*/"),
    certificateName: z.string().optional(),
    privKeyPath: z.string().optional(),
    passphrase: z.string().optional(),
    certPath: z.string().optional(),
    caPath: z.string().optional(),
    minVersion: MinimumTLSVersionModelDrivenTelemetry$outboundSchema.optional(),
    maxVersion: MaximumTLSVersionModelDrivenTelemetry$outboundSchema.optional(),
  });

export function tlsSettingsServerSideModelDrivenTelemetryToJSON(
  tlsSettingsServerSideModelDrivenTelemetry:
    TLSSettingsServerSideModelDrivenTelemetry,
): string {
  return JSON.stringify(
    TLSSettingsServerSideModelDrivenTelemetry$outboundSchema.parse(
      tlsSettingsServerSideModelDrivenTelemetry,
    ),
  );
}
export function tlsSettingsServerSideModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<
  TLSSettingsServerSideModelDrivenTelemetry,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsServerSideModelDrivenTelemetry$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'TLSSettingsServerSideModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const MetadatumModelDrivenTelemetry$inboundSchema: z.ZodType<
  MetadatumModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumModelDrivenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumModelDrivenTelemetry$outboundSchema: z.ZodType<
  MetadatumModelDrivenTelemetry$Outbound,
  z.ZodTypeDef,
  MetadatumModelDrivenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumModelDrivenTelemetryToJSON(
  metadatumModelDrivenTelemetry: MetadatumModelDrivenTelemetry,
): string {
  return JSON.stringify(
    MetadatumModelDrivenTelemetry$outboundSchema.parse(
      metadatumModelDrivenTelemetry,
    ),
  );
}
export function metadatumModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumModelDrivenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumModelDrivenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputModelDrivenTelemetry$inboundSchema: z.ZodType<
  InputModelDrivenTelemetry,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeModelDrivenTelemetry$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(
      z.lazy(() => ConnectionModelDrivenTelemetry$inboundSchema),
    ).optional(),
    pq: z.lazy(() => PqModelDrivenTelemetry$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number().default(57000),
    tls: z.lazy(() => TLSSettingsServerSideModelDrivenTelemetry$inboundSchema)
      .optional(),
    metadata: z.array(z.lazy(() => MetadatumModelDrivenTelemetry$inboundSchema))
      .optional(),
    maxActiveCxn: z.number().default(1000),
    shutdownTimeoutMs: z.number().default(5000),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputModelDrivenTelemetry$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionModelDrivenTelemetry$Outbound> | undefined;
  pq?: PqModelDrivenTelemetry$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideModelDrivenTelemetry$Outbound | undefined;
  metadata?: Array<MetadatumModelDrivenTelemetry$Outbound> | undefined;
  maxActiveCxn: number;
  shutdownTimeoutMs: number;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputModelDrivenTelemetry$outboundSchema: z.ZodType<
  InputModelDrivenTelemetry$Outbound,
  z.ZodTypeDef,
  InputModelDrivenTelemetry
> = z.object({
  id: z.string().optional(),
  type: TypeModelDrivenTelemetry$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(
    z.lazy(() => ConnectionModelDrivenTelemetry$outboundSchema),
  ).optional(),
  pq: z.lazy(() => PqModelDrivenTelemetry$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number().default(57000),
  tls: z.lazy(() => TLSSettingsServerSideModelDrivenTelemetry$outboundSchema)
    .optional(),
  metadata: z.array(z.lazy(() => MetadatumModelDrivenTelemetry$outboundSchema))
    .optional(),
  maxActiveCxn: z.number().default(1000),
  shutdownTimeoutMs: z.number().default(5000),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputModelDrivenTelemetryToJSON(
  inputModelDrivenTelemetry: InputModelDrivenTelemetry,
): string {
  return JSON.stringify(
    InputModelDrivenTelemetry$outboundSchema.parse(inputModelDrivenTelemetry),
  );
}
export function inputModelDrivenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputModelDrivenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputModelDrivenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputModelDrivenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputTypeOpenTelemetry$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeOpenTelemetry
> = z.nativeEnum(InputTypeOpenTelemetry);
/** @internal */
export const InputTypeOpenTelemetry$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeOpenTelemetry
> = InputTypeOpenTelemetry$inboundSchema;

/** @internal */
export const ConnectionOpenTelemetry$inboundSchema: z.ZodType<
  ConnectionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionOpenTelemetry$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionOpenTelemetry$outboundSchema: z.ZodType<
  ConnectionOpenTelemetry$Outbound,
  z.ZodTypeDef,
  ConnectionOpenTelemetry
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionOpenTelemetryToJSON(
  connectionOpenTelemetry: ConnectionOpenTelemetry,
): string {
  return JSON.stringify(
    ConnectionOpenTelemetry$outboundSchema.parse(connectionOpenTelemetry),
  );
}
export function connectionOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const PqModeOpenTelemetry$inboundSchema: z.ZodType<
  PqModeOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeOpenTelemetry$outboundSchema: z.ZodType<
  PqModeOpenTelemetry,
  z.ZodTypeDef,
  PqModeOpenTelemetry
> = z.union([
  z.nativeEnum(PqModeOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionOpenTelemetry$inboundSchema: z.ZodType<
  PqCompressionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionOpenTelemetry$outboundSchema: z.ZodType<
  PqCompressionOpenTelemetry,
  z.ZodTypeDef,
  PqCompressionOpenTelemetry
> = z.union([
  z.nativeEnum(PqCompressionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsOpenTelemetry$inboundSchema: z.ZodType<
  InputPqControlsOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsOpenTelemetry$Outbound = {};

/** @internal */
export const InputPqControlsOpenTelemetry$outboundSchema: z.ZodType<
  InputPqControlsOpenTelemetry$Outbound,
  z.ZodTypeDef,
  InputPqControlsOpenTelemetry
> = z.object({});

export function inputPqControlsOpenTelemetryToJSON(
  inputPqControlsOpenTelemetry: InputPqControlsOpenTelemetry,
): string {
  return JSON.stringify(
    InputPqControlsOpenTelemetry$outboundSchema.parse(
      inputPqControlsOpenTelemetry,
    ),
  );
}
export function inputPqControlsOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const PqOpenTelemetry$inboundSchema: z.ZodType<
  PqOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeOpenTelemetry$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionOpenTelemetry$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsOpenTelemetry$inboundSchema)
    .optional(),
});
/** @internal */
export type PqOpenTelemetry$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsOpenTelemetry$Outbound | undefined;
};

/** @internal */
export const PqOpenTelemetry$outboundSchema: z.ZodType<
  PqOpenTelemetry$Outbound,
  z.ZodTypeDef,
  PqOpenTelemetry
> = z.object({
  mode: PqModeOpenTelemetry$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionOpenTelemetry$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsOpenTelemetry$outboundSchema)
    .optional(),
});

export function pqOpenTelemetryToJSON(
  pqOpenTelemetry: PqOpenTelemetry,
): string {
  return JSON.stringify(PqOpenTelemetry$outboundSchema.parse(pqOpenTelemetry));
}
export function pqOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<PqOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionOpenTelemetry$inboundSchema: z.ZodType<
  InputMinimumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionOpenTelemetry$outboundSchema: z.ZodType<
  InputMinimumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  InputMinimumTLSVersionOpenTelemetry
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionOpenTelemetry$inboundSchema: z.ZodType<
  InputMaximumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionOpenTelemetry$outboundSchema: z.ZodType<
  InputMaximumTLSVersionOpenTelemetry,
  z.ZodTypeDef,
  InputMaximumTLSVersionOpenTelemetry
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideOpenTelemetry$inboundSchema: z.ZodType<
  TLSSettingsServerSideOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionOpenTelemetry$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionOpenTelemetry$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideOpenTelemetry$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideOpenTelemetry$outboundSchema: z.ZodType<
  TLSSettingsServerSideOpenTelemetry$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideOpenTelemetry
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionOpenTelemetry$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionOpenTelemetry$outboundSchema.optional(),
});

export function tlsSettingsServerSideOpenTelemetryToJSON(
  tlsSettingsServerSideOpenTelemetry: TLSSettingsServerSideOpenTelemetry,
): string {
  return JSON.stringify(
    TLSSettingsServerSideOpenTelemetry$outboundSchema.parse(
      tlsSettingsServerSideOpenTelemetry,
    ),
  );
}
export function tlsSettingsServerSideOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsServerSideOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputProtocolOpenTelemetry$inboundSchema: z.ZodType<
  InputProtocolOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputProtocolOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputProtocolOpenTelemetry$outboundSchema: z.ZodType<
  InputProtocolOpenTelemetry,
  z.ZodTypeDef,
  InputProtocolOpenTelemetry
> = z.union([
  z.nativeEnum(InputProtocolOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputOTLPVersion$inboundSchema: z.ZodType<
  InputOTLPVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputOTLPVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputOTLPVersion$outboundSchema: z.ZodType<
  InputOTLPVersion,
  z.ZodTypeDef,
  InputOTLPVersion
> = z.union([
  z.nativeEnum(InputOTLPVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputAuthenticationTypeOpenTelemetry$inboundSchema: z.ZodType<
  InputAuthenticationTypeOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationTypeOpenTelemetry),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationTypeOpenTelemetry$outboundSchema: z.ZodType<
  InputAuthenticationTypeOpenTelemetry,
  z.ZodTypeDef,
  InputAuthenticationTypeOpenTelemetry
> = z.union([
  z.nativeEnum(InputAuthenticationTypeOpenTelemetry),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMetadatumOpenTelemetry$inboundSchema: z.ZodType<
  InputMetadatumOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputMetadatumOpenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputMetadatumOpenTelemetry$outboundSchema: z.ZodType<
  InputMetadatumOpenTelemetry$Outbound,
  z.ZodTypeDef,
  InputMetadatumOpenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputMetadatumOpenTelemetryToJSON(
  inputMetadatumOpenTelemetry: InputMetadatumOpenTelemetry,
): string {
  return JSON.stringify(
    InputMetadatumOpenTelemetry$outboundSchema.parse(
      inputMetadatumOpenTelemetry,
    ),
  );
}
export function inputMetadatumOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputMetadatumOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputMetadatumOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputMetadatumOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputOauthParamOpenTelemetry$inboundSchema: z.ZodType<
  InputOauthParamOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputOauthParamOpenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputOauthParamOpenTelemetry$outboundSchema: z.ZodType<
  InputOauthParamOpenTelemetry$Outbound,
  z.ZodTypeDef,
  InputOauthParamOpenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputOauthParamOpenTelemetryToJSON(
  inputOauthParamOpenTelemetry: InputOauthParamOpenTelemetry,
): string {
  return JSON.stringify(
    InputOauthParamOpenTelemetry$outboundSchema.parse(
      inputOauthParamOpenTelemetry,
    ),
  );
}
export function inputOauthParamOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputOauthParamOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOauthParamOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOauthParamOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputOauthHeaderOpenTelemetry$inboundSchema: z.ZodType<
  InputOauthHeaderOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputOauthHeaderOpenTelemetry$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputOauthHeaderOpenTelemetry$outboundSchema: z.ZodType<
  InputOauthHeaderOpenTelemetry$Outbound,
  z.ZodTypeDef,
  InputOauthHeaderOpenTelemetry
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputOauthHeaderOpenTelemetryToJSON(
  inputOauthHeaderOpenTelemetry: InputOauthHeaderOpenTelemetry,
): string {
  return JSON.stringify(
    InputOauthHeaderOpenTelemetry$outboundSchema.parse(
      inputOauthHeaderOpenTelemetry,
    ),
  );
}
export function inputOauthHeaderOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputOauthHeaderOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOauthHeaderOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOauthHeaderOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputOpenTelemetry$inboundSchema: z.ZodType<
  InputOpenTelemetry,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeOpenTelemetry$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionOpenTelemetry$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqOpenTelemetry$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number().default(4317),
    tls: z.lazy(() => TLSSettingsServerSideOpenTelemetry$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.any().optional(),
    captureHeaders: z.any().optional(),
    activityLogSampleRate: z.any().optional(),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(15),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    protocol: InputProtocolOpenTelemetry$inboundSchema.default("grpc"),
    extractSpans: z.boolean().default(false),
    extractMetrics: z.boolean().default(false),
    otlpVersion: InputOTLPVersion$inboundSchema.default("0.10.0"),
    authType: InputAuthenticationTypeOpenTelemetry$inboundSchema.default(
      "none",
    ),
    metadata: z.array(z.lazy(() => InputMetadatumOpenTelemetry$inboundSchema))
      .optional(),
    maxActiveCxn: z.number().default(1000),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(
      z.lazy(() => InputOauthParamOpenTelemetry$inboundSchema),
    ).optional(),
    oauthHeaders: z.array(
      z.lazy(() => InputOauthHeaderOpenTelemetry$inboundSchema),
    ).optional(),
    extractLogs: z.boolean().default(false),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputOpenTelemetry$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionOpenTelemetry$Outbound> | undefined;
  pq?: PqOpenTelemetry$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideOpenTelemetry$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader?: any | undefined;
  captureHeaders?: any | undefined;
  activityLogSampleRate?: any | undefined;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  protocol: string;
  extractSpans: boolean;
  extractMetrics: boolean;
  otlpVersion: string;
  authType: string;
  metadata?: Array<InputMetadatumOpenTelemetry$Outbound> | undefined;
  maxActiveCxn: number;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<InputOauthParamOpenTelemetry$Outbound> | undefined;
  oauthHeaders?: Array<InputOauthHeaderOpenTelemetry$Outbound> | undefined;
  extractLogs: boolean;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputOpenTelemetry$outboundSchema: z.ZodType<
  InputOpenTelemetry$Outbound,
  z.ZodTypeDef,
  InputOpenTelemetry
> = z.object({
  id: z.string().optional(),
  type: InputTypeOpenTelemetry$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionOpenTelemetry$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqOpenTelemetry$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number().default(4317),
  tls: z.lazy(() => TLSSettingsServerSideOpenTelemetry$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.any().optional(),
  captureHeaders: z.any().optional(),
  activityLogSampleRate: z.any().optional(),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(15),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  protocol: InputProtocolOpenTelemetry$outboundSchema.default("grpc"),
  extractSpans: z.boolean().default(false),
  extractMetrics: z.boolean().default(false),
  otlpVersion: InputOTLPVersion$outboundSchema.default("0.10.0"),
  authType: InputAuthenticationTypeOpenTelemetry$outboundSchema.default("none"),
  metadata: z.array(z.lazy(() => InputMetadatumOpenTelemetry$outboundSchema))
    .optional(),
  maxActiveCxn: z.number().default(1000),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(
    z.lazy(() => InputOauthParamOpenTelemetry$outboundSchema),
  ).optional(),
  oauthHeaders: z.array(
    z.lazy(() => InputOauthHeaderOpenTelemetry$outboundSchema),
  ).optional(),
  extractLogs: z.boolean().default(false),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputOpenTelemetryToJSON(
  inputOpenTelemetry: InputOpenTelemetry,
): string {
  return JSON.stringify(
    InputOpenTelemetry$outboundSchema.parse(inputOpenTelemetry),
  );
}
export function inputOpenTelemetryFromJSON(
  jsonString: string,
): SafeParseResult<InputOpenTelemetry, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOpenTelemetry$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOpenTelemetry' from JSON`,
  );
}

/** @internal */
export const InputTypeSnmp$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeSnmp
> = z.nativeEnum(InputTypeSnmp);
/** @internal */
export const InputTypeSnmp$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeSnmp
> = InputTypeSnmp$inboundSchema;

/** @internal */
export const ConnectionSnmp$inboundSchema: z.ZodType<
  ConnectionSnmp,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSnmp$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSnmp$outboundSchema: z.ZodType<
  ConnectionSnmp$Outbound,
  z.ZodTypeDef,
  ConnectionSnmp
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSnmpToJSON(connectionSnmp: ConnectionSnmp): string {
  return JSON.stringify(ConnectionSnmp$outboundSchema.parse(connectionSnmp));
}
export function connectionSnmpFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSnmp' from JSON`,
  );
}

/** @internal */
export const ModeSnmp$inboundSchema: z.ZodType<
  ModeSnmp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSnmp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSnmp$outboundSchema: z.ZodType<
  ModeSnmp,
  z.ZodTypeDef,
  ModeSnmp
> = z.union([
  z.nativeEnum(ModeSnmp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSnmp$inboundSchema: z.ZodType<
  CompressionSnmp,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSnmp),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSnmp$outboundSchema: z.ZodType<
  CompressionSnmp,
  z.ZodTypeDef,
  CompressionSnmp
> = z.union([
  z.nativeEnum(CompressionSnmp),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSnmp$inboundSchema: z.ZodType<
  PqControlsSnmp,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSnmp$Outbound = {};

/** @internal */
export const PqControlsSnmp$outboundSchema: z.ZodType<
  PqControlsSnmp$Outbound,
  z.ZodTypeDef,
  PqControlsSnmp
> = z.object({});

export function pqControlsSnmpToJSON(pqControlsSnmp: PqControlsSnmp): string {
  return JSON.stringify(PqControlsSnmp$outboundSchema.parse(pqControlsSnmp));
}
export function pqControlsSnmpFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSnmp' from JSON`,
  );
}

/** @internal */
export const PqSnmp$inboundSchema: z.ZodType<PqSnmp, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeSnmp$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionSnmp$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsSnmp$inboundSchema).optional(),
  });
/** @internal */
export type PqSnmp$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsSnmp$Outbound | undefined;
};

/** @internal */
export const PqSnmp$outboundSchema: z.ZodType<
  PqSnmp$Outbound,
  z.ZodTypeDef,
  PqSnmp
> = z.object({
  mode: ModeSnmp$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSnmp$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSnmp$outboundSchema).optional(),
});

export function pqSnmpToJSON(pqSnmp: PqSnmp): string {
  return JSON.stringify(PqSnmp$outboundSchema.parse(pqSnmp));
}
export function pqSnmpFromJSON(
  jsonString: string,
): SafeParseResult<PqSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSnmp' from JSON`,
  );
}

/** @internal */
export const AuthenticationProtocol$inboundSchema: z.ZodType<
  AuthenticationProtocol,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationProtocol),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationProtocol$outboundSchema: z.ZodType<
  AuthenticationProtocol,
  z.ZodTypeDef,
  AuthenticationProtocol
> = z.union([
  z.nativeEnum(AuthenticationProtocol),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const V3User$inboundSchema: z.ZodType<V3User, z.ZodTypeDef, unknown> = z
  .object({
    name: z.string(),
    authProtocol: AuthenticationProtocol$inboundSchema.default("none"),
    authKey: z.any().optional(),
    privProtocol: z.string().default("none"),
  });
/** @internal */
export type V3User$Outbound = {
  name: string;
  authProtocol: string;
  authKey?: any | undefined;
  privProtocol: string;
};

/** @internal */
export const V3User$outboundSchema: z.ZodType<
  V3User$Outbound,
  z.ZodTypeDef,
  V3User
> = z.object({
  name: z.string(),
  authProtocol: AuthenticationProtocol$outboundSchema.default("none"),
  authKey: z.any().optional(),
  privProtocol: z.string().default("none"),
});

export function v3UserToJSON(v3User: V3User): string {
  return JSON.stringify(V3User$outboundSchema.parse(v3User));
}
export function v3UserFromJSON(
  jsonString: string,
): SafeParseResult<V3User, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => V3User$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'V3User' from JSON`,
  );
}

/** @internal */
export const SNMPv3Authentication$inboundSchema: z.ZodType<
  SNMPv3Authentication,
  z.ZodTypeDef,
  unknown
> = z.object({
  v3AuthEnabled: z.boolean().default(false),
  allowUnmatchedTrap: z.boolean().default(false),
  v3Users: z.array(z.lazy(() => V3User$inboundSchema)).optional(),
});
/** @internal */
export type SNMPv3Authentication$Outbound = {
  v3AuthEnabled: boolean;
  allowUnmatchedTrap: boolean;
  v3Users?: Array<V3User$Outbound> | undefined;
};

/** @internal */
export const SNMPv3Authentication$outboundSchema: z.ZodType<
  SNMPv3Authentication$Outbound,
  z.ZodTypeDef,
  SNMPv3Authentication
> = z.object({
  v3AuthEnabled: z.boolean().default(false),
  allowUnmatchedTrap: z.boolean().default(false),
  v3Users: z.array(z.lazy(() => V3User$outboundSchema)).optional(),
});

export function snmPv3AuthenticationToJSON(
  snmPv3Authentication: SNMPv3Authentication,
): string {
  return JSON.stringify(
    SNMPv3Authentication$outboundSchema.parse(snmPv3Authentication),
  );
}
export function snmPv3AuthenticationFromJSON(
  jsonString: string,
): SafeParseResult<SNMPv3Authentication, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SNMPv3Authentication$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SNMPv3Authentication' from JSON`,
  );
}

/** @internal */
export const MetadatumSnmp$inboundSchema: z.ZodType<
  MetadatumSnmp,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSnmp$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSnmp$outboundSchema: z.ZodType<
  MetadatumSnmp$Outbound,
  z.ZodTypeDef,
  MetadatumSnmp
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSnmpToJSON(metadatumSnmp: MetadatumSnmp): string {
  return JSON.stringify(MetadatumSnmp$outboundSchema.parse(metadatumSnmp));
}
export function metadatumSnmpFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSnmp' from JSON`,
  );
}

/** @internal */
export const InputSnmp$inboundSchema: z.ZodType<
  InputSnmp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeSnmp$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSnmp$inboundSchema)).optional(),
    pq: z.lazy(() => PqSnmp$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number().default(162),
    snmpV3Auth: z.lazy(() => SNMPv3Authentication$inboundSchema).optional(),
    maxBufferSize: z.number().default(1000),
    ipWhitelistRegex: z.string().default("/.*/"),
    metadata: z.array(z.lazy(() => MetadatumSnmp$inboundSchema)).optional(),
    udpSocketRxBufSize: z.number().optional(),
    varbindsWithTypes: z.boolean().default(false),
    bestEffortParsing: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSnmp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSnmp$Outbound> | undefined;
  pq?: PqSnmp$Outbound | undefined;
  host: string;
  port: number;
  snmpV3Auth?: SNMPv3Authentication$Outbound | undefined;
  maxBufferSize: number;
  ipWhitelistRegex: string;
  metadata?: Array<MetadatumSnmp$Outbound> | undefined;
  udpSocketRxBufSize?: number | undefined;
  varbindsWithTypes: boolean;
  bestEffortParsing: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSnmp$outboundSchema: z.ZodType<
  InputSnmp$Outbound,
  z.ZodTypeDef,
  InputSnmp
> = z.object({
  id: z.string().optional(),
  type: InputTypeSnmp$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSnmp$outboundSchema)).optional(),
  pq: z.lazy(() => PqSnmp$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number().default(162),
  snmpV3Auth: z.lazy(() => SNMPv3Authentication$outboundSchema).optional(),
  maxBufferSize: z.number().default(1000),
  ipWhitelistRegex: z.string().default("/.*/"),
  metadata: z.array(z.lazy(() => MetadatumSnmp$outboundSchema)).optional(),
  udpSocketRxBufSize: z.number().optional(),
  varbindsWithTypes: z.boolean().default(false),
  bestEffortParsing: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSnmpToJSON(inputSnmp: InputSnmp): string {
  return JSON.stringify(InputSnmp$outboundSchema.parse(inputSnmp));
}
export function inputSnmpFromJSON(
  jsonString: string,
): SafeParseResult<InputSnmp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSnmp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSnmp' from JSON`,
  );
}

/** @internal */
export const TypeS3Inventory$inboundSchema: z.ZodNativeEnum<
  typeof TypeS3Inventory
> = z.nativeEnum(TypeS3Inventory);
/** @internal */
export const TypeS3Inventory$outboundSchema: z.ZodNativeEnum<
  typeof TypeS3Inventory
> = TypeS3Inventory$inboundSchema;

/** @internal */
export const ConnectionS3Inventory$inboundSchema: z.ZodType<
  ConnectionS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionS3Inventory$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionS3Inventory$outboundSchema: z.ZodType<
  ConnectionS3Inventory$Outbound,
  z.ZodTypeDef,
  ConnectionS3Inventory
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionS3InventoryToJSON(
  connectionS3Inventory: ConnectionS3Inventory,
): string {
  return JSON.stringify(
    ConnectionS3Inventory$outboundSchema.parse(connectionS3Inventory),
  );
}
export function connectionS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionS3Inventory' from JSON`,
  );
}

/** @internal */
export const ModeS3Inventory$inboundSchema: z.ZodType<
  ModeS3Inventory,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeS3Inventory),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeS3Inventory$outboundSchema: z.ZodType<
  ModeS3Inventory,
  z.ZodTypeDef,
  ModeS3Inventory
> = z.union([
  z.nativeEnum(ModeS3Inventory),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionS3Inventory$inboundSchema: z.ZodType<
  CompressionS3Inventory,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionS3Inventory),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionS3Inventory$outboundSchema: z.ZodType<
  CompressionS3Inventory,
  z.ZodTypeDef,
  CompressionS3Inventory
> = z.union([
  z.nativeEnum(CompressionS3Inventory),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsS3Inventory$inboundSchema: z.ZodType<
  PqControlsS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsS3Inventory$Outbound = {};

/** @internal */
export const PqControlsS3Inventory$outboundSchema: z.ZodType<
  PqControlsS3Inventory$Outbound,
  z.ZodTypeDef,
  PqControlsS3Inventory
> = z.object({});

export function pqControlsS3InventoryToJSON(
  pqControlsS3Inventory: PqControlsS3Inventory,
): string {
  return JSON.stringify(
    PqControlsS3Inventory$outboundSchema.parse(pqControlsS3Inventory),
  );
}
export function pqControlsS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsS3Inventory' from JSON`,
  );
}

/** @internal */
export const PqS3Inventory$inboundSchema: z.ZodType<
  PqS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeS3Inventory$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionS3Inventory$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsS3Inventory$inboundSchema).optional(),
});
/** @internal */
export type PqS3Inventory$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsS3Inventory$Outbound | undefined;
};

/** @internal */
export const PqS3Inventory$outboundSchema: z.ZodType<
  PqS3Inventory$Outbound,
  z.ZodTypeDef,
  PqS3Inventory
> = z.object({
  mode: ModeS3Inventory$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionS3Inventory$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsS3Inventory$outboundSchema).optional(),
});

export function pqS3InventoryToJSON(pqS3Inventory: PqS3Inventory): string {
  return JSON.stringify(PqS3Inventory$outboundSchema.parse(pqS3Inventory));
}
export function pqS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<PqS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqS3Inventory' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodS3Inventory$inboundSchema: z.ZodType<
  AuthenticationMethodS3Inventory,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodS3Inventory),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodS3Inventory$outboundSchema: z.ZodType<
  AuthenticationMethodS3Inventory,
  z.ZodTypeDef,
  AuthenticationMethodS3Inventory
> = z.union([
  z.nativeEnum(AuthenticationMethodS3Inventory),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionS3Inventory$inboundSchema: z.ZodType<
  SignatureVersionS3Inventory,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionS3Inventory),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionS3Inventory$outboundSchema: z.ZodType<
  SignatureVersionS3Inventory,
  z.ZodTypeDef,
  SignatureVersionS3Inventory
> = z.union([
  z.nativeEnum(SignatureVersionS3Inventory),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PreprocessS3Inventory$inboundSchema: z.ZodType<
  PreprocessS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessS3Inventory$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessS3Inventory$outboundSchema: z.ZodType<
  PreprocessS3Inventory$Outbound,
  z.ZodTypeDef,
  PreprocessS3Inventory
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessS3InventoryToJSON(
  preprocessS3Inventory: PreprocessS3Inventory,
): string {
  return JSON.stringify(
    PreprocessS3Inventory$outboundSchema.parse(preprocessS3Inventory),
  );
}
export function preprocessS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<PreprocessS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessS3Inventory' from JSON`,
  );
}

/** @internal */
export const MetadatumS3Inventory$inboundSchema: z.ZodType<
  MetadatumS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumS3Inventory$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumS3Inventory$outboundSchema: z.ZodType<
  MetadatumS3Inventory$Outbound,
  z.ZodTypeDef,
  MetadatumS3Inventory
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumS3InventoryToJSON(
  metadatumS3Inventory: MetadatumS3Inventory,
): string {
  return JSON.stringify(
    MetadatumS3Inventory$outboundSchema.parse(metadatumS3Inventory),
  );
}
export function metadatumS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumS3Inventory' from JSON`,
  );
}

/** @internal */
export const CheckpointingS3Inventory$inboundSchema: z.ZodType<
  CheckpointingS3Inventory,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});
/** @internal */
export type CheckpointingS3Inventory$Outbound = {
  enabled: boolean;
  retries: number;
};

/** @internal */
export const CheckpointingS3Inventory$outboundSchema: z.ZodType<
  CheckpointingS3Inventory$Outbound,
  z.ZodTypeDef,
  CheckpointingS3Inventory
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});

export function checkpointingS3InventoryToJSON(
  checkpointingS3Inventory: CheckpointingS3Inventory,
): string {
  return JSON.stringify(
    CheckpointingS3Inventory$outboundSchema.parse(checkpointingS3Inventory),
  );
}
export function checkpointingS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<CheckpointingS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CheckpointingS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CheckpointingS3Inventory' from JSON`,
  );
}

/** @internal */
export const TagAfterProcessingS3Inventory$inboundSchema: z.ZodType<
  TagAfterProcessingS3Inventory,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TagAfterProcessingS3Inventory),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TagAfterProcessingS3Inventory$outboundSchema: z.ZodType<
  TagAfterProcessingS3Inventory,
  z.ZodTypeDef,
  TagAfterProcessingS3Inventory
> = z.union([
  z.nativeEnum(TagAfterProcessingS3Inventory),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputS3Inventory$inboundSchema: z.ZodType<
  InputS3Inventory,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeS3Inventory$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionS3Inventory$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqS3Inventory$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    awsAccountId: z.string().optional(),
    awsAuthenticationMethod: AuthenticationMethodS3Inventory$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionS3Inventory$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    maxMessages: z.number().default(1),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    socketTimeout: z.number().default(300),
    skipOnError: z.boolean().default(false),
    includeSqsMetadata: z.boolean().default(false),
    enableAssumeRole: z.boolean().default(true),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    enableSQSAssumeRole: z.boolean().default(false),
    preprocess: z.lazy(() => PreprocessS3Inventory$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumS3Inventory$inboundSchema))
      .optional(),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    checkpointing: z.lazy(() => CheckpointingS3Inventory$inboundSchema)
      .optional(),
    pollTimeout: z.number().default(10),
    checksumSuffix: z.string().default("checksum"),
    maxManifestSizeKB: z.number().int().default(4096),
    validateInventoryFiles: z.boolean().default(false),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    tagAfterProcessing: TagAfterProcessingS3Inventory$inboundSchema.optional(),
    processedTagKey: z.string().optional(),
    processedTagValue: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputS3Inventory$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionS3Inventory$Outbound> | undefined;
  pq?: PqS3Inventory$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  awsAccountId?: string | undefined;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  maxMessages: number;
  visibilityTimeout: number;
  numReceivers: number;
  socketTimeout: number;
  skipOnError: boolean;
  includeSqsMetadata: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  enableSQSAssumeRole: boolean;
  preprocess?: PreprocessS3Inventory$Outbound | undefined;
  metadata?: Array<MetadatumS3Inventory$Outbound> | undefined;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  checkpointing?: CheckpointingS3Inventory$Outbound | undefined;
  pollTimeout: number;
  checksumSuffix: string;
  maxManifestSizeKB: number;
  validateInventoryFiles: boolean;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  tagAfterProcessing?: string | undefined;
  processedTagKey?: string | undefined;
  processedTagValue?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputS3Inventory$outboundSchema: z.ZodType<
  InputS3Inventory$Outbound,
  z.ZodTypeDef,
  InputS3Inventory
> = z.object({
  id: z.string().optional(),
  type: TypeS3Inventory$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionS3Inventory$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqS3Inventory$outboundSchema).optional(),
  queueName: z.string(),
  fileFilter: z.string().default("/.*/"),
  awsAccountId: z.string().optional(),
  awsAuthenticationMethod: AuthenticationMethodS3Inventory$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionS3Inventory$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  maxMessages: z.number().default(1),
  visibilityTimeout: z.number().default(600),
  numReceivers: z.number().default(1),
  socketTimeout: z.number().default(300),
  skipOnError: z.boolean().default(false),
  includeSqsMetadata: z.boolean().default(false),
  enableAssumeRole: z.boolean().default(true),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  enableSQSAssumeRole: z.boolean().default(false),
  preprocess: z.lazy(() => PreprocessS3Inventory$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumS3Inventory$outboundSchema))
    .optional(),
  parquetChunkSizeMB: z.number().default(5),
  parquetChunkDownloadTimeout: z.number().default(600),
  checkpointing: z.lazy(() => CheckpointingS3Inventory$outboundSchema)
    .optional(),
  pollTimeout: z.number().default(10),
  checksumSuffix: z.string().default("checksum"),
  maxManifestSizeKB: z.number().int().default(4096),
  validateInventoryFiles: z.boolean().default(false),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  tagAfterProcessing: TagAfterProcessingS3Inventory$outboundSchema.optional(),
  processedTagKey: z.string().optional(),
  processedTagValue: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputS3InventoryToJSON(
  inputS3Inventory: InputS3Inventory,
): string {
  return JSON.stringify(
    InputS3Inventory$outboundSchema.parse(inputS3Inventory),
  );
}
export function inputS3InventoryFromJSON(
  jsonString: string,
): SafeParseResult<InputS3Inventory, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputS3Inventory$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputS3Inventory' from JSON`,
  );
}

/** @internal */
export const InputTypeS3$inboundSchema: z.ZodNativeEnum<typeof InputTypeS3> = z
  .nativeEnum(InputTypeS3);
/** @internal */
export const InputTypeS3$outboundSchema: z.ZodNativeEnum<typeof InputTypeS3> =
  InputTypeS3$inboundSchema;

/** @internal */
export const ConnectionS3$inboundSchema: z.ZodType<
  ConnectionS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionS3$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionS3$outboundSchema: z.ZodType<
  ConnectionS3$Outbound,
  z.ZodTypeDef,
  ConnectionS3
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionS3ToJSON(connectionS3: ConnectionS3): string {
  return JSON.stringify(ConnectionS3$outboundSchema.parse(connectionS3));
}
export function connectionS3FromJSON(
  jsonString: string,
): SafeParseResult<ConnectionS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionS3' from JSON`,
  );
}

/** @internal */
export const ModeS3$inboundSchema: z.ZodType<ModeS3, z.ZodTypeDef, unknown> = z
  .union([
    z.nativeEnum(ModeS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeS3$outboundSchema: z.ZodType<ModeS3, z.ZodTypeDef, ModeS3> = z
  .union([
    z.nativeEnum(ModeS3),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const PqCompressionS3$inboundSchema: z.ZodType<
  PqCompressionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionS3$outboundSchema: z.ZodType<
  PqCompressionS3,
  z.ZodTypeDef,
  PqCompressionS3
> = z.union([
  z.nativeEnum(PqCompressionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsS3$inboundSchema: z.ZodType<
  PqControlsS3,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsS3$Outbound = {};

/** @internal */
export const PqControlsS3$outboundSchema: z.ZodType<
  PqControlsS3$Outbound,
  z.ZodTypeDef,
  PqControlsS3
> = z.object({});

export function pqControlsS3ToJSON(pqControlsS3: PqControlsS3): string {
  return JSON.stringify(PqControlsS3$outboundSchema.parse(pqControlsS3));
}
export function pqControlsS3FromJSON(
  jsonString: string,
): SafeParseResult<PqControlsS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsS3' from JSON`,
  );
}

/** @internal */
export const PqS3$inboundSchema: z.ZodType<PqS3, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeS3$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionS3$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsS3$inboundSchema).optional(),
  });
/** @internal */
export type PqS3$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsS3$Outbound | undefined;
};

/** @internal */
export const PqS3$outboundSchema: z.ZodType<PqS3$Outbound, z.ZodTypeDef, PqS3> =
  z.object({
    mode: ModeS3$outboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionS3$outboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsS3$outboundSchema).optional(),
  });

export function pqS3ToJSON(pqS3: PqS3): string {
  return JSON.stringify(PqS3$outboundSchema.parse(pqS3));
}
export function pqS3FromJSON(
  jsonString: string,
): SafeParseResult<PqS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqS3' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodS3$inboundSchema: z.ZodType<
  InputAuthenticationMethodS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodS3$outboundSchema: z.ZodType<
  InputAuthenticationMethodS3,
  z.ZodTypeDef,
  InputAuthenticationMethodS3
> = z.union([
  z.nativeEnum(InputAuthenticationMethodS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSignatureVersionS3$inboundSchema: z.ZodType<
  InputSignatureVersionS3,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSignatureVersionS3),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSignatureVersionS3$outboundSchema: z.ZodType<
  InputSignatureVersionS3,
  z.ZodTypeDef,
  InputSignatureVersionS3
> = z.union([
  z.nativeEnum(InputSignatureVersionS3),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PreprocessS3$inboundSchema: z.ZodType<
  PreprocessS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessS3$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessS3$outboundSchema: z.ZodType<
  PreprocessS3$Outbound,
  z.ZodTypeDef,
  PreprocessS3
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessS3ToJSON(preprocessS3: PreprocessS3): string {
  return JSON.stringify(PreprocessS3$outboundSchema.parse(preprocessS3));
}
export function preprocessS3FromJSON(
  jsonString: string,
): SafeParseResult<PreprocessS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessS3' from JSON`,
  );
}

/** @internal */
export const MetadatumS3$inboundSchema: z.ZodType<
  MetadatumS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumS3$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumS3$outboundSchema: z.ZodType<
  MetadatumS3$Outbound,
  z.ZodTypeDef,
  MetadatumS3
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumS3ToJSON(metadatumS3: MetadatumS3): string {
  return JSON.stringify(MetadatumS3$outboundSchema.parse(metadatumS3));
}
export function metadatumS3FromJSON(
  jsonString: string,
): SafeParseResult<MetadatumS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumS3' from JSON`,
  );
}

/** @internal */
export const CheckpointingS3$inboundSchema: z.ZodType<
  CheckpointingS3,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});
/** @internal */
export type CheckpointingS3$Outbound = {
  enabled: boolean;
  retries: number;
};

/** @internal */
export const CheckpointingS3$outboundSchema: z.ZodType<
  CheckpointingS3$Outbound,
  z.ZodTypeDef,
  CheckpointingS3
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});

export function checkpointingS3ToJSON(
  checkpointingS3: CheckpointingS3,
): string {
  return JSON.stringify(CheckpointingS3$outboundSchema.parse(checkpointingS3));
}
export function checkpointingS3FromJSON(
  jsonString: string,
): SafeParseResult<CheckpointingS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CheckpointingS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CheckpointingS3' from JSON`,
  );
}

/** @internal */
export const InputS3$inboundSchema: z.ZodType<InputS3, z.ZodTypeDef, unknown> =
  collectExtraKeys$(
    z.object({
      id: z.string().optional(),
      type: InputTypeS3$inboundSchema,
      disabled: z.boolean().default(false),
      pipeline: z.string().optional(),
      sendToRoutes: z.boolean().default(true),
      environment: z.string().optional(),
      pqEnabled: z.boolean().default(false),
      streamtags: z.array(z.string()).optional(),
      connections: z.array(z.lazy(() => ConnectionS3$inboundSchema)).optional(),
      pq: z.lazy(() => PqS3$inboundSchema).optional(),
      queueName: z.string(),
      fileFilter: z.string().default("/.*/"),
      awsAccountId: z.string().optional(),
      awsAuthenticationMethod: InputAuthenticationMethodS3$inboundSchema
        .default("auto"),
      awsSecretKey: z.string().optional(),
      region: z.string().optional(),
      endpoint: z.string().optional(),
      signatureVersion: InputSignatureVersionS3$inboundSchema.default("v4"),
      reuseConnections: z.boolean().default(true),
      rejectUnauthorized: z.boolean().default(true),
      breakerRulesets: z.array(z.string()).optional(),
      staleChannelFlushMs: z.number().default(10000),
      maxMessages: z.number().default(1),
      visibilityTimeout: z.number().default(600),
      numReceivers: z.number().default(1),
      socketTimeout: z.number().default(300),
      skipOnError: z.boolean().default(false),
      includeSqsMetadata: z.boolean().default(false),
      enableAssumeRole: z.boolean().default(true),
      assumeRoleArn: z.string().optional(),
      assumeRoleExternalId: z.string().optional(),
      durationSeconds: z.number().default(3600),
      enableSQSAssumeRole: z.boolean().default(false),
      preprocess: z.lazy(() => PreprocessS3$inboundSchema).optional(),
      metadata: z.array(z.lazy(() => MetadatumS3$inboundSchema)).optional(),
      parquetChunkSizeMB: z.number().default(5),
      parquetChunkDownloadTimeout: z.number().default(600),
      checkpointing: z.lazy(() => CheckpointingS3$inboundSchema).optional(),
      pollTimeout: z.number().default(10),
      encoding: z.string().optional(),
      tagAfterProcessing: z.boolean().default(false),
      description: z.string().optional(),
      awsApiKey: z.string().optional(),
      awsSecret: z.string().optional(),
      processedTagKey: z.string().optional(),
      processedTagValue: z.string().optional(),
    }).catchall(z.any()),
    "additionalProperties",
    true,
  );
/** @internal */
export type InputS3$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionS3$Outbound> | undefined;
  pq?: PqS3$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  awsAccountId?: string | undefined;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  maxMessages: number;
  visibilityTimeout: number;
  numReceivers: number;
  socketTimeout: number;
  skipOnError: boolean;
  includeSqsMetadata: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  enableSQSAssumeRole: boolean;
  preprocess?: PreprocessS3$Outbound | undefined;
  metadata?: Array<MetadatumS3$Outbound> | undefined;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  checkpointing?: CheckpointingS3$Outbound | undefined;
  pollTimeout: number;
  encoding?: string | undefined;
  tagAfterProcessing: boolean;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  processedTagKey?: string | undefined;
  processedTagValue?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputS3$outboundSchema: z.ZodType<
  InputS3$Outbound,
  z.ZodTypeDef,
  InputS3
> = z.object({
  id: z.string().optional(),
  type: InputTypeS3$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionS3$outboundSchema)).optional(),
  pq: z.lazy(() => PqS3$outboundSchema).optional(),
  queueName: z.string(),
  fileFilter: z.string().default("/.*/"),
  awsAccountId: z.string().optional(),
  awsAuthenticationMethod: InputAuthenticationMethodS3$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: InputSignatureVersionS3$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  maxMessages: z.number().default(1),
  visibilityTimeout: z.number().default(600),
  numReceivers: z.number().default(1),
  socketTimeout: z.number().default(300),
  skipOnError: z.boolean().default(false),
  includeSqsMetadata: z.boolean().default(false),
  enableAssumeRole: z.boolean().default(true),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  enableSQSAssumeRole: z.boolean().default(false),
  preprocess: z.lazy(() => PreprocessS3$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumS3$outboundSchema)).optional(),
  parquetChunkSizeMB: z.number().default(5),
  parquetChunkDownloadTimeout: z.number().default(600),
  checkpointing: z.lazy(() => CheckpointingS3$outboundSchema).optional(),
  pollTimeout: z.number().default(10),
  encoding: z.string().optional(),
  tagAfterProcessing: z.boolean().default(false),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  processedTagKey: z.string().optional(),
  processedTagValue: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputS3ToJSON(inputS3: InputS3): string {
  return JSON.stringify(InputS3$outboundSchema.parse(inputS3));
}
export function inputS3FromJSON(
  jsonString: string,
): SafeParseResult<InputS3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputS3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputS3' from JSON`,
  );
}

/** @internal */
export const TypeMetrics$inboundSchema: z.ZodNativeEnum<typeof TypeMetrics> = z
  .nativeEnum(TypeMetrics);
/** @internal */
export const TypeMetrics$outboundSchema: z.ZodNativeEnum<typeof TypeMetrics> =
  TypeMetrics$inboundSchema;

/** @internal */
export const ConnectionMetrics$inboundSchema: z.ZodType<
  ConnectionMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionMetrics$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionMetrics$outboundSchema: z.ZodType<
  ConnectionMetrics$Outbound,
  z.ZodTypeDef,
  ConnectionMetrics
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionMetricsToJSON(
  connectionMetrics: ConnectionMetrics,
): string {
  return JSON.stringify(
    ConnectionMetrics$outboundSchema.parse(connectionMetrics),
  );
}
export function connectionMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionMetrics' from JSON`,
  );
}

/** @internal */
export const ModeMetrics$inboundSchema: z.ZodType<
  ModeMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeMetrics$outboundSchema: z.ZodType<
  ModeMetrics,
  z.ZodTypeDef,
  ModeMetrics
> = z.union([
  z.nativeEnum(ModeMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionMetrics$inboundSchema: z.ZodType<
  CompressionMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionMetrics$outboundSchema: z.ZodType<
  CompressionMetrics,
  z.ZodTypeDef,
  CompressionMetrics
> = z.union([
  z.nativeEnum(CompressionMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsMetrics$inboundSchema: z.ZodType<
  PqControlsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsMetrics$Outbound = {};

/** @internal */
export const PqControlsMetrics$outboundSchema: z.ZodType<
  PqControlsMetrics$Outbound,
  z.ZodTypeDef,
  PqControlsMetrics
> = z.object({});

export function pqControlsMetricsToJSON(
  pqControlsMetrics: PqControlsMetrics,
): string {
  return JSON.stringify(
    PqControlsMetrics$outboundSchema.parse(pqControlsMetrics),
  );
}
export function pqControlsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsMetrics' from JSON`,
  );
}

/** @internal */
export const PqMetrics$inboundSchema: z.ZodType<
  PqMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeMetrics$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionMetrics$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsMetrics$inboundSchema).optional(),
});
/** @internal */
export type PqMetrics$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsMetrics$Outbound | undefined;
};

/** @internal */
export const PqMetrics$outboundSchema: z.ZodType<
  PqMetrics$Outbound,
  z.ZodTypeDef,
  PqMetrics
> = z.object({
  mode: ModeMetrics$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionMetrics$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsMetrics$outboundSchema).optional(),
});

export function pqMetricsToJSON(pqMetrics: PqMetrics): string {
  return JSON.stringify(PqMetrics$outboundSchema.parse(pqMetrics));
}
export function pqMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqMetrics' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionMetrics$inboundSchema: z.ZodType<
  MinimumTLSVersionMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionMetrics$outboundSchema: z.ZodType<
  MinimumTLSVersionMetrics,
  z.ZodTypeDef,
  MinimumTLSVersionMetrics
> = z.union([
  z.nativeEnum(MinimumTLSVersionMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionMetrics$inboundSchema: z.ZodType<
  MaximumTLSVersionMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionMetrics$outboundSchema: z.ZodType<
  MaximumTLSVersionMetrics,
  z.ZodTypeDef,
  MaximumTLSVersionMetrics
> = z.union([
  z.nativeEnum(MaximumTLSVersionMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideMetrics$inboundSchema: z.ZodType<
  TLSSettingsServerSideMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionMetrics$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionMetrics$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideMetrics$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideMetrics$outboundSchema: z.ZodType<
  TLSSettingsServerSideMetrics$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideMetrics
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionMetrics$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionMetrics$outboundSchema.optional(),
});

export function tlsSettingsServerSideMetricsToJSON(
  tlsSettingsServerSideMetrics: TLSSettingsServerSideMetrics,
): string {
  return JSON.stringify(
    TLSSettingsServerSideMetrics$outboundSchema.parse(
      tlsSettingsServerSideMetrics,
    ),
  );
}
export function tlsSettingsServerSideMetricsFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideMetrics' from JSON`,
  );
}

/** @internal */
export const MetadatumMetrics$inboundSchema: z.ZodType<
  MetadatumMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumMetrics$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumMetrics$outboundSchema: z.ZodType<
  MetadatumMetrics$Outbound,
  z.ZodTypeDef,
  MetadatumMetrics
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumMetricsToJSON(
  metadatumMetrics: MetadatumMetrics,
): string {
  return JSON.stringify(
    MetadatumMetrics$outboundSchema.parse(metadatumMetrics),
  );
}
export function metadatumMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumMetrics' from JSON`,
  );
}

/** @internal */
export const InputMetrics$inboundSchema: z.ZodType<
  InputMetrics,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeMetrics$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionMetrics$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqMetrics$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    udpPort: z.number().optional(),
    tcpPort: z.number().optional(),
    maxBufferSize: z.number().default(1000),
    ipWhitelistRegex: z.string().default("/.*/"),
    enableProxyHeader: z.boolean().default(false),
    tls: z.lazy(() => TLSSettingsServerSideMetrics$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumMetrics$inboundSchema)).optional(),
    udpSocketRxBufSize: z.number().optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputMetrics$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionMetrics$Outbound> | undefined;
  pq?: PqMetrics$Outbound | undefined;
  host: string;
  udpPort?: number | undefined;
  tcpPort?: number | undefined;
  maxBufferSize: number;
  ipWhitelistRegex: string;
  enableProxyHeader: boolean;
  tls?: TLSSettingsServerSideMetrics$Outbound | undefined;
  metadata?: Array<MetadatumMetrics$Outbound> | undefined;
  udpSocketRxBufSize?: number | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputMetrics$outboundSchema: z.ZodType<
  InputMetrics$Outbound,
  z.ZodTypeDef,
  InputMetrics
> = z.object({
  id: z.string().optional(),
  type: TypeMetrics$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionMetrics$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqMetrics$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  udpPort: z.number().optional(),
  tcpPort: z.number().optional(),
  maxBufferSize: z.number().default(1000),
  ipWhitelistRegex: z.string().default("/.*/"),
  enableProxyHeader: z.boolean().default(false),
  tls: z.lazy(() => TLSSettingsServerSideMetrics$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumMetrics$outboundSchema)).optional(),
  udpSocketRxBufSize: z.number().optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputMetricsToJSON(inputMetrics: InputMetrics): string {
  return JSON.stringify(InputMetrics$outboundSchema.parse(inputMetrics));
}
export function inputMetricsFromJSON(
  jsonString: string,
): SafeParseResult<InputMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputMetrics' from JSON`,
  );
}

/** @internal */
export const TypeCriblmetrics$inboundSchema: z.ZodNativeEnum<
  typeof TypeCriblmetrics
> = z.nativeEnum(TypeCriblmetrics);
/** @internal */
export const TypeCriblmetrics$outboundSchema: z.ZodNativeEnum<
  typeof TypeCriblmetrics
> = TypeCriblmetrics$inboundSchema;

/** @internal */
export const ConnectionCriblmetrics$inboundSchema: z.ZodType<
  ConnectionCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCriblmetrics$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCriblmetrics$outboundSchema: z.ZodType<
  ConnectionCriblmetrics$Outbound,
  z.ZodTypeDef,
  ConnectionCriblmetrics
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCriblmetricsToJSON(
  connectionCriblmetrics: ConnectionCriblmetrics,
): string {
  return JSON.stringify(
    ConnectionCriblmetrics$outboundSchema.parse(connectionCriblmetrics),
  );
}
export function connectionCriblmetricsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCriblmetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCriblmetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCriblmetrics' from JSON`,
  );
}

/** @internal */
export const ModeCriblmetrics$inboundSchema: z.ZodType<
  ModeCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCriblmetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCriblmetrics$outboundSchema: z.ZodType<
  ModeCriblmetrics,
  z.ZodTypeDef,
  ModeCriblmetrics
> = z.union([
  z.nativeEnum(ModeCriblmetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCriblmetrics$inboundSchema: z.ZodType<
  CompressionCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCriblmetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCriblmetrics$outboundSchema: z.ZodType<
  CompressionCriblmetrics,
  z.ZodTypeDef,
  CompressionCriblmetrics
> = z.union([
  z.nativeEnum(CompressionCriblmetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCriblmetrics$inboundSchema: z.ZodType<
  PqControlsCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCriblmetrics$Outbound = {};

/** @internal */
export const PqControlsCriblmetrics$outboundSchema: z.ZodType<
  PqControlsCriblmetrics$Outbound,
  z.ZodTypeDef,
  PqControlsCriblmetrics
> = z.object({});

export function pqControlsCriblmetricsToJSON(
  pqControlsCriblmetrics: PqControlsCriblmetrics,
): string {
  return JSON.stringify(
    PqControlsCriblmetrics$outboundSchema.parse(pqControlsCriblmetrics),
  );
}
export function pqControlsCriblmetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCriblmetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCriblmetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCriblmetrics' from JSON`,
  );
}

/** @internal */
export const PqCriblmetrics$inboundSchema: z.ZodType<
  PqCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeCriblmetrics$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCriblmetrics$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCriblmetrics$inboundSchema).optional(),
});
/** @internal */
export type PqCriblmetrics$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCriblmetrics$Outbound | undefined;
};

/** @internal */
export const PqCriblmetrics$outboundSchema: z.ZodType<
  PqCriblmetrics$Outbound,
  z.ZodTypeDef,
  PqCriblmetrics
> = z.object({
  mode: ModeCriblmetrics$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCriblmetrics$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCriblmetrics$outboundSchema).optional(),
});

export function pqCriblmetricsToJSON(pqCriblmetrics: PqCriblmetrics): string {
  return JSON.stringify(PqCriblmetrics$outboundSchema.parse(pqCriblmetrics));
}
export function pqCriblmetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqCriblmetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCriblmetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCriblmetrics' from JSON`,
  );
}

/** @internal */
export const MetadatumCriblmetrics$inboundSchema: z.ZodType<
  MetadatumCriblmetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCriblmetrics$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCriblmetrics$outboundSchema: z.ZodType<
  MetadatumCriblmetrics$Outbound,
  z.ZodTypeDef,
  MetadatumCriblmetrics
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCriblmetricsToJSON(
  metadatumCriblmetrics: MetadatumCriblmetrics,
): string {
  return JSON.stringify(
    MetadatumCriblmetrics$outboundSchema.parse(metadatumCriblmetrics),
  );
}
export function metadatumCriblmetricsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCriblmetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCriblmetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCriblmetrics' from JSON`,
  );
}

/** @internal */
export const InputCriblmetrics$inboundSchema: z.ZodType<
  InputCriblmetrics,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCriblmetrics$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCriblmetrics$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCriblmetrics$inboundSchema).optional(),
    prefix: z.string().default("cribl.logstream."),
    fullFidelity: z.boolean().default(true),
    metadata: z.array(z.lazy(() => MetadatumCriblmetrics$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCriblmetrics$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCriblmetrics$Outbound> | undefined;
  pq?: PqCriblmetrics$Outbound | undefined;
  prefix: string;
  fullFidelity: boolean;
  metadata?: Array<MetadatumCriblmetrics$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCriblmetrics$outboundSchema: z.ZodType<
  InputCriblmetrics$Outbound,
  z.ZodTypeDef,
  InputCriblmetrics
> = z.object({
  id: z.string().optional(),
  type: TypeCriblmetrics$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCriblmetrics$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCriblmetrics$outboundSchema).optional(),
  prefix: z.string().default("cribl.logstream."),
  fullFidelity: z.boolean().default(true),
  metadata: z.array(z.lazy(() => MetadatumCriblmetrics$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCriblmetricsToJSON(
  inputCriblmetrics: InputCriblmetrics,
): string {
  return JSON.stringify(
    InputCriblmetrics$outboundSchema.parse(inputCriblmetrics),
  );
}
export function inputCriblmetricsFromJSON(
  jsonString: string,
): SafeParseResult<InputCriblmetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCriblmetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCriblmetrics' from JSON`,
  );
}

/** @internal */
export const InputTypeKinesis$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeKinesis
> = z.nativeEnum(InputTypeKinesis);
/** @internal */
export const InputTypeKinesis$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeKinesis
> = InputTypeKinesis$inboundSchema;

/** @internal */
export const ConnectionKinesis$inboundSchema: z.ZodType<
  ConnectionKinesis,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionKinesis$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionKinesis$outboundSchema: z.ZodType<
  ConnectionKinesis$Outbound,
  z.ZodTypeDef,
  ConnectionKinesis
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionKinesisToJSON(
  connectionKinesis: ConnectionKinesis,
): string {
  return JSON.stringify(
    ConnectionKinesis$outboundSchema.parse(connectionKinesis),
  );
}
export function connectionKinesisFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionKinesis' from JSON`,
  );
}

/** @internal */
export const PqModeKinesis$inboundSchema: z.ZodType<
  PqModeKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeKinesis$outboundSchema: z.ZodType<
  PqModeKinesis,
  z.ZodTypeDef,
  PqModeKinesis
> = z.union([
  z.nativeEnum(PqModeKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionKinesis$inboundSchema: z.ZodType<
  PqCompressionKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionKinesis$outboundSchema: z.ZodType<
  PqCompressionKinesis,
  z.ZodTypeDef,
  PqCompressionKinesis
> = z.union([
  z.nativeEnum(PqCompressionKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsKinesis$inboundSchema: z.ZodType<
  InputPqControlsKinesis,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsKinesis$Outbound = {};

/** @internal */
export const InputPqControlsKinesis$outboundSchema: z.ZodType<
  InputPqControlsKinesis$Outbound,
  z.ZodTypeDef,
  InputPqControlsKinesis
> = z.object({});

export function inputPqControlsKinesisToJSON(
  inputPqControlsKinesis: InputPqControlsKinesis,
): string {
  return JSON.stringify(
    InputPqControlsKinesis$outboundSchema.parse(inputPqControlsKinesis),
  );
}
export function inputPqControlsKinesisFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsKinesis' from JSON`,
  );
}

/** @internal */
export const PqKinesis$inboundSchema: z.ZodType<
  PqKinesis,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeKinesis$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionKinesis$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsKinesis$inboundSchema).optional(),
});
/** @internal */
export type PqKinesis$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsKinesis$Outbound | undefined;
};

/** @internal */
export const PqKinesis$outboundSchema: z.ZodType<
  PqKinesis$Outbound,
  z.ZodTypeDef,
  PqKinesis
> = z.object({
  mode: PqModeKinesis$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionKinesis$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsKinesis$outboundSchema).optional(),
});

export function pqKinesisToJSON(pqKinesis: PqKinesis): string {
  return JSON.stringify(PqKinesis$outboundSchema.parse(pqKinesis));
}
export function pqKinesisFromJSON(
  jsonString: string,
): SafeParseResult<PqKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqKinesis' from JSON`,
  );
}

/** @internal */
export const ShardIteratorStart$inboundSchema: z.ZodType<
  ShardIteratorStart,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ShardIteratorStart),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ShardIteratorStart$outboundSchema: z.ZodType<
  ShardIteratorStart,
  z.ZodTypeDef,
  ShardIteratorStart
> = z.union([
  z.nativeEnum(ShardIteratorStart),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputRecordDataFormat$inboundSchema: z.ZodType<
  InputRecordDataFormat,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputRecordDataFormat),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputRecordDataFormat$outboundSchema: z.ZodType<
  InputRecordDataFormat,
  z.ZodTypeDef,
  InputRecordDataFormat
> = z.union([
  z.nativeEnum(InputRecordDataFormat),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ShardLoadBalancing$inboundSchema: z.ZodType<
  ShardLoadBalancing,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ShardLoadBalancing),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ShardLoadBalancing$outboundSchema: z.ZodType<
  ShardLoadBalancing,
  z.ZodTypeDef,
  ShardLoadBalancing
> = z.union([
  z.nativeEnum(ShardLoadBalancing),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputAuthenticationMethodKinesis$inboundSchema: z.ZodType<
  InputAuthenticationMethodKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodKinesis$outboundSchema: z.ZodType<
  InputAuthenticationMethodKinesis,
  z.ZodTypeDef,
  InputAuthenticationMethodKinesis
> = z.union([
  z.nativeEnum(InputAuthenticationMethodKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSignatureVersionKinesis$inboundSchema: z.ZodType<
  InputSignatureVersionKinesis,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSignatureVersionKinesis),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSignatureVersionKinesis$outboundSchema: z.ZodType<
  InputSignatureVersionKinesis,
  z.ZodTypeDef,
  InputSignatureVersionKinesis
> = z.union([
  z.nativeEnum(InputSignatureVersionKinesis),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumKinesis$inboundSchema: z.ZodType<
  MetadatumKinesis,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumKinesis$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumKinesis$outboundSchema: z.ZodType<
  MetadatumKinesis$Outbound,
  z.ZodTypeDef,
  MetadatumKinesis
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumKinesisToJSON(
  metadatumKinesis: MetadatumKinesis,
): string {
  return JSON.stringify(
    MetadatumKinesis$outboundSchema.parse(metadatumKinesis),
  );
}
export function metadatumKinesisFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumKinesis' from JSON`,
  );
}

/** @internal */
export const InputKinesis$inboundSchema: z.ZodType<
  InputKinesis,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeKinesis$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionKinesis$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqKinesis$inboundSchema).optional(),
    streamName: z.string(),
    serviceInterval: z.number().default(1),
    shardExpr: z.string().default("true"),
    shardIteratorType: ShardIteratorStart$inboundSchema.default("TRIM_HORIZON"),
    payloadFormat: InputRecordDataFormat$inboundSchema.default("cribl"),
    getRecordsLimit: z.number().default(5000),
    getRecordsLimitTotal: z.number().default(20000),
    loadBalancingAlgorithm: ShardLoadBalancing$inboundSchema.default(
      "ConsistentHashing",
    ),
    awsAuthenticationMethod: InputAuthenticationMethodKinesis$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string(),
    endpoint: z.string().optional(),
    signatureVersion: InputSignatureVersionKinesis$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    verifyKPLCheckSums: z.boolean().default(false),
    avoidDuplicates: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumKinesis$inboundSchema)).optional(),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputKinesis$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionKinesis$Outbound> | undefined;
  pq?: PqKinesis$Outbound | undefined;
  streamName: string;
  serviceInterval: number;
  shardExpr: string;
  shardIteratorType: string;
  payloadFormat: string;
  getRecordsLimit: number;
  getRecordsLimitTotal: number;
  loadBalancingAlgorithm: string;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  verifyKPLCheckSums: boolean;
  avoidDuplicates: boolean;
  metadata?: Array<MetadatumKinesis$Outbound> | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputKinesis$outboundSchema: z.ZodType<
  InputKinesis$Outbound,
  z.ZodTypeDef,
  InputKinesis
> = z.object({
  id: z.string().optional(),
  type: InputTypeKinesis$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionKinesis$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqKinesis$outboundSchema).optional(),
  streamName: z.string(),
  serviceInterval: z.number().default(1),
  shardExpr: z.string().default("true"),
  shardIteratorType: ShardIteratorStart$outboundSchema.default("TRIM_HORIZON"),
  payloadFormat: InputRecordDataFormat$outboundSchema.default("cribl"),
  getRecordsLimit: z.number().default(5000),
  getRecordsLimitTotal: z.number().default(20000),
  loadBalancingAlgorithm: ShardLoadBalancing$outboundSchema.default(
    "ConsistentHashing",
  ),
  awsAuthenticationMethod: InputAuthenticationMethodKinesis$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string(),
  endpoint: z.string().optional(),
  signatureVersion: InputSignatureVersionKinesis$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  verifyKPLCheckSums: z.boolean().default(false),
  avoidDuplicates: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumKinesis$outboundSchema)).optional(),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputKinesisToJSON(inputKinesis: InputKinesis): string {
  return JSON.stringify(InputKinesis$outboundSchema.parse(inputKinesis));
}
export function inputKinesisFromJSON(
  jsonString: string,
): SafeParseResult<InputKinesis, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKinesis$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKinesis' from JSON`,
  );
}

/** @internal */
export const TypeHTTPRaw$inboundSchema: z.ZodNativeEnum<typeof TypeHTTPRaw> = z
  .nativeEnum(TypeHTTPRaw);
/** @internal */
export const TypeHTTPRaw$outboundSchema: z.ZodNativeEnum<typeof TypeHTTPRaw> =
  TypeHTTPRaw$inboundSchema;

/** @internal */
export const ConnectionHTTPRaw$inboundSchema: z.ZodType<
  ConnectionHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionHTTPRaw$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionHTTPRaw$outboundSchema: z.ZodType<
  ConnectionHTTPRaw$Outbound,
  z.ZodTypeDef,
  ConnectionHTTPRaw
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionHTTPRawToJSON(
  connectionHTTPRaw: ConnectionHTTPRaw,
): string {
  return JSON.stringify(
    ConnectionHTTPRaw$outboundSchema.parse(connectionHTTPRaw),
  );
}
export function connectionHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionHTTPRaw' from JSON`,
  );
}

/** @internal */
export const ModeHTTPRaw$inboundSchema: z.ZodType<
  ModeHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeHTTPRaw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeHTTPRaw$outboundSchema: z.ZodType<
  ModeHTTPRaw,
  z.ZodTypeDef,
  ModeHTTPRaw
> = z.union([
  z.nativeEnum(ModeHTTPRaw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionHTTPRaw$inboundSchema: z.ZodType<
  CompressionHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionHTTPRaw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionHTTPRaw$outboundSchema: z.ZodType<
  CompressionHTTPRaw,
  z.ZodTypeDef,
  CompressionHTTPRaw
> = z.union([
  z.nativeEnum(CompressionHTTPRaw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsHTTPRaw$inboundSchema: z.ZodType<
  PqControlsHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsHTTPRaw$Outbound = {};

/** @internal */
export const PqControlsHTTPRaw$outboundSchema: z.ZodType<
  PqControlsHTTPRaw$Outbound,
  z.ZodTypeDef,
  PqControlsHTTPRaw
> = z.object({});

export function pqControlsHTTPRawToJSON(
  pqControlsHTTPRaw: PqControlsHTTPRaw,
): string {
  return JSON.stringify(
    PqControlsHTTPRaw$outboundSchema.parse(pqControlsHTTPRaw),
  );
}
export function pqControlsHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsHTTPRaw' from JSON`,
  );
}

/** @internal */
export const PqHTTPRaw$inboundSchema: z.ZodType<
  PqHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeHTTPRaw$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionHTTPRaw$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsHTTPRaw$inboundSchema).optional(),
});
/** @internal */
export type PqHTTPRaw$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsHTTPRaw$Outbound | undefined;
};

/** @internal */
export const PqHTTPRaw$outboundSchema: z.ZodType<
  PqHTTPRaw$Outbound,
  z.ZodTypeDef,
  PqHTTPRaw
> = z.object({
  mode: ModeHTTPRaw$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionHTTPRaw$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsHTTPRaw$outboundSchema).optional(),
});

export function pqHTTPRawToJSON(pqHTTPRaw: PqHTTPRaw): string {
  return JSON.stringify(PqHTTPRaw$outboundSchema.parse(pqHTTPRaw));
}
export function pqHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<PqHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqHTTPRaw' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionHTTPRaw$inboundSchema: z.ZodType<
  MinimumTLSVersionHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionHTTPRaw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionHTTPRaw$outboundSchema: z.ZodType<
  MinimumTLSVersionHTTPRaw,
  z.ZodTypeDef,
  MinimumTLSVersionHTTPRaw
> = z.union([
  z.nativeEnum(MinimumTLSVersionHTTPRaw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionHTTPRaw$inboundSchema: z.ZodType<
  MaximumTLSVersionHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionHTTPRaw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionHTTPRaw$outboundSchema: z.ZodType<
  MaximumTLSVersionHTTPRaw,
  z.ZodTypeDef,
  MaximumTLSVersionHTTPRaw
> = z.union([
  z.nativeEnum(MaximumTLSVersionHTTPRaw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideHTTPRaw$inboundSchema: z.ZodType<
  TLSSettingsServerSideHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionHTTPRaw$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionHTTPRaw$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideHTTPRaw$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideHTTPRaw$outboundSchema: z.ZodType<
  TLSSettingsServerSideHTTPRaw$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideHTTPRaw
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionHTTPRaw$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionHTTPRaw$outboundSchema.optional(),
});

export function tlsSettingsServerSideHTTPRawToJSON(
  tlsSettingsServerSideHTTPRaw: TLSSettingsServerSideHTTPRaw,
): string {
  return JSON.stringify(
    TLSSettingsServerSideHTTPRaw$outboundSchema.parse(
      tlsSettingsServerSideHTTPRaw,
    ),
  );
}
export function tlsSettingsServerSideHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideHTTPRaw' from JSON`,
  );
}

/** @internal */
export const MetadatumHTTPRaw$inboundSchema: z.ZodType<
  MetadatumHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumHTTPRaw$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumHTTPRaw$outboundSchema: z.ZodType<
  MetadatumHTTPRaw$Outbound,
  z.ZodTypeDef,
  MetadatumHTTPRaw
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumHTTPRawToJSON(
  metadatumHTTPRaw: MetadatumHTTPRaw,
): string {
  return JSON.stringify(
    MetadatumHTTPRaw$outboundSchema.parse(metadatumHTTPRaw),
  );
}
export function metadatumHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumHTTPRaw' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtMetadatumHTTPRaw$inboundSchema: z.ZodType<
  AuthTokensExtMetadatumHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokensExtMetadatumHTTPRaw$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokensExtMetadatumHTTPRaw$outboundSchema: z.ZodType<
  AuthTokensExtMetadatumHTTPRaw$Outbound,
  z.ZodTypeDef,
  AuthTokensExtMetadatumHTTPRaw
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokensExtMetadatumHTTPRawToJSON(
  authTokensExtMetadatumHTTPRaw: AuthTokensExtMetadatumHTTPRaw,
): string {
  return JSON.stringify(
    AuthTokensExtMetadatumHTTPRaw$outboundSchema.parse(
      authTokensExtMetadatumHTTPRaw,
    ),
  );
}
export function authTokensExtMetadatumHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtMetadatumHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtMetadatumHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtMetadatumHTTPRaw' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtHTTPRaw$inboundSchema: z.ZodType<
  AuthTokensExtHTTPRaw,
  z.ZodTypeDef,
  unknown
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(z.lazy(() => AuthTokensExtMetadatumHTTPRaw$inboundSchema))
    .optional(),
});
/** @internal */
export type AuthTokensExtHTTPRaw$Outbound = {
  token: string;
  description?: string | undefined;
  metadata?: Array<AuthTokensExtMetadatumHTTPRaw$Outbound> | undefined;
};

/** @internal */
export const AuthTokensExtHTTPRaw$outboundSchema: z.ZodType<
  AuthTokensExtHTTPRaw$Outbound,
  z.ZodTypeDef,
  AuthTokensExtHTTPRaw
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(z.lazy(() => AuthTokensExtMetadatumHTTPRaw$outboundSchema))
    .optional(),
});

export function authTokensExtHTTPRawToJSON(
  authTokensExtHTTPRaw: AuthTokensExtHTTPRaw,
): string {
  return JSON.stringify(
    AuthTokensExtHTTPRaw$outboundSchema.parse(authTokensExtHTTPRaw),
  );
}
export function authTokensExtHTTPRawFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtHTTPRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtHTTPRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtHTTPRaw' from JSON`,
  );
}

/** @internal */
export const InputHttpRaw$inboundSchema: z.ZodType<
  InputHttpRaw,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeHTTPRaw$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionHTTPRaw$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqHTTPRaw$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.string()).optional(),
    tls: z.lazy(() => TLSSettingsServerSideHTTPRaw$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    metadata: z.array(z.lazy(() => MetadatumHTTPRaw$inboundSchema)).optional(),
    allowedPaths: z.array(z.string()).optional(),
    allowedMethods: z.array(z.string()).optional(),
    authTokensExt: z.array(z.lazy(() => AuthTokensExtHTTPRaw$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputHttpRaw$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionHTTPRaw$Outbound> | undefined;
  pq?: PqHTTPRaw$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideHTTPRaw$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  metadata?: Array<MetadatumHTTPRaw$Outbound> | undefined;
  allowedPaths?: Array<string> | undefined;
  allowedMethods?: Array<string> | undefined;
  authTokensExt?: Array<AuthTokensExtHTTPRaw$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputHttpRaw$outboundSchema: z.ZodType<
  InputHttpRaw$Outbound,
  z.ZodTypeDef,
  InputHttpRaw
> = z.object({
  id: z.string().optional(),
  type: TypeHTTPRaw$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionHTTPRaw$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqHTTPRaw$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.string()).optional(),
  tls: z.lazy(() => TLSSettingsServerSideHTTPRaw$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  metadata: z.array(z.lazy(() => MetadatumHTTPRaw$outboundSchema)).optional(),
  allowedPaths: z.array(z.string()).optional(),
  allowedMethods: z.array(z.string()).optional(),
  authTokensExt: z.array(z.lazy(() => AuthTokensExtHTTPRaw$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputHttpRawToJSON(inputHttpRaw: InputHttpRaw): string {
  return JSON.stringify(InputHttpRaw$outboundSchema.parse(inputHttpRaw));
}
export function inputHttpRawFromJSON(
  jsonString: string,
): SafeParseResult<InputHttpRaw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputHttpRaw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputHttpRaw' from JSON`,
  );
}

/** @internal */
export const TypeDatagen$inboundSchema: z.ZodNativeEnum<typeof TypeDatagen> = z
  .nativeEnum(TypeDatagen);
/** @internal */
export const TypeDatagen$outboundSchema: z.ZodNativeEnum<typeof TypeDatagen> =
  TypeDatagen$inboundSchema;

/** @internal */
export const ConnectionDatagen$inboundSchema: z.ZodType<
  ConnectionDatagen,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionDatagen$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionDatagen$outboundSchema: z.ZodType<
  ConnectionDatagen$Outbound,
  z.ZodTypeDef,
  ConnectionDatagen
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionDatagenToJSON(
  connectionDatagen: ConnectionDatagen,
): string {
  return JSON.stringify(
    ConnectionDatagen$outboundSchema.parse(connectionDatagen),
  );
}
export function connectionDatagenFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionDatagen, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionDatagen$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionDatagen' from JSON`,
  );
}

/** @internal */
export const ModeDatagen$inboundSchema: z.ZodType<
  ModeDatagen,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDatagen),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDatagen$outboundSchema: z.ZodType<
  ModeDatagen,
  z.ZodTypeDef,
  ModeDatagen
> = z.union([
  z.nativeEnum(ModeDatagen),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDatagen$inboundSchema: z.ZodType<
  CompressionDatagen,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDatagen),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDatagen$outboundSchema: z.ZodType<
  CompressionDatagen,
  z.ZodTypeDef,
  CompressionDatagen
> = z.union([
  z.nativeEnum(CompressionDatagen),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDatagen$inboundSchema: z.ZodType<
  PqControlsDatagen,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDatagen$Outbound = {};

/** @internal */
export const PqControlsDatagen$outboundSchema: z.ZodType<
  PqControlsDatagen$Outbound,
  z.ZodTypeDef,
  PqControlsDatagen
> = z.object({});

export function pqControlsDatagenToJSON(
  pqControlsDatagen: PqControlsDatagen,
): string {
  return JSON.stringify(
    PqControlsDatagen$outboundSchema.parse(pqControlsDatagen),
  );
}
export function pqControlsDatagenFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDatagen, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDatagen$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDatagen' from JSON`,
  );
}

/** @internal */
export const PqDatagen$inboundSchema: z.ZodType<
  PqDatagen,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeDatagen$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionDatagen$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsDatagen$inboundSchema).optional(),
});
/** @internal */
export type PqDatagen$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsDatagen$Outbound | undefined;
};

/** @internal */
export const PqDatagen$outboundSchema: z.ZodType<
  PqDatagen$Outbound,
  z.ZodTypeDef,
  PqDatagen
> = z.object({
  mode: ModeDatagen$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionDatagen$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsDatagen$outboundSchema).optional(),
});

export function pqDatagenToJSON(pqDatagen: PqDatagen): string {
  return JSON.stringify(PqDatagen$outboundSchema.parse(pqDatagen));
}
export function pqDatagenFromJSON(
  jsonString: string,
): SafeParseResult<PqDatagen, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqDatagen$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqDatagen' from JSON`,
  );
}

/** @internal */
export const Sample$inboundSchema: z.ZodType<Sample, z.ZodTypeDef, unknown> = z
  .object({
    sample: z.string(),
    eventsPerSec: z.number().default(10),
  });
/** @internal */
export type Sample$Outbound = {
  sample: string;
  eventsPerSec: number;
};

/** @internal */
export const Sample$outboundSchema: z.ZodType<
  Sample$Outbound,
  z.ZodTypeDef,
  Sample
> = z.object({
  sample: z.string(),
  eventsPerSec: z.number().default(10),
});

export function sampleToJSON(sample: Sample): string {
  return JSON.stringify(Sample$outboundSchema.parse(sample));
}
export function sampleFromJSON(
  jsonString: string,
): SafeParseResult<Sample, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Sample$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Sample' from JSON`,
  );
}

/** @internal */
export const MetadatumDatagen$inboundSchema: z.ZodType<
  MetadatumDatagen,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumDatagen$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumDatagen$outboundSchema: z.ZodType<
  MetadatumDatagen$Outbound,
  z.ZodTypeDef,
  MetadatumDatagen
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumDatagenToJSON(
  metadatumDatagen: MetadatumDatagen,
): string {
  return JSON.stringify(
    MetadatumDatagen$outboundSchema.parse(metadatumDatagen),
  );
}
export function metadatumDatagenFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumDatagen, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumDatagen$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumDatagen' from JSON`,
  );
}

/** @internal */
export const InputDatagen$inboundSchema: z.ZodType<
  InputDatagen,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDatagen$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionDatagen$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqDatagen$inboundSchema).optional(),
    samples: z.array(z.lazy(() => Sample$inboundSchema)),
    metadata: z.array(z.lazy(() => MetadatumDatagen$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputDatagen$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionDatagen$Outbound> | undefined;
  pq?: PqDatagen$Outbound | undefined;
  samples: Array<Sample$Outbound>;
  metadata?: Array<MetadatumDatagen$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputDatagen$outboundSchema: z.ZodType<
  InputDatagen$Outbound,
  z.ZodTypeDef,
  InputDatagen
> = z.object({
  id: z.string().optional(),
  type: TypeDatagen$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionDatagen$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqDatagen$outboundSchema).optional(),
  samples: z.array(z.lazy(() => Sample$outboundSchema)),
  metadata: z.array(z.lazy(() => MetadatumDatagen$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputDatagenToJSON(inputDatagen: InputDatagen): string {
  return JSON.stringify(InputDatagen$outboundSchema.parse(inputDatagen));
}
export function inputDatagenFromJSON(
  jsonString: string,
): SafeParseResult<InputDatagen, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputDatagen$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputDatagen' from JSON`,
  );
}

/** @internal */
export const TypeDatadogAgent$inboundSchema: z.ZodNativeEnum<
  typeof TypeDatadogAgent
> = z.nativeEnum(TypeDatadogAgent);
/** @internal */
export const TypeDatadogAgent$outboundSchema: z.ZodNativeEnum<
  typeof TypeDatadogAgent
> = TypeDatadogAgent$inboundSchema;

/** @internal */
export const ConnectionDatadogAgent$inboundSchema: z.ZodType<
  ConnectionDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionDatadogAgent$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionDatadogAgent$outboundSchema: z.ZodType<
  ConnectionDatadogAgent$Outbound,
  z.ZodTypeDef,
  ConnectionDatadogAgent
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionDatadogAgentToJSON(
  connectionDatadogAgent: ConnectionDatadogAgent,
): string {
  return JSON.stringify(
    ConnectionDatadogAgent$outboundSchema.parse(connectionDatadogAgent),
  );
}
export function connectionDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionDatadogAgent' from JSON`,
  );
}

/** @internal */
export const ModeDatadogAgent$inboundSchema: z.ZodType<
  ModeDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeDatadogAgent),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeDatadogAgent$outboundSchema: z.ZodType<
  ModeDatadogAgent,
  z.ZodTypeDef,
  ModeDatadogAgent
> = z.union([
  z.nativeEnum(ModeDatadogAgent),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionDatadogAgent$inboundSchema: z.ZodType<
  CompressionDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionDatadogAgent),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionDatadogAgent$outboundSchema: z.ZodType<
  CompressionDatadogAgent,
  z.ZodTypeDef,
  CompressionDatadogAgent
> = z.union([
  z.nativeEnum(CompressionDatadogAgent),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsDatadogAgent$inboundSchema: z.ZodType<
  PqControlsDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsDatadogAgent$Outbound = {};

/** @internal */
export const PqControlsDatadogAgent$outboundSchema: z.ZodType<
  PqControlsDatadogAgent$Outbound,
  z.ZodTypeDef,
  PqControlsDatadogAgent
> = z.object({});

export function pqControlsDatadogAgentToJSON(
  pqControlsDatadogAgent: PqControlsDatadogAgent,
): string {
  return JSON.stringify(
    PqControlsDatadogAgent$outboundSchema.parse(pqControlsDatadogAgent),
  );
}
export function pqControlsDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsDatadogAgent' from JSON`,
  );
}

/** @internal */
export const PqDatadogAgent$inboundSchema: z.ZodType<
  PqDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeDatadogAgent$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionDatadogAgent$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsDatadogAgent$inboundSchema).optional(),
});
/** @internal */
export type PqDatadogAgent$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsDatadogAgent$Outbound | undefined;
};

/** @internal */
export const PqDatadogAgent$outboundSchema: z.ZodType<
  PqDatadogAgent$Outbound,
  z.ZodTypeDef,
  PqDatadogAgent
> = z.object({
  mode: ModeDatadogAgent$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionDatadogAgent$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsDatadogAgent$outboundSchema).optional(),
});

export function pqDatadogAgentToJSON(pqDatadogAgent: PqDatadogAgent): string {
  return JSON.stringify(PqDatadogAgent$outboundSchema.parse(pqDatadogAgent));
}
export function pqDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<PqDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqDatadogAgent' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionDatadogAgent$inboundSchema: z.ZodType<
  MinimumTLSVersionDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionDatadogAgent),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionDatadogAgent$outboundSchema: z.ZodType<
  MinimumTLSVersionDatadogAgent,
  z.ZodTypeDef,
  MinimumTLSVersionDatadogAgent
> = z.union([
  z.nativeEnum(MinimumTLSVersionDatadogAgent),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionDatadogAgent$inboundSchema: z.ZodType<
  MaximumTLSVersionDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionDatadogAgent),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionDatadogAgent$outboundSchema: z.ZodType<
  MaximumTLSVersionDatadogAgent,
  z.ZodTypeDef,
  MaximumTLSVersionDatadogAgent
> = z.union([
  z.nativeEnum(MaximumTLSVersionDatadogAgent),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideDatadogAgent$inboundSchema: z.ZodType<
  TLSSettingsServerSideDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionDatadogAgent$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionDatadogAgent$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideDatadogAgent$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideDatadogAgent$outboundSchema: z.ZodType<
  TLSSettingsServerSideDatadogAgent$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideDatadogAgent
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionDatadogAgent$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionDatadogAgent$outboundSchema.optional(),
});

export function tlsSettingsServerSideDatadogAgentToJSON(
  tlsSettingsServerSideDatadogAgent: TLSSettingsServerSideDatadogAgent,
): string {
  return JSON.stringify(
    TLSSettingsServerSideDatadogAgent$outboundSchema.parse(
      tlsSettingsServerSideDatadogAgent,
    ),
  );
}
export function tlsSettingsServerSideDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideDatadogAgent' from JSON`,
  );
}

/** @internal */
export const MetadatumDatadogAgent$inboundSchema: z.ZodType<
  MetadatumDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumDatadogAgent$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumDatadogAgent$outboundSchema: z.ZodType<
  MetadatumDatadogAgent$Outbound,
  z.ZodTypeDef,
  MetadatumDatadogAgent
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumDatadogAgentToJSON(
  metadatumDatadogAgent: MetadatumDatadogAgent,
): string {
  return JSON.stringify(
    MetadatumDatadogAgent$outboundSchema.parse(metadatumDatadogAgent),
  );
}
export function metadatumDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumDatadogAgent' from JSON`,
  );
}

/** @internal */
export const ProxyModeDatadogAgent$inboundSchema: z.ZodType<
  ProxyModeDatadogAgent,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});
/** @internal */
export type ProxyModeDatadogAgent$Outbound = {
  enabled: boolean;
  rejectUnauthorized: boolean;
};

/** @internal */
export const ProxyModeDatadogAgent$outboundSchema: z.ZodType<
  ProxyModeDatadogAgent$Outbound,
  z.ZodTypeDef,
  ProxyModeDatadogAgent
> = z.object({
  enabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});

export function proxyModeDatadogAgentToJSON(
  proxyModeDatadogAgent: ProxyModeDatadogAgent,
): string {
  return JSON.stringify(
    ProxyModeDatadogAgent$outboundSchema.parse(proxyModeDatadogAgent),
  );
}
export function proxyModeDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<ProxyModeDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ProxyModeDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ProxyModeDatadogAgent' from JSON`,
  );
}

/** @internal */
export const InputDatadogAgent$inboundSchema: z.ZodType<
  InputDatadogAgent,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeDatadogAgent$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionDatadogAgent$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqDatadogAgent$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideDatadogAgent$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    extractMetrics: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumDatadogAgent$inboundSchema))
      .optional(),
    proxyMode: z.lazy(() => ProxyModeDatadogAgent$inboundSchema).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputDatadogAgent$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionDatadogAgent$Outbound> | undefined;
  pq?: PqDatadogAgent$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideDatadogAgent$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  extractMetrics: boolean;
  metadata?: Array<MetadatumDatadogAgent$Outbound> | undefined;
  proxyMode?: ProxyModeDatadogAgent$Outbound | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputDatadogAgent$outboundSchema: z.ZodType<
  InputDatadogAgent$Outbound,
  z.ZodTypeDef,
  InputDatadogAgent
> = z.object({
  id: z.string().optional(),
  type: TypeDatadogAgent$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionDatadogAgent$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqDatadogAgent$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideDatadogAgent$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  extractMetrics: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumDatadogAgent$outboundSchema))
    .optional(),
  proxyMode: z.lazy(() => ProxyModeDatadogAgent$outboundSchema).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputDatadogAgentToJSON(
  inputDatadogAgent: InputDatadogAgent,
): string {
  return JSON.stringify(
    InputDatadogAgent$outboundSchema.parse(inputDatadogAgent),
  );
}
export function inputDatadogAgentFromJSON(
  jsonString: string,
): SafeParseResult<InputDatadogAgent, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputDatadogAgent$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputDatadogAgent' from JSON`,
  );
}

/** @internal */
export const TypeCrowdstrike$inboundSchema: z.ZodNativeEnum<
  typeof TypeCrowdstrike
> = z.nativeEnum(TypeCrowdstrike);
/** @internal */
export const TypeCrowdstrike$outboundSchema: z.ZodNativeEnum<
  typeof TypeCrowdstrike
> = TypeCrowdstrike$inboundSchema;

/** @internal */
export const ConnectionCrowdstrike$inboundSchema: z.ZodType<
  ConnectionCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCrowdstrike$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCrowdstrike$outboundSchema: z.ZodType<
  ConnectionCrowdstrike$Outbound,
  z.ZodTypeDef,
  ConnectionCrowdstrike
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCrowdstrikeToJSON(
  connectionCrowdstrike: ConnectionCrowdstrike,
): string {
  return JSON.stringify(
    ConnectionCrowdstrike$outboundSchema.parse(connectionCrowdstrike),
  );
}
export function connectionCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCrowdstrike' from JSON`,
  );
}

/** @internal */
export const ModeCrowdstrike$inboundSchema: z.ZodType<
  ModeCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCrowdstrike),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCrowdstrike$outboundSchema: z.ZodType<
  ModeCrowdstrike,
  z.ZodTypeDef,
  ModeCrowdstrike
> = z.union([
  z.nativeEnum(ModeCrowdstrike),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCrowdstrike$inboundSchema: z.ZodType<
  CompressionCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCrowdstrike),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCrowdstrike$outboundSchema: z.ZodType<
  CompressionCrowdstrike,
  z.ZodTypeDef,
  CompressionCrowdstrike
> = z.union([
  z.nativeEnum(CompressionCrowdstrike),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCrowdstrike$inboundSchema: z.ZodType<
  PqControlsCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCrowdstrike$Outbound = {};

/** @internal */
export const PqControlsCrowdstrike$outboundSchema: z.ZodType<
  PqControlsCrowdstrike$Outbound,
  z.ZodTypeDef,
  PqControlsCrowdstrike
> = z.object({});

export function pqControlsCrowdstrikeToJSON(
  pqControlsCrowdstrike: PqControlsCrowdstrike,
): string {
  return JSON.stringify(
    PqControlsCrowdstrike$outboundSchema.parse(pqControlsCrowdstrike),
  );
}
export function pqControlsCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCrowdstrike' from JSON`,
  );
}

/** @internal */
export const PqCrowdstrike$inboundSchema: z.ZodType<
  PqCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeCrowdstrike$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCrowdstrike$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCrowdstrike$inboundSchema).optional(),
});
/** @internal */
export type PqCrowdstrike$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCrowdstrike$Outbound | undefined;
};

/** @internal */
export const PqCrowdstrike$outboundSchema: z.ZodType<
  PqCrowdstrike$Outbound,
  z.ZodTypeDef,
  PqCrowdstrike
> = z.object({
  mode: ModeCrowdstrike$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCrowdstrike$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCrowdstrike$outboundSchema).optional(),
});

export function pqCrowdstrikeToJSON(pqCrowdstrike: PqCrowdstrike): string {
  return JSON.stringify(PqCrowdstrike$outboundSchema.parse(pqCrowdstrike));
}
export function pqCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<PqCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCrowdstrike' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodCrowdstrike$inboundSchema: z.ZodType<
  AuthenticationMethodCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodCrowdstrike),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodCrowdstrike$outboundSchema: z.ZodType<
  AuthenticationMethodCrowdstrike,
  z.ZodTypeDef,
  AuthenticationMethodCrowdstrike
> = z.union([
  z.nativeEnum(AuthenticationMethodCrowdstrike),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SignatureVersionCrowdstrike$inboundSchema: z.ZodType<
  SignatureVersionCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionCrowdstrike),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionCrowdstrike$outboundSchema: z.ZodType<
  SignatureVersionCrowdstrike,
  z.ZodTypeDef,
  SignatureVersionCrowdstrike
> = z.union([
  z.nativeEnum(SignatureVersionCrowdstrike),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PreprocessCrowdstrike$inboundSchema: z.ZodType<
  PreprocessCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessCrowdstrike$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessCrowdstrike$outboundSchema: z.ZodType<
  PreprocessCrowdstrike$Outbound,
  z.ZodTypeDef,
  PreprocessCrowdstrike
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessCrowdstrikeToJSON(
  preprocessCrowdstrike: PreprocessCrowdstrike,
): string {
  return JSON.stringify(
    PreprocessCrowdstrike$outboundSchema.parse(preprocessCrowdstrike),
  );
}
export function preprocessCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<PreprocessCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessCrowdstrike' from JSON`,
  );
}

/** @internal */
export const MetadatumCrowdstrike$inboundSchema: z.ZodType<
  MetadatumCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCrowdstrike$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCrowdstrike$outboundSchema: z.ZodType<
  MetadatumCrowdstrike$Outbound,
  z.ZodTypeDef,
  MetadatumCrowdstrike
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCrowdstrikeToJSON(
  metadatumCrowdstrike: MetadatumCrowdstrike,
): string {
  return JSON.stringify(
    MetadatumCrowdstrike$outboundSchema.parse(metadatumCrowdstrike),
  );
}
export function metadatumCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCrowdstrike' from JSON`,
  );
}

/** @internal */
export const CheckpointingCrowdstrike$inboundSchema: z.ZodType<
  CheckpointingCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});
/** @internal */
export type CheckpointingCrowdstrike$Outbound = {
  enabled: boolean;
  retries: number;
};

/** @internal */
export const CheckpointingCrowdstrike$outboundSchema: z.ZodType<
  CheckpointingCrowdstrike$Outbound,
  z.ZodTypeDef,
  CheckpointingCrowdstrike
> = z.object({
  enabled: z.boolean().default(false),
  retries: z.number().default(5),
});

export function checkpointingCrowdstrikeToJSON(
  checkpointingCrowdstrike: CheckpointingCrowdstrike,
): string {
  return JSON.stringify(
    CheckpointingCrowdstrike$outboundSchema.parse(checkpointingCrowdstrike),
  );
}
export function checkpointingCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<CheckpointingCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CheckpointingCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CheckpointingCrowdstrike' from JSON`,
  );
}

/** @internal */
export const TagAfterProcessingCrowdstrike$inboundSchema: z.ZodType<
  TagAfterProcessingCrowdstrike,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TagAfterProcessingCrowdstrike),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TagAfterProcessingCrowdstrike$outboundSchema: z.ZodType<
  TagAfterProcessingCrowdstrike,
  z.ZodTypeDef,
  TagAfterProcessingCrowdstrike
> = z.union([
  z.nativeEnum(TagAfterProcessingCrowdstrike),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputCrowdstrike$inboundSchema: z.ZodType<
  InputCrowdstrike,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCrowdstrike$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCrowdstrike$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCrowdstrike$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    awsAccountId: z.string().optional(),
    awsAuthenticationMethod: AuthenticationMethodCrowdstrike$inboundSchema
      .default("auto"),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionCrowdstrike$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    maxMessages: z.number().default(1),
    visibilityTimeout: z.number().default(21600),
    numReceivers: z.number().default(1),
    socketTimeout: z.number().default(300),
    skipOnError: z.boolean().default(false),
    includeSqsMetadata: z.boolean().default(false),
    enableAssumeRole: z.boolean().default(true),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    enableSQSAssumeRole: z.boolean().default(false),
    preprocess: z.lazy(() => PreprocessCrowdstrike$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumCrowdstrike$inboundSchema))
      .optional(),
    checkpointing: z.lazy(() => CheckpointingCrowdstrike$inboundSchema)
      .optional(),
    pollTimeout: z.number().default(10),
    encoding: z.string().optional(),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    tagAfterProcessing: TagAfterProcessingCrowdstrike$inboundSchema.optional(),
    processedTagKey: z.string().optional(),
    processedTagValue: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCrowdstrike$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCrowdstrike$Outbound> | undefined;
  pq?: PqCrowdstrike$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  awsAccountId?: string | undefined;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  maxMessages: number;
  visibilityTimeout: number;
  numReceivers: number;
  socketTimeout: number;
  skipOnError: boolean;
  includeSqsMetadata: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  enableSQSAssumeRole: boolean;
  preprocess?: PreprocessCrowdstrike$Outbound | undefined;
  metadata?: Array<MetadatumCrowdstrike$Outbound> | undefined;
  checkpointing?: CheckpointingCrowdstrike$Outbound | undefined;
  pollTimeout: number;
  encoding?: string | undefined;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  tagAfterProcessing?: string | undefined;
  processedTagKey?: string | undefined;
  processedTagValue?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCrowdstrike$outboundSchema: z.ZodType<
  InputCrowdstrike$Outbound,
  z.ZodTypeDef,
  InputCrowdstrike
> = z.object({
  id: z.string().optional(),
  type: TypeCrowdstrike$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCrowdstrike$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCrowdstrike$outboundSchema).optional(),
  queueName: z.string(),
  fileFilter: z.string().default("/.*/"),
  awsAccountId: z.string().optional(),
  awsAuthenticationMethod: AuthenticationMethodCrowdstrike$outboundSchema
    .default("auto"),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionCrowdstrike$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  maxMessages: z.number().default(1),
  visibilityTimeout: z.number().default(21600),
  numReceivers: z.number().default(1),
  socketTimeout: z.number().default(300),
  skipOnError: z.boolean().default(false),
  includeSqsMetadata: z.boolean().default(false),
  enableAssumeRole: z.boolean().default(true),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  enableSQSAssumeRole: z.boolean().default(false),
  preprocess: z.lazy(() => PreprocessCrowdstrike$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumCrowdstrike$outboundSchema))
    .optional(),
  checkpointing: z.lazy(() => CheckpointingCrowdstrike$outboundSchema)
    .optional(),
  pollTimeout: z.number().default(10),
  encoding: z.string().optional(),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  tagAfterProcessing: TagAfterProcessingCrowdstrike$outboundSchema.optional(),
  processedTagKey: z.string().optional(),
  processedTagValue: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCrowdstrikeToJSON(
  inputCrowdstrike: InputCrowdstrike,
): string {
  return JSON.stringify(
    InputCrowdstrike$outboundSchema.parse(inputCrowdstrike),
  );
}
export function inputCrowdstrikeFromJSON(
  jsonString: string,
): SafeParseResult<InputCrowdstrike, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCrowdstrike$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCrowdstrike' from JSON`,
  );
}

/** @internal */
export const TypeWindowsMetrics$inboundSchema: z.ZodNativeEnum<
  typeof TypeWindowsMetrics
> = z.nativeEnum(TypeWindowsMetrics);
/** @internal */
export const TypeWindowsMetrics$outboundSchema: z.ZodNativeEnum<
  typeof TypeWindowsMetrics
> = TypeWindowsMetrics$inboundSchema;

/** @internal */
export const ConnectionWindowsMetrics$inboundSchema: z.ZodType<
  ConnectionWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionWindowsMetrics$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionWindowsMetrics$outboundSchema: z.ZodType<
  ConnectionWindowsMetrics$Outbound,
  z.ZodTypeDef,
  ConnectionWindowsMetrics
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionWindowsMetricsToJSON(
  connectionWindowsMetrics: ConnectionWindowsMetrics,
): string {
  return JSON.stringify(
    ConnectionWindowsMetrics$outboundSchema.parse(connectionWindowsMetrics),
  );
}
export function connectionWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const PqModeWindowsMetrics$inboundSchema: z.ZodType<
  PqModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeWindowsMetrics$outboundSchema: z.ZodType<
  PqModeWindowsMetrics,
  z.ZodTypeDef,
  PqModeWindowsMetrics
> = z.union([
  z.nativeEnum(PqModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionWindowsMetrics$inboundSchema: z.ZodType<
  CompressionWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionWindowsMetrics$outboundSchema: z.ZodType<
  CompressionWindowsMetrics,
  z.ZodTypeDef,
  CompressionWindowsMetrics
> = z.union([
  z.nativeEnum(CompressionWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsWindowsMetrics$inboundSchema: z.ZodType<
  PqControlsWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsWindowsMetrics$Outbound = {};

/** @internal */
export const PqControlsWindowsMetrics$outboundSchema: z.ZodType<
  PqControlsWindowsMetrics$Outbound,
  z.ZodTypeDef,
  PqControlsWindowsMetrics
> = z.object({});

export function pqControlsWindowsMetricsToJSON(
  pqControlsWindowsMetrics: PqControlsWindowsMetrics,
): string {
  return JSON.stringify(
    PqControlsWindowsMetrics$outboundSchema.parse(pqControlsWindowsMetrics),
  );
}
export function pqControlsWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const PqWindowsMetrics$inboundSchema: z.ZodType<
  PqWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeWindowsMetrics$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWindowsMetrics$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWindowsMetrics$inboundSchema).optional(),
});
/** @internal */
export type PqWindowsMetrics$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsWindowsMetrics$Outbound | undefined;
};

/** @internal */
export const PqWindowsMetrics$outboundSchema: z.ZodType<
  PqWindowsMetrics$Outbound,
  z.ZodTypeDef,
  PqWindowsMetrics
> = z.object({
  mode: PqModeWindowsMetrics$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionWindowsMetrics$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsWindowsMetrics$outboundSchema).optional(),
});

export function pqWindowsMetricsToJSON(
  pqWindowsMetrics: PqWindowsMetrics,
): string {
  return JSON.stringify(
    PqWindowsMetrics$outboundSchema.parse(pqWindowsMetrics),
  );
}
export function pqWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const HostModeWindowsMetrics$inboundSchema: z.ZodType<
  HostModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(HostModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const HostModeWindowsMetrics$outboundSchema: z.ZodType<
  HostModeWindowsMetrics,
  z.ZodTypeDef,
  HostModeWindowsMetrics
> = z.union([
  z.nativeEnum(HostModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SystemModeWindowsMetrics$inboundSchema: z.ZodType<
  SystemModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SystemModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SystemModeWindowsMetrics$outboundSchema: z.ZodType<
  SystemModeWindowsMetrics,
  z.ZodTypeDef,
  SystemModeWindowsMetrics
> = z.union([
  z.nativeEnum(SystemModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SystemWindowsMetrics$inboundSchema: z.ZodType<
  SystemWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: SystemModeWindowsMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
});
/** @internal */
export type SystemWindowsMetrics$Outbound = {
  mode: string;
  detail: boolean;
};

/** @internal */
export const SystemWindowsMetrics$outboundSchema: z.ZodType<
  SystemWindowsMetrics$Outbound,
  z.ZodTypeDef,
  SystemWindowsMetrics
> = z.object({
  mode: SystemModeWindowsMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
});

export function systemWindowsMetricsToJSON(
  systemWindowsMetrics: SystemWindowsMetrics,
): string {
  return JSON.stringify(
    SystemWindowsMetrics$outboundSchema.parse(systemWindowsMetrics),
  );
}
export function systemWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<SystemWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SystemWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SystemWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const CpuModeWindowsMetrics$inboundSchema: z.ZodType<
  CpuModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CpuModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CpuModeWindowsMetrics$outboundSchema: z.ZodType<
  CpuModeWindowsMetrics,
  z.ZodTypeDef,
  CpuModeWindowsMetrics
> = z.union([
  z.nativeEnum(CpuModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CpuWindowsMetrics$inboundSchema: z.ZodType<
  CpuWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: CpuModeWindowsMetrics$inboundSchema.default("basic"),
  perCpu: z.boolean().default(false),
  detail: z.boolean().default(false),
  time: z.boolean().default(false),
});
/** @internal */
export type CpuWindowsMetrics$Outbound = {
  mode: string;
  perCpu: boolean;
  detail: boolean;
  time: boolean;
};

/** @internal */
export const CpuWindowsMetrics$outboundSchema: z.ZodType<
  CpuWindowsMetrics$Outbound,
  z.ZodTypeDef,
  CpuWindowsMetrics
> = z.object({
  mode: CpuModeWindowsMetrics$outboundSchema.default("basic"),
  perCpu: z.boolean().default(false),
  detail: z.boolean().default(false),
  time: z.boolean().default(false),
});

export function cpuWindowsMetricsToJSON(
  cpuWindowsMetrics: CpuWindowsMetrics,
): string {
  return JSON.stringify(
    CpuWindowsMetrics$outboundSchema.parse(cpuWindowsMetrics),
  );
}
export function cpuWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<CpuWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CpuWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CpuWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const MemoryModeWindowsMetrics$inboundSchema: z.ZodType<
  MemoryModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MemoryModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MemoryModeWindowsMetrics$outboundSchema: z.ZodType<
  MemoryModeWindowsMetrics,
  z.ZodTypeDef,
  MemoryModeWindowsMetrics
> = z.union([
  z.nativeEnum(MemoryModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MemoryWindowsMetrics$inboundSchema: z.ZodType<
  MemoryWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: MemoryModeWindowsMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
});
/** @internal */
export type MemoryWindowsMetrics$Outbound = {
  mode: string;
  detail: boolean;
};

/** @internal */
export const MemoryWindowsMetrics$outboundSchema: z.ZodType<
  MemoryWindowsMetrics$Outbound,
  z.ZodTypeDef,
  MemoryWindowsMetrics
> = z.object({
  mode: MemoryModeWindowsMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
});

export function memoryWindowsMetricsToJSON(
  memoryWindowsMetrics: MemoryWindowsMetrics,
): string {
  return JSON.stringify(
    MemoryWindowsMetrics$outboundSchema.parse(memoryWindowsMetrics),
  );
}
export function memoryWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MemoryWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MemoryWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MemoryWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const NetworkModeWindowsMetrics$inboundSchema: z.ZodType<
  NetworkModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(NetworkModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const NetworkModeWindowsMetrics$outboundSchema: z.ZodType<
  NetworkModeWindowsMetrics,
  z.ZodTypeDef,
  NetworkModeWindowsMetrics
> = z.union([
  z.nativeEnum(NetworkModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const NetworkWindowsMetrics$inboundSchema: z.ZodType<
  NetworkWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: NetworkModeWindowsMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
  protocols: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  perInterface: z.boolean().default(false),
});
/** @internal */
export type NetworkWindowsMetrics$Outbound = {
  mode: string;
  detail: boolean;
  protocols: boolean;
  devices?: Array<string> | undefined;
  perInterface: boolean;
};

/** @internal */
export const NetworkWindowsMetrics$outboundSchema: z.ZodType<
  NetworkWindowsMetrics$Outbound,
  z.ZodTypeDef,
  NetworkWindowsMetrics
> = z.object({
  mode: NetworkModeWindowsMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
  protocols: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  perInterface: z.boolean().default(false),
});

export function networkWindowsMetricsToJSON(
  networkWindowsMetrics: NetworkWindowsMetrics,
): string {
  return JSON.stringify(
    NetworkWindowsMetrics$outboundSchema.parse(networkWindowsMetrics),
  );
}
export function networkWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<NetworkWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => NetworkWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'NetworkWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const DiskModeWindowsMetrics$inboundSchema: z.ZodType<
  DiskModeWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskModeWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskModeWindowsMetrics$outboundSchema: z.ZodType<
  DiskModeWindowsMetrics,
  z.ZodTypeDef,
  DiskModeWindowsMetrics
> = z.union([
  z.nativeEnum(DiskModeWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskWindowsMetrics$inboundSchema: z.ZodType<
  DiskWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: DiskModeWindowsMetrics$inboundSchema.default("basic"),
  perVolume: z.boolean().default(false),
  detail: z.boolean().default(false),
  volumes: z.array(z.string()).optional(),
});
/** @internal */
export type DiskWindowsMetrics$Outbound = {
  mode: string;
  perVolume: boolean;
  detail: boolean;
  volumes?: Array<string> | undefined;
};

/** @internal */
export const DiskWindowsMetrics$outboundSchema: z.ZodType<
  DiskWindowsMetrics$Outbound,
  z.ZodTypeDef,
  DiskWindowsMetrics
> = z.object({
  mode: DiskModeWindowsMetrics$outboundSchema.default("basic"),
  perVolume: z.boolean().default(false),
  detail: z.boolean().default(false),
  volumes: z.array(z.string()).optional(),
});

export function diskWindowsMetricsToJSON(
  diskWindowsMetrics: DiskWindowsMetrics,
): string {
  return JSON.stringify(
    DiskWindowsMetrics$outboundSchema.parse(diskWindowsMetrics),
  );
}
export function diskWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<DiskWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => DiskWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'DiskWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const CustomWindowsMetrics$inboundSchema: z.ZodType<
  CustomWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  system: z.lazy(() => SystemWindowsMetrics$inboundSchema).optional(),
  cpu: z.lazy(() => CpuWindowsMetrics$inboundSchema).optional(),
  memory: z.lazy(() => MemoryWindowsMetrics$inboundSchema).optional(),
  network: z.lazy(() => NetworkWindowsMetrics$inboundSchema).optional(),
  disk: z.lazy(() => DiskWindowsMetrics$inboundSchema).optional(),
});
/** @internal */
export type CustomWindowsMetrics$Outbound = {
  system?: SystemWindowsMetrics$Outbound | undefined;
  cpu?: CpuWindowsMetrics$Outbound | undefined;
  memory?: MemoryWindowsMetrics$Outbound | undefined;
  network?: NetworkWindowsMetrics$Outbound | undefined;
  disk?: DiskWindowsMetrics$Outbound | undefined;
};

/** @internal */
export const CustomWindowsMetrics$outboundSchema: z.ZodType<
  CustomWindowsMetrics$Outbound,
  z.ZodTypeDef,
  CustomWindowsMetrics
> = z.object({
  system: z.lazy(() => SystemWindowsMetrics$outboundSchema).optional(),
  cpu: z.lazy(() => CpuWindowsMetrics$outboundSchema).optional(),
  memory: z.lazy(() => MemoryWindowsMetrics$outboundSchema).optional(),
  network: z.lazy(() => NetworkWindowsMetrics$outboundSchema).optional(),
  disk: z.lazy(() => DiskWindowsMetrics$outboundSchema).optional(),
});

export function customWindowsMetricsToJSON(
  customWindowsMetrics: CustomWindowsMetrics,
): string {
  return JSON.stringify(
    CustomWindowsMetrics$outboundSchema.parse(customWindowsMetrics),
  );
}
export function customWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<CustomWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CustomWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CustomWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const HostWindowsMetrics$inboundSchema: z.ZodType<
  HostWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: HostModeWindowsMetrics$inboundSchema.default("basic"),
  custom: z.lazy(() => CustomWindowsMetrics$inboundSchema).optional(),
});
/** @internal */
export type HostWindowsMetrics$Outbound = {
  mode: string;
  custom?: CustomWindowsMetrics$Outbound | undefined;
};

/** @internal */
export const HostWindowsMetrics$outboundSchema: z.ZodType<
  HostWindowsMetrics$Outbound,
  z.ZodTypeDef,
  HostWindowsMetrics
> = z.object({
  mode: HostModeWindowsMetrics$outboundSchema.default("basic"),
  custom: z.lazy(() => CustomWindowsMetrics$outboundSchema).optional(),
});

export function hostWindowsMetricsToJSON(
  hostWindowsMetrics: HostWindowsMetrics,
): string {
  return JSON.stringify(
    HostWindowsMetrics$outboundSchema.parse(hostWindowsMetrics),
  );
}
export function hostWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<HostWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const SetWindowsMetrics$inboundSchema: z.ZodType<
  SetWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  filter: z.string(),
  includeChildren: z.boolean().default(false),
});
/** @internal */
export type SetWindowsMetrics$Outbound = {
  name: string;
  filter: string;
  includeChildren: boolean;
};

/** @internal */
export const SetWindowsMetrics$outboundSchema: z.ZodType<
  SetWindowsMetrics$Outbound,
  z.ZodTypeDef,
  SetWindowsMetrics
> = z.object({
  name: z.string(),
  filter: z.string(),
  includeChildren: z.boolean().default(false),
});

export function setWindowsMetricsToJSON(
  setWindowsMetrics: SetWindowsMetrics,
): string {
  return JSON.stringify(
    SetWindowsMetrics$outboundSchema.parse(setWindowsMetrics),
  );
}
export function setWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<SetWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SetWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SetWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const ProcessWindowsMetrics$inboundSchema: z.ZodType<
  ProcessWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  sets: z.array(z.lazy(() => SetWindowsMetrics$inboundSchema)).optional(),
});
/** @internal */
export type ProcessWindowsMetrics$Outbound = {
  sets?: Array<SetWindowsMetrics$Outbound> | undefined;
};

/** @internal */
export const ProcessWindowsMetrics$outboundSchema: z.ZodType<
  ProcessWindowsMetrics$Outbound,
  z.ZodTypeDef,
  ProcessWindowsMetrics
> = z.object({
  sets: z.array(z.lazy(() => SetWindowsMetrics$outboundSchema)).optional(),
});

export function processWindowsMetricsToJSON(
  processWindowsMetrics: ProcessWindowsMetrics,
): string {
  return JSON.stringify(
    ProcessWindowsMetrics$outboundSchema.parse(processWindowsMetrics),
  );
}
export function processWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ProcessWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ProcessWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ProcessWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const MetadatumWindowsMetrics$inboundSchema: z.ZodType<
  MetadatumWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumWindowsMetrics$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumWindowsMetrics$outboundSchema: z.ZodType<
  MetadatumWindowsMetrics$Outbound,
  z.ZodTypeDef,
  MetadatumWindowsMetrics
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumWindowsMetricsToJSON(
  metadatumWindowsMetrics: MetadatumWindowsMetrics,
): string {
  return JSON.stringify(
    MetadatumWindowsMetrics$outboundSchema.parse(metadatumWindowsMetrics),
  );
}
export function metadatumWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const DataCompressionFormatWindowsMetrics$inboundSchema: z.ZodType<
  DataCompressionFormatWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataCompressionFormatWindowsMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataCompressionFormatWindowsMetrics$outboundSchema: z.ZodType<
  DataCompressionFormatWindowsMetrics,
  z.ZodTypeDef,
  DataCompressionFormatWindowsMetrics
> = z.union([
  z.nativeEnum(DataCompressionFormatWindowsMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceWindowsMetrics$inboundSchema: z.ZodType<
  PersistenceWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatWindowsMetrics$inboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/windows_metrics"),
});
/** @internal */
export type PersistenceWindowsMetrics$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath: string;
};

/** @internal */
export const PersistenceWindowsMetrics$outboundSchema: z.ZodType<
  PersistenceWindowsMetrics$Outbound,
  z.ZodTypeDef,
  PersistenceWindowsMetrics
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatWindowsMetrics$outboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/windows_metrics"),
});

export function persistenceWindowsMetricsToJSON(
  persistenceWindowsMetrics: PersistenceWindowsMetrics,
): string {
  return JSON.stringify(
    PersistenceWindowsMetrics$outboundSchema.parse(persistenceWindowsMetrics),
  );
}
export function persistenceWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PersistenceWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PersistenceWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PersistenceWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const InputWindowsMetrics$inboundSchema: z.ZodType<
  InputWindowsMetrics,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeWindowsMetrics$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionWindowsMetrics$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqWindowsMetrics$inboundSchema).optional(),
    interval: z.number().default(10),
    host: z.lazy(() => HostWindowsMetrics$inboundSchema).optional(),
    process: z.lazy(() => ProcessWindowsMetrics$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumWindowsMetrics$inboundSchema))
      .optional(),
    persistence: z.lazy(() => PersistenceWindowsMetrics$inboundSchema)
      .optional(),
    disableNativeModule: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputWindowsMetrics$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionWindowsMetrics$Outbound> | undefined;
  pq?: PqWindowsMetrics$Outbound | undefined;
  interval: number;
  host?: HostWindowsMetrics$Outbound | undefined;
  process?: ProcessWindowsMetrics$Outbound | undefined;
  metadata?: Array<MetadatumWindowsMetrics$Outbound> | undefined;
  persistence?: PersistenceWindowsMetrics$Outbound | undefined;
  disableNativeModule: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputWindowsMetrics$outboundSchema: z.ZodType<
  InputWindowsMetrics$Outbound,
  z.ZodTypeDef,
  InputWindowsMetrics
> = z.object({
  id: z.string().optional(),
  type: TypeWindowsMetrics$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionWindowsMetrics$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqWindowsMetrics$outboundSchema).optional(),
  interval: z.number().default(10),
  host: z.lazy(() => HostWindowsMetrics$outboundSchema).optional(),
  process: z.lazy(() => ProcessWindowsMetrics$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumWindowsMetrics$outboundSchema))
    .optional(),
  persistence: z.lazy(() => PersistenceWindowsMetrics$outboundSchema)
    .optional(),
  disableNativeModule: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputWindowsMetricsToJSON(
  inputWindowsMetrics: InputWindowsMetrics,
): string {
  return JSON.stringify(
    InputWindowsMetrics$outboundSchema.parse(inputWindowsMetrics),
  );
}
export function inputWindowsMetricsFromJSON(
  jsonString: string,
): SafeParseResult<InputWindowsMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputWindowsMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputWindowsMetrics' from JSON`,
  );
}

/** @internal */
export const TypeKubeEvents$inboundSchema: z.ZodNativeEnum<
  typeof TypeKubeEvents
> = z.nativeEnum(TypeKubeEvents);
/** @internal */
export const TypeKubeEvents$outboundSchema: z.ZodNativeEnum<
  typeof TypeKubeEvents
> = TypeKubeEvents$inboundSchema;

/** @internal */
export const ConnectionKubeEvents$inboundSchema: z.ZodType<
  ConnectionKubeEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionKubeEvents$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionKubeEvents$outboundSchema: z.ZodType<
  ConnectionKubeEvents$Outbound,
  z.ZodTypeDef,
  ConnectionKubeEvents
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionKubeEventsToJSON(
  connectionKubeEvents: ConnectionKubeEvents,
): string {
  return JSON.stringify(
    ConnectionKubeEvents$outboundSchema.parse(connectionKubeEvents),
  );
}
export function connectionKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionKubeEvents' from JSON`,
  );
}

/** @internal */
export const ModeKubeEvents$inboundSchema: z.ZodType<
  ModeKubeEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeKubeEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeKubeEvents$outboundSchema: z.ZodType<
  ModeKubeEvents,
  z.ZodTypeDef,
  ModeKubeEvents
> = z.union([
  z.nativeEnum(ModeKubeEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionKubeEvents$inboundSchema: z.ZodType<
  CompressionKubeEvents,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionKubeEvents),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionKubeEvents$outboundSchema: z.ZodType<
  CompressionKubeEvents,
  z.ZodTypeDef,
  CompressionKubeEvents
> = z.union([
  z.nativeEnum(CompressionKubeEvents),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsKubeEvents$inboundSchema: z.ZodType<
  PqControlsKubeEvents,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsKubeEvents$Outbound = {};

/** @internal */
export const PqControlsKubeEvents$outboundSchema: z.ZodType<
  PqControlsKubeEvents$Outbound,
  z.ZodTypeDef,
  PqControlsKubeEvents
> = z.object({});

export function pqControlsKubeEventsToJSON(
  pqControlsKubeEvents: PqControlsKubeEvents,
): string {
  return JSON.stringify(
    PqControlsKubeEvents$outboundSchema.parse(pqControlsKubeEvents),
  );
}
export function pqControlsKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsKubeEvents' from JSON`,
  );
}

/** @internal */
export const PqKubeEvents$inboundSchema: z.ZodType<
  PqKubeEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeKubeEvents$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionKubeEvents$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeEvents$inboundSchema).optional(),
});
/** @internal */
export type PqKubeEvents$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsKubeEvents$Outbound | undefined;
};

/** @internal */
export const PqKubeEvents$outboundSchema: z.ZodType<
  PqKubeEvents$Outbound,
  z.ZodTypeDef,
  PqKubeEvents
> = z.object({
  mode: ModeKubeEvents$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionKubeEvents$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeEvents$outboundSchema).optional(),
});

export function pqKubeEventsToJSON(pqKubeEvents: PqKubeEvents): string {
  return JSON.stringify(PqKubeEvents$outboundSchema.parse(pqKubeEvents));
}
export function pqKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<PqKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqKubeEvents' from JSON`,
  );
}

/** @internal */
export const RuleKubeEvents$inboundSchema: z.ZodType<
  RuleKubeEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type RuleKubeEvents$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const RuleKubeEvents$outboundSchema: z.ZodType<
  RuleKubeEvents$Outbound,
  z.ZodTypeDef,
  RuleKubeEvents
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function ruleKubeEventsToJSON(ruleKubeEvents: RuleKubeEvents): string {
  return JSON.stringify(RuleKubeEvents$outboundSchema.parse(ruleKubeEvents));
}
export function ruleKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<RuleKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RuleKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RuleKubeEvents' from JSON`,
  );
}

/** @internal */
export const MetadatumKubeEvents$inboundSchema: z.ZodType<
  MetadatumKubeEvents,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumKubeEvents$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumKubeEvents$outboundSchema: z.ZodType<
  MetadatumKubeEvents$Outbound,
  z.ZodTypeDef,
  MetadatumKubeEvents
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumKubeEventsToJSON(
  metadatumKubeEvents: MetadatumKubeEvents,
): string {
  return JSON.stringify(
    MetadatumKubeEvents$outboundSchema.parse(metadatumKubeEvents),
  );
}
export function metadatumKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumKubeEvents' from JSON`,
  );
}

/** @internal */
export const InputKubeEvents$inboundSchema: z.ZodType<
  InputKubeEvents,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeKubeEvents$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionKubeEvents$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqKubeEvents$inboundSchema).optional(),
    rules: z.array(z.lazy(() => RuleKubeEvents$inboundSchema)).optional(),
    metadata: z.array(z.lazy(() => MetadatumKubeEvents$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputKubeEvents$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionKubeEvents$Outbound> | undefined;
  pq?: PqKubeEvents$Outbound | undefined;
  rules?: Array<RuleKubeEvents$Outbound> | undefined;
  metadata?: Array<MetadatumKubeEvents$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputKubeEvents$outboundSchema: z.ZodType<
  InputKubeEvents$Outbound,
  z.ZodTypeDef,
  InputKubeEvents
> = z.object({
  id: z.string().optional(),
  type: TypeKubeEvents$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionKubeEvents$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqKubeEvents$outboundSchema).optional(),
  rules: z.array(z.lazy(() => RuleKubeEvents$outboundSchema)).optional(),
  metadata: z.array(z.lazy(() => MetadatumKubeEvents$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputKubeEventsToJSON(
  inputKubeEvents: InputKubeEvents,
): string {
  return JSON.stringify(InputKubeEvents$outboundSchema.parse(inputKubeEvents));
}
export function inputKubeEventsFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeEvents, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeEvents$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeEvents' from JSON`,
  );
}

/** @internal */
export const TypeKubeLogs$inboundSchema: z.ZodNativeEnum<typeof TypeKubeLogs> =
  z.nativeEnum(TypeKubeLogs);
/** @internal */
export const TypeKubeLogs$outboundSchema: z.ZodNativeEnum<typeof TypeKubeLogs> =
  TypeKubeLogs$inboundSchema;

/** @internal */
export const ConnectionKubeLogs$inboundSchema: z.ZodType<
  ConnectionKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionKubeLogs$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionKubeLogs$outboundSchema: z.ZodType<
  ConnectionKubeLogs$Outbound,
  z.ZodTypeDef,
  ConnectionKubeLogs
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionKubeLogsToJSON(
  connectionKubeLogs: ConnectionKubeLogs,
): string {
  return JSON.stringify(
    ConnectionKubeLogs$outboundSchema.parse(connectionKubeLogs),
  );
}
export function connectionKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionKubeLogs' from JSON`,
  );
}

/** @internal */
export const ModeKubeLogs$inboundSchema: z.ZodType<
  ModeKubeLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeKubeLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeKubeLogs$outboundSchema: z.ZodType<
  ModeKubeLogs,
  z.ZodTypeDef,
  ModeKubeLogs
> = z.union([
  z.nativeEnum(ModeKubeLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionKubeLogs$inboundSchema: z.ZodType<
  PqCompressionKubeLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionKubeLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionKubeLogs$outboundSchema: z.ZodType<
  PqCompressionKubeLogs,
  z.ZodTypeDef,
  PqCompressionKubeLogs
> = z.union([
  z.nativeEnum(PqCompressionKubeLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsKubeLogs$inboundSchema: z.ZodType<
  PqControlsKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsKubeLogs$Outbound = {};

/** @internal */
export const PqControlsKubeLogs$outboundSchema: z.ZodType<
  PqControlsKubeLogs$Outbound,
  z.ZodTypeDef,
  PqControlsKubeLogs
> = z.object({});

export function pqControlsKubeLogsToJSON(
  pqControlsKubeLogs: PqControlsKubeLogs,
): string {
  return JSON.stringify(
    PqControlsKubeLogs$outboundSchema.parse(pqControlsKubeLogs),
  );
}
export function pqControlsKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsKubeLogs' from JSON`,
  );
}

/** @internal */
export const PqKubeLogs$inboundSchema: z.ZodType<
  PqKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeKubeLogs$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionKubeLogs$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeLogs$inboundSchema).optional(),
});
/** @internal */
export type PqKubeLogs$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsKubeLogs$Outbound | undefined;
};

/** @internal */
export const PqKubeLogs$outboundSchema: z.ZodType<
  PqKubeLogs$Outbound,
  z.ZodTypeDef,
  PqKubeLogs
> = z.object({
  mode: ModeKubeLogs$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionKubeLogs$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeLogs$outboundSchema).optional(),
});

export function pqKubeLogsToJSON(pqKubeLogs: PqKubeLogs): string {
  return JSON.stringify(PqKubeLogs$outboundSchema.parse(pqKubeLogs));
}
export function pqKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<PqKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqKubeLogs' from JSON`,
  );
}

/** @internal */
export const RuleKubeLogs$inboundSchema: z.ZodType<
  RuleKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type RuleKubeLogs$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const RuleKubeLogs$outboundSchema: z.ZodType<
  RuleKubeLogs$Outbound,
  z.ZodTypeDef,
  RuleKubeLogs
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function ruleKubeLogsToJSON(ruleKubeLogs: RuleKubeLogs): string {
  return JSON.stringify(RuleKubeLogs$outboundSchema.parse(ruleKubeLogs));
}
export function ruleKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<RuleKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RuleKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RuleKubeLogs' from JSON`,
  );
}

/** @internal */
export const MetadatumKubeLogs$inboundSchema: z.ZodType<
  MetadatumKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumKubeLogs$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumKubeLogs$outboundSchema: z.ZodType<
  MetadatumKubeLogs$Outbound,
  z.ZodTypeDef,
  MetadatumKubeLogs
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumKubeLogsToJSON(
  metadatumKubeLogs: MetadatumKubeLogs,
): string {
  return JSON.stringify(
    MetadatumKubeLogs$outboundSchema.parse(metadatumKubeLogs),
  );
}
export function metadatumKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumKubeLogs' from JSON`,
  );
}

/** @internal */
export const PersistenceCompressionKubeLogs$inboundSchema: z.ZodType<
  PersistenceCompressionKubeLogs,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PersistenceCompressionKubeLogs),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PersistenceCompressionKubeLogs$outboundSchema: z.ZodType<
  PersistenceCompressionKubeLogs,
  z.ZodTypeDef,
  PersistenceCompressionKubeLogs
> = z.union([
  z.nativeEnum(PersistenceCompressionKubeLogs),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpoolingKubeLogs$inboundSchema: z.ZodType<
  DiskSpoolingKubeLogs,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PersistenceCompressionKubeLogs$inboundSchema.default("gzip"),
});
/** @internal */
export type DiskSpoolingKubeLogs$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
};

/** @internal */
export const DiskSpoolingKubeLogs$outboundSchema: z.ZodType<
  DiskSpoolingKubeLogs$Outbound,
  z.ZodTypeDef,
  DiskSpoolingKubeLogs
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PersistenceCompressionKubeLogs$outboundSchema.default("gzip"),
});

export function diskSpoolingKubeLogsToJSON(
  diskSpoolingKubeLogs: DiskSpoolingKubeLogs,
): string {
  return JSON.stringify(
    DiskSpoolingKubeLogs$outboundSchema.parse(diskSpoolingKubeLogs),
  );
}
export function diskSpoolingKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<DiskSpoolingKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => DiskSpoolingKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'DiskSpoolingKubeLogs' from JSON`,
  );
}

/** @internal */
export const InputKubeLogs$inboundSchema: z.ZodType<
  InputKubeLogs,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeKubeLogs$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionKubeLogs$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqKubeLogs$inboundSchema).optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => RuleKubeLogs$inboundSchema)).optional(),
    timestamps: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumKubeLogs$inboundSchema)).optional(),
    persistence: z.lazy(() => DiskSpoolingKubeLogs$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    enableLoadBalancing: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputKubeLogs$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionKubeLogs$Outbound> | undefined;
  pq?: PqKubeLogs$Outbound | undefined;
  interval: number;
  rules?: Array<RuleKubeLogs$Outbound> | undefined;
  timestamps: boolean;
  metadata?: Array<MetadatumKubeLogs$Outbound> | undefined;
  persistence?: DiskSpoolingKubeLogs$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  enableLoadBalancing: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputKubeLogs$outboundSchema: z.ZodType<
  InputKubeLogs$Outbound,
  z.ZodTypeDef,
  InputKubeLogs
> = z.object({
  id: z.string().optional(),
  type: TypeKubeLogs$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionKubeLogs$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqKubeLogs$outboundSchema).optional(),
  interval: z.number().default(15),
  rules: z.array(z.lazy(() => RuleKubeLogs$outboundSchema)).optional(),
  timestamps: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumKubeLogs$outboundSchema)).optional(),
  persistence: z.lazy(() => DiskSpoolingKubeLogs$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  enableLoadBalancing: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputKubeLogsToJSON(inputKubeLogs: InputKubeLogs): string {
  return JSON.stringify(InputKubeLogs$outboundSchema.parse(inputKubeLogs));
}
export function inputKubeLogsFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeLogs, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeLogs$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeLogs' from JSON`,
  );
}

/** @internal */
export const TypeKubeMetrics$inboundSchema: z.ZodNativeEnum<
  typeof TypeKubeMetrics
> = z.nativeEnum(TypeKubeMetrics);
/** @internal */
export const TypeKubeMetrics$outboundSchema: z.ZodNativeEnum<
  typeof TypeKubeMetrics
> = TypeKubeMetrics$inboundSchema;

/** @internal */
export const ConnectionKubeMetrics$inboundSchema: z.ZodType<
  ConnectionKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionKubeMetrics$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionKubeMetrics$outboundSchema: z.ZodType<
  ConnectionKubeMetrics$Outbound,
  z.ZodTypeDef,
  ConnectionKubeMetrics
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionKubeMetricsToJSON(
  connectionKubeMetrics: ConnectionKubeMetrics,
): string {
  return JSON.stringify(
    ConnectionKubeMetrics$outboundSchema.parse(connectionKubeMetrics),
  );
}
export function connectionKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionKubeMetrics' from JSON`,
  );
}

/** @internal */
export const ModeKubeMetrics$inboundSchema: z.ZodType<
  ModeKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeKubeMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeKubeMetrics$outboundSchema: z.ZodType<
  ModeKubeMetrics,
  z.ZodTypeDef,
  ModeKubeMetrics
> = z.union([
  z.nativeEnum(ModeKubeMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionKubeMetrics$inboundSchema: z.ZodType<
  CompressionKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionKubeMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionKubeMetrics$outboundSchema: z.ZodType<
  CompressionKubeMetrics,
  z.ZodTypeDef,
  CompressionKubeMetrics
> = z.union([
  z.nativeEnum(CompressionKubeMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsKubeMetrics$inboundSchema: z.ZodType<
  PqControlsKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsKubeMetrics$Outbound = {};

/** @internal */
export const PqControlsKubeMetrics$outboundSchema: z.ZodType<
  PqControlsKubeMetrics$Outbound,
  z.ZodTypeDef,
  PqControlsKubeMetrics
> = z.object({});

export function pqControlsKubeMetricsToJSON(
  pqControlsKubeMetrics: PqControlsKubeMetrics,
): string {
  return JSON.stringify(
    PqControlsKubeMetrics$outboundSchema.parse(pqControlsKubeMetrics),
  );
}
export function pqControlsKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsKubeMetrics' from JSON`,
  );
}

/** @internal */
export const PqKubeMetrics$inboundSchema: z.ZodType<
  PqKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeKubeMetrics$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionKubeMetrics$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeMetrics$inboundSchema).optional(),
});
/** @internal */
export type PqKubeMetrics$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsKubeMetrics$Outbound | undefined;
};

/** @internal */
export const PqKubeMetrics$outboundSchema: z.ZodType<
  PqKubeMetrics$Outbound,
  z.ZodTypeDef,
  PqKubeMetrics
> = z.object({
  mode: ModeKubeMetrics$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionKubeMetrics$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsKubeMetrics$outboundSchema).optional(),
});

export function pqKubeMetricsToJSON(pqKubeMetrics: PqKubeMetrics): string {
  return JSON.stringify(PqKubeMetrics$outboundSchema.parse(pqKubeMetrics));
}
export function pqKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqKubeMetrics' from JSON`,
  );
}

/** @internal */
export const RuleKubeMetrics$inboundSchema: z.ZodType<
  RuleKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type RuleKubeMetrics$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const RuleKubeMetrics$outboundSchema: z.ZodType<
  RuleKubeMetrics$Outbound,
  z.ZodTypeDef,
  RuleKubeMetrics
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function ruleKubeMetricsToJSON(
  ruleKubeMetrics: RuleKubeMetrics,
): string {
  return JSON.stringify(RuleKubeMetrics$outboundSchema.parse(ruleKubeMetrics));
}
export function ruleKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<RuleKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RuleKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RuleKubeMetrics' from JSON`,
  );
}

/** @internal */
export const MetadatumKubeMetrics$inboundSchema: z.ZodType<
  MetadatumKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumKubeMetrics$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumKubeMetrics$outboundSchema: z.ZodType<
  MetadatumKubeMetrics$Outbound,
  z.ZodTypeDef,
  MetadatumKubeMetrics
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumKubeMetricsToJSON(
  metadatumKubeMetrics: MetadatumKubeMetrics,
): string {
  return JSON.stringify(
    MetadatumKubeMetrics$outboundSchema.parse(metadatumKubeMetrics),
  );
}
export function metadatumKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumKubeMetrics' from JSON`,
  );
}

/** @internal */
export const DataCompressionFormatKubeMetrics$inboundSchema: z.ZodType<
  DataCompressionFormatKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataCompressionFormatKubeMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataCompressionFormatKubeMetrics$outboundSchema: z.ZodType<
  DataCompressionFormatKubeMetrics,
  z.ZodTypeDef,
  DataCompressionFormatKubeMetrics
> = z.union([
  z.nativeEnum(DataCompressionFormatKubeMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceKubeMetrics$inboundSchema: z.ZodType<
  PersistenceKubeMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatKubeMetrics$inboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/kube_metrics"),
});
/** @internal */
export type PersistenceKubeMetrics$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath: string;
};

/** @internal */
export const PersistenceKubeMetrics$outboundSchema: z.ZodType<
  PersistenceKubeMetrics$Outbound,
  z.ZodTypeDef,
  PersistenceKubeMetrics
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatKubeMetrics$outboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/kube_metrics"),
});

export function persistenceKubeMetricsToJSON(
  persistenceKubeMetrics: PersistenceKubeMetrics,
): string {
  return JSON.stringify(
    PersistenceKubeMetrics$outboundSchema.parse(persistenceKubeMetrics),
  );
}
export function persistenceKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PersistenceKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PersistenceKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PersistenceKubeMetrics' from JSON`,
  );
}

/** @internal */
export const InputKubeMetrics$inboundSchema: z.ZodType<
  InputKubeMetrics,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeKubeMetrics$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionKubeMetrics$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqKubeMetrics$inboundSchema).optional(),
    interval: z.number().default(15),
    rules: z.array(z.lazy(() => RuleKubeMetrics$inboundSchema)).optional(),
    metadata: z.array(z.lazy(() => MetadatumKubeMetrics$inboundSchema))
      .optional(),
    persistence: z.lazy(() => PersistenceKubeMetrics$inboundSchema).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputKubeMetrics$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionKubeMetrics$Outbound> | undefined;
  pq?: PqKubeMetrics$Outbound | undefined;
  interval: number;
  rules?: Array<RuleKubeMetrics$Outbound> | undefined;
  metadata?: Array<MetadatumKubeMetrics$Outbound> | undefined;
  persistence?: PersistenceKubeMetrics$Outbound | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputKubeMetrics$outboundSchema: z.ZodType<
  InputKubeMetrics$Outbound,
  z.ZodTypeDef,
  InputKubeMetrics
> = z.object({
  id: z.string().optional(),
  type: TypeKubeMetrics$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionKubeMetrics$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqKubeMetrics$outboundSchema).optional(),
  interval: z.number().default(15),
  rules: z.array(z.lazy(() => RuleKubeMetrics$outboundSchema)).optional(),
  metadata: z.array(z.lazy(() => MetadatumKubeMetrics$outboundSchema))
    .optional(),
  persistence: z.lazy(() => PersistenceKubeMetrics$outboundSchema).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputKubeMetricsToJSON(
  inputKubeMetrics: InputKubeMetrics,
): string {
  return JSON.stringify(
    InputKubeMetrics$outboundSchema.parse(inputKubeMetrics),
  );
}
export function inputKubeMetricsFromJSON(
  jsonString: string,
): SafeParseResult<InputKubeMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKubeMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKubeMetrics' from JSON`,
  );
}

/** @internal */
export const TypeSystemState$inboundSchema: z.ZodNativeEnum<
  typeof TypeSystemState
> = z.nativeEnum(TypeSystemState);
/** @internal */
export const TypeSystemState$outboundSchema: z.ZodNativeEnum<
  typeof TypeSystemState
> = TypeSystemState$inboundSchema;

/** @internal */
export const ConnectionSystemState$inboundSchema: z.ZodType<
  ConnectionSystemState,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSystemState$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSystemState$outboundSchema: z.ZodType<
  ConnectionSystemState$Outbound,
  z.ZodTypeDef,
  ConnectionSystemState
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSystemStateToJSON(
  connectionSystemState: ConnectionSystemState,
): string {
  return JSON.stringify(
    ConnectionSystemState$outboundSchema.parse(connectionSystemState),
  );
}
export function connectionSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSystemState' from JSON`,
  );
}

/** @internal */
export const ModeSystemState$inboundSchema: z.ZodType<
  ModeSystemState,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSystemState),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSystemState$outboundSchema: z.ZodType<
  ModeSystemState,
  z.ZodTypeDef,
  ModeSystemState
> = z.union([
  z.nativeEnum(ModeSystemState),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSystemState$inboundSchema: z.ZodType<
  CompressionSystemState,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSystemState),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSystemState$outboundSchema: z.ZodType<
  CompressionSystemState,
  z.ZodTypeDef,
  CompressionSystemState
> = z.union([
  z.nativeEnum(CompressionSystemState),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSystemState$inboundSchema: z.ZodType<
  PqControlsSystemState,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSystemState$Outbound = {};

/** @internal */
export const PqControlsSystemState$outboundSchema: z.ZodType<
  PqControlsSystemState$Outbound,
  z.ZodTypeDef,
  PqControlsSystemState
> = z.object({});

export function pqControlsSystemStateToJSON(
  pqControlsSystemState: PqControlsSystemState,
): string {
  return JSON.stringify(
    PqControlsSystemState$outboundSchema.parse(pqControlsSystemState),
  );
}
export function pqControlsSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSystemState' from JSON`,
  );
}

/** @internal */
export const PqSystemState$inboundSchema: z.ZodType<
  PqSystemState,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeSystemState$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSystemState$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSystemState$inboundSchema).optional(),
});
/** @internal */
export type PqSystemState$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsSystemState$Outbound | undefined;
};

/** @internal */
export const PqSystemState$outboundSchema: z.ZodType<
  PqSystemState$Outbound,
  z.ZodTypeDef,
  PqSystemState
> = z.object({
  mode: ModeSystemState$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSystemState$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSystemState$outboundSchema).optional(),
});

export function pqSystemStateToJSON(pqSystemState: PqSystemState): string {
  return JSON.stringify(PqSystemState$outboundSchema.parse(pqSystemState));
}
export function pqSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<PqSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSystemState' from JSON`,
  );
}

/** @internal */
export const MetadatumSystemState$inboundSchema: z.ZodType<
  MetadatumSystemState,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSystemState$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSystemState$outboundSchema: z.ZodType<
  MetadatumSystemState$Outbound,
  z.ZodTypeDef,
  MetadatumSystemState
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSystemStateToJSON(
  metadatumSystemState: MetadatumSystemState,
): string {
  return JSON.stringify(
    MetadatumSystemState$outboundSchema.parse(metadatumSystemState),
  );
}
export function metadatumSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSystemState' from JSON`,
  );
}

/** @internal */
export const HostsFile$inboundSchema: z.ZodType<
  HostsFile,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type HostsFile$Outbound = {
  enable: boolean;
};

/** @internal */
export const HostsFile$outboundSchema: z.ZodType<
  HostsFile$Outbound,
  z.ZodTypeDef,
  HostsFile
> = z.object({
  enable: z.boolean().default(true),
});

export function hostsFileToJSON(hostsFile: HostsFile): string {
  return JSON.stringify(HostsFile$outboundSchema.parse(hostsFile));
}
export function hostsFileFromJSON(
  jsonString: string,
): SafeParseResult<HostsFile, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostsFile$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostsFile' from JSON`,
  );
}

/** @internal */
export const Interfaces$inboundSchema: z.ZodType<
  Interfaces,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type Interfaces$Outbound = {
  enable: boolean;
};

/** @internal */
export const Interfaces$outboundSchema: z.ZodType<
  Interfaces$Outbound,
  z.ZodTypeDef,
  Interfaces
> = z.object({
  enable: z.boolean().default(true),
});

export function interfacesToJSON(interfaces: Interfaces): string {
  return JSON.stringify(Interfaces$outboundSchema.parse(interfaces));
}
export function interfacesFromJSON(
  jsonString: string,
): SafeParseResult<Interfaces, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Interfaces$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Interfaces' from JSON`,
  );
}

/** @internal */
export const DisksAndFileSystems$inboundSchema: z.ZodType<
  DisksAndFileSystems,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type DisksAndFileSystems$Outbound = {
  enable: boolean;
};

/** @internal */
export const DisksAndFileSystems$outboundSchema: z.ZodType<
  DisksAndFileSystems$Outbound,
  z.ZodTypeDef,
  DisksAndFileSystems
> = z.object({
  enable: z.boolean().default(true),
});

export function disksAndFileSystemsToJSON(
  disksAndFileSystems: DisksAndFileSystems,
): string {
  return JSON.stringify(
    DisksAndFileSystems$outboundSchema.parse(disksAndFileSystems),
  );
}
export function disksAndFileSystemsFromJSON(
  jsonString: string,
): SafeParseResult<DisksAndFileSystems, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => DisksAndFileSystems$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'DisksAndFileSystems' from JSON`,
  );
}

/** @internal */
export const HostInfo$inboundSchema: z.ZodType<
  HostInfo,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type HostInfo$Outbound = {
  enable: boolean;
};

/** @internal */
export const HostInfo$outboundSchema: z.ZodType<
  HostInfo$Outbound,
  z.ZodTypeDef,
  HostInfo
> = z.object({
  enable: z.boolean().default(true),
});

export function hostInfoToJSON(hostInfo: HostInfo): string {
  return JSON.stringify(HostInfo$outboundSchema.parse(hostInfo));
}
export function hostInfoFromJSON(
  jsonString: string,
): SafeParseResult<HostInfo, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostInfo$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostInfo' from JSON`,
  );
}

/** @internal */
export const InputRoutes$inboundSchema: z.ZodType<
  InputRoutes,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type InputRoutes$Outbound = {
  enable: boolean;
};

/** @internal */
export const InputRoutes$outboundSchema: z.ZodType<
  InputRoutes$Outbound,
  z.ZodTypeDef,
  InputRoutes
> = z.object({
  enable: z.boolean().default(true),
});

export function inputRoutesToJSON(inputRoutes: InputRoutes): string {
  return JSON.stringify(InputRoutes$outboundSchema.parse(inputRoutes));
}
export function inputRoutesFromJSON(
  jsonString: string,
): SafeParseResult<InputRoutes, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputRoutes$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputRoutes' from JSON`,
  );
}

/** @internal */
export const Dns$inboundSchema: z.ZodType<Dns, z.ZodTypeDef, unknown> = z
  .object({
    enable: z.boolean().default(true),
  });
/** @internal */
export type Dns$Outbound = {
  enable: boolean;
};

/** @internal */
export const Dns$outboundSchema: z.ZodType<Dns$Outbound, z.ZodTypeDef, Dns> = z
  .object({
    enable: z.boolean().default(true),
  });

export function dnsToJSON(dns: Dns): string {
  return JSON.stringify(Dns$outboundSchema.parse(dns));
}
export function dnsFromJSON(
  jsonString: string,
): SafeParseResult<Dns, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Dns$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Dns' from JSON`,
  );
}

/** @internal */
export const UsersAndGroups$inboundSchema: z.ZodType<
  UsersAndGroups,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type UsersAndGroups$Outbound = {
  enable: boolean;
};

/** @internal */
export const UsersAndGroups$outboundSchema: z.ZodType<
  UsersAndGroups$Outbound,
  z.ZodTypeDef,
  UsersAndGroups
> = z.object({
  enable: z.boolean().default(true),
});

export function usersAndGroupsToJSON(usersAndGroups: UsersAndGroups): string {
  return JSON.stringify(UsersAndGroups$outboundSchema.parse(usersAndGroups));
}
export function usersAndGroupsFromJSON(
  jsonString: string,
): SafeParseResult<UsersAndGroups, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => UsersAndGroups$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'UsersAndGroups' from JSON`,
  );
}

/** @internal */
export const Firewall$inboundSchema: z.ZodType<
  Firewall,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type Firewall$Outbound = {
  enable: boolean;
};

/** @internal */
export const Firewall$outboundSchema: z.ZodType<
  Firewall$Outbound,
  z.ZodTypeDef,
  Firewall
> = z.object({
  enable: z.boolean().default(true),
});

export function firewallToJSON(firewall: Firewall): string {
  return JSON.stringify(Firewall$outboundSchema.parse(firewall));
}
export function firewallFromJSON(
  jsonString: string,
): SafeParseResult<Firewall, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Firewall$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Firewall' from JSON`,
  );
}

/** @internal */
export const Services$inboundSchema: z.ZodType<
  Services,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type Services$Outbound = {
  enable: boolean;
};

/** @internal */
export const Services$outboundSchema: z.ZodType<
  Services$Outbound,
  z.ZodTypeDef,
  Services
> = z.object({
  enable: z.boolean().default(true),
});

export function servicesToJSON(services: Services): string {
  return JSON.stringify(Services$outboundSchema.parse(services));
}
export function servicesFromJSON(
  jsonString: string,
): SafeParseResult<Services, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Services$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Services' from JSON`,
  );
}

/** @internal */
export const ListeningPorts$inboundSchema: z.ZodType<
  ListeningPorts,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type ListeningPorts$Outbound = {
  enable: boolean;
};

/** @internal */
export const ListeningPorts$outboundSchema: z.ZodType<
  ListeningPorts$Outbound,
  z.ZodTypeDef,
  ListeningPorts
> = z.object({
  enable: z.boolean().default(true),
});

export function listeningPortsToJSON(listeningPorts: ListeningPorts): string {
  return JSON.stringify(ListeningPorts$outboundSchema.parse(listeningPorts));
}
export function listeningPortsFromJSON(
  jsonString: string,
): SafeParseResult<ListeningPorts, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ListeningPorts$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ListeningPorts' from JSON`,
  );
}

/** @internal */
export const LoggedInUsers$inboundSchema: z.ZodType<
  LoggedInUsers,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(true),
});
/** @internal */
export type LoggedInUsers$Outbound = {
  enable: boolean;
};

/** @internal */
export const LoggedInUsers$outboundSchema: z.ZodType<
  LoggedInUsers$Outbound,
  z.ZodTypeDef,
  LoggedInUsers
> = z.object({
  enable: z.boolean().default(true),
});

export function loggedInUsersToJSON(loggedInUsers: LoggedInUsers): string {
  return JSON.stringify(LoggedInUsers$outboundSchema.parse(loggedInUsers));
}
export function loggedInUsersFromJSON(
  jsonString: string,
): SafeParseResult<LoggedInUsers, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LoggedInUsers$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LoggedInUsers' from JSON`,
  );
}

/** @internal */
export const Collectors$inboundSchema: z.ZodType<
  Collectors,
  z.ZodTypeDef,
  unknown
> = z.object({
  hostsfile: z.lazy(() => HostsFile$inboundSchema).optional(),
  interfaces: z.lazy(() => Interfaces$inboundSchema).optional(),
  disk: z.lazy(() => DisksAndFileSystems$inboundSchema).optional(),
  metadata: z.lazy(() => HostInfo$inboundSchema).optional(),
  routes: z.lazy(() => InputRoutes$inboundSchema).optional(),
  dns: z.lazy(() => Dns$inboundSchema).optional(),
  user: z.lazy(() => UsersAndGroups$inboundSchema).optional(),
  firewall: z.lazy(() => Firewall$inboundSchema).optional(),
  services: z.lazy(() => Services$inboundSchema).optional(),
  ports: z.lazy(() => ListeningPorts$inboundSchema).optional(),
  loginUsers: z.lazy(() => LoggedInUsers$inboundSchema).optional(),
});
/** @internal */
export type Collectors$Outbound = {
  hostsfile?: HostsFile$Outbound | undefined;
  interfaces?: Interfaces$Outbound | undefined;
  disk?: DisksAndFileSystems$Outbound | undefined;
  metadata?: HostInfo$Outbound | undefined;
  routes?: InputRoutes$Outbound | undefined;
  dns?: Dns$Outbound | undefined;
  user?: UsersAndGroups$Outbound | undefined;
  firewall?: Firewall$Outbound | undefined;
  services?: Services$Outbound | undefined;
  ports?: ListeningPorts$Outbound | undefined;
  loginUsers?: LoggedInUsers$Outbound | undefined;
};

/** @internal */
export const Collectors$outboundSchema: z.ZodType<
  Collectors$Outbound,
  z.ZodTypeDef,
  Collectors
> = z.object({
  hostsfile: z.lazy(() => HostsFile$outboundSchema).optional(),
  interfaces: z.lazy(() => Interfaces$outboundSchema).optional(),
  disk: z.lazy(() => DisksAndFileSystems$outboundSchema).optional(),
  metadata: z.lazy(() => HostInfo$outboundSchema).optional(),
  routes: z.lazy(() => InputRoutes$outboundSchema).optional(),
  dns: z.lazy(() => Dns$outboundSchema).optional(),
  user: z.lazy(() => UsersAndGroups$outboundSchema).optional(),
  firewall: z.lazy(() => Firewall$outboundSchema).optional(),
  services: z.lazy(() => Services$outboundSchema).optional(),
  ports: z.lazy(() => ListeningPorts$outboundSchema).optional(),
  loginUsers: z.lazy(() => LoggedInUsers$outboundSchema).optional(),
});

export function collectorsToJSON(collectors: Collectors): string {
  return JSON.stringify(Collectors$outboundSchema.parse(collectors));
}
export function collectorsFromJSON(
  jsonString: string,
): SafeParseResult<Collectors, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Collectors$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Collectors' from JSON`,
  );
}

/** @internal */
export const DataCompressionFormatSystemState$inboundSchema: z.ZodType<
  DataCompressionFormatSystemState,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataCompressionFormatSystemState),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataCompressionFormatSystemState$outboundSchema: z.ZodType<
  DataCompressionFormatSystemState,
  z.ZodTypeDef,
  DataCompressionFormatSystemState
> = z.union([
  z.nativeEnum(DataCompressionFormatSystemState),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceSystemState$inboundSchema: z.ZodType<
  PersistenceSystemState,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatSystemState$inboundSchema.default("none"),
  destPath: z.string().default("$CRIBL_HOME/state/system_state"),
});
/** @internal */
export type PersistenceSystemState$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath: string;
};

/** @internal */
export const PersistenceSystemState$outboundSchema: z.ZodType<
  PersistenceSystemState$Outbound,
  z.ZodTypeDef,
  PersistenceSystemState
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatSystemState$outboundSchema.default("none"),
  destPath: z.string().default("$CRIBL_HOME/state/system_state"),
});

export function persistenceSystemStateToJSON(
  persistenceSystemState: PersistenceSystemState,
): string {
  return JSON.stringify(
    PersistenceSystemState$outboundSchema.parse(persistenceSystemState),
  );
}
export function persistenceSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<PersistenceSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PersistenceSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PersistenceSystemState' from JSON`,
  );
}

/** @internal */
export const InputSystemState$inboundSchema: z.ZodType<
  InputSystemState,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSystemState$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSystemState$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSystemState$inboundSchema).optional(),
    interval: z.number().default(300),
    metadata: z.array(z.lazy(() => MetadatumSystemState$inboundSchema))
      .optional(),
    collectors: z.lazy(() => Collectors$inboundSchema).optional(),
    persistence: z.lazy(() => PersistenceSystemState$inboundSchema).optional(),
    disableNativeModule: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSystemState$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSystemState$Outbound> | undefined;
  pq?: PqSystemState$Outbound | undefined;
  interval: number;
  metadata?: Array<MetadatumSystemState$Outbound> | undefined;
  collectors?: Collectors$Outbound | undefined;
  persistence?: PersistenceSystemState$Outbound | undefined;
  disableNativeModule: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSystemState$outboundSchema: z.ZodType<
  InputSystemState$Outbound,
  z.ZodTypeDef,
  InputSystemState
> = z.object({
  id: z.string().optional(),
  type: TypeSystemState$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSystemState$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSystemState$outboundSchema).optional(),
  interval: z.number().default(300),
  metadata: z.array(z.lazy(() => MetadatumSystemState$outboundSchema))
    .optional(),
  collectors: z.lazy(() => Collectors$outboundSchema).optional(),
  persistence: z.lazy(() => PersistenceSystemState$outboundSchema).optional(),
  disableNativeModule: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSystemStateToJSON(
  inputSystemState: InputSystemState,
): string {
  return JSON.stringify(
    InputSystemState$outboundSchema.parse(inputSystemState),
  );
}
export function inputSystemStateFromJSON(
  jsonString: string,
): SafeParseResult<InputSystemState, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSystemState$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSystemState' from JSON`,
  );
}

/** @internal */
export const TypeSystemMetrics$inboundSchema: z.ZodNativeEnum<
  typeof TypeSystemMetrics
> = z.nativeEnum(TypeSystemMetrics);
/** @internal */
export const TypeSystemMetrics$outboundSchema: z.ZodNativeEnum<
  typeof TypeSystemMetrics
> = TypeSystemMetrics$inboundSchema;

/** @internal */
export const ConnectionSystemMetrics$inboundSchema: z.ZodType<
  ConnectionSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSystemMetrics$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSystemMetrics$outboundSchema: z.ZodType<
  ConnectionSystemMetrics$Outbound,
  z.ZodTypeDef,
  ConnectionSystemMetrics
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSystemMetricsToJSON(
  connectionSystemMetrics: ConnectionSystemMetrics,
): string {
  return JSON.stringify(
    ConnectionSystemMetrics$outboundSchema.parse(connectionSystemMetrics),
  );
}
export function connectionSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSystemMetrics' from JSON`,
  );
}

/** @internal */
export const PqModeSystemMetrics$inboundSchema: z.ZodType<
  PqModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeSystemMetrics$outboundSchema: z.ZodType<
  PqModeSystemMetrics,
  z.ZodTypeDef,
  PqModeSystemMetrics
> = z.union([
  z.nativeEnum(PqModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSystemMetrics$inboundSchema: z.ZodType<
  CompressionSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSystemMetrics$outboundSchema: z.ZodType<
  CompressionSystemMetrics,
  z.ZodTypeDef,
  CompressionSystemMetrics
> = z.union([
  z.nativeEnum(CompressionSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSystemMetrics$inboundSchema: z.ZodType<
  PqControlsSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSystemMetrics$Outbound = {};

/** @internal */
export const PqControlsSystemMetrics$outboundSchema: z.ZodType<
  PqControlsSystemMetrics$Outbound,
  z.ZodTypeDef,
  PqControlsSystemMetrics
> = z.object({});

export function pqControlsSystemMetricsToJSON(
  pqControlsSystemMetrics: PqControlsSystemMetrics,
): string {
  return JSON.stringify(
    PqControlsSystemMetrics$outboundSchema.parse(pqControlsSystemMetrics),
  );
}
export function pqControlsSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSystemMetrics' from JSON`,
  );
}

/** @internal */
export const PqSystemMetrics$inboundSchema: z.ZodType<
  PqSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeSystemMetrics$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSystemMetrics$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSystemMetrics$inboundSchema).optional(),
});
/** @internal */
export type PqSystemMetrics$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsSystemMetrics$Outbound | undefined;
};

/** @internal */
export const PqSystemMetrics$outboundSchema: z.ZodType<
  PqSystemMetrics$Outbound,
  z.ZodTypeDef,
  PqSystemMetrics
> = z.object({
  mode: PqModeSystemMetrics$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSystemMetrics$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSystemMetrics$outboundSchema).optional(),
});

export function pqSystemMetricsToJSON(
  pqSystemMetrics: PqSystemMetrics,
): string {
  return JSON.stringify(PqSystemMetrics$outboundSchema.parse(pqSystemMetrics));
}
export function pqSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PqSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSystemMetrics' from JSON`,
  );
}

/** @internal */
export const HostModeSystemMetrics$inboundSchema: z.ZodType<
  HostModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(HostModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const HostModeSystemMetrics$outboundSchema: z.ZodType<
  HostModeSystemMetrics,
  z.ZodTypeDef,
  HostModeSystemMetrics
> = z.union([
  z.nativeEnum(HostModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SystemModeSystemMetrics$inboundSchema: z.ZodType<
  SystemModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SystemModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SystemModeSystemMetrics$outboundSchema: z.ZodType<
  SystemModeSystemMetrics,
  z.ZodTypeDef,
  SystemModeSystemMetrics
> = z.union([
  z.nativeEnum(SystemModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SystemSystemMetrics$inboundSchema: z.ZodType<
  SystemSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: SystemModeSystemMetrics$inboundSchema.default("basic"),
  processes: z.boolean().default(false),
});
/** @internal */
export type SystemSystemMetrics$Outbound = {
  mode: string;
  processes: boolean;
};

/** @internal */
export const SystemSystemMetrics$outboundSchema: z.ZodType<
  SystemSystemMetrics$Outbound,
  z.ZodTypeDef,
  SystemSystemMetrics
> = z.object({
  mode: SystemModeSystemMetrics$outboundSchema.default("basic"),
  processes: z.boolean().default(false),
});

export function systemSystemMetricsToJSON(
  systemSystemMetrics: SystemSystemMetrics,
): string {
  return JSON.stringify(
    SystemSystemMetrics$outboundSchema.parse(systemSystemMetrics),
  );
}
export function systemSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<SystemSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SystemSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SystemSystemMetrics' from JSON`,
  );
}

/** @internal */
export const CpuModeSystemMetrics$inboundSchema: z.ZodType<
  CpuModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CpuModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CpuModeSystemMetrics$outboundSchema: z.ZodType<
  CpuModeSystemMetrics,
  z.ZodTypeDef,
  CpuModeSystemMetrics
> = z.union([
  z.nativeEnum(CpuModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CpuSystemMetrics$inboundSchema: z.ZodType<
  CpuSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: CpuModeSystemMetrics$inboundSchema.default("basic"),
  perCpu: z.boolean().default(false),
  detail: z.boolean().default(false),
  time: z.boolean().default(false),
});
/** @internal */
export type CpuSystemMetrics$Outbound = {
  mode: string;
  perCpu: boolean;
  detail: boolean;
  time: boolean;
};

/** @internal */
export const CpuSystemMetrics$outboundSchema: z.ZodType<
  CpuSystemMetrics$Outbound,
  z.ZodTypeDef,
  CpuSystemMetrics
> = z.object({
  mode: CpuModeSystemMetrics$outboundSchema.default("basic"),
  perCpu: z.boolean().default(false),
  detail: z.boolean().default(false),
  time: z.boolean().default(false),
});

export function cpuSystemMetricsToJSON(
  cpuSystemMetrics: CpuSystemMetrics,
): string {
  return JSON.stringify(
    CpuSystemMetrics$outboundSchema.parse(cpuSystemMetrics),
  );
}
export function cpuSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<CpuSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CpuSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CpuSystemMetrics' from JSON`,
  );
}

/** @internal */
export const MemoryModeSystemMetrics$inboundSchema: z.ZodType<
  MemoryModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MemoryModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MemoryModeSystemMetrics$outboundSchema: z.ZodType<
  MemoryModeSystemMetrics,
  z.ZodTypeDef,
  MemoryModeSystemMetrics
> = z.union([
  z.nativeEnum(MemoryModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MemorySystemMetrics$inboundSchema: z.ZodType<
  MemorySystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: MemoryModeSystemMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
});
/** @internal */
export type MemorySystemMetrics$Outbound = {
  mode: string;
  detail: boolean;
};

/** @internal */
export const MemorySystemMetrics$outboundSchema: z.ZodType<
  MemorySystemMetrics$Outbound,
  z.ZodTypeDef,
  MemorySystemMetrics
> = z.object({
  mode: MemoryModeSystemMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
});

export function memorySystemMetricsToJSON(
  memorySystemMetrics: MemorySystemMetrics,
): string {
  return JSON.stringify(
    MemorySystemMetrics$outboundSchema.parse(memorySystemMetrics),
  );
}
export function memorySystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MemorySystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MemorySystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MemorySystemMetrics' from JSON`,
  );
}

/** @internal */
export const NetworkModeSystemMetrics$inboundSchema: z.ZodType<
  NetworkModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(NetworkModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const NetworkModeSystemMetrics$outboundSchema: z.ZodType<
  NetworkModeSystemMetrics,
  z.ZodTypeDef,
  NetworkModeSystemMetrics
> = z.union([
  z.nativeEnum(NetworkModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const NetworkSystemMetrics$inboundSchema: z.ZodType<
  NetworkSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: NetworkModeSystemMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
  protocols: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  perInterface: z.boolean().default(false),
});
/** @internal */
export type NetworkSystemMetrics$Outbound = {
  mode: string;
  detail: boolean;
  protocols: boolean;
  devices?: Array<string> | undefined;
  perInterface: boolean;
};

/** @internal */
export const NetworkSystemMetrics$outboundSchema: z.ZodType<
  NetworkSystemMetrics$Outbound,
  z.ZodTypeDef,
  NetworkSystemMetrics
> = z.object({
  mode: NetworkModeSystemMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
  protocols: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  perInterface: z.boolean().default(false),
});

export function networkSystemMetricsToJSON(
  networkSystemMetrics: NetworkSystemMetrics,
): string {
  return JSON.stringify(
    NetworkSystemMetrics$outboundSchema.parse(networkSystemMetrics),
  );
}
export function networkSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<NetworkSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => NetworkSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'NetworkSystemMetrics' from JSON`,
  );
}

/** @internal */
export const DiskModeSystemMetrics$inboundSchema: z.ZodType<
  DiskModeSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiskModeSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiskModeSystemMetrics$outboundSchema: z.ZodType<
  DiskModeSystemMetrics,
  z.ZodTypeDef,
  DiskModeSystemMetrics
> = z.union([
  z.nativeEnum(DiskModeSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSystemMetrics$inboundSchema: z.ZodType<
  DiskSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: DiskModeSystemMetrics$inboundSchema.default("basic"),
  detail: z.boolean().default(false),
  inodes: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  mountpoints: z.array(z.string()).optional(),
  fstypes: z.array(z.string()).optional(),
  perDevice: z.boolean().default(false),
});
/** @internal */
export type DiskSystemMetrics$Outbound = {
  mode: string;
  detail: boolean;
  inodes: boolean;
  devices?: Array<string> | undefined;
  mountpoints?: Array<string> | undefined;
  fstypes?: Array<string> | undefined;
  perDevice: boolean;
};

/** @internal */
export const DiskSystemMetrics$outboundSchema: z.ZodType<
  DiskSystemMetrics$Outbound,
  z.ZodTypeDef,
  DiskSystemMetrics
> = z.object({
  mode: DiskModeSystemMetrics$outboundSchema.default("basic"),
  detail: z.boolean().default(false),
  inodes: z.boolean().default(false),
  devices: z.array(z.string()).optional(),
  mountpoints: z.array(z.string()).optional(),
  fstypes: z.array(z.string()).optional(),
  perDevice: z.boolean().default(false),
});

export function diskSystemMetricsToJSON(
  diskSystemMetrics: DiskSystemMetrics,
): string {
  return JSON.stringify(
    DiskSystemMetrics$outboundSchema.parse(diskSystemMetrics),
  );
}
export function diskSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<DiskSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => DiskSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'DiskSystemMetrics' from JSON`,
  );
}

/** @internal */
export const CustomSystemMetrics$inboundSchema: z.ZodType<
  CustomSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  system: z.lazy(() => SystemSystemMetrics$inboundSchema).optional(),
  cpu: z.lazy(() => CpuSystemMetrics$inboundSchema).optional(),
  memory: z.lazy(() => MemorySystemMetrics$inboundSchema).optional(),
  network: z.lazy(() => NetworkSystemMetrics$inboundSchema).optional(),
  disk: z.lazy(() => DiskSystemMetrics$inboundSchema).optional(),
});
/** @internal */
export type CustomSystemMetrics$Outbound = {
  system?: SystemSystemMetrics$Outbound | undefined;
  cpu?: CpuSystemMetrics$Outbound | undefined;
  memory?: MemorySystemMetrics$Outbound | undefined;
  network?: NetworkSystemMetrics$Outbound | undefined;
  disk?: DiskSystemMetrics$Outbound | undefined;
};

/** @internal */
export const CustomSystemMetrics$outboundSchema: z.ZodType<
  CustomSystemMetrics$Outbound,
  z.ZodTypeDef,
  CustomSystemMetrics
> = z.object({
  system: z.lazy(() => SystemSystemMetrics$outboundSchema).optional(),
  cpu: z.lazy(() => CpuSystemMetrics$outboundSchema).optional(),
  memory: z.lazy(() => MemorySystemMetrics$outboundSchema).optional(),
  network: z.lazy(() => NetworkSystemMetrics$outboundSchema).optional(),
  disk: z.lazy(() => DiskSystemMetrics$outboundSchema).optional(),
});

export function customSystemMetricsToJSON(
  customSystemMetrics: CustomSystemMetrics,
): string {
  return JSON.stringify(
    CustomSystemMetrics$outboundSchema.parse(customSystemMetrics),
  );
}
export function customSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<CustomSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CustomSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CustomSystemMetrics' from JSON`,
  );
}

/** @internal */
export const HostSystemMetrics$inboundSchema: z.ZodType<
  HostSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: HostModeSystemMetrics$inboundSchema.default("basic"),
  custom: z.lazy(() => CustomSystemMetrics$inboundSchema).optional(),
});
/** @internal */
export type HostSystemMetrics$Outbound = {
  mode: string;
  custom?: CustomSystemMetrics$Outbound | undefined;
};

/** @internal */
export const HostSystemMetrics$outboundSchema: z.ZodType<
  HostSystemMetrics$Outbound,
  z.ZodTypeDef,
  HostSystemMetrics
> = z.object({
  mode: HostModeSystemMetrics$outboundSchema.default("basic"),
  custom: z.lazy(() => CustomSystemMetrics$outboundSchema).optional(),
});

export function hostSystemMetricsToJSON(
  hostSystemMetrics: HostSystemMetrics,
): string {
  return JSON.stringify(
    HostSystemMetrics$outboundSchema.parse(hostSystemMetrics),
  );
}
export function hostSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<HostSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => HostSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'HostSystemMetrics' from JSON`,
  );
}

/** @internal */
export const SetSystemMetrics$inboundSchema: z.ZodType<
  SetSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  filter: z.string(),
  includeChildren: z.boolean().default(false),
});
/** @internal */
export type SetSystemMetrics$Outbound = {
  name: string;
  filter: string;
  includeChildren: boolean;
};

/** @internal */
export const SetSystemMetrics$outboundSchema: z.ZodType<
  SetSystemMetrics$Outbound,
  z.ZodTypeDef,
  SetSystemMetrics
> = z.object({
  name: z.string(),
  filter: z.string(),
  includeChildren: z.boolean().default(false),
});

export function setSystemMetricsToJSON(
  setSystemMetrics: SetSystemMetrics,
): string {
  return JSON.stringify(
    SetSystemMetrics$outboundSchema.parse(setSystemMetrics),
  );
}
export function setSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<SetSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SetSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SetSystemMetrics' from JSON`,
  );
}

/** @internal */
export const ProcessSystemMetrics$inboundSchema: z.ZodType<
  ProcessSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  sets: z.array(z.lazy(() => SetSystemMetrics$inboundSchema)).optional(),
});
/** @internal */
export type ProcessSystemMetrics$Outbound = {
  sets?: Array<SetSystemMetrics$Outbound> | undefined;
};

/** @internal */
export const ProcessSystemMetrics$outboundSchema: z.ZodType<
  ProcessSystemMetrics$Outbound,
  z.ZodTypeDef,
  ProcessSystemMetrics
> = z.object({
  sets: z.array(z.lazy(() => SetSystemMetrics$outboundSchema)).optional(),
});

export function processSystemMetricsToJSON(
  processSystemMetrics: ProcessSystemMetrics,
): string {
  return JSON.stringify(
    ProcessSystemMetrics$outboundSchema.parse(processSystemMetrics),
  );
}
export function processSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<ProcessSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ProcessSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ProcessSystemMetrics' from JSON`,
  );
}

/** @internal */
export const ContainerMode$inboundSchema: z.ZodType<
  ContainerMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ContainerMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ContainerMode$outboundSchema: z.ZodType<
  ContainerMode,
  z.ZodTypeDef,
  ContainerMode
> = z.union([
  z.nativeEnum(ContainerMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ContainerFilter$inboundSchema: z.ZodType<
  ContainerFilter,
  z.ZodTypeDef,
  unknown
> = z.object({
  expr: z.string(),
});
/** @internal */
export type ContainerFilter$Outbound = {
  expr: string;
};

/** @internal */
export const ContainerFilter$outboundSchema: z.ZodType<
  ContainerFilter$Outbound,
  z.ZodTypeDef,
  ContainerFilter
> = z.object({
  expr: z.string(),
});

export function containerFilterToJSON(
  containerFilter: ContainerFilter,
): string {
  return JSON.stringify(ContainerFilter$outboundSchema.parse(containerFilter));
}
export function containerFilterFromJSON(
  jsonString: string,
): SafeParseResult<ContainerFilter, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ContainerFilter$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ContainerFilter' from JSON`,
  );
}

/** @internal */
export const Container$inboundSchema: z.ZodType<
  Container,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ContainerMode$inboundSchema.default("basic"),
  dockerSocket: z.array(z.string()).optional(),
  dockerTimeout: z.number().default(5),
  filters: z.array(z.lazy(() => ContainerFilter$inboundSchema)).optional(),
  allContainers: z.boolean().default(false),
  perDevice: z.boolean().default(false),
  detail: z.boolean().default(false),
});
/** @internal */
export type Container$Outbound = {
  mode: string;
  dockerSocket?: Array<string> | undefined;
  dockerTimeout: number;
  filters?: Array<ContainerFilter$Outbound> | undefined;
  allContainers: boolean;
  perDevice: boolean;
  detail: boolean;
};

/** @internal */
export const Container$outboundSchema: z.ZodType<
  Container$Outbound,
  z.ZodTypeDef,
  Container
> = z.object({
  mode: ContainerMode$outboundSchema.default("basic"),
  dockerSocket: z.array(z.string()).optional(),
  dockerTimeout: z.number().default(5),
  filters: z.array(z.lazy(() => ContainerFilter$outboundSchema)).optional(),
  allContainers: z.boolean().default(false),
  perDevice: z.boolean().default(false),
  detail: z.boolean().default(false),
});

export function containerToJSON(container: Container): string {
  return JSON.stringify(Container$outboundSchema.parse(container));
}
export function containerFromJSON(
  jsonString: string,
): SafeParseResult<Container, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Container$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Container' from JSON`,
  );
}

/** @internal */
export const MetadatumSystemMetrics$inboundSchema: z.ZodType<
  MetadatumSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSystemMetrics$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSystemMetrics$outboundSchema: z.ZodType<
  MetadatumSystemMetrics$Outbound,
  z.ZodTypeDef,
  MetadatumSystemMetrics
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSystemMetricsToJSON(
  metadatumSystemMetrics: MetadatumSystemMetrics,
): string {
  return JSON.stringify(
    MetadatumSystemMetrics$outboundSchema.parse(metadatumSystemMetrics),
  );
}
export function metadatumSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSystemMetrics' from JSON`,
  );
}

/** @internal */
export const DataCompressionFormatSystemMetrics$inboundSchema: z.ZodType<
  DataCompressionFormatSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DataCompressionFormatSystemMetrics),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DataCompressionFormatSystemMetrics$outboundSchema: z.ZodType<
  DataCompressionFormatSystemMetrics,
  z.ZodTypeDef,
  DataCompressionFormatSystemMetrics
> = z.union([
  z.nativeEnum(DataCompressionFormatSystemMetrics),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceSystemMetrics$inboundSchema: z.ZodType<
  PersistenceSystemMetrics,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatSystemMetrics$inboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/system_metrics"),
});
/** @internal */
export type PersistenceSystemMetrics$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
  destPath: string;
};

/** @internal */
export const PersistenceSystemMetrics$outboundSchema: z.ZodType<
  PersistenceSystemMetrics$Outbound,
  z.ZodTypeDef,
  PersistenceSystemMetrics
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: DataCompressionFormatSystemMetrics$outboundSchema.default("gzip"),
  destPath: z.string().default("$CRIBL_HOME/state/system_metrics"),
});

export function persistenceSystemMetricsToJSON(
  persistenceSystemMetrics: PersistenceSystemMetrics,
): string {
  return JSON.stringify(
    PersistenceSystemMetrics$outboundSchema.parse(persistenceSystemMetrics),
  );
}
export function persistenceSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<PersistenceSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PersistenceSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PersistenceSystemMetrics' from JSON`,
  );
}

/** @internal */
export const InputSystemMetrics$inboundSchema: z.ZodType<
  InputSystemMetrics,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSystemMetrics$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSystemMetrics$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSystemMetrics$inboundSchema).optional(),
    interval: z.number().default(10),
    host: z.lazy(() => HostSystemMetrics$inboundSchema).optional(),
    process: z.lazy(() => ProcessSystemMetrics$inboundSchema).optional(),
    container: z.lazy(() => Container$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => MetadatumSystemMetrics$inboundSchema))
      .optional(),
    persistence: z.lazy(() => PersistenceSystemMetrics$inboundSchema)
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSystemMetrics$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSystemMetrics$Outbound> | undefined;
  pq?: PqSystemMetrics$Outbound | undefined;
  interval: number;
  host?: HostSystemMetrics$Outbound | undefined;
  process?: ProcessSystemMetrics$Outbound | undefined;
  container?: Container$Outbound | undefined;
  metadata?: Array<MetadatumSystemMetrics$Outbound> | undefined;
  persistence?: PersistenceSystemMetrics$Outbound | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSystemMetrics$outboundSchema: z.ZodType<
  InputSystemMetrics$Outbound,
  z.ZodTypeDef,
  InputSystemMetrics
> = z.object({
  id: z.string().optional(),
  type: TypeSystemMetrics$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSystemMetrics$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSystemMetrics$outboundSchema).optional(),
  interval: z.number().default(10),
  host: z.lazy(() => HostSystemMetrics$outboundSchema).optional(),
  process: z.lazy(() => ProcessSystemMetrics$outboundSchema).optional(),
  container: z.lazy(() => Container$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => MetadatumSystemMetrics$outboundSchema))
    .optional(),
  persistence: z.lazy(() => PersistenceSystemMetrics$outboundSchema).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSystemMetricsToJSON(
  inputSystemMetrics: InputSystemMetrics,
): string {
  return JSON.stringify(
    InputSystemMetrics$outboundSchema.parse(inputSystemMetrics),
  );
}
export function inputSystemMetricsFromJSON(
  jsonString: string,
): SafeParseResult<InputSystemMetrics, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSystemMetrics$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSystemMetrics' from JSON`,
  );
}

/** @internal */
export const InputTypeTcpjson$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeTcpjson
> = z.nativeEnum(InputTypeTcpjson);
/** @internal */
export const InputTypeTcpjson$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeTcpjson
> = InputTypeTcpjson$inboundSchema;

/** @internal */
export const ConnectionTcpjson$inboundSchema: z.ZodType<
  ConnectionTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionTcpjson$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionTcpjson$outboundSchema: z.ZodType<
  ConnectionTcpjson$Outbound,
  z.ZodTypeDef,
  ConnectionTcpjson
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionTcpjsonToJSON(
  connectionTcpjson: ConnectionTcpjson,
): string {
  return JSON.stringify(
    ConnectionTcpjson$outboundSchema.parse(connectionTcpjson),
  );
}
export function connectionTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionTcpjson' from JSON`,
  );
}

/** @internal */
export const PqModeTcpjson$inboundSchema: z.ZodType<
  PqModeTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeTcpjson$outboundSchema: z.ZodType<
  PqModeTcpjson,
  z.ZodTypeDef,
  PqModeTcpjson
> = z.union([
  z.nativeEnum(PqModeTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionTcpjson$inboundSchema: z.ZodType<
  PqCompressionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionTcpjson$outboundSchema: z.ZodType<
  PqCompressionTcpjson,
  z.ZodTypeDef,
  PqCompressionTcpjson
> = z.union([
  z.nativeEnum(PqCompressionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsTcpjson$inboundSchema: z.ZodType<
  InputPqControlsTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsTcpjson$Outbound = {};

/** @internal */
export const InputPqControlsTcpjson$outboundSchema: z.ZodType<
  InputPqControlsTcpjson$Outbound,
  z.ZodTypeDef,
  InputPqControlsTcpjson
> = z.object({});

export function inputPqControlsTcpjsonToJSON(
  inputPqControlsTcpjson: InputPqControlsTcpjson,
): string {
  return JSON.stringify(
    InputPqControlsTcpjson$outboundSchema.parse(inputPqControlsTcpjson),
  );
}
export function inputPqControlsTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsTcpjson' from JSON`,
  );
}

/** @internal */
export const PqTcpjson$inboundSchema: z.ZodType<
  PqTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeTcpjson$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionTcpjson$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsTcpjson$inboundSchema).optional(),
});
/** @internal */
export type PqTcpjson$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsTcpjson$Outbound | undefined;
};

/** @internal */
export const PqTcpjson$outboundSchema: z.ZodType<
  PqTcpjson$Outbound,
  z.ZodTypeDef,
  PqTcpjson
> = z.object({
  mode: PqModeTcpjson$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionTcpjson$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsTcpjson$outboundSchema).optional(),
});

export function pqTcpjsonToJSON(pqTcpjson: PqTcpjson): string {
  return JSON.stringify(PqTcpjson$outboundSchema.parse(pqTcpjson));
}
export function pqTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<PqTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqTcpjson' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionTcpjson$inboundSchema: z.ZodType<
  InputMinimumTLSVersionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionTcpjson$outboundSchema: z.ZodType<
  InputMinimumTLSVersionTcpjson,
  z.ZodTypeDef,
  InputMinimumTLSVersionTcpjson
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionTcpjson$inboundSchema: z.ZodType<
  InputMaximumTLSVersionTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionTcpjson$outboundSchema: z.ZodType<
  InputMaximumTLSVersionTcpjson,
  z.ZodTypeDef,
  InputMaximumTLSVersionTcpjson
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideTcpjson$inboundSchema: z.ZodType<
  TLSSettingsServerSideTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionTcpjson$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionTcpjson$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideTcpjson$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideTcpjson$outboundSchema: z.ZodType<
  TLSSettingsServerSideTcpjson$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideTcpjson
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionTcpjson$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionTcpjson$outboundSchema.optional(),
});

export function tlsSettingsServerSideTcpjsonToJSON(
  tlsSettingsServerSideTcpjson: TLSSettingsServerSideTcpjson,
): string {
  return JSON.stringify(
    TLSSettingsServerSideTcpjson$outboundSchema.parse(
      tlsSettingsServerSideTcpjson,
    ),
  );
}
export function tlsSettingsServerSideTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideTcpjson' from JSON`,
  );
}

/** @internal */
export const MetadatumTcpjson$inboundSchema: z.ZodType<
  MetadatumTcpjson,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumTcpjson$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumTcpjson$outboundSchema: z.ZodType<
  MetadatumTcpjson$Outbound,
  z.ZodTypeDef,
  MetadatumTcpjson
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumTcpjsonToJSON(
  metadatumTcpjson: MetadatumTcpjson,
): string {
  return JSON.stringify(
    MetadatumTcpjson$outboundSchema.parse(metadatumTcpjson),
  );
}
export function metadatumTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumTcpjson' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodTcpjson$inboundSchema: z.ZodType<
  InputAuthenticationMethodTcpjson,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodTcpjson),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodTcpjson$outboundSchema: z.ZodType<
  InputAuthenticationMethodTcpjson,
  z.ZodTypeDef,
  InputAuthenticationMethodTcpjson
> = z.union([
  z.nativeEnum(InputAuthenticationMethodTcpjson),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputTcpjson$inboundSchema: z.ZodType<
  InputTcpjson,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeTcpjson$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionTcpjson$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqTcpjson$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideTcpjson$inboundSchema).optional(),
    ipWhitelistRegex: z.string().default("/.*/"),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    enableProxyHeader: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumTcpjson$inboundSchema)).optional(),
    enableLoadBalancing: z.boolean().default(false),
    authType: InputAuthenticationMethodTcpjson$inboundSchema.default("manual"),
    description: z.string().optional(),
    authToken: z.string().default(""),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputTcpjson$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionTcpjson$Outbound> | undefined;
  pq?: PqTcpjson$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideTcpjson$Outbound | undefined;
  ipWhitelistRegex: string;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  enableProxyHeader: boolean;
  metadata?: Array<MetadatumTcpjson$Outbound> | undefined;
  enableLoadBalancing: boolean;
  authType: string;
  description?: string | undefined;
  authToken: string;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputTcpjson$outboundSchema: z.ZodType<
  InputTcpjson$Outbound,
  z.ZodTypeDef,
  InputTcpjson
> = z.object({
  id: z.string().optional(),
  type: InputTypeTcpjson$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionTcpjson$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqTcpjson$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideTcpjson$outboundSchema).optional(),
  ipWhitelistRegex: z.string().default("/.*/"),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  enableProxyHeader: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumTcpjson$outboundSchema)).optional(),
  enableLoadBalancing: z.boolean().default(false),
  authType: InputAuthenticationMethodTcpjson$outboundSchema.default("manual"),
  description: z.string().optional(),
  authToken: z.string().default(""),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputTcpjsonToJSON(inputTcpjson: InputTcpjson): string {
  return JSON.stringify(InputTcpjson$outboundSchema.parse(inputTcpjson));
}
export function inputTcpjsonFromJSON(
  jsonString: string,
): SafeParseResult<InputTcpjson, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputTcpjson$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputTcpjson' from JSON`,
  );
}

/** @internal */
export const TypeCriblLakeHTTP$inboundSchema: z.ZodNativeEnum<
  typeof TypeCriblLakeHTTP
> = z.nativeEnum(TypeCriblLakeHTTP);
/** @internal */
export const TypeCriblLakeHTTP$outboundSchema: z.ZodNativeEnum<
  typeof TypeCriblLakeHTTP
> = TypeCriblLakeHTTP$inboundSchema;

/** @internal */
export const ConnectionCriblLakeHTTP$inboundSchema: z.ZodType<
  ConnectionCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCriblLakeHTTP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCriblLakeHTTP$outboundSchema: z.ZodType<
  ConnectionCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  ConnectionCriblLakeHTTP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCriblLakeHTTPToJSON(
  connectionCriblLakeHTTP: ConnectionCriblLakeHTTP,
): string {
  return JSON.stringify(
    ConnectionCriblLakeHTTP$outboundSchema.parse(connectionCriblLakeHTTP),
  );
}
export function connectionCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const ModeCriblLakeHTTP$inboundSchema: z.ZodType<
  ModeCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCriblLakeHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCriblLakeHTTP$outboundSchema: z.ZodType<
  ModeCriblLakeHTTP,
  z.ZodTypeDef,
  ModeCriblLakeHTTP
> = z.union([
  z.nativeEnum(ModeCriblLakeHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCriblLakeHTTP$inboundSchema: z.ZodType<
  CompressionCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCriblLakeHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCriblLakeHTTP$outboundSchema: z.ZodType<
  CompressionCriblLakeHTTP,
  z.ZodTypeDef,
  CompressionCriblLakeHTTP
> = z.union([
  z.nativeEnum(CompressionCriblLakeHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCriblLakeHTTP$inboundSchema: z.ZodType<
  PqControlsCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCriblLakeHTTP$Outbound = {};

/** @internal */
export const PqControlsCriblLakeHTTP$outboundSchema: z.ZodType<
  PqControlsCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  PqControlsCriblLakeHTTP
> = z.object({});

export function pqControlsCriblLakeHTTPToJSON(
  pqControlsCriblLakeHTTP: PqControlsCriblLakeHTTP,
): string {
  return JSON.stringify(
    PqControlsCriblLakeHTTP$outboundSchema.parse(pqControlsCriblLakeHTTP),
  );
}
export function pqControlsCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const PqCriblLakeHTTP$inboundSchema: z.ZodType<
  PqCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeCriblLakeHTTP$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCriblLakeHTTP$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCriblLakeHTTP$inboundSchema).optional(),
});
/** @internal */
export type PqCriblLakeHTTP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCriblLakeHTTP$Outbound | undefined;
};

/** @internal */
export const PqCriblLakeHTTP$outboundSchema: z.ZodType<
  PqCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  PqCriblLakeHTTP
> = z.object({
  mode: ModeCriblLakeHTTP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCriblLakeHTTP$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCriblLakeHTTP$outboundSchema).optional(),
});

export function pqCriblLakeHTTPToJSON(
  pqCriblLakeHTTP: PqCriblLakeHTTP,
): string {
  return JSON.stringify(PqCriblLakeHTTP$outboundSchema.parse(pqCriblLakeHTTP));
}
export function pqCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionCriblLakeHTTP$inboundSchema: z.ZodType<
  MinimumTLSVersionCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionCriblLakeHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionCriblLakeHTTP$outboundSchema: z.ZodType<
  MinimumTLSVersionCriblLakeHTTP,
  z.ZodTypeDef,
  MinimumTLSVersionCriblLakeHTTP
> = z.union([
  z.nativeEnum(MinimumTLSVersionCriblLakeHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionCriblLakeHTTP$inboundSchema: z.ZodType<
  MaximumTLSVersionCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionCriblLakeHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionCriblLakeHTTP$outboundSchema: z.ZodType<
  MaximumTLSVersionCriblLakeHTTP,
  z.ZodTypeDef,
  MaximumTLSVersionCriblLakeHTTP
> = z.union([
  z.nativeEnum(MaximumTLSVersionCriblLakeHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideCriblLakeHTTP$inboundSchema: z.ZodType<
  TLSSettingsServerSideCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionCriblLakeHTTP$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionCriblLakeHTTP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideCriblLakeHTTP$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideCriblLakeHTTP$outboundSchema: z.ZodType<
  TLSSettingsServerSideCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideCriblLakeHTTP
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionCriblLakeHTTP$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionCriblLakeHTTP$outboundSchema.optional(),
});

export function tlsSettingsServerSideCriblLakeHTTPToJSON(
  tlsSettingsServerSideCriblLakeHTTP: TLSSettingsServerSideCriblLakeHTTP,
): string {
  return JSON.stringify(
    TLSSettingsServerSideCriblLakeHTTP$outboundSchema.parse(
      tlsSettingsServerSideCriblLakeHTTP,
    ),
  );
}
export function tlsSettingsServerSideCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      TLSSettingsServerSideCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const MetadatumCriblLakeHTTP$inboundSchema: z.ZodType<
  MetadatumCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCriblLakeHTTP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCriblLakeHTTP$outboundSchema: z.ZodType<
  MetadatumCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  MetadatumCriblLakeHTTP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCriblLakeHTTPToJSON(
  metadatumCriblLakeHTTP: MetadatumCriblLakeHTTP,
): string {
  return JSON.stringify(
    MetadatumCriblLakeHTTP$outboundSchema.parse(metadatumCriblLakeHTTP),
  );
}
export function metadatumCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtMetadatumCriblLakeHTTP$inboundSchema: z.ZodType<
  AuthTokensExtMetadatumCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokensExtMetadatumCriblLakeHTTP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokensExtMetadatumCriblLakeHTTP$outboundSchema: z.ZodType<
  AuthTokensExtMetadatumCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  AuthTokensExtMetadatumCriblLakeHTTP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokensExtMetadatumCriblLakeHTTPToJSON(
  authTokensExtMetadatumCriblLakeHTTP: AuthTokensExtMetadatumCriblLakeHTTP,
): string {
  return JSON.stringify(
    AuthTokensExtMetadatumCriblLakeHTTP$outboundSchema.parse(
      authTokensExtMetadatumCriblLakeHTTP,
    ),
  );
}
export function authTokensExtMetadatumCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtMetadatumCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      AuthTokensExtMetadatumCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtMetadatumCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const SplunkHecMetadata$inboundSchema: z.ZodType<
  SplunkHecMetadata,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().optional(),
});
/** @internal */
export type SplunkHecMetadata$Outbound = {
  enabled?: boolean | undefined;
};

/** @internal */
export const SplunkHecMetadata$outboundSchema: z.ZodType<
  SplunkHecMetadata$Outbound,
  z.ZodTypeDef,
  SplunkHecMetadata
> = z.object({
  enabled: z.boolean().optional(),
});

export function splunkHecMetadataToJSON(
  splunkHecMetadata: SplunkHecMetadata,
): string {
  return JSON.stringify(
    SplunkHecMetadata$outboundSchema.parse(splunkHecMetadata),
  );
}
export function splunkHecMetadataFromJSON(
  jsonString: string,
): SafeParseResult<SplunkHecMetadata, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SplunkHecMetadata$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SplunkHecMetadata' from JSON`,
  );
}

/** @internal */
export const ElasticsearchMetadata$inboundSchema: z.ZodType<
  ElasticsearchMetadata,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().optional(),
});
/** @internal */
export type ElasticsearchMetadata$Outbound = {
  enabled?: boolean | undefined;
};

/** @internal */
export const ElasticsearchMetadata$outboundSchema: z.ZodType<
  ElasticsearchMetadata$Outbound,
  z.ZodTypeDef,
  ElasticsearchMetadata
> = z.object({
  enabled: z.boolean().optional(),
});

export function elasticsearchMetadataToJSON(
  elasticsearchMetadata: ElasticsearchMetadata,
): string {
  return JSON.stringify(
    ElasticsearchMetadata$outboundSchema.parse(elasticsearchMetadata),
  );
}
export function elasticsearchMetadataFromJSON(
  jsonString: string,
): SafeParseResult<ElasticsearchMetadata, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ElasticsearchMetadata$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ElasticsearchMetadata' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtCriblLakeHTTP$inboundSchema: z.ZodType<
  AuthTokensExtCriblLakeHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(
    z.lazy(() => AuthTokensExtMetadatumCriblLakeHTTP$inboundSchema),
  ).optional(),
  splunkHecMetadata: z.lazy(() => SplunkHecMetadata$inboundSchema).optional(),
  elasticsearchMetadata: z.lazy(() => ElasticsearchMetadata$inboundSchema)
    .optional(),
});
/** @internal */
export type AuthTokensExtCriblLakeHTTP$Outbound = {
  token: string;
  description?: string | undefined;
  metadata?: Array<AuthTokensExtMetadatumCriblLakeHTTP$Outbound> | undefined;
  splunkHecMetadata?: SplunkHecMetadata$Outbound | undefined;
  elasticsearchMetadata?: ElasticsearchMetadata$Outbound | undefined;
};

/** @internal */
export const AuthTokensExtCriblLakeHTTP$outboundSchema: z.ZodType<
  AuthTokensExtCriblLakeHTTP$Outbound,
  z.ZodTypeDef,
  AuthTokensExtCriblLakeHTTP
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(
    z.lazy(() => AuthTokensExtMetadatumCriblLakeHTTP$outboundSchema),
  ).optional(),
  splunkHecMetadata: z.lazy(() => SplunkHecMetadata$outboundSchema).optional(),
  elasticsearchMetadata: z.lazy(() => ElasticsearchMetadata$outboundSchema)
    .optional(),
});

export function authTokensExtCriblLakeHTTPToJSON(
  authTokensExtCriblLakeHTTP: AuthTokensExtCriblLakeHTTP,
): string {
  return JSON.stringify(
    AuthTokensExtCriblLakeHTTP$outboundSchema.parse(authTokensExtCriblLakeHTTP),
  );
}
export function authTokensExtCriblLakeHTTPFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtCriblLakeHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtCriblLakeHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtCriblLakeHTTP' from JSON`,
  );
}

/** @internal */
export const InputCriblLakeHttp$inboundSchema: z.ZodType<
  InputCriblLakeHttp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCriblLakeHTTP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCriblLakeHTTP$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCriblLakeHTTP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.string()).optional(),
    tls: z.lazy(() => TLSSettingsServerSideCriblLakeHTTP$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    criblAPI: z.string().default("/cribl"),
    elasticAPI: z.string().default("/elastic"),
    splunkHecAPI: z.string().default("/services/collector"),
    splunkHecAcks: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumCriblLakeHTTP$inboundSchema))
      .optional(),
    authTokensExt: z.array(
      z.lazy(() => AuthTokensExtCriblLakeHTTP$inboundSchema),
    ).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCriblLakeHttp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCriblLakeHTTP$Outbound> | undefined;
  pq?: PqCriblLakeHTTP$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideCriblLakeHTTP$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  criblAPI: string;
  elasticAPI: string;
  splunkHecAPI: string;
  splunkHecAcks: boolean;
  metadata?: Array<MetadatumCriblLakeHTTP$Outbound> | undefined;
  authTokensExt?: Array<AuthTokensExtCriblLakeHTTP$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCriblLakeHttp$outboundSchema: z.ZodType<
  InputCriblLakeHttp$Outbound,
  z.ZodTypeDef,
  InputCriblLakeHttp
> = z.object({
  id: z.string().optional(),
  type: TypeCriblLakeHTTP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCriblLakeHTTP$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCriblLakeHTTP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.string()).optional(),
  tls: z.lazy(() => TLSSettingsServerSideCriblLakeHTTP$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  criblAPI: z.string().default("/cribl"),
  elasticAPI: z.string().default("/elastic"),
  splunkHecAPI: z.string().default("/services/collector"),
  splunkHecAcks: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumCriblLakeHTTP$outboundSchema))
    .optional(),
  authTokensExt: z.array(
    z.lazy(() => AuthTokensExtCriblLakeHTTP$outboundSchema),
  ).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCriblLakeHttpToJSON(
  inputCriblLakeHttp: InputCriblLakeHttp,
): string {
  return JSON.stringify(
    InputCriblLakeHttp$outboundSchema.parse(inputCriblLakeHttp),
  );
}
export function inputCriblLakeHttpFromJSON(
  jsonString: string,
): SafeParseResult<InputCriblLakeHttp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCriblLakeHttp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCriblLakeHttp' from JSON`,
  );
}

/** @internal */
export const InputTypeCriblHTTP$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeCriblHTTP
> = z.nativeEnum(InputTypeCriblHTTP);
/** @internal */
export const InputTypeCriblHTTP$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeCriblHTTP
> = InputTypeCriblHTTP$inboundSchema;

/** @internal */
export const ConnectionCriblHTTP$inboundSchema: z.ZodType<
  ConnectionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCriblHTTP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCriblHTTP$outboundSchema: z.ZodType<
  ConnectionCriblHTTP$Outbound,
  z.ZodTypeDef,
  ConnectionCriblHTTP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCriblHTTPToJSON(
  connectionCriblHTTP: ConnectionCriblHTTP,
): string {
  return JSON.stringify(
    ConnectionCriblHTTP$outboundSchema.parse(connectionCriblHTTP),
  );
}
export function connectionCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCriblHTTP' from JSON`,
  );
}

/** @internal */
export const PqModeCriblHTTP$inboundSchema: z.ZodType<
  PqModeCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeCriblHTTP$outboundSchema: z.ZodType<
  PqModeCriblHTTP,
  z.ZodTypeDef,
  PqModeCriblHTTP
> = z.union([
  z.nativeEnum(PqModeCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionCriblHTTP$inboundSchema: z.ZodType<
  PqCompressionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionCriblHTTP$outboundSchema: z.ZodType<
  PqCompressionCriblHTTP,
  z.ZodTypeDef,
  PqCompressionCriblHTTP
> = z.union([
  z.nativeEnum(PqCompressionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsCriblHTTP$inboundSchema: z.ZodType<
  InputPqControlsCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsCriblHTTP$Outbound = {};

/** @internal */
export const InputPqControlsCriblHTTP$outboundSchema: z.ZodType<
  InputPqControlsCriblHTTP$Outbound,
  z.ZodTypeDef,
  InputPqControlsCriblHTTP
> = z.object({});

export function inputPqControlsCriblHTTPToJSON(
  inputPqControlsCriblHTTP: InputPqControlsCriblHTTP,
): string {
  return JSON.stringify(
    InputPqControlsCriblHTTP$outboundSchema.parse(inputPqControlsCriblHTTP),
  );
}
export function inputPqControlsCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsCriblHTTP' from JSON`,
  );
}

/** @internal */
export const PqCriblHTTP$inboundSchema: z.ZodType<
  PqCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeCriblHTTP$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionCriblHTTP$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsCriblHTTP$inboundSchema).optional(),
});
/** @internal */
export type PqCriblHTTP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsCriblHTTP$Outbound | undefined;
};

/** @internal */
export const PqCriblHTTP$outboundSchema: z.ZodType<
  PqCriblHTTP$Outbound,
  z.ZodTypeDef,
  PqCriblHTTP
> = z.object({
  mode: PqModeCriblHTTP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionCriblHTTP$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsCriblHTTP$outboundSchema).optional(),
});

export function pqCriblHTTPToJSON(pqCriblHTTP: PqCriblHTTP): string {
  return JSON.stringify(PqCriblHTTP$outboundSchema.parse(pqCriblHTTP));
}
export function pqCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCriblHTTP' from JSON`,
  );
}

/** @internal */
export const InputAuthTokenCriblHTTP$inboundSchema: z.ZodType<
  InputAuthTokenCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});
/** @internal */
export type InputAuthTokenCriblHTTP$Outbound = {
  tokenSecret: string;
  enabled: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputAuthTokenCriblHTTP$outboundSchema: z.ZodType<
  InputAuthTokenCriblHTTP$Outbound,
  z.ZodTypeDef,
  InputAuthTokenCriblHTTP
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});

export function inputAuthTokenCriblHTTPToJSON(
  inputAuthTokenCriblHTTP: InputAuthTokenCriblHTTP,
): string {
  return JSON.stringify(
    InputAuthTokenCriblHTTP$outboundSchema.parse(inputAuthTokenCriblHTTP),
  );
}
export function inputAuthTokenCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthTokenCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthTokenCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthTokenCriblHTTP' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionCriblHTTP$inboundSchema: z.ZodType<
  InputMinimumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionCriblHTTP$outboundSchema: z.ZodType<
  InputMinimumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  InputMinimumTLSVersionCriblHTTP
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionCriblHTTP$inboundSchema: z.ZodType<
  InputMaximumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionCriblHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionCriblHTTP$outboundSchema: z.ZodType<
  InputMaximumTLSVersionCriblHTTP,
  z.ZodTypeDef,
  InputMaximumTLSVersionCriblHTTP
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionCriblHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideCriblHTTP$inboundSchema: z.ZodType<
  TLSSettingsServerSideCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionCriblHTTP$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionCriblHTTP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideCriblHTTP$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideCriblHTTP$outboundSchema: z.ZodType<
  TLSSettingsServerSideCriblHTTP$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideCriblHTTP
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionCriblHTTP$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionCriblHTTP$outboundSchema.optional(),
});

export function tlsSettingsServerSideCriblHTTPToJSON(
  tlsSettingsServerSideCriblHTTP: TLSSettingsServerSideCriblHTTP,
): string {
  return JSON.stringify(
    TLSSettingsServerSideCriblHTTP$outboundSchema.parse(
      tlsSettingsServerSideCriblHTTP,
    ),
  );
}
export function tlsSettingsServerSideCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideCriblHTTP' from JSON`,
  );
}

/** @internal */
export const MetadatumCriblHTTP$inboundSchema: z.ZodType<
  MetadatumCriblHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCriblHTTP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCriblHTTP$outboundSchema: z.ZodType<
  MetadatumCriblHTTP$Outbound,
  z.ZodTypeDef,
  MetadatumCriblHTTP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCriblHTTPToJSON(
  metadatumCriblHTTP: MetadatumCriblHTTP,
): string {
  return JSON.stringify(
    MetadatumCriblHTTP$outboundSchema.parse(metadatumCriblHTTP),
  );
}
export function metadatumCriblHTTPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCriblHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCriblHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCriblHTTP' from JSON`,
  );
}

/** @internal */
export const InputCriblHttp$inboundSchema: z.ZodType<
  InputCriblHttp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeCriblHTTP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCriblHTTP$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCriblHTTP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.lazy(() => InputAuthTokenCriblHTTP$inboundSchema))
      .optional(),
    tls: z.lazy(() => TLSSettingsServerSideCriblHTTP$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    metadata: z.array(z.lazy(() => MetadatumCriblHTTP$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCriblHttp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCriblHTTP$Outbound> | undefined;
  pq?: PqCriblHTTP$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<InputAuthTokenCriblHTTP$Outbound> | undefined;
  tls?: TLSSettingsServerSideCriblHTTP$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  metadata?: Array<MetadatumCriblHTTP$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCriblHttp$outboundSchema: z.ZodType<
  InputCriblHttp$Outbound,
  z.ZodTypeDef,
  InputCriblHttp
> = z.object({
  id: z.string().optional(),
  type: InputTypeCriblHTTP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCriblHTTP$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCriblHTTP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.lazy(() => InputAuthTokenCriblHTTP$outboundSchema))
    .optional(),
  tls: z.lazy(() => TLSSettingsServerSideCriblHTTP$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  metadata: z.array(z.lazy(() => MetadatumCriblHTTP$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCriblHttpToJSON(inputCriblHttp: InputCriblHttp): string {
  return JSON.stringify(InputCriblHttp$outboundSchema.parse(inputCriblHttp));
}
export function inputCriblHttpFromJSON(
  jsonString: string,
): SafeParseResult<InputCriblHttp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCriblHttp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCriblHttp' from JSON`,
  );
}

/** @internal */
export const InputTypeCriblTCP$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeCriblTCP
> = z.nativeEnum(InputTypeCriblTCP);
/** @internal */
export const InputTypeCriblTCP$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeCriblTCP
> = InputTypeCriblTCP$inboundSchema;

/** @internal */
export const ConnectionCriblTCP$inboundSchema: z.ZodType<
  ConnectionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCriblTCP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCriblTCP$outboundSchema: z.ZodType<
  ConnectionCriblTCP$Outbound,
  z.ZodTypeDef,
  ConnectionCriblTCP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCriblTCPToJSON(
  connectionCriblTCP: ConnectionCriblTCP,
): string {
  return JSON.stringify(
    ConnectionCriblTCP$outboundSchema.parse(connectionCriblTCP),
  );
}
export function connectionCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCriblTCP' from JSON`,
  );
}

/** @internal */
export const PqModeCriblTCP$inboundSchema: z.ZodType<
  PqModeCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeCriblTCP$outboundSchema: z.ZodType<
  PqModeCriblTCP,
  z.ZodTypeDef,
  PqModeCriblTCP
> = z.union([
  z.nativeEnum(PqModeCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionCriblTCP$inboundSchema: z.ZodType<
  PqCompressionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionCriblTCP$outboundSchema: z.ZodType<
  PqCompressionCriblTCP,
  z.ZodTypeDef,
  PqCompressionCriblTCP
> = z.union([
  z.nativeEnum(PqCompressionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsCriblTCP$inboundSchema: z.ZodType<
  InputPqControlsCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsCriblTCP$Outbound = {};

/** @internal */
export const InputPqControlsCriblTCP$outboundSchema: z.ZodType<
  InputPqControlsCriblTCP$Outbound,
  z.ZodTypeDef,
  InputPqControlsCriblTCP
> = z.object({});

export function inputPqControlsCriblTCPToJSON(
  inputPqControlsCriblTCP: InputPqControlsCriblTCP,
): string {
  return JSON.stringify(
    InputPqControlsCriblTCP$outboundSchema.parse(inputPqControlsCriblTCP),
  );
}
export function inputPqControlsCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsCriblTCP' from JSON`,
  );
}

/** @internal */
export const PqCriblTCP$inboundSchema: z.ZodType<
  PqCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeCriblTCP$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionCriblTCP$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsCriblTCP$inboundSchema).optional(),
});
/** @internal */
export type PqCriblTCP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsCriblTCP$Outbound | undefined;
};

/** @internal */
export const PqCriblTCP$outboundSchema: z.ZodType<
  PqCriblTCP$Outbound,
  z.ZodTypeDef,
  PqCriblTCP
> = z.object({
  mode: PqModeCriblTCP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionCriblTCP$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsCriblTCP$outboundSchema).optional(),
});

export function pqCriblTCPToJSON(pqCriblTCP: PqCriblTCP): string {
  return JSON.stringify(PqCriblTCP$outboundSchema.parse(pqCriblTCP));
}
export function pqCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<PqCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCriblTCP' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionCriblTCP$inboundSchema: z.ZodType<
  InputMinimumTLSVersionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionCriblTCP$outboundSchema: z.ZodType<
  InputMinimumTLSVersionCriblTCP,
  z.ZodTypeDef,
  InputMinimumTLSVersionCriblTCP
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionCriblTCP$inboundSchema: z.ZodType<
  InputMaximumTLSVersionCriblTCP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionCriblTCP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionCriblTCP$outboundSchema: z.ZodType<
  InputMaximumTLSVersionCriblTCP,
  z.ZodTypeDef,
  InputMaximumTLSVersionCriblTCP
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionCriblTCP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideCriblTCP$inboundSchema: z.ZodType<
  TLSSettingsServerSideCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionCriblTCP$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionCriblTCP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideCriblTCP$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideCriblTCP$outboundSchema: z.ZodType<
  TLSSettingsServerSideCriblTCP$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideCriblTCP
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionCriblTCP$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionCriblTCP$outboundSchema.optional(),
});

export function tlsSettingsServerSideCriblTCPToJSON(
  tlsSettingsServerSideCriblTCP: TLSSettingsServerSideCriblTCP,
): string {
  return JSON.stringify(
    TLSSettingsServerSideCriblTCP$outboundSchema.parse(
      tlsSettingsServerSideCriblTCP,
    ),
  );
}
export function tlsSettingsServerSideCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideCriblTCP' from JSON`,
  );
}

/** @internal */
export const MetadatumCriblTCP$inboundSchema: z.ZodType<
  MetadatumCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCriblTCP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCriblTCP$outboundSchema: z.ZodType<
  MetadatumCriblTCP$Outbound,
  z.ZodTypeDef,
  MetadatumCriblTCP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCriblTCPToJSON(
  metadatumCriblTCP: MetadatumCriblTCP,
): string {
  return JSON.stringify(
    MetadatumCriblTCP$outboundSchema.parse(metadatumCriblTCP),
  );
}
export function metadatumCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCriblTCP' from JSON`,
  );
}

/** @internal */
export const InputAuthTokenCriblTCP$inboundSchema: z.ZodType<
  InputAuthTokenCriblTCP,
  z.ZodTypeDef,
  unknown
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});
/** @internal */
export type InputAuthTokenCriblTCP$Outbound = {
  tokenSecret: string;
  enabled: boolean;
  description?: string | undefined;
};

/** @internal */
export const InputAuthTokenCriblTCP$outboundSchema: z.ZodType<
  InputAuthTokenCriblTCP$Outbound,
  z.ZodTypeDef,
  InputAuthTokenCriblTCP
> = z.object({
  tokenSecret: z.string(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
});

export function inputAuthTokenCriblTCPToJSON(
  inputAuthTokenCriblTCP: InputAuthTokenCriblTCP,
): string {
  return JSON.stringify(
    InputAuthTokenCriblTCP$outboundSchema.parse(inputAuthTokenCriblTCP),
  );
}
export function inputAuthTokenCriblTCPFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthTokenCriblTCP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthTokenCriblTCP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthTokenCriblTCP' from JSON`,
  );
}

/** @internal */
export const InputCriblTcp$inboundSchema: z.ZodType<
  InputCriblTcp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeCriblTCP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCriblTCP$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCriblTCP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideCriblTCP$inboundSchema).optional(),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    enableProxyHeader: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumCriblTCP$inboundSchema)).optional(),
    enableLoadBalancing: z.boolean().default(false),
    authTokens: z.array(z.lazy(() => InputAuthTokenCriblTCP$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCriblTcp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCriblTCP$Outbound> | undefined;
  pq?: PqCriblTCP$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideCriblTCP$Outbound | undefined;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  enableProxyHeader: boolean;
  metadata?: Array<MetadatumCriblTCP$Outbound> | undefined;
  enableLoadBalancing: boolean;
  authTokens?: Array<InputAuthTokenCriblTCP$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCriblTcp$outboundSchema: z.ZodType<
  InputCriblTcp$Outbound,
  z.ZodTypeDef,
  InputCriblTcp
> = z.object({
  id: z.string().optional(),
  type: InputTypeCriblTCP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCriblTCP$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCriblTCP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideCriblTCP$outboundSchema).optional(),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  enableProxyHeader: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumCriblTCP$outboundSchema)).optional(),
  enableLoadBalancing: z.boolean().default(false),
  authTokens: z.array(z.lazy(() => InputAuthTokenCriblTCP$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCriblTcpToJSON(inputCriblTcp: InputCriblTcp): string {
  return JSON.stringify(InputCriblTcp$outboundSchema.parse(inputCriblTcp));
}
export function inputCriblTcpFromJSON(
  jsonString: string,
): SafeParseResult<InputCriblTcp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCriblTcp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCriblTcp' from JSON`,
  );
}

/** @internal */
export const TypeCribl$inboundSchema: z.ZodNativeEnum<typeof TypeCribl> = z
  .nativeEnum(TypeCribl);
/** @internal */
export const TypeCribl$outboundSchema: z.ZodNativeEnum<typeof TypeCribl> =
  TypeCribl$inboundSchema;

/** @internal */
export const ConnectionCribl$inboundSchema: z.ZodType<
  ConnectionCribl,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCribl$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCribl$outboundSchema: z.ZodType<
  ConnectionCribl$Outbound,
  z.ZodTypeDef,
  ConnectionCribl
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCriblToJSON(
  connectionCribl: ConnectionCribl,
): string {
  return JSON.stringify(ConnectionCribl$outboundSchema.parse(connectionCribl));
}
export function connectionCriblFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCribl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCribl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCribl' from JSON`,
  );
}

/** @internal */
export const ModeCribl$inboundSchema: z.ZodType<
  ModeCribl,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCribl),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCribl$outboundSchema: z.ZodType<
  ModeCribl,
  z.ZodTypeDef,
  ModeCribl
> = z.union([
  z.nativeEnum(ModeCribl),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCribl$inboundSchema: z.ZodType<
  CompressionCribl,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCribl),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCribl$outboundSchema: z.ZodType<
  CompressionCribl,
  z.ZodTypeDef,
  CompressionCribl
> = z.union([
  z.nativeEnum(CompressionCribl),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCribl$inboundSchema: z.ZodType<
  PqControlsCribl,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCribl$Outbound = {};

/** @internal */
export const PqControlsCribl$outboundSchema: z.ZodType<
  PqControlsCribl$Outbound,
  z.ZodTypeDef,
  PqControlsCribl
> = z.object({});

export function pqControlsCriblToJSON(
  pqControlsCribl: PqControlsCribl,
): string {
  return JSON.stringify(PqControlsCribl$outboundSchema.parse(pqControlsCribl));
}
export function pqControlsCriblFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCribl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCribl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCribl' from JSON`,
  );
}

/** @internal */
export const PqCribl$inboundSchema: z.ZodType<PqCribl, z.ZodTypeDef, unknown> =
  z.object({
    mode: ModeCribl$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionCribl$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsCribl$inboundSchema).optional(),
  });
/** @internal */
export type PqCribl$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCribl$Outbound | undefined;
};

/** @internal */
export const PqCribl$outboundSchema: z.ZodType<
  PqCribl$Outbound,
  z.ZodTypeDef,
  PqCribl
> = z.object({
  mode: ModeCribl$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCribl$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCribl$outboundSchema).optional(),
});

export function pqCriblToJSON(pqCribl: PqCribl): string {
  return JSON.stringify(PqCribl$outboundSchema.parse(pqCribl));
}
export function pqCriblFromJSON(
  jsonString: string,
): SafeParseResult<PqCribl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCribl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCribl' from JSON`,
  );
}

/** @internal */
export const MetadatumCribl$inboundSchema: z.ZodType<
  MetadatumCribl,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCribl$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCribl$outboundSchema: z.ZodType<
  MetadatumCribl$Outbound,
  z.ZodTypeDef,
  MetadatumCribl
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCriblToJSON(metadatumCribl: MetadatumCribl): string {
  return JSON.stringify(MetadatumCribl$outboundSchema.parse(metadatumCribl));
}
export function metadatumCriblFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCribl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCribl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCribl' from JSON`,
  );
}

/** @internal */
export const InputCribl$inboundSchema: z.ZodType<
  InputCribl,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeCribl$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCribl$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCribl$inboundSchema).optional(),
    filter: z.string().optional(),
    metadata: z.array(z.lazy(() => MetadatumCribl$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCribl$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCribl$Outbound> | undefined;
  pq?: PqCribl$Outbound | undefined;
  filter?: string | undefined;
  metadata?: Array<MetadatumCribl$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCribl$outboundSchema: z.ZodType<
  InputCribl$Outbound,
  z.ZodTypeDef,
  InputCribl
> = z.object({
  id: z.string().optional(),
  type: TypeCribl$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCribl$outboundSchema)).optional(),
  pq: z.lazy(() => PqCribl$outboundSchema).optional(),
  filter: z.string().optional(),
  metadata: z.array(z.lazy(() => MetadatumCribl$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCriblToJSON(inputCribl: InputCribl): string {
  return JSON.stringify(InputCribl$outboundSchema.parse(inputCribl));
}
export function inputCriblFromJSON(
  jsonString: string,
): SafeParseResult<InputCribl, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCribl$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCribl' from JSON`,
  );
}

/** @internal */
export const InputTypeGooglePubsub$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeGooglePubsub
> = z.nativeEnum(InputTypeGooglePubsub);
/** @internal */
export const InputTypeGooglePubsub$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeGooglePubsub
> = InputTypeGooglePubsub$inboundSchema;

/** @internal */
export const ConnectionGooglePubsub$inboundSchema: z.ZodType<
  ConnectionGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionGooglePubsub$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionGooglePubsub$outboundSchema: z.ZodType<
  ConnectionGooglePubsub$Outbound,
  z.ZodTypeDef,
  ConnectionGooglePubsub
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionGooglePubsubToJSON(
  connectionGooglePubsub: ConnectionGooglePubsub,
): string {
  return JSON.stringify(
    ConnectionGooglePubsub$outboundSchema.parse(connectionGooglePubsub),
  );
}
export function connectionGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionGooglePubsub' from JSON`,
  );
}

/** @internal */
export const PqModeGooglePubsub$inboundSchema: z.ZodType<
  PqModeGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeGooglePubsub$outboundSchema: z.ZodType<
  PqModeGooglePubsub,
  z.ZodTypeDef,
  PqModeGooglePubsub
> = z.union([
  z.nativeEnum(PqModeGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionGooglePubsub$inboundSchema: z.ZodType<
  PqCompressionGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionGooglePubsub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionGooglePubsub$outboundSchema: z.ZodType<
  PqCompressionGooglePubsub,
  z.ZodTypeDef,
  PqCompressionGooglePubsub
> = z.union([
  z.nativeEnum(PqCompressionGooglePubsub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsGooglePubsub$inboundSchema: z.ZodType<
  InputPqControlsGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsGooglePubsub$Outbound = {};

/** @internal */
export const InputPqControlsGooglePubsub$outboundSchema: z.ZodType<
  InputPqControlsGooglePubsub$Outbound,
  z.ZodTypeDef,
  InputPqControlsGooglePubsub
> = z.object({});

export function inputPqControlsGooglePubsubToJSON(
  inputPqControlsGooglePubsub: InputPqControlsGooglePubsub,
): string {
  return JSON.stringify(
    InputPqControlsGooglePubsub$outboundSchema.parse(
      inputPqControlsGooglePubsub,
    ),
  );
}
export function inputPqControlsGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsGooglePubsub' from JSON`,
  );
}

/** @internal */
export const PqGooglePubsub$inboundSchema: z.ZodType<
  PqGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeGooglePubsub$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionGooglePubsub$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsGooglePubsub$inboundSchema)
    .optional(),
});
/** @internal */
export type PqGooglePubsub$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsGooglePubsub$Outbound | undefined;
};

/** @internal */
export const PqGooglePubsub$outboundSchema: z.ZodType<
  PqGooglePubsub$Outbound,
  z.ZodTypeDef,
  PqGooglePubsub
> = z.object({
  mode: PqModeGooglePubsub$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionGooglePubsub$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsGooglePubsub$outboundSchema)
    .optional(),
});

export function pqGooglePubsubToJSON(pqGooglePubsub: PqGooglePubsub): string {
  return JSON.stringify(PqGooglePubsub$outboundSchema.parse(pqGooglePubsub));
}
export function pqGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<PqGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqGooglePubsub' from JSON`,
  );
}

/** @internal */
export const InputGoogleAuthenticationMethod$inboundSchema: z.ZodType<
  InputGoogleAuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGoogleAuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGoogleAuthenticationMethod$outboundSchema: z.ZodType<
  InputGoogleAuthenticationMethod,
  z.ZodTypeDef,
  InputGoogleAuthenticationMethod
> = z.union([
  z.nativeEnum(InputGoogleAuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumGooglePubsub$inboundSchema: z.ZodType<
  MetadatumGooglePubsub,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumGooglePubsub$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumGooglePubsub$outboundSchema: z.ZodType<
  MetadatumGooglePubsub$Outbound,
  z.ZodTypeDef,
  MetadatumGooglePubsub
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumGooglePubsubToJSON(
  metadatumGooglePubsub: MetadatumGooglePubsub,
): string {
  return JSON.stringify(
    MetadatumGooglePubsub$outboundSchema.parse(metadatumGooglePubsub),
  );
}
export function metadatumGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumGooglePubsub' from JSON`,
  );
}

/** @internal */
export const InputGooglePubsub$inboundSchema: z.ZodType<
  InputGooglePubsub,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeGooglePubsub$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionGooglePubsub$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqGooglePubsub$inboundSchema).optional(),
    topicName: z.string().default("cribl"),
    subscriptionName: z.string(),
    monitorSubscription: z.boolean().default(false),
    createTopic: z.boolean().default(false),
    createSubscription: z.boolean().default(true),
    region: z.string().optional(),
    googleAuthMethod: InputGoogleAuthenticationMethod$inboundSchema.default(
      "manual",
    ),
    serviceAccountCredentials: z.string().optional(),
    secret: z.string().optional(),
    maxBacklog: z.number().default(1000),
    concurrency: z.number().default(5),
    requestTimeout: z.number().default(60000),
    metadata: z.array(z.lazy(() => MetadatumGooglePubsub$inboundSchema))
      .optional(),
    description: z.string().optional(),
    orderedDelivery: z.boolean().default(false),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputGooglePubsub$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionGooglePubsub$Outbound> | undefined;
  pq?: PqGooglePubsub$Outbound | undefined;
  topicName: string;
  subscriptionName: string;
  monitorSubscription: boolean;
  createTopic: boolean;
  createSubscription: boolean;
  region?: string | undefined;
  googleAuthMethod: string;
  serviceAccountCredentials?: string | undefined;
  secret?: string | undefined;
  maxBacklog: number;
  concurrency: number;
  requestTimeout: number;
  metadata?: Array<MetadatumGooglePubsub$Outbound> | undefined;
  description?: string | undefined;
  orderedDelivery: boolean;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputGooglePubsub$outboundSchema: z.ZodType<
  InputGooglePubsub$Outbound,
  z.ZodTypeDef,
  InputGooglePubsub
> = z.object({
  id: z.string().optional(),
  type: InputTypeGooglePubsub$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionGooglePubsub$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqGooglePubsub$outboundSchema).optional(),
  topicName: z.string().default("cribl"),
  subscriptionName: z.string(),
  monitorSubscription: z.boolean().default(false),
  createTopic: z.boolean().default(false),
  createSubscription: z.boolean().default(true),
  region: z.string().optional(),
  googleAuthMethod: InputGoogleAuthenticationMethod$outboundSchema.default(
    "manual",
  ),
  serviceAccountCredentials: z.string().optional(),
  secret: z.string().optional(),
  maxBacklog: z.number().default(1000),
  concurrency: z.number().default(5),
  requestTimeout: z.number().default(60000),
  metadata: z.array(z.lazy(() => MetadatumGooglePubsub$outboundSchema))
    .optional(),
  description: z.string().optional(),
  orderedDelivery: z.boolean().default(false),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputGooglePubsubToJSON(
  inputGooglePubsub: InputGooglePubsub,
): string {
  return JSON.stringify(
    InputGooglePubsub$outboundSchema.parse(inputGooglePubsub),
  );
}
export function inputGooglePubsubFromJSON(
  jsonString: string,
): SafeParseResult<InputGooglePubsub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGooglePubsub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGooglePubsub' from JSON`,
  );
}

/** @internal */
export const TypeFirehose$inboundSchema: z.ZodNativeEnum<typeof TypeFirehose> =
  z.nativeEnum(TypeFirehose);
/** @internal */
export const TypeFirehose$outboundSchema: z.ZodNativeEnum<typeof TypeFirehose> =
  TypeFirehose$inboundSchema;

/** @internal */
export const ConnectionFirehose$inboundSchema: z.ZodType<
  ConnectionFirehose,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionFirehose$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionFirehose$outboundSchema: z.ZodType<
  ConnectionFirehose$Outbound,
  z.ZodTypeDef,
  ConnectionFirehose
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionFirehoseToJSON(
  connectionFirehose: ConnectionFirehose,
): string {
  return JSON.stringify(
    ConnectionFirehose$outboundSchema.parse(connectionFirehose),
  );
}
export function connectionFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionFirehose' from JSON`,
  );
}

/** @internal */
export const ModeFirehose$inboundSchema: z.ZodType<
  ModeFirehose,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeFirehose),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeFirehose$outboundSchema: z.ZodType<
  ModeFirehose,
  z.ZodTypeDef,
  ModeFirehose
> = z.union([
  z.nativeEnum(ModeFirehose),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionFirehose$inboundSchema: z.ZodType<
  CompressionFirehose,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionFirehose),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionFirehose$outboundSchema: z.ZodType<
  CompressionFirehose,
  z.ZodTypeDef,
  CompressionFirehose
> = z.union([
  z.nativeEnum(CompressionFirehose),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsFirehose$inboundSchema: z.ZodType<
  PqControlsFirehose,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsFirehose$Outbound = {};

/** @internal */
export const PqControlsFirehose$outboundSchema: z.ZodType<
  PqControlsFirehose$Outbound,
  z.ZodTypeDef,
  PqControlsFirehose
> = z.object({});

export function pqControlsFirehoseToJSON(
  pqControlsFirehose: PqControlsFirehose,
): string {
  return JSON.stringify(
    PqControlsFirehose$outboundSchema.parse(pqControlsFirehose),
  );
}
export function pqControlsFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsFirehose' from JSON`,
  );
}

/** @internal */
export const PqFirehose$inboundSchema: z.ZodType<
  PqFirehose,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeFirehose$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionFirehose$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsFirehose$inboundSchema).optional(),
});
/** @internal */
export type PqFirehose$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsFirehose$Outbound | undefined;
};

/** @internal */
export const PqFirehose$outboundSchema: z.ZodType<
  PqFirehose$Outbound,
  z.ZodTypeDef,
  PqFirehose
> = z.object({
  mode: ModeFirehose$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionFirehose$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsFirehose$outboundSchema).optional(),
});

export function pqFirehoseToJSON(pqFirehose: PqFirehose): string {
  return JSON.stringify(PqFirehose$outboundSchema.parse(pqFirehose));
}
export function pqFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<PqFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqFirehose' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionFirehose$inboundSchema: z.ZodType<
  MinimumTLSVersionFirehose,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionFirehose),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionFirehose$outboundSchema: z.ZodType<
  MinimumTLSVersionFirehose,
  z.ZodTypeDef,
  MinimumTLSVersionFirehose
> = z.union([
  z.nativeEnum(MinimumTLSVersionFirehose),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionFirehose$inboundSchema: z.ZodType<
  MaximumTLSVersionFirehose,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionFirehose),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionFirehose$outboundSchema: z.ZodType<
  MaximumTLSVersionFirehose,
  z.ZodTypeDef,
  MaximumTLSVersionFirehose
> = z.union([
  z.nativeEnum(MaximumTLSVersionFirehose),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideFirehose$inboundSchema: z.ZodType<
  TLSSettingsServerSideFirehose,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionFirehose$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionFirehose$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideFirehose$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideFirehose$outboundSchema: z.ZodType<
  TLSSettingsServerSideFirehose$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideFirehose
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionFirehose$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionFirehose$outboundSchema.optional(),
});

export function tlsSettingsServerSideFirehoseToJSON(
  tlsSettingsServerSideFirehose: TLSSettingsServerSideFirehose,
): string {
  return JSON.stringify(
    TLSSettingsServerSideFirehose$outboundSchema.parse(
      tlsSettingsServerSideFirehose,
    ),
  );
}
export function tlsSettingsServerSideFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideFirehose' from JSON`,
  );
}

/** @internal */
export const MetadatumFirehose$inboundSchema: z.ZodType<
  MetadatumFirehose,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumFirehose$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumFirehose$outboundSchema: z.ZodType<
  MetadatumFirehose$Outbound,
  z.ZodTypeDef,
  MetadatumFirehose
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumFirehoseToJSON(
  metadatumFirehose: MetadatumFirehose,
): string {
  return JSON.stringify(
    MetadatumFirehose$outboundSchema.parse(metadatumFirehose),
  );
}
export function metadatumFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumFirehose' from JSON`,
  );
}

/** @internal */
export const InputFirehose$inboundSchema: z.ZodType<
  InputFirehose,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeFirehose$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionFirehose$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqFirehose$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.string()).optional(),
    tls: z.lazy(() => TLSSettingsServerSideFirehose$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    metadata: z.array(z.lazy(() => MetadatumFirehose$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputFirehose$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionFirehose$Outbound> | undefined;
  pq?: PqFirehose$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideFirehose$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  metadata?: Array<MetadatumFirehose$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputFirehose$outboundSchema: z.ZodType<
  InputFirehose$Outbound,
  z.ZodTypeDef,
  InputFirehose
> = z.object({
  id: z.string().optional(),
  type: TypeFirehose$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionFirehose$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqFirehose$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.string()).optional(),
  tls: z.lazy(() => TLSSettingsServerSideFirehose$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  metadata: z.array(z.lazy(() => MetadatumFirehose$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputFirehoseToJSON(inputFirehose: InputFirehose): string {
  return JSON.stringify(InputFirehose$outboundSchema.parse(inputFirehose));
}
export function inputFirehoseFromJSON(
  jsonString: string,
): SafeParseResult<InputFirehose, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputFirehose$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputFirehose' from JSON`,
  );
}

/** @internal */
export const InputExecType$inboundSchema: z.ZodNativeEnum<
  typeof InputExecType
> = z.nativeEnum(InputExecType);
/** @internal */
export const InputExecType$outboundSchema: z.ZodNativeEnum<
  typeof InputExecType
> = InputExecType$inboundSchema;

/** @internal */
export const InputExecConnection$inboundSchema: z.ZodType<
  InputExecConnection,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputExecConnection$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputExecConnection$outboundSchema: z.ZodType<
  InputExecConnection$Outbound,
  z.ZodTypeDef,
  InputExecConnection
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputExecConnectionToJSON(
  inputExecConnection: InputExecConnection,
): string {
  return JSON.stringify(
    InputExecConnection$outboundSchema.parse(inputExecConnection),
  );
}
export function inputExecConnectionFromJSON(
  jsonString: string,
): SafeParseResult<InputExecConnection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExecConnection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExecConnection' from JSON`,
  );
}

/** @internal */
export const InputExecMode$inboundSchema: z.ZodType<
  InputExecMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputExecMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputExecMode$outboundSchema: z.ZodType<
  InputExecMode,
  z.ZodTypeDef,
  InputExecMode
> = z.union([
  z.nativeEnum(InputExecMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputExecCompression$inboundSchema: z.ZodType<
  InputExecCompression,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputExecCompression),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputExecCompression$outboundSchema: z.ZodType<
  InputExecCompression,
  z.ZodTypeDef,
  InputExecCompression
> = z.union([
  z.nativeEnum(InputExecCompression),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputExecPqControls$inboundSchema: z.ZodType<
  InputExecPqControls,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputExecPqControls$Outbound = {};

/** @internal */
export const InputExecPqControls$outboundSchema: z.ZodType<
  InputExecPqControls$Outbound,
  z.ZodTypeDef,
  InputExecPqControls
> = z.object({});

export function inputExecPqControlsToJSON(
  inputExecPqControls: InputExecPqControls,
): string {
  return JSON.stringify(
    InputExecPqControls$outboundSchema.parse(inputExecPqControls),
  );
}
export function inputExecPqControlsFromJSON(
  jsonString: string,
): SafeParseResult<InputExecPqControls, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExecPqControls$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExecPqControls' from JSON`,
  );
}

/** @internal */
export const InputExecPq$inboundSchema: z.ZodType<
  InputExecPq,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputExecMode$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputExecCompression$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputExecPqControls$inboundSchema).optional(),
});
/** @internal */
export type InputExecPq$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputExecPqControls$Outbound | undefined;
};

/** @internal */
export const InputExecPq$outboundSchema: z.ZodType<
  InputExecPq$Outbound,
  z.ZodTypeDef,
  InputExecPq
> = z.object({
  mode: InputExecMode$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputExecCompression$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputExecPqControls$outboundSchema).optional(),
});

export function inputExecPqToJSON(inputExecPq: InputExecPq): string {
  return JSON.stringify(InputExecPq$outboundSchema.parse(inputExecPq));
}
export function inputExecPqFromJSON(
  jsonString: string,
): SafeParseResult<InputExecPq, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExecPq$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExecPq' from JSON`,
  );
}

/** @internal */
export const ScheduleType$inboundSchema: z.ZodType<
  ScheduleType,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ScheduleType),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ScheduleType$outboundSchema: z.ZodType<
  ScheduleType,
  z.ZodTypeDef,
  ScheduleType
> = z.union([
  z.nativeEnum(ScheduleType),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputExecMetadatum$inboundSchema: z.ZodType<
  InputExecMetadatum,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputExecMetadatum$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputExecMetadatum$outboundSchema: z.ZodType<
  InputExecMetadatum$Outbound,
  z.ZodTypeDef,
  InputExecMetadatum
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputExecMetadatumToJSON(
  inputExecMetadatum: InputExecMetadatum,
): string {
  return JSON.stringify(
    InputExecMetadatum$outboundSchema.parse(inputExecMetadatum),
  );
}
export function inputExecMetadatumFromJSON(
  jsonString: string,
): SafeParseResult<InputExecMetadatum, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExecMetadatum$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExecMetadatum' from JSON`,
  );
}

/** @internal */
export const InputExec$inboundSchema: z.ZodType<
  InputExec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputExecType$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputExecConnection$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputExecPq$inboundSchema).optional(),
    command: z.string(),
    retries: z.number().default(10),
    scheduleType: ScheduleType$inboundSchema.default("interval"),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    metadata: z.array(z.lazy(() => InputExecMetadatum$inboundSchema))
      .optional(),
    description: z.string().optional(),
    interval: z.number().default(60),
    cronSchedule: z.string().default("* * * * *"),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputExec$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputExecConnection$Outbound> | undefined;
  pq?: InputExecPq$Outbound | undefined;
  command: string;
  retries: number;
  scheduleType: string;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  metadata?: Array<InputExecMetadatum$Outbound> | undefined;
  description?: string | undefined;
  interval: number;
  cronSchedule: string;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputExec$outboundSchema: z.ZodType<
  InputExec$Outbound,
  z.ZodTypeDef,
  InputExec
> = z.object({
  id: z.string().optional(),
  type: InputExecType$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputExecConnection$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputExecPq$outboundSchema).optional(),
  command: z.string(),
  retries: z.number().default(10),
  scheduleType: ScheduleType$outboundSchema.default("interval"),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  metadata: z.array(z.lazy(() => InputExecMetadatum$outboundSchema)).optional(),
  description: z.string().optional(),
  interval: z.number().default(60),
  cronSchedule: z.string().default("* * * * *"),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputExecToJSON(inputExec: InputExec): string {
  return JSON.stringify(InputExec$outboundSchema.parse(inputExec));
}
export function inputExecFromJSON(
  jsonString: string,
): SafeParseResult<InputExec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExec' from JSON`,
  );
}

/** @internal */
export const TypeEventhub$inboundSchema: z.ZodNativeEnum<typeof TypeEventhub> =
  z.nativeEnum(TypeEventhub);
/** @internal */
export const TypeEventhub$outboundSchema: z.ZodNativeEnum<typeof TypeEventhub> =
  TypeEventhub$inboundSchema;

/** @internal */
export const ConnectionEventhub$inboundSchema: z.ZodType<
  ConnectionEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionEventhub$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionEventhub$outboundSchema: z.ZodType<
  ConnectionEventhub$Outbound,
  z.ZodTypeDef,
  ConnectionEventhub
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionEventhubToJSON(
  connectionEventhub: ConnectionEventhub,
): string {
  return JSON.stringify(
    ConnectionEventhub$outboundSchema.parse(connectionEventhub),
  );
}
export function connectionEventhubFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionEventhub' from JSON`,
  );
}

/** @internal */
export const ModeEventhub$inboundSchema: z.ZodType<
  ModeEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeEventhub$outboundSchema: z.ZodType<
  ModeEventhub,
  z.ZodTypeDef,
  ModeEventhub
> = z.union([
  z.nativeEnum(ModeEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionEventhub$inboundSchema: z.ZodType<
  CompressionEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionEventhub$outboundSchema: z.ZodType<
  CompressionEventhub,
  z.ZodTypeDef,
  CompressionEventhub
> = z.union([
  z.nativeEnum(CompressionEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsEventhub$inboundSchema: z.ZodType<
  PqControlsEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsEventhub$Outbound = {};

/** @internal */
export const PqControlsEventhub$outboundSchema: z.ZodType<
  PqControlsEventhub$Outbound,
  z.ZodTypeDef,
  PqControlsEventhub
> = z.object({});

export function pqControlsEventhubToJSON(
  pqControlsEventhub: PqControlsEventhub,
): string {
  return JSON.stringify(
    PqControlsEventhub$outboundSchema.parse(pqControlsEventhub),
  );
}
export function pqControlsEventhubFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsEventhub' from JSON`,
  );
}

/** @internal */
export const PqEventhub$inboundSchema: z.ZodType<
  PqEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeEventhub$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionEventhub$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsEventhub$inboundSchema).optional(),
});
/** @internal */
export type PqEventhub$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsEventhub$Outbound | undefined;
};

/** @internal */
export const PqEventhub$outboundSchema: z.ZodType<
  PqEventhub$Outbound,
  z.ZodTypeDef,
  PqEventhub
> = z.object({
  mode: ModeEventhub$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionEventhub$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsEventhub$outboundSchema).optional(),
});

export function pqEventhubToJSON(pqEventhub: PqEventhub): string {
  return JSON.stringify(PqEventhub$outboundSchema.parse(pqEventhub));
}
export function pqEventhubFromJSON(
  jsonString: string,
): SafeParseResult<PqEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqEventhub' from JSON`,
  );
}

/** @internal */
export const AuthTypeAuthenticationMethodEventhub$inboundSchema: z.ZodType<
  AuthTypeAuthenticationMethodEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthTypeAuthenticationMethodEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthTypeAuthenticationMethodEventhub$outboundSchema: z.ZodType<
  AuthTypeAuthenticationMethodEventhub,
  z.ZodTypeDef,
  AuthTypeAuthenticationMethodEventhub
> = z.union([
  z.nativeEnum(AuthTypeAuthenticationMethodEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const SASLMechanismEventhub$inboundSchema: z.ZodType<
  SASLMechanismEventhub,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SASLMechanismEventhub),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SASLMechanismEventhub$outboundSchema: z.ZodType<
  SASLMechanismEventhub,
  z.ZodTypeDef,
  SASLMechanismEventhub
> = z.union([
  z.nativeEnum(SASLMechanismEventhub),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ClientSecretAuthTypeAuthenticationMethodEventhub$inboundSchema:
  z.ZodType<
    ClientSecretAuthTypeAuthenticationMethodEventhub,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(ClientSecretAuthTypeAuthenticationMethodEventhub),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const ClientSecretAuthTypeAuthenticationMethodEventhub$outboundSchema:
  z.ZodType<
    ClientSecretAuthTypeAuthenticationMethodEventhub,
    z.ZodTypeDef,
    ClientSecretAuthTypeAuthenticationMethodEventhub
  > = z.union([
    z.nativeEnum(ClientSecretAuthTypeAuthenticationMethodEventhub),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputMicrosoftEntraIDAuthenticationEndpoint$inboundSchema:
  z.ZodType<
    InputMicrosoftEntraIDAuthenticationEndpoint,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputMicrosoftEntraIDAuthenticationEndpoint),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputMicrosoftEntraIDAuthenticationEndpoint$outboundSchema:
  z.ZodType<
    InputMicrosoftEntraIDAuthenticationEndpoint,
    z.ZodTypeDef,
    InputMicrosoftEntraIDAuthenticationEndpoint
  > = z.union([
    z.nativeEnum(InputMicrosoftEntraIDAuthenticationEndpoint),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const AuthenticationEventhub$inboundSchema: z.ZodType<
  AuthenticationEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  authType: AuthTypeAuthenticationMethodEventhub$inboundSchema.default(
    "manual",
  ),
  password: z.string().optional(),
  textSecret: z.string().optional(),
  mechanism: SASLMechanismEventhub$inboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  clientSecretAuthType:
    ClientSecretAuthTypeAuthenticationMethodEventhub$inboundSchema.default(
      "manual",
    ),
  clientSecret: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint: InputMicrosoftEntraIDAuthenticationEndpoint$inboundSchema
    .default("https://login.microsoftonline.com"),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});
/** @internal */
export type AuthenticationEventhub$Outbound = {
  disabled: boolean;
  authType: string;
  password?: string | undefined;
  textSecret?: string | undefined;
  mechanism: string;
  username: string;
  clientSecretAuthType: string;
  clientSecret?: string | undefined;
  clientTextSecret?: string | undefined;
  certificateName?: string | undefined;
  certPath?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  oauthEndpoint: string;
  clientId?: string | undefined;
  tenantId?: string | undefined;
  scope?: string | undefined;
};

/** @internal */
export const AuthenticationEventhub$outboundSchema: z.ZodType<
  AuthenticationEventhub$Outbound,
  z.ZodTypeDef,
  AuthenticationEventhub
> = z.object({
  disabled: z.boolean().default(false),
  authType: AuthTypeAuthenticationMethodEventhub$outboundSchema.default(
    "manual",
  ),
  password: z.string().optional(),
  textSecret: z.string().optional(),
  mechanism: SASLMechanismEventhub$outboundSchema.default("plain"),
  username: z.string().default("$ConnectionString"),
  clientSecretAuthType:
    ClientSecretAuthTypeAuthenticationMethodEventhub$outboundSchema.default(
      "manual",
    ),
  clientSecret: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificateName: z.string().optional(),
  certPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  oauthEndpoint: InputMicrosoftEntraIDAuthenticationEndpoint$outboundSchema
    .default("https://login.microsoftonline.com"),
  clientId: z.string().optional(),
  tenantId: z.string().optional(),
  scope: z.string().optional(),
});

export function authenticationEventhubToJSON(
  authenticationEventhub: AuthenticationEventhub,
): string {
  return JSON.stringify(
    AuthenticationEventhub$outboundSchema.parse(authenticationEventhub),
  );
}
export function authenticationEventhubFromJSON(
  jsonString: string,
): SafeParseResult<AuthenticationEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthenticationEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthenticationEventhub' from JSON`,
  );
}

/** @internal */
export const TLSSettingsClientSideEventhub$inboundSchema: z.ZodType<
  TLSSettingsClientSideEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});
/** @internal */
export type TLSSettingsClientSideEventhub$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
};

/** @internal */
export const TLSSettingsClientSideEventhub$outboundSchema: z.ZodType<
  TLSSettingsClientSideEventhub$Outbound,
  z.ZodTypeDef,
  TLSSettingsClientSideEventhub
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
});

export function tlsSettingsClientSideEventhubToJSON(
  tlsSettingsClientSideEventhub: TLSSettingsClientSideEventhub,
): string {
  return JSON.stringify(
    TLSSettingsClientSideEventhub$outboundSchema.parse(
      tlsSettingsClientSideEventhub,
    ),
  );
}
export function tlsSettingsClientSideEventhubFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsClientSideEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsClientSideEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsClientSideEventhub' from JSON`,
  );
}

/** @internal */
export const MetadatumEventhub$inboundSchema: z.ZodType<
  MetadatumEventhub,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumEventhub$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumEventhub$outboundSchema: z.ZodType<
  MetadatumEventhub$Outbound,
  z.ZodTypeDef,
  MetadatumEventhub
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumEventhubToJSON(
  metadatumEventhub: MetadatumEventhub,
): string {
  return JSON.stringify(
    MetadatumEventhub$outboundSchema.parse(metadatumEventhub),
  );
}
export function metadatumEventhubFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumEventhub' from JSON`,
  );
}

/** @internal */
export const InputEventhub$inboundSchema: z.ZodType<
  InputEventhub,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeEventhub$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionEventhub$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqEventhub$inboundSchema).optional(),
    brokers: z.array(z.string()),
    topics: z.array(z.string()),
    groupId: z.string().default("Cribl"),
    fromBeginning: z.boolean().default(true),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => AuthenticationEventhub$inboundSchema).optional(),
    tls: z.lazy(() => TLSSettingsClientSideEventhub$inboundSchema).optional(),
    sessionTimeout: z.number().default(30000),
    rebalanceTimeout: z.number().default(60000),
    heartbeatInterval: z.number().default(3000),
    autoCommitInterval: z.number().optional(),
    autoCommitThreshold: z.number().optional(),
    maxBytesPerPartition: z.number().default(1048576),
    maxBytes: z.number().default(10485760),
    maxSocketErrors: z.number().default(0),
    minimizeDuplicates: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumEventhub$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputEventhub$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionEventhub$Outbound> | undefined;
  pq?: PqEventhub$Outbound | undefined;
  brokers: Array<string>;
  topics: Array<string>;
  groupId: string;
  fromBeginning: boolean;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: AuthenticationEventhub$Outbound | undefined;
  tls?: TLSSettingsClientSideEventhub$Outbound | undefined;
  sessionTimeout: number;
  rebalanceTimeout: number;
  heartbeatInterval: number;
  autoCommitInterval?: number | undefined;
  autoCommitThreshold?: number | undefined;
  maxBytesPerPartition: number;
  maxBytes: number;
  maxSocketErrors: number;
  minimizeDuplicates: boolean;
  metadata?: Array<MetadatumEventhub$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputEventhub$outboundSchema: z.ZodType<
  InputEventhub$Outbound,
  z.ZodTypeDef,
  InputEventhub
> = z.object({
  id: z.string().optional(),
  type: TypeEventhub$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionEventhub$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqEventhub$outboundSchema).optional(),
  brokers: z.array(z.string()),
  topics: z.array(z.string()),
  groupId: z.string().default("Cribl"),
  fromBeginning: z.boolean().default(true),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => AuthenticationEventhub$outboundSchema).optional(),
  tls: z.lazy(() => TLSSettingsClientSideEventhub$outboundSchema).optional(),
  sessionTimeout: z.number().default(30000),
  rebalanceTimeout: z.number().default(60000),
  heartbeatInterval: z.number().default(3000),
  autoCommitInterval: z.number().optional(),
  autoCommitThreshold: z.number().optional(),
  maxBytesPerPartition: z.number().default(1048576),
  maxBytes: z.number().default(10485760),
  maxSocketErrors: z.number().default(0),
  minimizeDuplicates: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumEventhub$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputEventhubToJSON(inputEventhub: InputEventhub): string {
  return JSON.stringify(InputEventhub$outboundSchema.parse(inputEventhub));
}
export function inputEventhubFromJSON(
  jsonString: string,
): SafeParseResult<InputEventhub, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputEventhub$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputEventhub' from JSON`,
  );
}

/** @internal */
export const TypeOffice365MsgTrace$inboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365MsgTrace
> = z.nativeEnum(TypeOffice365MsgTrace);
/** @internal */
export const TypeOffice365MsgTrace$outboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365MsgTrace
> = TypeOffice365MsgTrace$inboundSchema;

/** @internal */
export const ConnectionOffice365MsgTrace$inboundSchema: z.ZodType<
  ConnectionOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionOffice365MsgTrace$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionOffice365MsgTrace$outboundSchema: z.ZodType<
  ConnectionOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  ConnectionOffice365MsgTrace
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionOffice365MsgTraceToJSON(
  connectionOffice365MsgTrace: ConnectionOffice365MsgTrace,
): string {
  return JSON.stringify(
    ConnectionOffice365MsgTrace$outboundSchema.parse(
      connectionOffice365MsgTrace,
    ),
  );
}
export function connectionOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const ModeOffice365MsgTrace$inboundSchema: z.ZodType<
  ModeOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeOffice365MsgTrace$outboundSchema: z.ZodType<
  ModeOffice365MsgTrace,
  z.ZodTypeDef,
  ModeOffice365MsgTrace
> = z.union([
  z.nativeEnum(ModeOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionOffice365MsgTrace$inboundSchema: z.ZodType<
  CompressionOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionOffice365MsgTrace$outboundSchema: z.ZodType<
  CompressionOffice365MsgTrace,
  z.ZodTypeDef,
  CompressionOffice365MsgTrace
> = z.union([
  z.nativeEnum(CompressionOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsOffice365MsgTrace$inboundSchema: z.ZodType<
  PqControlsOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsOffice365MsgTrace$Outbound = {};

/** @internal */
export const PqControlsOffice365MsgTrace$outboundSchema: z.ZodType<
  PqControlsOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  PqControlsOffice365MsgTrace
> = z.object({});

export function pqControlsOffice365MsgTraceToJSON(
  pqControlsOffice365MsgTrace: PqControlsOffice365MsgTrace,
): string {
  return JSON.stringify(
    PqControlsOffice365MsgTrace$outboundSchema.parse(
      pqControlsOffice365MsgTrace,
    ),
  );
}
export function pqControlsOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const PqOffice365MsgTrace$inboundSchema: z.ZodType<
  PqOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeOffice365MsgTrace$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365MsgTrace$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365MsgTrace$inboundSchema)
    .optional(),
});
/** @internal */
export type PqOffice365MsgTrace$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsOffice365MsgTrace$Outbound | undefined;
};

/** @internal */
export const PqOffice365MsgTrace$outboundSchema: z.ZodType<
  PqOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  PqOffice365MsgTrace
> = z.object({
  mode: ModeOffice365MsgTrace$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365MsgTrace$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365MsgTrace$outboundSchema)
    .optional(),
});

export function pqOffice365MsgTraceToJSON(
  pqOffice365MsgTrace: PqOffice365MsgTrace,
): string {
  return JSON.stringify(
    PqOffice365MsgTrace$outboundSchema.parse(pqOffice365MsgTrace),
  );
}
export function pqOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<PqOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodOffice365MsgTrace$inboundSchema: z.ZodType<
  AuthenticationMethodOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodOffice365MsgTrace$outboundSchema: z.ZodType<
  AuthenticationMethodOffice365MsgTrace,
  z.ZodTypeDef,
  AuthenticationMethodOffice365MsgTrace
> = z.union([
  z.nativeEnum(AuthenticationMethodOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LogLevelOffice365MsgTrace$inboundSchema: z.ZodType<
  LogLevelOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLevelOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLevelOffice365MsgTrace$outboundSchema: z.ZodType<
  LogLevelOffice365MsgTrace,
  z.ZodTypeDef,
  LogLevelOffice365MsgTrace
> = z.union([
  z.nativeEnum(LogLevelOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumOffice365MsgTrace$inboundSchema: z.ZodType<
  MetadatumOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumOffice365MsgTrace$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumOffice365MsgTrace$outboundSchema: z.ZodType<
  MetadatumOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  MetadatumOffice365MsgTrace
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumOffice365MsgTraceToJSON(
  metadatumOffice365MsgTrace: MetadatumOffice365MsgTrace,
): string {
  return JSON.stringify(
    MetadatumOffice365MsgTrace$outboundSchema.parse(metadatumOffice365MsgTrace),
  );
}
export function metadatumOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const RetryTypeOffice365MsgTrace$inboundSchema: z.ZodType<
  RetryTypeOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RetryTypeOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RetryTypeOffice365MsgTrace$outboundSchema: z.ZodType<
  RetryTypeOffice365MsgTrace,
  z.ZodTypeDef,
  RetryTypeOffice365MsgTrace
> = z.union([
  z.nativeEnum(RetryTypeOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RetryRulesOffice365MsgTrace$inboundSchema: z.ZodType<
  RetryRulesOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RetryTypeOffice365MsgTrace$inboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});
/** @internal */
export type RetryRulesOffice365MsgTrace$Outbound = {
  type: string;
  interval: number;
  limit: number;
  multiplier: number;
  codes?: Array<number> | undefined;
  enableHeader: boolean;
  retryConnectTimeout: boolean;
  retryConnectReset: boolean;
};

/** @internal */
export const RetryRulesOffice365MsgTrace$outboundSchema: z.ZodType<
  RetryRulesOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  RetryRulesOffice365MsgTrace
> = z.object({
  type: RetryTypeOffice365MsgTrace$outboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});

export function retryRulesOffice365MsgTraceToJSON(
  retryRulesOffice365MsgTrace: RetryRulesOffice365MsgTrace,
): string {
  return JSON.stringify(
    RetryRulesOffice365MsgTrace$outboundSchema.parse(
      retryRulesOffice365MsgTrace,
    ),
  );
}
export function retryRulesOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<RetryRulesOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RetryRulesOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RetryRulesOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const SubscriptionPlanOffice365MsgTrace$inboundSchema: z.ZodType<
  SubscriptionPlanOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SubscriptionPlanOffice365MsgTrace),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SubscriptionPlanOffice365MsgTrace$outboundSchema: z.ZodType<
  SubscriptionPlanOffice365MsgTrace,
  z.ZodTypeDef,
  SubscriptionPlanOffice365MsgTrace
> = z.union([
  z.nativeEnum(SubscriptionPlanOffice365MsgTrace),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CertOptions$inboundSchema: z.ZodType<
  CertOptions,
  z.ZodTypeDef,
  unknown
> = z.object({
  certificateName: z.string().optional(),
  privKeyPath: z.string(),
  passphrase: z.string().optional(),
  certPath: z.string(),
});
/** @internal */
export type CertOptions$Outbound = {
  certificateName?: string | undefined;
  privKeyPath: string;
  passphrase?: string | undefined;
  certPath: string;
};

/** @internal */
export const CertOptions$outboundSchema: z.ZodType<
  CertOptions$Outbound,
  z.ZodTypeDef,
  CertOptions
> = z.object({
  certificateName: z.string().optional(),
  privKeyPath: z.string(),
  passphrase: z.string().optional(),
  certPath: z.string(),
});

export function certOptionsToJSON(certOptions: CertOptions): string {
  return JSON.stringify(CertOptions$outboundSchema.parse(certOptions));
}
export function certOptionsFromJSON(
  jsonString: string,
): SafeParseResult<CertOptions, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CertOptions$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CertOptions' from JSON`,
  );
}

/** @internal */
export const InputOffice365MsgTrace$inboundSchema: z.ZodType<
  InputOffice365MsgTrace,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeOffice365MsgTrace$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(
      z.lazy(() => ConnectionOffice365MsgTrace$inboundSchema),
    ).optional(),
    pq: z.lazy(() => PqOffice365MsgTrace$inboundSchema).optional(),
    url: z.string().default(
      "https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace",
    ),
    interval: z.number().default(60),
    startDate: z.string().optional(),
    endDate: z.string().optional(),
    timeout: z.number().default(300),
    disableTimeFilter: z.boolean().default(true),
    authType: AuthenticationMethodOffice365MsgTrace$inboundSchema.default(
      "oauth",
    ),
    rescheduleDroppedTasks: z.boolean().default(true),
    maxTaskReschedule: z.number().default(1),
    logLevel: LogLevelOffice365MsgTrace$inboundSchema.default("info"),
    jobTimeout: z.string().default("0"),
    keepAliveTime: z.number().default(30),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumOffice365MsgTrace$inboundSchema))
      .optional(),
    retryRules: z.lazy(() => RetryRulesOffice365MsgTrace$inboundSchema)
      .optional(),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    credentialsSecret: z.string().optional(),
    clientSecret: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    resource: z.string().default("https://outlook.office365.com"),
    planType: SubscriptionPlanOffice365MsgTrace$inboundSchema.default(
      "enterprise_gcc",
    ),
    textSecret: z.string().optional(),
    certOptions: z.lazy(() => CertOptions$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputOffice365MsgTrace$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionOffice365MsgTrace$Outbound> | undefined;
  pq?: PqOffice365MsgTrace$Outbound | undefined;
  url: string;
  interval: number;
  startDate?: string | undefined;
  endDate?: string | undefined;
  timeout: number;
  disableTimeFilter: boolean;
  authType: string;
  rescheduleDroppedTasks: boolean;
  maxTaskReschedule: number;
  logLevel: string;
  jobTimeout: string;
  keepAliveTime: number;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumOffice365MsgTrace$Outbound> | undefined;
  retryRules?: RetryRulesOffice365MsgTrace$Outbound | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  clientSecret?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  resource: string;
  planType: string;
  textSecret?: string | undefined;
  certOptions?: CertOptions$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputOffice365MsgTrace$outboundSchema: z.ZodType<
  InputOffice365MsgTrace$Outbound,
  z.ZodTypeDef,
  InputOffice365MsgTrace
> = z.object({
  id: z.string().optional(),
  type: TypeOffice365MsgTrace$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionOffice365MsgTrace$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqOffice365MsgTrace$outboundSchema).optional(),
  url: z.string().default(
    "https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace",
  ),
  interval: z.number().default(60),
  startDate: z.string().optional(),
  endDate: z.string().optional(),
  timeout: z.number().default(300),
  disableTimeFilter: z.boolean().default(true),
  authType: AuthenticationMethodOffice365MsgTrace$outboundSchema.default(
    "oauth",
  ),
  rescheduleDroppedTasks: z.boolean().default(true),
  maxTaskReschedule: z.number().default(1),
  logLevel: LogLevelOffice365MsgTrace$outboundSchema.default("info"),
  jobTimeout: z.string().default("0"),
  keepAliveTime: z.number().default(30),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumOffice365MsgTrace$outboundSchema))
    .optional(),
  retryRules: z.lazy(() => RetryRulesOffice365MsgTrace$outboundSchema)
    .optional(),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  clientSecret: z.string().optional(),
  tenantId: z.string().optional(),
  clientId: z.string().optional(),
  resource: z.string().default("https://outlook.office365.com"),
  planType: SubscriptionPlanOffice365MsgTrace$outboundSchema.default(
    "enterprise_gcc",
  ),
  textSecret: z.string().optional(),
  certOptions: z.lazy(() => CertOptions$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputOffice365MsgTraceToJSON(
  inputOffice365MsgTrace: InputOffice365MsgTrace,
): string {
  return JSON.stringify(
    InputOffice365MsgTrace$outboundSchema.parse(inputOffice365MsgTrace),
  );
}
export function inputOffice365MsgTraceFromJSON(
  jsonString: string,
): SafeParseResult<InputOffice365MsgTrace, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOffice365MsgTrace$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOffice365MsgTrace' from JSON`,
  );
}

/** @internal */
export const TypeOffice365Service$inboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365Service
> = z.nativeEnum(TypeOffice365Service);
/** @internal */
export const TypeOffice365Service$outboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365Service
> = TypeOffice365Service$inboundSchema;

/** @internal */
export const ConnectionOffice365Service$inboundSchema: z.ZodType<
  ConnectionOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionOffice365Service$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionOffice365Service$outboundSchema: z.ZodType<
  ConnectionOffice365Service$Outbound,
  z.ZodTypeDef,
  ConnectionOffice365Service
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionOffice365ServiceToJSON(
  connectionOffice365Service: ConnectionOffice365Service,
): string {
  return JSON.stringify(
    ConnectionOffice365Service$outboundSchema.parse(connectionOffice365Service),
  );
}
export function connectionOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionOffice365Service' from JSON`,
  );
}

/** @internal */
export const ModeOffice365Service$inboundSchema: z.ZodType<
  ModeOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeOffice365Service$outboundSchema: z.ZodType<
  ModeOffice365Service,
  z.ZodTypeDef,
  ModeOffice365Service
> = z.union([
  z.nativeEnum(ModeOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionOffice365Service$inboundSchema: z.ZodType<
  CompressionOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionOffice365Service$outboundSchema: z.ZodType<
  CompressionOffice365Service,
  z.ZodTypeDef,
  CompressionOffice365Service
> = z.union([
  z.nativeEnum(CompressionOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsOffice365Service$inboundSchema: z.ZodType<
  PqControlsOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsOffice365Service$Outbound = {};

/** @internal */
export const PqControlsOffice365Service$outboundSchema: z.ZodType<
  PqControlsOffice365Service$Outbound,
  z.ZodTypeDef,
  PqControlsOffice365Service
> = z.object({});

export function pqControlsOffice365ServiceToJSON(
  pqControlsOffice365Service: PqControlsOffice365Service,
): string {
  return JSON.stringify(
    PqControlsOffice365Service$outboundSchema.parse(pqControlsOffice365Service),
  );
}
export function pqControlsOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsOffice365Service' from JSON`,
  );
}

/** @internal */
export const PqOffice365Service$inboundSchema: z.ZodType<
  PqOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeOffice365Service$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365Service$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365Service$inboundSchema).optional(),
});
/** @internal */
export type PqOffice365Service$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsOffice365Service$Outbound | undefined;
};

/** @internal */
export const PqOffice365Service$outboundSchema: z.ZodType<
  PqOffice365Service$Outbound,
  z.ZodTypeDef,
  PqOffice365Service
> = z.object({
  mode: ModeOffice365Service$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365Service$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365Service$outboundSchema)
    .optional(),
});

export function pqOffice365ServiceToJSON(
  pqOffice365Service: PqOffice365Service,
): string {
  return JSON.stringify(
    PqOffice365Service$outboundSchema.parse(pqOffice365Service),
  );
}
export function pqOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<PqOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqOffice365Service' from JSON`,
  );
}

/** @internal */
export const SubscriptionPlanOffice365Service$inboundSchema: z.ZodType<
  SubscriptionPlanOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SubscriptionPlanOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SubscriptionPlanOffice365Service$outboundSchema: z.ZodType<
  SubscriptionPlanOffice365Service,
  z.ZodTypeDef,
  SubscriptionPlanOffice365Service
> = z.union([
  z.nativeEnum(SubscriptionPlanOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumOffice365Service$inboundSchema: z.ZodType<
  MetadatumOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumOffice365Service$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumOffice365Service$outboundSchema: z.ZodType<
  MetadatumOffice365Service$Outbound,
  z.ZodTypeDef,
  MetadatumOffice365Service
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumOffice365ServiceToJSON(
  metadatumOffice365Service: MetadatumOffice365Service,
): string {
  return JSON.stringify(
    MetadatumOffice365Service$outboundSchema.parse(metadatumOffice365Service),
  );
}
export function metadatumOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumOffice365Service' from JSON`,
  );
}

/** @internal */
export const LogLevelOffice365Service$inboundSchema: z.ZodType<
  LogLevelOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLevelOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLevelOffice365Service$outboundSchema: z.ZodType<
  LogLevelOffice365Service,
  z.ZodTypeDef,
  LogLevelOffice365Service
> = z.union([
  z.nativeEnum(LogLevelOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ContentConfigOffice365Service$inboundSchema: z.ZodType<
  ContentConfigOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({
  contentType: z.string().optional(),
  description: z.string().optional(),
  interval: z.number().optional(),
  logLevel: LogLevelOffice365Service$inboundSchema.optional(),
  enabled: z.boolean().optional(),
});
/** @internal */
export type ContentConfigOffice365Service$Outbound = {
  contentType?: string | undefined;
  description?: string | undefined;
  interval?: number | undefined;
  logLevel?: string | undefined;
  enabled?: boolean | undefined;
};

/** @internal */
export const ContentConfigOffice365Service$outboundSchema: z.ZodType<
  ContentConfigOffice365Service$Outbound,
  z.ZodTypeDef,
  ContentConfigOffice365Service
> = z.object({
  contentType: z.string().optional(),
  description: z.string().optional(),
  interval: z.number().optional(),
  logLevel: LogLevelOffice365Service$outboundSchema.optional(),
  enabled: z.boolean().optional(),
});

export function contentConfigOffice365ServiceToJSON(
  contentConfigOffice365Service: ContentConfigOffice365Service,
): string {
  return JSON.stringify(
    ContentConfigOffice365Service$outboundSchema.parse(
      contentConfigOffice365Service,
    ),
  );
}
export function contentConfigOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<ContentConfigOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ContentConfigOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ContentConfigOffice365Service' from JSON`,
  );
}

/** @internal */
export const RetryTypeOffice365Service$inboundSchema: z.ZodType<
  RetryTypeOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RetryTypeOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RetryTypeOffice365Service$outboundSchema: z.ZodType<
  RetryTypeOffice365Service,
  z.ZodTypeDef,
  RetryTypeOffice365Service
> = z.union([
  z.nativeEnum(RetryTypeOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RetryRulesOffice365Service$inboundSchema: z.ZodType<
  RetryRulesOffice365Service,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RetryTypeOffice365Service$inboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});
/** @internal */
export type RetryRulesOffice365Service$Outbound = {
  type: string;
  interval: number;
  limit: number;
  multiplier: number;
  codes?: Array<number> | undefined;
  enableHeader: boolean;
  retryConnectTimeout: boolean;
  retryConnectReset: boolean;
};

/** @internal */
export const RetryRulesOffice365Service$outboundSchema: z.ZodType<
  RetryRulesOffice365Service$Outbound,
  z.ZodTypeDef,
  RetryRulesOffice365Service
> = z.object({
  type: RetryTypeOffice365Service$outboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});

export function retryRulesOffice365ServiceToJSON(
  retryRulesOffice365Service: RetryRulesOffice365Service,
): string {
  return JSON.stringify(
    RetryRulesOffice365Service$outboundSchema.parse(retryRulesOffice365Service),
  );
}
export function retryRulesOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<RetryRulesOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RetryRulesOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RetryRulesOffice365Service' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodOffice365Service$inboundSchema: z.ZodType<
  AuthenticationMethodOffice365Service,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodOffice365Service),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodOffice365Service$outboundSchema: z.ZodType<
  AuthenticationMethodOffice365Service,
  z.ZodTypeDef,
  AuthenticationMethodOffice365Service
> = z.union([
  z.nativeEnum(AuthenticationMethodOffice365Service),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputOffice365Service$inboundSchema: z.ZodType<
  InputOffice365Service,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeOffice365Service$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionOffice365Service$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqOffice365Service$inboundSchema).optional(),
    planType: SubscriptionPlanOffice365Service$inboundSchema.default(
      "enterprise_gcc",
    ),
    tenantId: z.string(),
    appId: z.string(),
    timeout: z.number().default(300),
    keepAliveTime: z.number().default(30),
    jobTimeout: z.string().default("0"),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumOffice365Service$inboundSchema))
      .optional(),
    contentConfig: z.array(
      z.lazy(() => ContentConfigOffice365Service$inboundSchema),
    ).optional(),
    retryRules: z.lazy(() => RetryRulesOffice365Service$inboundSchema)
      .optional(),
    authType: AuthenticationMethodOffice365Service$inboundSchema.default(
      "manual",
    ),
    description: z.string().optional(),
    clientSecret: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputOffice365Service$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionOffice365Service$Outbound> | undefined;
  pq?: PqOffice365Service$Outbound | undefined;
  planType: string;
  tenantId: string;
  appId: string;
  timeout: number;
  keepAliveTime: number;
  jobTimeout: string;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumOffice365Service$Outbound> | undefined;
  contentConfig?: Array<ContentConfigOffice365Service$Outbound> | undefined;
  retryRules?: RetryRulesOffice365Service$Outbound | undefined;
  authType: string;
  description?: string | undefined;
  clientSecret?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputOffice365Service$outboundSchema: z.ZodType<
  InputOffice365Service$Outbound,
  z.ZodTypeDef,
  InputOffice365Service
> = z.object({
  id: z.string().optional(),
  type: TypeOffice365Service$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionOffice365Service$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqOffice365Service$outboundSchema).optional(),
  planType: SubscriptionPlanOffice365Service$outboundSchema.default(
    "enterprise_gcc",
  ),
  tenantId: z.string(),
  appId: z.string(),
  timeout: z.number().default(300),
  keepAliveTime: z.number().default(30),
  jobTimeout: z.string().default("0"),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumOffice365Service$outboundSchema))
    .optional(),
  contentConfig: z.array(
    z.lazy(() => ContentConfigOffice365Service$outboundSchema),
  ).optional(),
  retryRules: z.lazy(() => RetryRulesOffice365Service$outboundSchema)
    .optional(),
  authType: AuthenticationMethodOffice365Service$outboundSchema.default(
    "manual",
  ),
  description: z.string().optional(),
  clientSecret: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputOffice365ServiceToJSON(
  inputOffice365Service: InputOffice365Service,
): string {
  return JSON.stringify(
    InputOffice365Service$outboundSchema.parse(inputOffice365Service),
  );
}
export function inputOffice365ServiceFromJSON(
  jsonString: string,
): SafeParseResult<InputOffice365Service, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOffice365Service$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOffice365Service' from JSON`,
  );
}

/** @internal */
export const TypeOffice365Mgmt$inboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365Mgmt
> = z.nativeEnum(TypeOffice365Mgmt);
/** @internal */
export const TypeOffice365Mgmt$outboundSchema: z.ZodNativeEnum<
  typeof TypeOffice365Mgmt
> = TypeOffice365Mgmt$inboundSchema;

/** @internal */
export const ConnectionOffice365Mgmt$inboundSchema: z.ZodType<
  ConnectionOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionOffice365Mgmt$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionOffice365Mgmt$outboundSchema: z.ZodType<
  ConnectionOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  ConnectionOffice365Mgmt
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionOffice365MgmtToJSON(
  connectionOffice365Mgmt: ConnectionOffice365Mgmt,
): string {
  return JSON.stringify(
    ConnectionOffice365Mgmt$outboundSchema.parse(connectionOffice365Mgmt),
  );
}
export function connectionOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const ModeOffice365Mgmt$inboundSchema: z.ZodType<
  ModeOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeOffice365Mgmt$outboundSchema: z.ZodType<
  ModeOffice365Mgmt,
  z.ZodTypeDef,
  ModeOffice365Mgmt
> = z.union([
  z.nativeEnum(ModeOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionOffice365Mgmt$inboundSchema: z.ZodType<
  CompressionOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionOffice365Mgmt$outboundSchema: z.ZodType<
  CompressionOffice365Mgmt,
  z.ZodTypeDef,
  CompressionOffice365Mgmt
> = z.union([
  z.nativeEnum(CompressionOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsOffice365Mgmt$inboundSchema: z.ZodType<
  PqControlsOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsOffice365Mgmt$Outbound = {};

/** @internal */
export const PqControlsOffice365Mgmt$outboundSchema: z.ZodType<
  PqControlsOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  PqControlsOffice365Mgmt
> = z.object({});

export function pqControlsOffice365MgmtToJSON(
  pqControlsOffice365Mgmt: PqControlsOffice365Mgmt,
): string {
  return JSON.stringify(
    PqControlsOffice365Mgmt$outboundSchema.parse(pqControlsOffice365Mgmt),
  );
}
export function pqControlsOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const PqOffice365Mgmt$inboundSchema: z.ZodType<
  PqOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeOffice365Mgmt$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365Mgmt$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365Mgmt$inboundSchema).optional(),
});
/** @internal */
export type PqOffice365Mgmt$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsOffice365Mgmt$Outbound | undefined;
};

/** @internal */
export const PqOffice365Mgmt$outboundSchema: z.ZodType<
  PqOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  PqOffice365Mgmt
> = z.object({
  mode: ModeOffice365Mgmt$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionOffice365Mgmt$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsOffice365Mgmt$outboundSchema).optional(),
});

export function pqOffice365MgmtToJSON(
  pqOffice365Mgmt: PqOffice365Mgmt,
): string {
  return JSON.stringify(PqOffice365Mgmt$outboundSchema.parse(pqOffice365Mgmt));
}
export function pqOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<PqOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const SubscriptionPlanOffice365Mgmt$inboundSchema: z.ZodType<
  SubscriptionPlanOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SubscriptionPlanOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SubscriptionPlanOffice365Mgmt$outboundSchema: z.ZodType<
  SubscriptionPlanOffice365Mgmt,
  z.ZodTypeDef,
  SubscriptionPlanOffice365Mgmt
> = z.union([
  z.nativeEnum(SubscriptionPlanOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumOffice365Mgmt$inboundSchema: z.ZodType<
  MetadatumOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumOffice365Mgmt$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumOffice365Mgmt$outboundSchema: z.ZodType<
  MetadatumOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  MetadatumOffice365Mgmt
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumOffice365MgmtToJSON(
  metadatumOffice365Mgmt: MetadatumOffice365Mgmt,
): string {
  return JSON.stringify(
    MetadatumOffice365Mgmt$outboundSchema.parse(metadatumOffice365Mgmt),
  );
}
export function metadatumOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const LogLevelOffice365Mgmt$inboundSchema: z.ZodType<
  LogLevelOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLevelOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLevelOffice365Mgmt$outboundSchema: z.ZodType<
  LogLevelOffice365Mgmt,
  z.ZodTypeDef,
  LogLevelOffice365Mgmt
> = z.union([
  z.nativeEnum(LogLevelOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ContentConfigOffice365Mgmt$inboundSchema: z.ZodType<
  ContentConfigOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({
  contentType: z.string().optional(),
  description: z.string().optional(),
  interval: z.number().optional(),
  logLevel: LogLevelOffice365Mgmt$inboundSchema.optional(),
  enabled: z.boolean().optional(),
});
/** @internal */
export type ContentConfigOffice365Mgmt$Outbound = {
  contentType?: string | undefined;
  description?: string | undefined;
  interval?: number | undefined;
  logLevel?: string | undefined;
  enabled?: boolean | undefined;
};

/** @internal */
export const ContentConfigOffice365Mgmt$outboundSchema: z.ZodType<
  ContentConfigOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  ContentConfigOffice365Mgmt
> = z.object({
  contentType: z.string().optional(),
  description: z.string().optional(),
  interval: z.number().optional(),
  logLevel: LogLevelOffice365Mgmt$outboundSchema.optional(),
  enabled: z.boolean().optional(),
});

export function contentConfigOffice365MgmtToJSON(
  contentConfigOffice365Mgmt: ContentConfigOffice365Mgmt,
): string {
  return JSON.stringify(
    ContentConfigOffice365Mgmt$outboundSchema.parse(contentConfigOffice365Mgmt),
  );
}
export function contentConfigOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<ContentConfigOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ContentConfigOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ContentConfigOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const RetryTypeOffice365Mgmt$inboundSchema: z.ZodType<
  RetryTypeOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RetryTypeOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RetryTypeOffice365Mgmt$outboundSchema: z.ZodType<
  RetryTypeOffice365Mgmt,
  z.ZodTypeDef,
  RetryTypeOffice365Mgmt
> = z.union([
  z.nativeEnum(RetryTypeOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RetryRulesOffice365Mgmt$inboundSchema: z.ZodType<
  RetryRulesOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RetryTypeOffice365Mgmt$inboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});
/** @internal */
export type RetryRulesOffice365Mgmt$Outbound = {
  type: string;
  interval: number;
  limit: number;
  multiplier: number;
  codes?: Array<number> | undefined;
  enableHeader: boolean;
  retryConnectTimeout: boolean;
  retryConnectReset: boolean;
};

/** @internal */
export const RetryRulesOffice365Mgmt$outboundSchema: z.ZodType<
  RetryRulesOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  RetryRulesOffice365Mgmt
> = z.object({
  type: RetryTypeOffice365Mgmt$outboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});

export function retryRulesOffice365MgmtToJSON(
  retryRulesOffice365Mgmt: RetryRulesOffice365Mgmt,
): string {
  return JSON.stringify(
    RetryRulesOffice365Mgmt$outboundSchema.parse(retryRulesOffice365Mgmt),
  );
}
export function retryRulesOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<RetryRulesOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RetryRulesOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RetryRulesOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const AuthenticationMethodOffice365Mgmt$inboundSchema: z.ZodType<
  AuthenticationMethodOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationMethodOffice365Mgmt),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationMethodOffice365Mgmt$outboundSchema: z.ZodType<
  AuthenticationMethodOffice365Mgmt,
  z.ZodTypeDef,
  AuthenticationMethodOffice365Mgmt
> = z.union([
  z.nativeEnum(AuthenticationMethodOffice365Mgmt),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputOffice365Mgmt$inboundSchema: z.ZodType<
  InputOffice365Mgmt,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeOffice365Mgmt$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionOffice365Mgmt$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqOffice365Mgmt$inboundSchema).optional(),
    planType: SubscriptionPlanOffice365Mgmt$inboundSchema.default(
      "enterprise_gcc",
    ),
    tenantId: z.string(),
    appId: z.string(),
    timeout: z.number().default(300),
    keepAliveTime: z.number().default(30),
    jobTimeout: z.string().default("0"),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumOffice365Mgmt$inboundSchema))
      .optional(),
    publisherIdentifier: z.string().optional(),
    contentConfig: z.array(
      z.lazy(() => ContentConfigOffice365Mgmt$inboundSchema),
    ).optional(),
    ingestionLag: z.number().default(0),
    retryRules: z.lazy(() => RetryRulesOffice365Mgmt$inboundSchema).optional(),
    authType: AuthenticationMethodOffice365Mgmt$inboundSchema.default("manual"),
    description: z.string().optional(),
    clientSecret: z.string().optional(),
    textSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputOffice365Mgmt$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionOffice365Mgmt$Outbound> | undefined;
  pq?: PqOffice365Mgmt$Outbound | undefined;
  planType: string;
  tenantId: string;
  appId: string;
  timeout: number;
  keepAliveTime: number;
  jobTimeout: string;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumOffice365Mgmt$Outbound> | undefined;
  publisherIdentifier?: string | undefined;
  contentConfig?: Array<ContentConfigOffice365Mgmt$Outbound> | undefined;
  ingestionLag: number;
  retryRules?: RetryRulesOffice365Mgmt$Outbound | undefined;
  authType: string;
  description?: string | undefined;
  clientSecret?: string | undefined;
  textSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputOffice365Mgmt$outboundSchema: z.ZodType<
  InputOffice365Mgmt$Outbound,
  z.ZodTypeDef,
  InputOffice365Mgmt
> = z.object({
  id: z.string().optional(),
  type: TypeOffice365Mgmt$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionOffice365Mgmt$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqOffice365Mgmt$outboundSchema).optional(),
  planType: SubscriptionPlanOffice365Mgmt$outboundSchema.default(
    "enterprise_gcc",
  ),
  tenantId: z.string(),
  appId: z.string(),
  timeout: z.number().default(300),
  keepAliveTime: z.number().default(30),
  jobTimeout: z.string().default("0"),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumOffice365Mgmt$outboundSchema))
    .optional(),
  publisherIdentifier: z.string().optional(),
  contentConfig: z.array(
    z.lazy(() => ContentConfigOffice365Mgmt$outboundSchema),
  ).optional(),
  ingestionLag: z.number().default(0),
  retryRules: z.lazy(() => RetryRulesOffice365Mgmt$outboundSchema).optional(),
  authType: AuthenticationMethodOffice365Mgmt$outboundSchema.default("manual"),
  description: z.string().optional(),
  clientSecret: z.string().optional(),
  textSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputOffice365MgmtToJSON(
  inputOffice365Mgmt: InputOffice365Mgmt,
): string {
  return JSON.stringify(
    InputOffice365Mgmt$outboundSchema.parse(inputOffice365Mgmt),
  );
}
export function inputOffice365MgmtFromJSON(
  jsonString: string,
): SafeParseResult<InputOffice365Mgmt, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOffice365Mgmt$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOffice365Mgmt' from JSON`,
  );
}

/** @internal */
export const TypeEdgePrometheus$inboundSchema: z.ZodNativeEnum<
  typeof TypeEdgePrometheus
> = z.nativeEnum(TypeEdgePrometheus);
/** @internal */
export const TypeEdgePrometheus$outboundSchema: z.ZodNativeEnum<
  typeof TypeEdgePrometheus
> = TypeEdgePrometheus$inboundSchema;

/** @internal */
export const ConnectionEdgePrometheus$inboundSchema: z.ZodType<
  ConnectionEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionEdgePrometheus$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionEdgePrometheus$outboundSchema: z.ZodType<
  ConnectionEdgePrometheus$Outbound,
  z.ZodTypeDef,
  ConnectionEdgePrometheus
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionEdgePrometheusToJSON(
  connectionEdgePrometheus: ConnectionEdgePrometheus,
): string {
  return JSON.stringify(
    ConnectionEdgePrometheus$outboundSchema.parse(connectionEdgePrometheus),
  );
}
export function connectionEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const ModeEdgePrometheus$inboundSchema: z.ZodType<
  ModeEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeEdgePrometheus$outboundSchema: z.ZodType<
  ModeEdgePrometheus,
  z.ZodTypeDef,
  ModeEdgePrometheus
> = z.union([
  z.nativeEnum(ModeEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionEdgePrometheus$inboundSchema: z.ZodType<
  PqCompressionEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionEdgePrometheus$outboundSchema: z.ZodType<
  PqCompressionEdgePrometheus,
  z.ZodTypeDef,
  PqCompressionEdgePrometheus
> = z.union([
  z.nativeEnum(PqCompressionEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsEdgePrometheus$inboundSchema: z.ZodType<
  PqControlsEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsEdgePrometheus$Outbound = {};

/** @internal */
export const PqControlsEdgePrometheus$outboundSchema: z.ZodType<
  PqControlsEdgePrometheus$Outbound,
  z.ZodTypeDef,
  PqControlsEdgePrometheus
> = z.object({});

export function pqControlsEdgePrometheusToJSON(
  pqControlsEdgePrometheus: PqControlsEdgePrometheus,
): string {
  return JSON.stringify(
    PqControlsEdgePrometheus$outboundSchema.parse(pqControlsEdgePrometheus),
  );
}
export function pqControlsEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const PqEdgePrometheus$inboundSchema: z.ZodType<
  PqEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeEdgePrometheus$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionEdgePrometheus$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsEdgePrometheus$inboundSchema).optional(),
});
/** @internal */
export type PqEdgePrometheus$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsEdgePrometheus$Outbound | undefined;
};

/** @internal */
export const PqEdgePrometheus$outboundSchema: z.ZodType<
  PqEdgePrometheus$Outbound,
  z.ZodTypeDef,
  PqEdgePrometheus
> = z.object({
  mode: ModeEdgePrometheus$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionEdgePrometheus$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsEdgePrometheus$outboundSchema).optional(),
});

export function pqEdgePrometheusToJSON(
  pqEdgePrometheus: PqEdgePrometheus,
): string {
  return JSON.stringify(
    PqEdgePrometheus$outboundSchema.parse(pqEdgePrometheus),
  );
}
export function pqEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<PqEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const DiscoveryTypeEdgePrometheus$inboundSchema: z.ZodType<
  DiscoveryTypeEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiscoveryTypeEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiscoveryTypeEdgePrometheus$outboundSchema: z.ZodType<
  DiscoveryTypeEdgePrometheus,
  z.ZodTypeDef,
  DiscoveryTypeEdgePrometheus
> = z.union([
  z.nativeEnum(DiscoveryTypeEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PersistenceCompressionEdgePrometheus$inboundSchema: z.ZodType<
  PersistenceCompressionEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PersistenceCompressionEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PersistenceCompressionEdgePrometheus$outboundSchema: z.ZodType<
  PersistenceCompressionEdgePrometheus,
  z.ZodTypeDef,
  PersistenceCompressionEdgePrometheus
> = z.union([
  z.nativeEnum(PersistenceCompressionEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const DiskSpoolingEdgePrometheus$inboundSchema: z.ZodType<
  DiskSpoolingEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PersistenceCompressionEdgePrometheus$inboundSchema.default("gzip"),
});
/** @internal */
export type DiskSpoolingEdgePrometheus$Outbound = {
  enable: boolean;
  timeWindow: string;
  maxDataSize: string;
  maxDataTime: string;
  compress: string;
};

/** @internal */
export const DiskSpoolingEdgePrometheus$outboundSchema: z.ZodType<
  DiskSpoolingEdgePrometheus$Outbound,
  z.ZodTypeDef,
  DiskSpoolingEdgePrometheus
> = z.object({
  enable: z.boolean().default(false),
  timeWindow: z.string().default("10m"),
  maxDataSize: z.string().default("1GB"),
  maxDataTime: z.string().default("24h"),
  compress: PersistenceCompressionEdgePrometheus$outboundSchema.default("gzip"),
});

export function diskSpoolingEdgePrometheusToJSON(
  diskSpoolingEdgePrometheus: DiskSpoolingEdgePrometheus,
): string {
  return JSON.stringify(
    DiskSpoolingEdgePrometheus$outboundSchema.parse(diskSpoolingEdgePrometheus),
  );
}
export function diskSpoolingEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<DiskSpoolingEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => DiskSpoolingEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'DiskSpoolingEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const MetadatumEdgePrometheus$inboundSchema: z.ZodType<
  MetadatumEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumEdgePrometheus$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumEdgePrometheus$outboundSchema: z.ZodType<
  MetadatumEdgePrometheus$Outbound,
  z.ZodTypeDef,
  MetadatumEdgePrometheus
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumEdgePrometheusToJSON(
  metadatumEdgePrometheus: MetadatumEdgePrometheus,
): string {
  return JSON.stringify(
    MetadatumEdgePrometheus$outboundSchema.parse(metadatumEdgePrometheus),
  );
}
export function metadatumEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const AuthTypeAuthenticationMethodEdgePrometheus$inboundSchema:
  z.ZodType<AuthTypeAuthenticationMethodEdgePrometheus, z.ZodTypeDef, unknown> =
    z
      .union([
        z.nativeEnum(AuthTypeAuthenticationMethodEdgePrometheus),
        z.string().transform(catchUnrecognizedEnum),
      ]);
/** @internal */
export const AuthTypeAuthenticationMethodEdgePrometheus$outboundSchema:
  z.ZodType<
    AuthTypeAuthenticationMethodEdgePrometheus,
    z.ZodTypeDef,
    AuthTypeAuthenticationMethodEdgePrometheus
  > = z.union([
    z.nativeEnum(AuthTypeAuthenticationMethodEdgePrometheus),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const TargetProtocol$inboundSchema: z.ZodType<
  TargetProtocol,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(TargetProtocol),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const TargetProtocol$outboundSchema: z.ZodType<
  TargetProtocol,
  z.ZodTypeDef,
  TargetProtocol
> = z.union([
  z.nativeEnum(TargetProtocol),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const Target$inboundSchema: z.ZodType<Target, z.ZodTypeDef, unknown> = z
  .object({
    protocol: TargetProtocol$inboundSchema.default("http"),
    host: z.string(),
    port: z.number().default(9090),
    path: z.string().default("/metrics"),
  });
/** @internal */
export type Target$Outbound = {
  protocol: string;
  host: string;
  port: number;
  path: string;
};

/** @internal */
export const Target$outboundSchema: z.ZodType<
  Target$Outbound,
  z.ZodTypeDef,
  Target
> = z.object({
  protocol: TargetProtocol$outboundSchema.default("http"),
  host: z.string(),
  port: z.number().default(9090),
  path: z.string().default("/metrics"),
});

export function targetToJSON(target: Target): string {
  return JSON.stringify(Target$outboundSchema.parse(target));
}
export function targetFromJSON(
  jsonString: string,
): SafeParseResult<Target, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Target$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Target' from JSON`,
  );
}

/** @internal */
export const RecordTypeEdgePrometheus$inboundSchema: z.ZodType<
  RecordTypeEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordTypeEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordTypeEdgePrometheus$outboundSchema: z.ZodType<
  RecordTypeEdgePrometheus,
  z.ZodTypeDef,
  RecordTypeEdgePrometheus
> = z.union([
  z.nativeEnum(RecordTypeEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ScrapeProtocolProtocol$inboundSchema: z.ZodType<
  ScrapeProtocolProtocol,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ScrapeProtocolProtocol),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ScrapeProtocolProtocol$outboundSchema: z.ZodType<
  ScrapeProtocolProtocol,
  z.ZodTypeDef,
  ScrapeProtocolProtocol
> = z.union([
  z.nativeEnum(ScrapeProtocolProtocol),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AwsAuthenticationMethodAuthenticationMethodEdgePrometheus$inboundSchema:
  z.ZodType<
    AwsAuthenticationMethodAuthenticationMethodEdgePrometheus,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(AwsAuthenticationMethodAuthenticationMethodEdgePrometheus),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const AwsAuthenticationMethodAuthenticationMethodEdgePrometheus$outboundSchema:
  z.ZodType<
    AwsAuthenticationMethodAuthenticationMethodEdgePrometheus,
    z.ZodTypeDef,
    AwsAuthenticationMethodAuthenticationMethodEdgePrometheus
  > = z.union([
    z.nativeEnum(AwsAuthenticationMethodAuthenticationMethodEdgePrometheus),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const SearchFilterEdgePrometheus$inboundSchema: z.ZodType<
  SearchFilterEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  Name: z.string(),
  Values: z.array(z.string()),
}).transform((v) => {
  return remap$(v, {
    "Name": "name",
    "Values": "values",
  });
});
/** @internal */
export type SearchFilterEdgePrometheus$Outbound = {
  Name: string;
  Values: Array<string>;
};

/** @internal */
export const SearchFilterEdgePrometheus$outboundSchema: z.ZodType<
  SearchFilterEdgePrometheus$Outbound,
  z.ZodTypeDef,
  SearchFilterEdgePrometheus
> = z.object({
  name: z.string(),
  values: z.array(z.string()),
}).transform((v) => {
  return remap$(v, {
    name: "Name",
    values: "Values",
  });
});

export function searchFilterEdgePrometheusToJSON(
  searchFilterEdgePrometheus: SearchFilterEdgePrometheus,
): string {
  return JSON.stringify(
    SearchFilterEdgePrometheus$outboundSchema.parse(searchFilterEdgePrometheus),
  );
}
export function searchFilterEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<SearchFilterEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SearchFilterEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SearchFilterEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const SignatureVersionEdgePrometheus$inboundSchema: z.ZodType<
  SignatureVersionEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionEdgePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionEdgePrometheus$outboundSchema: z.ZodType<
  SignatureVersionEdgePrometheus,
  z.ZodTypeDef,
  SignatureVersionEdgePrometheus
> = z.union([
  z.nativeEnum(SignatureVersionEdgePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PodFilter$inboundSchema: z.ZodType<
  PodFilter,
  z.ZodTypeDef,
  unknown
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type PodFilter$Outbound = {
  filter: string;
  description?: string | undefined;
};

/** @internal */
export const PodFilter$outboundSchema: z.ZodType<
  PodFilter$Outbound,
  z.ZodTypeDef,
  PodFilter
> = z.object({
  filter: z.string(),
  description: z.string().optional(),
});

export function podFilterToJSON(podFilter: PodFilter): string {
  return JSON.stringify(PodFilter$outboundSchema.parse(podFilter));
}
export function podFilterFromJSON(
  jsonString: string,
): SafeParseResult<PodFilter, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PodFilter$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PodFilter' from JSON`,
  );
}

/** @internal */
export const InputEdgePrometheus$inboundSchema: z.ZodType<
  InputEdgePrometheus,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeEdgePrometheus$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionEdgePrometheus$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqEdgePrometheus$inboundSchema).optional(),
    dimensionList: z.array(z.string()).optional(),
    discoveryType: DiscoveryTypeEdgePrometheus$inboundSchema.default("static"),
    interval: z.number().default(15),
    timeout: z.number().default(5000),
    persistence: z.lazy(() => DiskSpoolingEdgePrometheus$inboundSchema)
      .optional(),
    metadata: z.array(z.lazy(() => MetadatumEdgePrometheus$inboundSchema))
      .optional(),
    authType: AuthTypeAuthenticationMethodEdgePrometheus$inboundSchema.default(
      "manual",
    ),
    description: z.string().optional(),
    targets: z.array(z.lazy(() => Target$inboundSchema)).optional(),
    recordType: RecordTypeEdgePrometheus$inboundSchema.default("SRV"),
    scrapePort: z.number().default(9090),
    nameList: z.array(z.string()).optional(),
    scrapeProtocol: ScrapeProtocolProtocol$inboundSchema.default("http"),
    scrapePath: z.string().default("/metrics"),
    awsAuthenticationMethod:
      AwsAuthenticationMethodAuthenticationMethodEdgePrometheus$inboundSchema
        .default("auto"),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    usePublicIp: z.boolean().default(true),
    searchFilter: z.array(
      z.lazy(() => SearchFilterEdgePrometheus$inboundSchema),
    ).optional(),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionEdgePrometheus$inboundSchema.default(
      "v4",
    ),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    scrapeProtocolExpr: z.string().default(
      "metadata.annotations['prometheus.io/scheme'] || 'http'",
    ),
    scrapePortExpr: z.string().default(
      "metadata.annotations['prometheus.io/port'] || 9090",
    ),
    scrapePathExpr: z.string().default(
      "metadata.annotations['prometheus.io/path'] || '/metrics'",
    ),
    podFilter: z.array(z.lazy(() => PodFilter$inboundSchema)).optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    credentialsSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputEdgePrometheus$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionEdgePrometheus$Outbound> | undefined;
  pq?: PqEdgePrometheus$Outbound | undefined;
  dimensionList?: Array<string> | undefined;
  discoveryType: string;
  interval: number;
  timeout: number;
  persistence?: DiskSpoolingEdgePrometheus$Outbound | undefined;
  metadata?: Array<MetadatumEdgePrometheus$Outbound> | undefined;
  authType: string;
  description?: string | undefined;
  targets?: Array<Target$Outbound> | undefined;
  recordType: string;
  scrapePort: number;
  nameList?: Array<string> | undefined;
  scrapeProtocol: string;
  scrapePath: string;
  awsAuthenticationMethod: string;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  usePublicIp: boolean;
  searchFilter?: Array<SearchFilterEdgePrometheus$Outbound> | undefined;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  scrapeProtocolExpr: string;
  scrapePortExpr: string;
  scrapePathExpr: string;
  podFilter?: Array<PodFilter$Outbound> | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputEdgePrometheus$outboundSchema: z.ZodType<
  InputEdgePrometheus$Outbound,
  z.ZodTypeDef,
  InputEdgePrometheus
> = z.object({
  id: z.string().optional(),
  type: TypeEdgePrometheus$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionEdgePrometheus$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqEdgePrometheus$outboundSchema).optional(),
  dimensionList: z.array(z.string()).optional(),
  discoveryType: DiscoveryTypeEdgePrometheus$outboundSchema.default("static"),
  interval: z.number().default(15),
  timeout: z.number().default(5000),
  persistence: z.lazy(() => DiskSpoolingEdgePrometheus$outboundSchema)
    .optional(),
  metadata: z.array(z.lazy(() => MetadatumEdgePrometheus$outboundSchema))
    .optional(),
  authType: AuthTypeAuthenticationMethodEdgePrometheus$outboundSchema.default(
    "manual",
  ),
  description: z.string().optional(),
  targets: z.array(z.lazy(() => Target$outboundSchema)).optional(),
  recordType: RecordTypeEdgePrometheus$outboundSchema.default("SRV"),
  scrapePort: z.number().default(9090),
  nameList: z.array(z.string()).optional(),
  scrapeProtocol: ScrapeProtocolProtocol$outboundSchema.default("http"),
  scrapePath: z.string().default("/metrics"),
  awsAuthenticationMethod:
    AwsAuthenticationMethodAuthenticationMethodEdgePrometheus$outboundSchema
      .default("auto"),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  usePublicIp: z.boolean().default(true),
  searchFilter: z.array(z.lazy(() => SearchFilterEdgePrometheus$outboundSchema))
    .optional(),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionEdgePrometheus$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  scrapeProtocolExpr: z.string().default(
    "metadata.annotations['prometheus.io/scheme'] || 'http'",
  ),
  scrapePortExpr: z.string().default(
    "metadata.annotations['prometheus.io/port'] || 9090",
  ),
  scrapePathExpr: z.string().default(
    "metadata.annotations['prometheus.io/path'] || '/metrics'",
  ),
  podFilter: z.array(z.lazy(() => PodFilter$outboundSchema)).optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputEdgePrometheusToJSON(
  inputEdgePrometheus: InputEdgePrometheus,
): string {
  return JSON.stringify(
    InputEdgePrometheus$outboundSchema.parse(inputEdgePrometheus),
  );
}
export function inputEdgePrometheusFromJSON(
  jsonString: string,
): SafeParseResult<InputEdgePrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputEdgePrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputEdgePrometheus' from JSON`,
  );
}

/** @internal */
export const InputTypePrometheus$inboundSchema: z.ZodNativeEnum<
  typeof InputTypePrometheus
> = z.nativeEnum(InputTypePrometheus);
/** @internal */
export const InputTypePrometheus$outboundSchema: z.ZodNativeEnum<
  typeof InputTypePrometheus
> = InputTypePrometheus$inboundSchema;

/** @internal */
export const ConnectionPrometheus$inboundSchema: z.ZodType<
  ConnectionPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionPrometheus$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionPrometheus$outboundSchema: z.ZodType<
  ConnectionPrometheus$Outbound,
  z.ZodTypeDef,
  ConnectionPrometheus
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionPrometheusToJSON(
  connectionPrometheus: ConnectionPrometheus,
): string {
  return JSON.stringify(
    ConnectionPrometheus$outboundSchema.parse(connectionPrometheus),
  );
}
export function connectionPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionPrometheus' from JSON`,
  );
}

/** @internal */
export const PqModePrometheus$inboundSchema: z.ZodType<
  PqModePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModePrometheus$outboundSchema: z.ZodType<
  PqModePrometheus,
  z.ZodTypeDef,
  PqModePrometheus
> = z.union([
  z.nativeEnum(PqModePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionPrometheus$inboundSchema: z.ZodType<
  PqCompressionPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionPrometheus$outboundSchema: z.ZodType<
  PqCompressionPrometheus,
  z.ZodTypeDef,
  PqCompressionPrometheus
> = z.union([
  z.nativeEnum(PqCompressionPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsPrometheus$inboundSchema: z.ZodType<
  InputPqControlsPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsPrometheus$Outbound = {};

/** @internal */
export const InputPqControlsPrometheus$outboundSchema: z.ZodType<
  InputPqControlsPrometheus$Outbound,
  z.ZodTypeDef,
  InputPqControlsPrometheus
> = z.object({});

export function inputPqControlsPrometheusToJSON(
  inputPqControlsPrometheus: InputPqControlsPrometheus,
): string {
  return JSON.stringify(
    InputPqControlsPrometheus$outboundSchema.parse(inputPqControlsPrometheus),
  );
}
export function inputPqControlsPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsPrometheus' from JSON`,
  );
}

/** @internal */
export const PqPrometheus$inboundSchema: z.ZodType<
  PqPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModePrometheus$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionPrometheus$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsPrometheus$inboundSchema).optional(),
});
/** @internal */
export type PqPrometheus$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsPrometheus$Outbound | undefined;
};

/** @internal */
export const PqPrometheus$outboundSchema: z.ZodType<
  PqPrometheus$Outbound,
  z.ZodTypeDef,
  PqPrometheus
> = z.object({
  mode: PqModePrometheus$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionPrometheus$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsPrometheus$outboundSchema).optional(),
});

export function pqPrometheusToJSON(pqPrometheus: PqPrometheus): string {
  return JSON.stringify(PqPrometheus$outboundSchema.parse(pqPrometheus));
}
export function pqPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<PqPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqPrometheus' from JSON`,
  );
}

/** @internal */
export const DiscoveryTypePrometheus$inboundSchema: z.ZodType<
  DiscoveryTypePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(DiscoveryTypePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const DiscoveryTypePrometheus$outboundSchema: z.ZodType<
  DiscoveryTypePrometheus,
  z.ZodTypeDef,
  DiscoveryTypePrometheus
> = z.union([
  z.nativeEnum(DiscoveryTypePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LogLevelPrometheus$inboundSchema: z.ZodType<
  LogLevelPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLevelPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLevelPrometheus$outboundSchema: z.ZodType<
  LogLevelPrometheus,
  z.ZodTypeDef,
  LogLevelPrometheus
> = z.union([
  z.nativeEnum(LogLevelPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumPrometheus$inboundSchema: z.ZodType<
  MetadatumPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumPrometheus$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumPrometheus$outboundSchema: z.ZodType<
  MetadatumPrometheus$Outbound,
  z.ZodTypeDef,
  MetadatumPrometheus
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumPrometheusToJSON(
  metadatumPrometheus: MetadatumPrometheus,
): string {
  return JSON.stringify(
    MetadatumPrometheus$outboundSchema.parse(metadatumPrometheus),
  );
}
export function metadatumPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumPrometheus' from JSON`,
  );
}

/** @internal */
export const AuthTypeAuthenticationMethodPrometheus$inboundSchema: z.ZodType<
  AuthTypeAuthenticationMethodPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthTypeAuthenticationMethodPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthTypeAuthenticationMethodPrometheus$outboundSchema: z.ZodType<
  AuthTypeAuthenticationMethodPrometheus,
  z.ZodTypeDef,
  AuthTypeAuthenticationMethodPrometheus
> = z.union([
  z.nativeEnum(AuthTypeAuthenticationMethodPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RecordTypePrometheus$inboundSchema: z.ZodType<
  RecordTypePrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RecordTypePrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RecordTypePrometheus$outboundSchema: z.ZodType<
  RecordTypePrometheus,
  z.ZodTypeDef,
  RecordTypePrometheus
> = z.union([
  z.nativeEnum(RecordTypePrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetricsProtocol$inboundSchema: z.ZodType<
  MetricsProtocol,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MetricsProtocol),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MetricsProtocol$outboundSchema: z.ZodType<
  MetricsProtocol,
  z.ZodTypeDef,
  MetricsProtocol
> = z.union([
  z.nativeEnum(MetricsProtocol),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AwsAuthenticationMethodAuthenticationMethodPrometheus$inboundSchema:
  z.ZodType<
    AwsAuthenticationMethodAuthenticationMethodPrometheus,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(AwsAuthenticationMethodAuthenticationMethodPrometheus),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const AwsAuthenticationMethodAuthenticationMethodPrometheus$outboundSchema:
  z.ZodType<
    AwsAuthenticationMethodAuthenticationMethodPrometheus,
    z.ZodTypeDef,
    AwsAuthenticationMethodAuthenticationMethodPrometheus
  > = z.union([
    z.nativeEnum(AwsAuthenticationMethodAuthenticationMethodPrometheus),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const SearchFilterPrometheus$inboundSchema: z.ZodType<
  SearchFilterPrometheus,
  z.ZodTypeDef,
  unknown
> = z.object({
  Name: z.string(),
  Values: z.array(z.string()),
}).transform((v) => {
  return remap$(v, {
    "Name": "name",
    "Values": "values",
  });
});
/** @internal */
export type SearchFilterPrometheus$Outbound = {
  Name: string;
  Values: Array<string>;
};

/** @internal */
export const SearchFilterPrometheus$outboundSchema: z.ZodType<
  SearchFilterPrometheus$Outbound,
  z.ZodTypeDef,
  SearchFilterPrometheus
> = z.object({
  name: z.string(),
  values: z.array(z.string()),
}).transform((v) => {
  return remap$(v, {
    name: "Name",
    values: "Values",
  });
});

export function searchFilterPrometheusToJSON(
  searchFilterPrometheus: SearchFilterPrometheus,
): string {
  return JSON.stringify(
    SearchFilterPrometheus$outboundSchema.parse(searchFilterPrometheus),
  );
}
export function searchFilterPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<SearchFilterPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => SearchFilterPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'SearchFilterPrometheus' from JSON`,
  );
}

/** @internal */
export const SignatureVersionPrometheus$inboundSchema: z.ZodType<
  SignatureVersionPrometheus,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(SignatureVersionPrometheus),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const SignatureVersionPrometheus$outboundSchema: z.ZodType<
  SignatureVersionPrometheus,
  z.ZodTypeDef,
  SignatureVersionPrometheus
> = z.union([
  z.nativeEnum(SignatureVersionPrometheus),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPrometheus$inboundSchema: z.ZodType<
  InputPrometheus,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypePrometheus$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionPrometheus$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqPrometheus$inboundSchema).optional(),
    dimensionList: z.array(z.string()).optional(),
    discoveryType: DiscoveryTypePrometheus$inboundSchema.default("static"),
    interval: z.number().default(15),
    logLevel: LogLevelPrometheus$inboundSchema.default("info"),
    rejectUnauthorized: z.boolean().default(true),
    keepAliveTime: z.number().default(30),
    jobTimeout: z.string().default("0"),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumPrometheus$inboundSchema))
      .optional(),
    authType: AuthTypeAuthenticationMethodPrometheus$inboundSchema.default(
      "manual",
    ),
    description: z.string().optional(),
    targetList: z.array(z.string()).optional(),
    recordType: RecordTypePrometheus$inboundSchema.default("SRV"),
    scrapePort: z.number().default(9090),
    nameList: z.array(z.string()).optional(),
    scrapeProtocol: MetricsProtocol$inboundSchema.default("http"),
    scrapePath: z.string().default("/metrics"),
    awsAuthenticationMethod:
      AwsAuthenticationMethodAuthenticationMethodPrometheus$inboundSchema
        .default("auto"),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
    usePublicIp: z.boolean().default(true),
    searchFilter: z.array(z.lazy(() => SearchFilterPrometheus$inboundSchema))
      .optional(),
    awsSecretKey: z.string().optional(),
    region: z.string().optional(),
    endpoint: z.string().optional(),
    signatureVersion: SignatureVersionPrometheus$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    username: z.string().optional(),
    password: z.string().optional(),
    credentialsSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputPrometheus$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionPrometheus$Outbound> | undefined;
  pq?: PqPrometheus$Outbound | undefined;
  dimensionList?: Array<string> | undefined;
  discoveryType: string;
  interval: number;
  logLevel: string;
  rejectUnauthorized: boolean;
  keepAliveTime: number;
  jobTimeout: string;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumPrometheus$Outbound> | undefined;
  authType: string;
  description?: string | undefined;
  targetList?: Array<string> | undefined;
  recordType: string;
  scrapePort: number;
  nameList?: Array<string> | undefined;
  scrapeProtocol: string;
  scrapePath: string;
  awsAuthenticationMethod: string;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  usePublicIp: boolean;
  searchFilter?: Array<SearchFilterPrometheus$Outbound> | undefined;
  awsSecretKey?: string | undefined;
  region?: string | undefined;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputPrometheus$outboundSchema: z.ZodType<
  InputPrometheus$Outbound,
  z.ZodTypeDef,
  InputPrometheus
> = z.object({
  id: z.string().optional(),
  type: InputTypePrometheus$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionPrometheus$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqPrometheus$outboundSchema).optional(),
  dimensionList: z.array(z.string()).optional(),
  discoveryType: DiscoveryTypePrometheus$outboundSchema.default("static"),
  interval: z.number().default(15),
  logLevel: LogLevelPrometheus$outboundSchema.default("info"),
  rejectUnauthorized: z.boolean().default(true),
  keepAliveTime: z.number().default(30),
  jobTimeout: z.string().default("0"),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumPrometheus$outboundSchema))
    .optional(),
  authType: AuthTypeAuthenticationMethodPrometheus$outboundSchema.default(
    "manual",
  ),
  description: z.string().optional(),
  targetList: z.array(z.string()).optional(),
  recordType: RecordTypePrometheus$outboundSchema.default("SRV"),
  scrapePort: z.number().default(9090),
  nameList: z.array(z.string()).optional(),
  scrapeProtocol: MetricsProtocol$outboundSchema.default("http"),
  scrapePath: z.string().default("/metrics"),
  awsAuthenticationMethod:
    AwsAuthenticationMethodAuthenticationMethodPrometheus$outboundSchema
      .default("auto"),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  usePublicIp: z.boolean().default(true),
  searchFilter: z.array(z.lazy(() => SearchFilterPrometheus$outboundSchema))
    .optional(),
  awsSecretKey: z.string().optional(),
  region: z.string().optional(),
  endpoint: z.string().optional(),
  signatureVersion: SignatureVersionPrometheus$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputPrometheusToJSON(
  inputPrometheus: InputPrometheus,
): string {
  return JSON.stringify(InputPrometheus$outboundSchema.parse(inputPrometheus));
}
export function inputPrometheusFromJSON(
  jsonString: string,
): SafeParseResult<InputPrometheus, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPrometheus$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPrometheus' from JSON`,
  );
}

/** @internal */
export const TypePrometheusRw$inboundSchema: z.ZodNativeEnum<
  typeof TypePrometheusRw
> = z.nativeEnum(TypePrometheusRw);
/** @internal */
export const TypePrometheusRw$outboundSchema: z.ZodNativeEnum<
  typeof TypePrometheusRw
> = TypePrometheusRw$inboundSchema;

/** @internal */
export const ConnectionPrometheusRw$inboundSchema: z.ZodType<
  ConnectionPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionPrometheusRw$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionPrometheusRw$outboundSchema: z.ZodType<
  ConnectionPrometheusRw$Outbound,
  z.ZodTypeDef,
  ConnectionPrometheusRw
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionPrometheusRwToJSON(
  connectionPrometheusRw: ConnectionPrometheusRw,
): string {
  return JSON.stringify(
    ConnectionPrometheusRw$outboundSchema.parse(connectionPrometheusRw),
  );
}
export function connectionPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionPrometheusRw' from JSON`,
  );
}

/** @internal */
export const ModePrometheusRw$inboundSchema: z.ZodType<
  ModePrometheusRw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModePrometheusRw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModePrometheusRw$outboundSchema: z.ZodType<
  ModePrometheusRw,
  z.ZodTypeDef,
  ModePrometheusRw
> = z.union([
  z.nativeEnum(ModePrometheusRw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionPrometheusRw$inboundSchema: z.ZodType<
  CompressionPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionPrometheusRw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionPrometheusRw$outboundSchema: z.ZodType<
  CompressionPrometheusRw,
  z.ZodTypeDef,
  CompressionPrometheusRw
> = z.union([
  z.nativeEnum(CompressionPrometheusRw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsPrometheusRw$inboundSchema: z.ZodType<
  PqControlsPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsPrometheusRw$Outbound = {};

/** @internal */
export const PqControlsPrometheusRw$outboundSchema: z.ZodType<
  PqControlsPrometheusRw$Outbound,
  z.ZodTypeDef,
  PqControlsPrometheusRw
> = z.object({});

export function pqControlsPrometheusRwToJSON(
  pqControlsPrometheusRw: PqControlsPrometheusRw,
): string {
  return JSON.stringify(
    PqControlsPrometheusRw$outboundSchema.parse(pqControlsPrometheusRw),
  );
}
export function pqControlsPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsPrometheusRw' from JSON`,
  );
}

/** @internal */
export const PqPrometheusRw$inboundSchema: z.ZodType<
  PqPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModePrometheusRw$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionPrometheusRw$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsPrometheusRw$inboundSchema).optional(),
});
/** @internal */
export type PqPrometheusRw$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsPrometheusRw$Outbound | undefined;
};

/** @internal */
export const PqPrometheusRw$outboundSchema: z.ZodType<
  PqPrometheusRw$Outbound,
  z.ZodTypeDef,
  PqPrometheusRw
> = z.object({
  mode: ModePrometheusRw$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionPrometheusRw$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsPrometheusRw$outboundSchema).optional(),
});

export function pqPrometheusRwToJSON(pqPrometheusRw: PqPrometheusRw): string {
  return JSON.stringify(PqPrometheusRw$outboundSchema.parse(pqPrometheusRw));
}
export function pqPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<PqPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqPrometheusRw' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionPrometheusRw$inboundSchema: z.ZodType<
  MinimumTLSVersionPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionPrometheusRw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionPrometheusRw$outboundSchema: z.ZodType<
  MinimumTLSVersionPrometheusRw,
  z.ZodTypeDef,
  MinimumTLSVersionPrometheusRw
> = z.union([
  z.nativeEnum(MinimumTLSVersionPrometheusRw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionPrometheusRw$inboundSchema: z.ZodType<
  MaximumTLSVersionPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionPrometheusRw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionPrometheusRw$outboundSchema: z.ZodType<
  MaximumTLSVersionPrometheusRw,
  z.ZodTypeDef,
  MaximumTLSVersionPrometheusRw
> = z.union([
  z.nativeEnum(MaximumTLSVersionPrometheusRw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSidePrometheusRw$inboundSchema: z.ZodType<
  TLSSettingsServerSidePrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionPrometheusRw$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionPrometheusRw$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSidePrometheusRw$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSidePrometheusRw$outboundSchema: z.ZodType<
  TLSSettingsServerSidePrometheusRw$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSidePrometheusRw
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionPrometheusRw$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionPrometheusRw$outboundSchema.optional(),
});

export function tlsSettingsServerSidePrometheusRwToJSON(
  tlsSettingsServerSidePrometheusRw: TLSSettingsServerSidePrometheusRw,
): string {
  return JSON.stringify(
    TLSSettingsServerSidePrometheusRw$outboundSchema.parse(
      tlsSettingsServerSidePrometheusRw,
    ),
  );
}
export function tlsSettingsServerSidePrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSidePrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSidePrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSidePrometheusRw' from JSON`,
  );
}

/** @internal */
export const AuthenticationTypePrometheusRw$inboundSchema: z.ZodType<
  AuthenticationTypePrometheusRw,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypePrometheusRw),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypePrometheusRw$outboundSchema: z.ZodType<
  AuthenticationTypePrometheusRw,
  z.ZodTypeDef,
  AuthenticationTypePrometheusRw
> = z.union([
  z.nativeEnum(AuthenticationTypePrometheusRw),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumPrometheusRw$inboundSchema: z.ZodType<
  MetadatumPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumPrometheusRw$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumPrometheusRw$outboundSchema: z.ZodType<
  MetadatumPrometheusRw$Outbound,
  z.ZodTypeDef,
  MetadatumPrometheusRw
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumPrometheusRwToJSON(
  metadatumPrometheusRw: MetadatumPrometheusRw,
): string {
  return JSON.stringify(
    MetadatumPrometheusRw$outboundSchema.parse(metadatumPrometheusRw),
  );
}
export function metadatumPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumPrometheusRw' from JSON`,
  );
}

/** @internal */
export const OauthParamPrometheusRw$inboundSchema: z.ZodType<
  OauthParamPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamPrometheusRw$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamPrometheusRw$outboundSchema: z.ZodType<
  OauthParamPrometheusRw$Outbound,
  z.ZodTypeDef,
  OauthParamPrometheusRw
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamPrometheusRwToJSON(
  oauthParamPrometheusRw: OauthParamPrometheusRw,
): string {
  return JSON.stringify(
    OauthParamPrometheusRw$outboundSchema.parse(oauthParamPrometheusRw),
  );
}
export function oauthParamPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamPrometheusRw' from JSON`,
  );
}

/** @internal */
export const OauthHeaderPrometheusRw$inboundSchema: z.ZodType<
  OauthHeaderPrometheusRw,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderPrometheusRw$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderPrometheusRw$outboundSchema: z.ZodType<
  OauthHeaderPrometheusRw$Outbound,
  z.ZodTypeDef,
  OauthHeaderPrometheusRw
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderPrometheusRwToJSON(
  oauthHeaderPrometheusRw: OauthHeaderPrometheusRw,
): string {
  return JSON.stringify(
    OauthHeaderPrometheusRw$outboundSchema.parse(oauthHeaderPrometheusRw),
  );
}
export function oauthHeaderPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderPrometheusRw' from JSON`,
  );
}

/** @internal */
export const InputPrometheusRw$inboundSchema: z.ZodType<
  InputPrometheusRw,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypePrometheusRw$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionPrometheusRw$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqPrometheusRw$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSidePrometheusRw$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    prometheusAPI: z.string().default("/write"),
    authType: AuthenticationTypePrometheusRw$inboundSchema.default("none"),
    metadata: z.array(z.lazy(() => MetadatumPrometheusRw$inboundSchema))
      .optional(),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamPrometheusRw$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderPrometheusRw$inboundSchema))
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputPrometheusRw$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionPrometheusRw$Outbound> | undefined;
  pq?: PqPrometheusRw$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSidePrometheusRw$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  prometheusAPI: string;
  authType: string;
  metadata?: Array<MetadatumPrometheusRw$Outbound> | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamPrometheusRw$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderPrometheusRw$Outbound> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputPrometheusRw$outboundSchema: z.ZodType<
  InputPrometheusRw$Outbound,
  z.ZodTypeDef,
  InputPrometheusRw
> = z.object({
  id: z.string().optional(),
  type: TypePrometheusRw$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionPrometheusRw$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqPrometheusRw$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSidePrometheusRw$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  prometheusAPI: z.string().default("/write"),
  authType: AuthenticationTypePrometheusRw$outboundSchema.default("none"),
  metadata: z.array(z.lazy(() => MetadatumPrometheusRw$outboundSchema))
    .optional(),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamPrometheusRw$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderPrometheusRw$outboundSchema))
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputPrometheusRwToJSON(
  inputPrometheusRw: InputPrometheusRw,
): string {
  return JSON.stringify(
    InputPrometheusRw$outboundSchema.parse(inputPrometheusRw),
  );
}
export function inputPrometheusRwFromJSON(
  jsonString: string,
): SafeParseResult<InputPrometheusRw, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPrometheusRw$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPrometheusRw' from JSON`,
  );
}

/** @internal */
export const InputTypeLoki$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeLoki
> = z.nativeEnum(InputTypeLoki);
/** @internal */
export const InputTypeLoki$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeLoki
> = InputTypeLoki$inboundSchema;

/** @internal */
export const ConnectionLoki$inboundSchema: z.ZodType<
  ConnectionLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionLoki$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionLoki$outboundSchema: z.ZodType<
  ConnectionLoki$Outbound,
  z.ZodTypeDef,
  ConnectionLoki
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionLokiToJSON(connectionLoki: ConnectionLoki): string {
  return JSON.stringify(ConnectionLoki$outboundSchema.parse(connectionLoki));
}
export function connectionLokiFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionLoki' from JSON`,
  );
}

/** @internal */
export const PqModeLoki$inboundSchema: z.ZodType<
  PqModeLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeLoki$outboundSchema: z.ZodType<
  PqModeLoki,
  z.ZodTypeDef,
  PqModeLoki
> = z.union([
  z.nativeEnum(PqModeLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionLoki$inboundSchema: z.ZodType<
  PqCompressionLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionLoki$outboundSchema: z.ZodType<
  PqCompressionLoki,
  z.ZodTypeDef,
  PqCompressionLoki
> = z.union([
  z.nativeEnum(PqCompressionLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsLoki$inboundSchema: z.ZodType<
  InputPqControlsLoki,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsLoki$Outbound = {};

/** @internal */
export const InputPqControlsLoki$outboundSchema: z.ZodType<
  InputPqControlsLoki$Outbound,
  z.ZodTypeDef,
  InputPqControlsLoki
> = z.object({});

export function inputPqControlsLokiToJSON(
  inputPqControlsLoki: InputPqControlsLoki,
): string {
  return JSON.stringify(
    InputPqControlsLoki$outboundSchema.parse(inputPqControlsLoki),
  );
}
export function inputPqControlsLokiFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsLoki' from JSON`,
  );
}

/** @internal */
export const PqLoki$inboundSchema: z.ZodType<PqLoki, z.ZodTypeDef, unknown> = z
  .object({
    mode: PqModeLoki$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionLoki$inboundSchema.default("none"),
    pqControls: z.lazy(() => InputPqControlsLoki$inboundSchema).optional(),
  });
/** @internal */
export type PqLoki$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsLoki$Outbound | undefined;
};

/** @internal */
export const PqLoki$outboundSchema: z.ZodType<
  PqLoki$Outbound,
  z.ZodTypeDef,
  PqLoki
> = z.object({
  mode: PqModeLoki$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionLoki$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsLoki$outboundSchema).optional(),
});

export function pqLokiToJSON(pqLoki: PqLoki): string {
  return JSON.stringify(PqLoki$outboundSchema.parse(pqLoki));
}
export function pqLokiFromJSON(
  jsonString: string,
): SafeParseResult<PqLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqLoki' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionLoki$inboundSchema: z.ZodType<
  MinimumTLSVersionLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionLoki$outboundSchema: z.ZodType<
  MinimumTLSVersionLoki,
  z.ZodTypeDef,
  MinimumTLSVersionLoki
> = z.union([
  z.nativeEnum(MinimumTLSVersionLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionLoki$inboundSchema: z.ZodType<
  MaximumTLSVersionLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionLoki$outboundSchema: z.ZodType<
  MaximumTLSVersionLoki,
  z.ZodTypeDef,
  MaximumTLSVersionLoki
> = z.union([
  z.nativeEnum(MaximumTLSVersionLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideLoki$inboundSchema: z.ZodType<
  TLSSettingsServerSideLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionLoki$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionLoki$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideLoki$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideLoki$outboundSchema: z.ZodType<
  TLSSettingsServerSideLoki$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideLoki
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionLoki$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionLoki$outboundSchema.optional(),
});

export function tlsSettingsServerSideLokiToJSON(
  tlsSettingsServerSideLoki: TLSSettingsServerSideLoki,
): string {
  return JSON.stringify(
    TLSSettingsServerSideLoki$outboundSchema.parse(tlsSettingsServerSideLoki),
  );
}
export function tlsSettingsServerSideLokiFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideLoki' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationTypeLoki$inboundSchema: z.ZodType<
  InputAuthenticationTypeLoki,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationTypeLoki),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationTypeLoki$outboundSchema: z.ZodType<
  InputAuthenticationTypeLoki,
  z.ZodTypeDef,
  InputAuthenticationTypeLoki
> = z.union([
  z.nativeEnum(InputAuthenticationTypeLoki),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumLoki$inboundSchema: z.ZodType<
  MetadatumLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumLoki$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumLoki$outboundSchema: z.ZodType<
  MetadatumLoki$Outbound,
  z.ZodTypeDef,
  MetadatumLoki
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumLokiToJSON(metadatumLoki: MetadatumLoki): string {
  return JSON.stringify(MetadatumLoki$outboundSchema.parse(metadatumLoki));
}
export function metadatumLokiFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumLoki' from JSON`,
  );
}

/** @internal */
export const OauthParamLoki$inboundSchema: z.ZodType<
  OauthParamLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamLoki$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamLoki$outboundSchema: z.ZodType<
  OauthParamLoki$Outbound,
  z.ZodTypeDef,
  OauthParamLoki
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamLokiToJSON(oauthParamLoki: OauthParamLoki): string {
  return JSON.stringify(OauthParamLoki$outboundSchema.parse(oauthParamLoki));
}
export function oauthParamLokiFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamLoki' from JSON`,
  );
}

/** @internal */
export const OauthHeaderLoki$inboundSchema: z.ZodType<
  OauthHeaderLoki,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderLoki$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderLoki$outboundSchema: z.ZodType<
  OauthHeaderLoki$Outbound,
  z.ZodTypeDef,
  OauthHeaderLoki
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderLokiToJSON(
  oauthHeaderLoki: OauthHeaderLoki,
): string {
  return JSON.stringify(OauthHeaderLoki$outboundSchema.parse(oauthHeaderLoki));
}
export function oauthHeaderLokiFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderLoki' from JSON`,
  );
}

/** @internal */
export const InputLoki$inboundSchema: z.ZodType<
  InputLoki,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeLoki$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionLoki$inboundSchema)).optional(),
    pq: z.lazy(() => PqLoki$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideLoki$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    lokiAPI: z.string().default("/loki/api/v1/push"),
    authType: InputAuthenticationTypeLoki$inboundSchema.default("none"),
    metadata: z.array(z.lazy(() => MetadatumLoki$inboundSchema)).optional(),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamLoki$inboundSchema)).optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderLoki$inboundSchema))
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputLoki$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionLoki$Outbound> | undefined;
  pq?: PqLoki$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideLoki$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  lokiAPI: string;
  authType: string;
  metadata?: Array<MetadatumLoki$Outbound> | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamLoki$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderLoki$Outbound> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputLoki$outboundSchema: z.ZodType<
  InputLoki$Outbound,
  z.ZodTypeDef,
  InputLoki
> = z.object({
  id: z.string().optional(),
  type: InputTypeLoki$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionLoki$outboundSchema)).optional(),
  pq: z.lazy(() => PqLoki$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideLoki$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  lokiAPI: z.string().default("/loki/api/v1/push"),
  authType: InputAuthenticationTypeLoki$outboundSchema.default("none"),
  metadata: z.array(z.lazy(() => MetadatumLoki$outboundSchema)).optional(),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamLoki$outboundSchema)).optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderLoki$outboundSchema))
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputLokiToJSON(inputLoki: InputLoki): string {
  return JSON.stringify(InputLoki$outboundSchema.parse(inputLoki));
}
export function inputLokiFromJSON(
  jsonString: string,
): SafeParseResult<InputLoki, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputLoki$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputLoki' from JSON`,
  );
}

/** @internal */
export const InputGrafanaType2$inboundSchema: z.ZodNativeEnum<
  typeof InputGrafanaType2
> = z.nativeEnum(InputGrafanaType2);
/** @internal */
export const InputGrafanaType2$outboundSchema: z.ZodNativeEnum<
  typeof InputGrafanaType2
> = InputGrafanaType2$inboundSchema;

/** @internal */
export const InputGrafanaConnection2$inboundSchema: z.ZodType<
  InputGrafanaConnection2,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputGrafanaConnection2$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputGrafanaConnection2$outboundSchema: z.ZodType<
  InputGrafanaConnection2$Outbound,
  z.ZodTypeDef,
  InputGrafanaConnection2
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputGrafanaConnection2ToJSON(
  inputGrafanaConnection2: InputGrafanaConnection2,
): string {
  return JSON.stringify(
    InputGrafanaConnection2$outboundSchema.parse(inputGrafanaConnection2),
  );
}
export function inputGrafanaConnection2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaConnection2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaConnection2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaConnection2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMode2$inboundSchema: z.ZodType<
  InputGrafanaMode2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMode2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMode2$outboundSchema: z.ZodType<
  InputGrafanaMode2,
  z.ZodTypeDef,
  InputGrafanaMode2
> = z.union([
  z.nativeEnum(InputGrafanaMode2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaCompression2$inboundSchema: z.ZodType<
  InputGrafanaCompression2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaCompression2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaCompression2$outboundSchema: z.ZodType<
  InputGrafanaCompression2,
  z.ZodTypeDef,
  InputGrafanaCompression2
> = z.union([
  z.nativeEnum(InputGrafanaCompression2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaPqControls2$inboundSchema: z.ZodType<
  InputGrafanaPqControls2,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputGrafanaPqControls2$Outbound = {};

/** @internal */
export const InputGrafanaPqControls2$outboundSchema: z.ZodType<
  InputGrafanaPqControls2$Outbound,
  z.ZodTypeDef,
  InputGrafanaPqControls2
> = z.object({});

export function inputGrafanaPqControls2ToJSON(
  inputGrafanaPqControls2: InputGrafanaPqControls2,
): string {
  return JSON.stringify(
    InputGrafanaPqControls2$outboundSchema.parse(inputGrafanaPqControls2),
  );
}
export function inputGrafanaPqControls2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaPqControls2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaPqControls2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaPqControls2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaPq2$inboundSchema: z.ZodType<
  InputGrafanaPq2,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputGrafanaMode2$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputGrafanaCompression2$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputGrafanaPqControls2$inboundSchema).optional(),
});
/** @internal */
export type InputGrafanaPq2$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputGrafanaPqControls2$Outbound | undefined;
};

/** @internal */
export const InputGrafanaPq2$outboundSchema: z.ZodType<
  InputGrafanaPq2$Outbound,
  z.ZodTypeDef,
  InputGrafanaPq2
> = z.object({
  mode: InputGrafanaMode2$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputGrafanaCompression2$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputGrafanaPqControls2$outboundSchema).optional(),
});

export function inputGrafanaPq2ToJSON(
  inputGrafanaPq2: InputGrafanaPq2,
): string {
  return JSON.stringify(InputGrafanaPq2$outboundSchema.parse(inputGrafanaPq2));
}
export function inputGrafanaPq2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaPq2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaPq2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaPq2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMinimumTLSVersion2$inboundSchema: z.ZodType<
  InputGrafanaMinimumTLSVersion2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMinimumTLSVersion2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMinimumTLSVersion2$outboundSchema: z.ZodType<
  InputGrafanaMinimumTLSVersion2,
  z.ZodTypeDef,
  InputGrafanaMinimumTLSVersion2
> = z.union([
  z.nativeEnum(InputGrafanaMinimumTLSVersion2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaMaximumTLSVersion2$inboundSchema: z.ZodType<
  InputGrafanaMaximumTLSVersion2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMaximumTLSVersion2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMaximumTLSVersion2$outboundSchema: z.ZodType<
  InputGrafanaMaximumTLSVersion2,
  z.ZodTypeDef,
  InputGrafanaMaximumTLSVersion2
> = z.union([
  z.nativeEnum(InputGrafanaMaximumTLSVersion2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaTLSSettingsServerSide2$inboundSchema: z.ZodType<
  InputGrafanaTLSSettingsServerSide2,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputGrafanaMinimumTLSVersion2$inboundSchema.optional(),
  maxVersion: InputGrafanaMaximumTLSVersion2$inboundSchema.optional(),
});
/** @internal */
export type InputGrafanaTLSSettingsServerSide2$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputGrafanaTLSSettingsServerSide2$outboundSchema: z.ZodType<
  InputGrafanaTLSSettingsServerSide2$Outbound,
  z.ZodTypeDef,
  InputGrafanaTLSSettingsServerSide2
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputGrafanaMinimumTLSVersion2$outboundSchema.optional(),
  maxVersion: InputGrafanaMaximumTLSVersion2$outboundSchema.optional(),
});

export function inputGrafanaTLSSettingsServerSide2ToJSON(
  inputGrafanaTLSSettingsServerSide2: InputGrafanaTLSSettingsServerSide2,
): string {
  return JSON.stringify(
    InputGrafanaTLSSettingsServerSide2$outboundSchema.parse(
      inputGrafanaTLSSettingsServerSide2,
    ),
  );
}
export function inputGrafanaTLSSettingsServerSide2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaTLSSettingsServerSide2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      InputGrafanaTLSSettingsServerSide2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaTLSSettingsServerSide2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaPrometheusAuthAuthenticationType2$inboundSchema:
  z.ZodType<
    InputGrafanaPrometheusAuthAuthenticationType2,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputGrafanaPrometheusAuthAuthenticationType2),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputGrafanaPrometheusAuthAuthenticationType2$outboundSchema:
  z.ZodType<
    InputGrafanaPrometheusAuthAuthenticationType2,
    z.ZodTypeDef,
    InputGrafanaPrometheusAuthAuthenticationType2
  > = z.union([
    z.nativeEnum(InputGrafanaPrometheusAuthAuthenticationType2),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const PrometheusAuthOauthParam2$inboundSchema: z.ZodType<
  PrometheusAuthOauthParam2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type PrometheusAuthOauthParam2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const PrometheusAuthOauthParam2$outboundSchema: z.ZodType<
  PrometheusAuthOauthParam2$Outbound,
  z.ZodTypeDef,
  PrometheusAuthOauthParam2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function prometheusAuthOauthParam2ToJSON(
  prometheusAuthOauthParam2: PrometheusAuthOauthParam2,
): string {
  return JSON.stringify(
    PrometheusAuthOauthParam2$outboundSchema.parse(prometheusAuthOauthParam2),
  );
}
export function prometheusAuthOauthParam2FromJSON(
  jsonString: string,
): SafeParseResult<PrometheusAuthOauthParam2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PrometheusAuthOauthParam2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PrometheusAuthOauthParam2' from JSON`,
  );
}

/** @internal */
export const PrometheusAuthOauthHeader2$inboundSchema: z.ZodType<
  PrometheusAuthOauthHeader2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type PrometheusAuthOauthHeader2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const PrometheusAuthOauthHeader2$outboundSchema: z.ZodType<
  PrometheusAuthOauthHeader2$Outbound,
  z.ZodTypeDef,
  PrometheusAuthOauthHeader2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function prometheusAuthOauthHeader2ToJSON(
  prometheusAuthOauthHeader2: PrometheusAuthOauthHeader2,
): string {
  return JSON.stringify(
    PrometheusAuthOauthHeader2$outboundSchema.parse(prometheusAuthOauthHeader2),
  );
}
export function prometheusAuthOauthHeader2FromJSON(
  jsonString: string,
): SafeParseResult<PrometheusAuthOauthHeader2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PrometheusAuthOauthHeader2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PrometheusAuthOauthHeader2' from JSON`,
  );
}

/** @internal */
export const InputPrometheusAuth2$inboundSchema: z.ZodType<
  InputPrometheusAuth2,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: InputGrafanaPrometheusAuthAuthenticationType2$inboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => PrometheusAuthOauthParam2$inboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => PrometheusAuthOauthHeader2$inboundSchema))
    .optional(),
});
/** @internal */
export type InputPrometheusAuth2$Outbound = {
  authType: string;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<PrometheusAuthOauthParam2$Outbound> | undefined;
  oauthHeaders?: Array<PrometheusAuthOauthHeader2$Outbound> | undefined;
};

/** @internal */
export const InputPrometheusAuth2$outboundSchema: z.ZodType<
  InputPrometheusAuth2$Outbound,
  z.ZodTypeDef,
  InputPrometheusAuth2
> = z.object({
  authType: InputGrafanaPrometheusAuthAuthenticationType2$outboundSchema
    .default("none"),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => PrometheusAuthOauthParam2$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => PrometheusAuthOauthHeader2$outboundSchema))
    .optional(),
});

export function inputPrometheusAuth2ToJSON(
  inputPrometheusAuth2: InputPrometheusAuth2,
): string {
  return JSON.stringify(
    InputPrometheusAuth2$outboundSchema.parse(inputPrometheusAuth2),
  );
}
export function inputPrometheusAuth2FromJSON(
  jsonString: string,
): SafeParseResult<InputPrometheusAuth2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPrometheusAuth2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPrometheusAuth2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaLokiAuthAuthenticationType2$inboundSchema: z.ZodType<
  InputGrafanaLokiAuthAuthenticationType2,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaLokiAuthAuthenticationType2),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaLokiAuthAuthenticationType2$outboundSchema: z.ZodType<
  InputGrafanaLokiAuthAuthenticationType2,
  z.ZodTypeDef,
  InputGrafanaLokiAuthAuthenticationType2
> = z.union([
  z.nativeEnum(InputGrafanaLokiAuthAuthenticationType2),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LokiAuthOauthParam2$inboundSchema: z.ZodType<
  LokiAuthOauthParam2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type LokiAuthOauthParam2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const LokiAuthOauthParam2$outboundSchema: z.ZodType<
  LokiAuthOauthParam2$Outbound,
  z.ZodTypeDef,
  LokiAuthOauthParam2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function lokiAuthOauthParam2ToJSON(
  lokiAuthOauthParam2: LokiAuthOauthParam2,
): string {
  return JSON.stringify(
    LokiAuthOauthParam2$outboundSchema.parse(lokiAuthOauthParam2),
  );
}
export function lokiAuthOauthParam2FromJSON(
  jsonString: string,
): SafeParseResult<LokiAuthOauthParam2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LokiAuthOauthParam2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LokiAuthOauthParam2' from JSON`,
  );
}

/** @internal */
export const LokiAuthOauthHeader2$inboundSchema: z.ZodType<
  LokiAuthOauthHeader2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type LokiAuthOauthHeader2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const LokiAuthOauthHeader2$outboundSchema: z.ZodType<
  LokiAuthOauthHeader2$Outbound,
  z.ZodTypeDef,
  LokiAuthOauthHeader2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function lokiAuthOauthHeader2ToJSON(
  lokiAuthOauthHeader2: LokiAuthOauthHeader2,
): string {
  return JSON.stringify(
    LokiAuthOauthHeader2$outboundSchema.parse(lokiAuthOauthHeader2),
  );
}
export function lokiAuthOauthHeader2FromJSON(
  jsonString: string,
): SafeParseResult<LokiAuthOauthHeader2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LokiAuthOauthHeader2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LokiAuthOauthHeader2' from JSON`,
  );
}

/** @internal */
export const InputLokiAuth2$inboundSchema: z.ZodType<
  InputLokiAuth2,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: InputGrafanaLokiAuthAuthenticationType2$inboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => LokiAuthOauthParam2$inboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => LokiAuthOauthHeader2$inboundSchema))
    .optional(),
});
/** @internal */
export type InputLokiAuth2$Outbound = {
  authType: string;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<LokiAuthOauthParam2$Outbound> | undefined;
  oauthHeaders?: Array<LokiAuthOauthHeader2$Outbound> | undefined;
};

/** @internal */
export const InputLokiAuth2$outboundSchema: z.ZodType<
  InputLokiAuth2$Outbound,
  z.ZodTypeDef,
  InputLokiAuth2
> = z.object({
  authType: InputGrafanaLokiAuthAuthenticationType2$outboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => LokiAuthOauthParam2$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => LokiAuthOauthHeader2$outboundSchema))
    .optional(),
});

export function inputLokiAuth2ToJSON(inputLokiAuth2: InputLokiAuth2): string {
  return JSON.stringify(InputLokiAuth2$outboundSchema.parse(inputLokiAuth2));
}
export function inputLokiAuth2FromJSON(
  jsonString: string,
): SafeParseResult<InputLokiAuth2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputLokiAuth2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputLokiAuth2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMetadatum2$inboundSchema: z.ZodType<
  InputGrafanaMetadatum2,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputGrafanaMetadatum2$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputGrafanaMetadatum2$outboundSchema: z.ZodType<
  InputGrafanaMetadatum2$Outbound,
  z.ZodTypeDef,
  InputGrafanaMetadatum2
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputGrafanaMetadatum2ToJSON(
  inputGrafanaMetadatum2: InputGrafanaMetadatum2,
): string {
  return JSON.stringify(
    InputGrafanaMetadatum2$outboundSchema.parse(inputGrafanaMetadatum2),
  );
}
export function inputGrafanaMetadatum2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaMetadatum2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaMetadatum2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaMetadatum2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaGrafana2$inboundSchema: z.ZodType<
  InputGrafanaGrafana2,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputGrafanaType2$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputGrafanaConnection2$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputGrafanaPq2$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => InputGrafanaTLSSettingsServerSide2$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    prometheusAPI: z.string().default("/api/prom/push"),
    lokiAPI: z.string().default("/loki/api/v1/push"),
    prometheusAuth: z.lazy(() => InputPrometheusAuth2$inboundSchema).optional(),
    lokiAuth: z.lazy(() => InputLokiAuth2$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => InputGrafanaMetadatum2$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputGrafanaGrafana2$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputGrafanaConnection2$Outbound> | undefined;
  pq?: InputGrafanaPq2$Outbound | undefined;
  host: string;
  port: number;
  tls?: InputGrafanaTLSSettingsServerSide2$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  prometheusAPI: string;
  lokiAPI: string;
  prometheusAuth?: InputPrometheusAuth2$Outbound | undefined;
  lokiAuth?: InputLokiAuth2$Outbound | undefined;
  metadata?: Array<InputGrafanaMetadatum2$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputGrafanaGrafana2$outboundSchema: z.ZodType<
  InputGrafanaGrafana2$Outbound,
  z.ZodTypeDef,
  InputGrafanaGrafana2
> = z.object({
  id: z.string().optional(),
  type: InputGrafanaType2$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputGrafanaConnection2$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputGrafanaPq2$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => InputGrafanaTLSSettingsServerSide2$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  prometheusAPI: z.string().default("/api/prom/push"),
  lokiAPI: z.string().default("/loki/api/v1/push"),
  prometheusAuth: z.lazy(() => InputPrometheusAuth2$outboundSchema).optional(),
  lokiAuth: z.lazy(() => InputLokiAuth2$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => InputGrafanaMetadatum2$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputGrafanaGrafana2ToJSON(
  inputGrafanaGrafana2: InputGrafanaGrafana2,
): string {
  return JSON.stringify(
    InputGrafanaGrafana2$outboundSchema.parse(inputGrafanaGrafana2),
  );
}
export function inputGrafanaGrafana2FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaGrafana2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaGrafana2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaGrafana2' from JSON`,
  );
}

/** @internal */
export const InputGrafanaType1$inboundSchema: z.ZodNativeEnum<
  typeof InputGrafanaType1
> = z.nativeEnum(InputGrafanaType1);
/** @internal */
export const InputGrafanaType1$outboundSchema: z.ZodNativeEnum<
  typeof InputGrafanaType1
> = InputGrafanaType1$inboundSchema;

/** @internal */
export const InputGrafanaConnection1$inboundSchema: z.ZodType<
  InputGrafanaConnection1,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type InputGrafanaConnection1$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const InputGrafanaConnection1$outboundSchema: z.ZodType<
  InputGrafanaConnection1$Outbound,
  z.ZodTypeDef,
  InputGrafanaConnection1
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function inputGrafanaConnection1ToJSON(
  inputGrafanaConnection1: InputGrafanaConnection1,
): string {
  return JSON.stringify(
    InputGrafanaConnection1$outboundSchema.parse(inputGrafanaConnection1),
  );
}
export function inputGrafanaConnection1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaConnection1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaConnection1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaConnection1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMode1$inboundSchema: z.ZodType<
  InputGrafanaMode1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMode1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMode1$outboundSchema: z.ZodType<
  InputGrafanaMode1,
  z.ZodTypeDef,
  InputGrafanaMode1
> = z.union([
  z.nativeEnum(InputGrafanaMode1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaCompression1$inboundSchema: z.ZodType<
  InputGrafanaCompression1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaCompression1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaCompression1$outboundSchema: z.ZodType<
  InputGrafanaCompression1,
  z.ZodTypeDef,
  InputGrafanaCompression1
> = z.union([
  z.nativeEnum(InputGrafanaCompression1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaPqControls1$inboundSchema: z.ZodType<
  InputGrafanaPqControls1,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputGrafanaPqControls1$Outbound = {};

/** @internal */
export const InputGrafanaPqControls1$outboundSchema: z.ZodType<
  InputGrafanaPqControls1$Outbound,
  z.ZodTypeDef,
  InputGrafanaPqControls1
> = z.object({});

export function inputGrafanaPqControls1ToJSON(
  inputGrafanaPqControls1: InputGrafanaPqControls1,
): string {
  return JSON.stringify(
    InputGrafanaPqControls1$outboundSchema.parse(inputGrafanaPqControls1),
  );
}
export function inputGrafanaPqControls1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaPqControls1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaPqControls1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaPqControls1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaPq1$inboundSchema: z.ZodType<
  InputGrafanaPq1,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: InputGrafanaMode1$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputGrafanaCompression1$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputGrafanaPqControls1$inboundSchema).optional(),
});
/** @internal */
export type InputGrafanaPq1$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputGrafanaPqControls1$Outbound | undefined;
};

/** @internal */
export const InputGrafanaPq1$outboundSchema: z.ZodType<
  InputGrafanaPq1$Outbound,
  z.ZodTypeDef,
  InputGrafanaPq1
> = z.object({
  mode: InputGrafanaMode1$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: InputGrafanaCompression1$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputGrafanaPqControls1$outboundSchema).optional(),
});

export function inputGrafanaPq1ToJSON(
  inputGrafanaPq1: InputGrafanaPq1,
): string {
  return JSON.stringify(InputGrafanaPq1$outboundSchema.parse(inputGrafanaPq1));
}
export function inputGrafanaPq1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaPq1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaPq1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaPq1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMinimumTLSVersion1$inboundSchema: z.ZodType<
  InputGrafanaMinimumTLSVersion1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMinimumTLSVersion1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMinimumTLSVersion1$outboundSchema: z.ZodType<
  InputGrafanaMinimumTLSVersion1,
  z.ZodTypeDef,
  InputGrafanaMinimumTLSVersion1
> = z.union([
  z.nativeEnum(InputGrafanaMinimumTLSVersion1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaMaximumTLSVersion1$inboundSchema: z.ZodType<
  InputGrafanaMaximumTLSVersion1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaMaximumTLSVersion1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaMaximumTLSVersion1$outboundSchema: z.ZodType<
  InputGrafanaMaximumTLSVersion1,
  z.ZodTypeDef,
  InputGrafanaMaximumTLSVersion1
> = z.union([
  z.nativeEnum(InputGrafanaMaximumTLSVersion1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputGrafanaTLSSettingsServerSide1$inboundSchema: z.ZodType<
  InputGrafanaTLSSettingsServerSide1,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputGrafanaMinimumTLSVersion1$inboundSchema.optional(),
  maxVersion: InputGrafanaMaximumTLSVersion1$inboundSchema.optional(),
});
/** @internal */
export type InputGrafanaTLSSettingsServerSide1$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputGrafanaTLSSettingsServerSide1$outboundSchema: z.ZodType<
  InputGrafanaTLSSettingsServerSide1$Outbound,
  z.ZodTypeDef,
  InputGrafanaTLSSettingsServerSide1
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputGrafanaMinimumTLSVersion1$outboundSchema.optional(),
  maxVersion: InputGrafanaMaximumTLSVersion1$outboundSchema.optional(),
});

export function inputGrafanaTLSSettingsServerSide1ToJSON(
  inputGrafanaTLSSettingsServerSide1: InputGrafanaTLSSettingsServerSide1,
): string {
  return JSON.stringify(
    InputGrafanaTLSSettingsServerSide1$outboundSchema.parse(
      inputGrafanaTLSSettingsServerSide1,
    ),
  );
}
export function inputGrafanaTLSSettingsServerSide1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaTLSSettingsServerSide1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) =>
      InputGrafanaTLSSettingsServerSide1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaTLSSettingsServerSide1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaPrometheusAuthAuthenticationType1$inboundSchema:
  z.ZodType<
    InputGrafanaPrometheusAuthAuthenticationType1,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputGrafanaPrometheusAuthAuthenticationType1),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputGrafanaPrometheusAuthAuthenticationType1$outboundSchema:
  z.ZodType<
    InputGrafanaPrometheusAuthAuthenticationType1,
    z.ZodTypeDef,
    InputGrafanaPrometheusAuthAuthenticationType1
  > = z.union([
    z.nativeEnum(InputGrafanaPrometheusAuthAuthenticationType1),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const PrometheusAuthOauthParam1$inboundSchema: z.ZodType<
  PrometheusAuthOauthParam1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type PrometheusAuthOauthParam1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const PrometheusAuthOauthParam1$outboundSchema: z.ZodType<
  PrometheusAuthOauthParam1$Outbound,
  z.ZodTypeDef,
  PrometheusAuthOauthParam1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function prometheusAuthOauthParam1ToJSON(
  prometheusAuthOauthParam1: PrometheusAuthOauthParam1,
): string {
  return JSON.stringify(
    PrometheusAuthOauthParam1$outboundSchema.parse(prometheusAuthOauthParam1),
  );
}
export function prometheusAuthOauthParam1FromJSON(
  jsonString: string,
): SafeParseResult<PrometheusAuthOauthParam1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PrometheusAuthOauthParam1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PrometheusAuthOauthParam1' from JSON`,
  );
}

/** @internal */
export const PrometheusAuthOauthHeader1$inboundSchema: z.ZodType<
  PrometheusAuthOauthHeader1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type PrometheusAuthOauthHeader1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const PrometheusAuthOauthHeader1$outboundSchema: z.ZodType<
  PrometheusAuthOauthHeader1$Outbound,
  z.ZodTypeDef,
  PrometheusAuthOauthHeader1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function prometheusAuthOauthHeader1ToJSON(
  prometheusAuthOauthHeader1: PrometheusAuthOauthHeader1,
): string {
  return JSON.stringify(
    PrometheusAuthOauthHeader1$outboundSchema.parse(prometheusAuthOauthHeader1),
  );
}
export function prometheusAuthOauthHeader1FromJSON(
  jsonString: string,
): SafeParseResult<PrometheusAuthOauthHeader1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PrometheusAuthOauthHeader1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PrometheusAuthOauthHeader1' from JSON`,
  );
}

/** @internal */
export const InputPrometheusAuth1$inboundSchema: z.ZodType<
  InputPrometheusAuth1,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: InputGrafanaPrometheusAuthAuthenticationType1$inboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => PrometheusAuthOauthParam1$inboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => PrometheusAuthOauthHeader1$inboundSchema))
    .optional(),
});
/** @internal */
export type InputPrometheusAuth1$Outbound = {
  authType: string;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<PrometheusAuthOauthParam1$Outbound> | undefined;
  oauthHeaders?: Array<PrometheusAuthOauthHeader1$Outbound> | undefined;
};

/** @internal */
export const InputPrometheusAuth1$outboundSchema: z.ZodType<
  InputPrometheusAuth1$Outbound,
  z.ZodTypeDef,
  InputPrometheusAuth1
> = z.object({
  authType: InputGrafanaPrometheusAuthAuthenticationType1$outboundSchema
    .default("none"),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => PrometheusAuthOauthParam1$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => PrometheusAuthOauthHeader1$outboundSchema))
    .optional(),
});

export function inputPrometheusAuth1ToJSON(
  inputPrometheusAuth1: InputPrometheusAuth1,
): string {
  return JSON.stringify(
    InputPrometheusAuth1$outboundSchema.parse(inputPrometheusAuth1),
  );
}
export function inputPrometheusAuth1FromJSON(
  jsonString: string,
): SafeParseResult<InputPrometheusAuth1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPrometheusAuth1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPrometheusAuth1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaLokiAuthAuthenticationType1$inboundSchema: z.ZodType<
  InputGrafanaLokiAuthAuthenticationType1,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputGrafanaLokiAuthAuthenticationType1),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputGrafanaLokiAuthAuthenticationType1$outboundSchema: z.ZodType<
  InputGrafanaLokiAuthAuthenticationType1,
  z.ZodTypeDef,
  InputGrafanaLokiAuthAuthenticationType1
> = z.union([
  z.nativeEnum(InputGrafanaLokiAuthAuthenticationType1),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const LokiAuthOauthParam1$inboundSchema: z.ZodType<
  LokiAuthOauthParam1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type LokiAuthOauthParam1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const LokiAuthOauthParam1$outboundSchema: z.ZodType<
  LokiAuthOauthParam1$Outbound,
  z.ZodTypeDef,
  LokiAuthOauthParam1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function lokiAuthOauthParam1ToJSON(
  lokiAuthOauthParam1: LokiAuthOauthParam1,
): string {
  return JSON.stringify(
    LokiAuthOauthParam1$outboundSchema.parse(lokiAuthOauthParam1),
  );
}
export function lokiAuthOauthParam1FromJSON(
  jsonString: string,
): SafeParseResult<LokiAuthOauthParam1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LokiAuthOauthParam1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LokiAuthOauthParam1' from JSON`,
  );
}

/** @internal */
export const LokiAuthOauthHeader1$inboundSchema: z.ZodType<
  LokiAuthOauthHeader1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type LokiAuthOauthHeader1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const LokiAuthOauthHeader1$outboundSchema: z.ZodType<
  LokiAuthOauthHeader1$Outbound,
  z.ZodTypeDef,
  LokiAuthOauthHeader1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function lokiAuthOauthHeader1ToJSON(
  lokiAuthOauthHeader1: LokiAuthOauthHeader1,
): string {
  return JSON.stringify(
    LokiAuthOauthHeader1$outboundSchema.parse(lokiAuthOauthHeader1),
  );
}
export function lokiAuthOauthHeader1FromJSON(
  jsonString: string,
): SafeParseResult<LokiAuthOauthHeader1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => LokiAuthOauthHeader1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'LokiAuthOauthHeader1' from JSON`,
  );
}

/** @internal */
export const InputLokiAuth1$inboundSchema: z.ZodType<
  InputLokiAuth1,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: InputGrafanaLokiAuthAuthenticationType1$inboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => LokiAuthOauthParam1$inboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => LokiAuthOauthHeader1$inboundSchema))
    .optional(),
});
/** @internal */
export type InputLokiAuth1$Outbound = {
  authType: string;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<LokiAuthOauthParam1$Outbound> | undefined;
  oauthHeaders?: Array<LokiAuthOauthHeader1$Outbound> | undefined;
};

/** @internal */
export const InputLokiAuth1$outboundSchema: z.ZodType<
  InputLokiAuth1$Outbound,
  z.ZodTypeDef,
  InputLokiAuth1
> = z.object({
  authType: InputGrafanaLokiAuthAuthenticationType1$outboundSchema.default(
    "none",
  ),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => LokiAuthOauthParam1$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => LokiAuthOauthHeader1$outboundSchema))
    .optional(),
});

export function inputLokiAuth1ToJSON(inputLokiAuth1: InputLokiAuth1): string {
  return JSON.stringify(InputLokiAuth1$outboundSchema.parse(inputLokiAuth1));
}
export function inputLokiAuth1FromJSON(
  jsonString: string,
): SafeParseResult<InputLokiAuth1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputLokiAuth1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputLokiAuth1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaMetadatum1$inboundSchema: z.ZodType<
  InputGrafanaMetadatum1,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputGrafanaMetadatum1$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputGrafanaMetadatum1$outboundSchema: z.ZodType<
  InputGrafanaMetadatum1$Outbound,
  z.ZodTypeDef,
  InputGrafanaMetadatum1
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputGrafanaMetadatum1ToJSON(
  inputGrafanaMetadatum1: InputGrafanaMetadatum1,
): string {
  return JSON.stringify(
    InputGrafanaMetadatum1$outboundSchema.parse(inputGrafanaMetadatum1),
  );
}
export function inputGrafanaMetadatum1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaMetadatum1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaMetadatum1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaMetadatum1' from JSON`,
  );
}

/** @internal */
export const InputGrafanaGrafana1$inboundSchema: z.ZodType<
  InputGrafanaGrafana1,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputGrafanaType1$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => InputGrafanaConnection1$inboundSchema))
      .optional(),
    pq: z.lazy(() => InputGrafanaPq1$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => InputGrafanaTLSSettingsServerSide1$inboundSchema)
      .optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    prometheusAPI: z.string().default("/api/prom/push"),
    lokiAPI: z.string().default("/loki/api/v1/push"),
    prometheusAuth: z.lazy(() => InputPrometheusAuth1$inboundSchema).optional(),
    lokiAuth: z.lazy(() => InputLokiAuth1$inboundSchema).optional(),
    metadata: z.array(z.lazy(() => InputGrafanaMetadatum1$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputGrafanaGrafana1$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<InputGrafanaConnection1$Outbound> | undefined;
  pq?: InputGrafanaPq1$Outbound | undefined;
  host: string;
  port: number;
  tls?: InputGrafanaTLSSettingsServerSide1$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  prometheusAPI: string;
  lokiAPI: string;
  prometheusAuth?: InputPrometheusAuth1$Outbound | undefined;
  lokiAuth?: InputLokiAuth1$Outbound | undefined;
  metadata?: Array<InputGrafanaMetadatum1$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputGrafanaGrafana1$outboundSchema: z.ZodType<
  InputGrafanaGrafana1$Outbound,
  z.ZodTypeDef,
  InputGrafanaGrafana1
> = z.object({
  id: z.string().optional(),
  type: InputGrafanaType1$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => InputGrafanaConnection1$outboundSchema))
    .optional(),
  pq: z.lazy(() => InputGrafanaPq1$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => InputGrafanaTLSSettingsServerSide1$outboundSchema)
    .optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  prometheusAPI: z.string().default("/api/prom/push"),
  lokiAPI: z.string().default("/loki/api/v1/push"),
  prometheusAuth: z.lazy(() => InputPrometheusAuth1$outboundSchema).optional(),
  lokiAuth: z.lazy(() => InputLokiAuth1$outboundSchema).optional(),
  metadata: z.array(z.lazy(() => InputGrafanaMetadatum1$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputGrafanaGrafana1ToJSON(
  inputGrafanaGrafana1: InputGrafanaGrafana1,
): string {
  return JSON.stringify(
    InputGrafanaGrafana1$outboundSchema.parse(inputGrafanaGrafana1),
  );
}
export function inputGrafanaGrafana1FromJSON(
  jsonString: string,
): SafeParseResult<InputGrafanaGrafana1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafanaGrafana1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafanaGrafana1' from JSON`,
  );
}

/** @internal */
export const InputGrafana$inboundSchema: z.ZodType<
  InputGrafana,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => InputGrafanaGrafana1$inboundSchema),
  z.lazy(() => InputGrafanaGrafana2$inboundSchema),
]);
/** @internal */
export type InputGrafana$Outbound =
  | InputGrafanaGrafana1$Outbound
  | InputGrafanaGrafana2$Outbound;

/** @internal */
export const InputGrafana$outboundSchema: z.ZodType<
  InputGrafana$Outbound,
  z.ZodTypeDef,
  InputGrafana
> = z.union([
  z.lazy(() => InputGrafanaGrafana1$outboundSchema),
  z.lazy(() => InputGrafanaGrafana2$outboundSchema),
]);

export function inputGrafanaToJSON(inputGrafana: InputGrafana): string {
  return JSON.stringify(InputGrafana$outboundSchema.parse(inputGrafana));
}
export function inputGrafanaFromJSON(
  jsonString: string,
): SafeParseResult<InputGrafana, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputGrafana$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputGrafana' from JSON`,
  );
}

/** @internal */
export const InputTypeConfluentCloud$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeConfluentCloud
> = z.nativeEnum(InputTypeConfluentCloud);
/** @internal */
export const InputTypeConfluentCloud$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeConfluentCloud
> = InputTypeConfluentCloud$inboundSchema;

/** @internal */
export const ConnectionConfluentCloud$inboundSchema: z.ZodType<
  ConnectionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionConfluentCloud$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionConfluentCloud$outboundSchema: z.ZodType<
  ConnectionConfluentCloud$Outbound,
  z.ZodTypeDef,
  ConnectionConfluentCloud
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionConfluentCloudToJSON(
  connectionConfluentCloud: ConnectionConfluentCloud,
): string {
  return JSON.stringify(
    ConnectionConfluentCloud$outboundSchema.parse(connectionConfluentCloud),
  );
}
export function connectionConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionConfluentCloud' from JSON`,
  );
}

/** @internal */
export const PqModeConfluentCloud$inboundSchema: z.ZodType<
  PqModeConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeConfluentCloud$outboundSchema: z.ZodType<
  PqModeConfluentCloud,
  z.ZodTypeDef,
  PqModeConfluentCloud
> = z.union([
  z.nativeEnum(PqModeConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionConfluentCloud$inboundSchema: z.ZodType<
  PqCompressionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionConfluentCloud$outboundSchema: z.ZodType<
  PqCompressionConfluentCloud,
  z.ZodTypeDef,
  PqCompressionConfluentCloud
> = z.union([
  z.nativeEnum(PqCompressionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsConfluentCloud$inboundSchema: z.ZodType<
  InputPqControlsConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsConfluentCloud$Outbound = {};

/** @internal */
export const InputPqControlsConfluentCloud$outboundSchema: z.ZodType<
  InputPqControlsConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputPqControlsConfluentCloud
> = z.object({});

export function inputPqControlsConfluentCloudToJSON(
  inputPqControlsConfluentCloud: InputPqControlsConfluentCloud,
): string {
  return JSON.stringify(
    InputPqControlsConfluentCloud$outboundSchema.parse(
      inputPqControlsConfluentCloud,
    ),
  );
}
export function inputPqControlsConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsConfluentCloud' from JSON`,
  );
}

/** @internal */
export const PqConfluentCloud$inboundSchema: z.ZodType<
  PqConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeConfluentCloud$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionConfluentCloud$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsConfluentCloud$inboundSchema)
    .optional(),
});
/** @internal */
export type PqConfluentCloud$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsConfluentCloud$Outbound | undefined;
};

/** @internal */
export const PqConfluentCloud$outboundSchema: z.ZodType<
  PqConfluentCloud$Outbound,
  z.ZodTypeDef,
  PqConfluentCloud
> = z.object({
  mode: PqModeConfluentCloud$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionConfluentCloud$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsConfluentCloud$outboundSchema)
    .optional(),
});

export function pqConfluentCloudToJSON(
  pqConfluentCloud: PqConfluentCloud,
): string {
  return JSON.stringify(
    PqConfluentCloud$outboundSchema.parse(pqConfluentCloud),
  );
}
export function pqConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<PqConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionConfluentCloud$inboundSchema: z.ZodType<
  InputMinimumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionConfluentCloud$outboundSchema: z.ZodType<
  InputMinimumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  InputMinimumTLSVersionConfluentCloud
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionConfluentCloud$inboundSchema: z.ZodType<
  InputMaximumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionConfluentCloud$outboundSchema: z.ZodType<
  InputMaximumTLSVersionConfluentCloud,
  z.ZodTypeDef,
  InputMaximumTLSVersionConfluentCloud
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputTLSSettingsClientSideConfluentCloud$inboundSchema: z.ZodType<
  InputTLSSettingsClientSideConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionConfluentCloud$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionConfluentCloud$inboundSchema.optional(),
});
/** @internal */
export type InputTLSSettingsClientSideConfluentCloud$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputTLSSettingsClientSideConfluentCloud$outboundSchema: z.ZodType<
  InputTLSSettingsClientSideConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputTLSSettingsClientSideConfluentCloud
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionConfluentCloud$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionConfluentCloud$outboundSchema.optional(),
});

export function inputTLSSettingsClientSideConfluentCloudToJSON(
  inputTLSSettingsClientSideConfluentCloud:
    InputTLSSettingsClientSideConfluentCloud,
): string {
  return JSON.stringify(
    InputTLSSettingsClientSideConfluentCloud$outboundSchema.parse(
      inputTLSSettingsClientSideConfluentCloud,
    ),
  );
}
export function inputTLSSettingsClientSideConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  InputTLSSettingsClientSideConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputTLSSettingsClientSideConfluentCloud$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputTLSSettingsClientSideConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputAuthConfluentCloud$inboundSchema: z.ZodType<
  InputAuthConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type InputAuthConfluentCloud$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const InputAuthConfluentCloud$outboundSchema: z.ZodType<
  InputAuthConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputAuthConfluentCloud
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function inputAuthConfluentCloudToJSON(
  inputAuthConfluentCloud: InputAuthConfluentCloud,
): string {
  return JSON.stringify(
    InputAuthConfluentCloud$outboundSchema.parse(inputAuthConfluentCloud),
  );
}
export function inputAuthConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion:
      InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$inboundSchema
        .optional(),
    maxVersion:
      InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$inboundSchema
        .optional(),
  });
/** @internal */
export type InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound =
  {
    disabled: boolean;
    rejectUnauthorized: boolean;
    servername?: string | undefined;
    certificateName?: string | undefined;
    caPath?: string | undefined;
    privKeyPath?: string | undefined;
    certPath?: string | undefined;
    passphrase?: string | undefined;
    minVersion?: string | undefined;
    maxVersion?: string | undefined;
  };

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion:
      InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud$outboundSchema
        .optional(),
    maxVersion:
      InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud$outboundSchema
        .optional(),
  });

export function inputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloudToJSON(
  inputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud:
    InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema
      .parse(inputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud),
  );
}
export function inputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryAuthenticationConfluentCloud,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => InputAuthConfluentCloud$inboundSchema).optional(),
    tls: z.lazy(() =>
      InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$inboundSchema
    ).optional(),
  });
/** @internal */
export type InputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: InputAuthConfluentCloud$Outbound | undefined;
  tls?:
    | InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$Outbound
    | undefined;
};

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryAuthenticationConfluentCloud
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => InputAuthConfluentCloud$outboundSchema).optional(),
    tls: z.lazy(() =>
      InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud$outboundSchema
    ).optional(),
  });

export function inputKafkaSchemaRegistryAuthenticationConfluentCloudToJSON(
  inputKafkaSchemaRegistryAuthenticationConfluentCloud:
    InputKafkaSchemaRegistryAuthenticationConfluentCloud,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema.parse(
      inputKafkaSchemaRegistryAuthenticationConfluentCloud,
    ),
  );
}
export function inputKafkaSchemaRegistryAuthenticationConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryAuthenticationConfluentCloud,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKafkaSchemaRegistryAuthenticationConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodConfluentCloud$inboundSchema: z.ZodType<
  InputAuthenticationMethodConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodConfluentCloud$outboundSchema: z.ZodType<
  InputAuthenticationMethodConfluentCloud,
  z.ZodTypeDef,
  InputAuthenticationMethodConfluentCloud
> = z.union([
  z.nativeEnum(InputAuthenticationMethodConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSASLMechanismConfluentCloud$inboundSchema: z.ZodType<
  InputSASLMechanismConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSASLMechanismConfluentCloud),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSASLMechanismConfluentCloud$outboundSchema: z.ZodType<
  InputSASLMechanismConfluentCloud,
  z.ZodTypeDef,
  InputSASLMechanismConfluentCloud
> = z.union([
  z.nativeEnum(InputSASLMechanismConfluentCloud),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputOauthParamConfluentCloud$inboundSchema: z.ZodType<
  InputOauthParamConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputOauthParamConfluentCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputOauthParamConfluentCloud$outboundSchema: z.ZodType<
  InputOauthParamConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputOauthParamConfluentCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputOauthParamConfluentCloudToJSON(
  inputOauthParamConfluentCloud: InputOauthParamConfluentCloud,
): string {
  return JSON.stringify(
    InputOauthParamConfluentCloud$outboundSchema.parse(
      inputOauthParamConfluentCloud,
    ),
  );
}
export function inputOauthParamConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputOauthParamConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOauthParamConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOauthParamConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputSaslExtensionConfluentCloud$inboundSchema: z.ZodType<
  InputSaslExtensionConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputSaslExtensionConfluentCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputSaslExtensionConfluentCloud$outboundSchema: z.ZodType<
  InputSaslExtensionConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputSaslExtensionConfluentCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputSaslExtensionConfluentCloudToJSON(
  inputSaslExtensionConfluentCloud: InputSaslExtensionConfluentCloud,
): string {
  return JSON.stringify(
    InputSaslExtensionConfluentCloud$outboundSchema.parse(
      inputSaslExtensionConfluentCloud,
    ),
  );
}
export function inputSaslExtensionConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputSaslExtensionConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSaslExtensionConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSaslExtensionConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationConfluentCloud$inboundSchema: z.ZodType<
  InputAuthenticationConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: InputAuthenticationMethodConfluentCloud$inboundSchema.default(
    "manual",
  ),
  credentialsSecret: z.string().optional(),
  mechanism: InputSASLMechanismConfluentCloud$inboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(
    z.lazy(() => InputOauthParamConfluentCloud$inboundSchema),
  ).optional(),
  saslExtensions: z.array(
    z.lazy(() => InputSaslExtensionConfluentCloud$inboundSchema),
  ).optional(),
});
/** @internal */
export type InputAuthenticationConfluentCloud$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  mechanism: string;
  keytabLocation?: string | undefined;
  principal?: string | undefined;
  brokerServiceClass?: string | undefined;
  oauthEnabled: boolean;
  tokenUrl?: string | undefined;
  clientId?: string | undefined;
  oauthSecretType: string;
  clientTextSecret?: string | undefined;
  oauthParams?: Array<InputOauthParamConfluentCloud$Outbound> | undefined;
  saslExtensions?: Array<InputSaslExtensionConfluentCloud$Outbound> | undefined;
};

/** @internal */
export const InputAuthenticationConfluentCloud$outboundSchema: z.ZodType<
  InputAuthenticationConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputAuthenticationConfluentCloud
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: InputAuthenticationMethodConfluentCloud$outboundSchema.default(
    "manual",
  ),
  credentialsSecret: z.string().optional(),
  mechanism: InputSASLMechanismConfluentCloud$outboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(
    z.lazy(() => InputOauthParamConfluentCloud$outboundSchema),
  ).optional(),
  saslExtensions: z.array(
    z.lazy(() => InputSaslExtensionConfluentCloud$outboundSchema),
  ).optional(),
});

export function inputAuthenticationConfluentCloudToJSON(
  inputAuthenticationConfluentCloud: InputAuthenticationConfluentCloud,
): string {
  return JSON.stringify(
    InputAuthenticationConfluentCloud$outboundSchema.parse(
      inputAuthenticationConfluentCloud,
    ),
  );
}
export function inputAuthenticationConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthenticationConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthenticationConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthenticationConfluentCloud' from JSON`,
  );
}

/** @internal */
export const MetadatumConfluentCloud$inboundSchema: z.ZodType<
  MetadatumConfluentCloud,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumConfluentCloud$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumConfluentCloud$outboundSchema: z.ZodType<
  MetadatumConfluentCloud$Outbound,
  z.ZodTypeDef,
  MetadatumConfluentCloud
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumConfluentCloudToJSON(
  metadatumConfluentCloud: MetadatumConfluentCloud,
): string {
  return JSON.stringify(
    MetadatumConfluentCloud$outboundSchema.parse(metadatumConfluentCloud),
  );
}
export function metadatumConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputConfluentCloud$inboundSchema: z.ZodType<
  InputConfluentCloud,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeConfluentCloud$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionConfluentCloud$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqConfluentCloud$inboundSchema).optional(),
    brokers: z.array(z.string()),
    tls: z.lazy(() => InputTLSSettingsClientSideConfluentCloud$inboundSchema)
      .optional(),
    topics: z.array(z.string()),
    groupId: z.string().default("Cribl"),
    fromBeginning: z.boolean().default(true),
    kafkaSchemaRegistry: z.lazy(() =>
      InputKafkaSchemaRegistryAuthenticationConfluentCloud$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => InputAuthenticationConfluentCloud$inboundSchema)
      .optional(),
    sessionTimeout: z.number().default(30000),
    rebalanceTimeout: z.number().default(60000),
    heartbeatInterval: z.number().default(3000),
    autoCommitInterval: z.number().optional(),
    autoCommitThreshold: z.number().optional(),
    maxBytesPerPartition: z.number().default(1048576),
    maxBytes: z.number().default(10485760),
    maxSocketErrors: z.number().default(0),
    metadata: z.array(z.lazy(() => MetadatumConfluentCloud$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputConfluentCloud$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionConfluentCloud$Outbound> | undefined;
  pq?: PqConfluentCloud$Outbound | undefined;
  brokers: Array<string>;
  tls?: InputTLSSettingsClientSideConfluentCloud$Outbound | undefined;
  topics: Array<string>;
  groupId: string;
  fromBeginning: boolean;
  kafkaSchemaRegistry?:
    | InputKafkaSchemaRegistryAuthenticationConfluentCloud$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: InputAuthenticationConfluentCloud$Outbound | undefined;
  sessionTimeout: number;
  rebalanceTimeout: number;
  heartbeatInterval: number;
  autoCommitInterval?: number | undefined;
  autoCommitThreshold?: number | undefined;
  maxBytesPerPartition: number;
  maxBytes: number;
  maxSocketErrors: number;
  metadata?: Array<MetadatumConfluentCloud$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputConfluentCloud$outboundSchema: z.ZodType<
  InputConfluentCloud$Outbound,
  z.ZodTypeDef,
  InputConfluentCloud
> = z.object({
  id: z.string().optional(),
  type: InputTypeConfluentCloud$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionConfluentCloud$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqConfluentCloud$outboundSchema).optional(),
  brokers: z.array(z.string()),
  tls: z.lazy(() => InputTLSSettingsClientSideConfluentCloud$outboundSchema)
    .optional(),
  topics: z.array(z.string()),
  groupId: z.string().default("Cribl"),
  fromBeginning: z.boolean().default(true),
  kafkaSchemaRegistry: z.lazy(() =>
    InputKafkaSchemaRegistryAuthenticationConfluentCloud$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => InputAuthenticationConfluentCloud$outboundSchema)
    .optional(),
  sessionTimeout: z.number().default(30000),
  rebalanceTimeout: z.number().default(60000),
  heartbeatInterval: z.number().default(3000),
  autoCommitInterval: z.number().optional(),
  autoCommitThreshold: z.number().optional(),
  maxBytesPerPartition: z.number().default(1048576),
  maxBytes: z.number().default(10485760),
  maxSocketErrors: z.number().default(0),
  metadata: z.array(z.lazy(() => MetadatumConfluentCloud$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputConfluentCloudToJSON(
  inputConfluentCloud: InputConfluentCloud,
): string {
  return JSON.stringify(
    InputConfluentCloud$outboundSchema.parse(inputConfluentCloud),
  );
}
export function inputConfluentCloudFromJSON(
  jsonString: string,
): SafeParseResult<InputConfluentCloud, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputConfluentCloud$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputConfluentCloud' from JSON`,
  );
}

/** @internal */
export const InputTypeElastic$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeElastic
> = z.nativeEnum(InputTypeElastic);
/** @internal */
export const InputTypeElastic$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeElastic
> = InputTypeElastic$inboundSchema;

/** @internal */
export const ConnectionElastic$inboundSchema: z.ZodType<
  ConnectionElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionElastic$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionElastic$outboundSchema: z.ZodType<
  ConnectionElastic$Outbound,
  z.ZodTypeDef,
  ConnectionElastic
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionElasticToJSON(
  connectionElastic: ConnectionElastic,
): string {
  return JSON.stringify(
    ConnectionElastic$outboundSchema.parse(connectionElastic),
  );
}
export function connectionElasticFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionElastic' from JSON`,
  );
}

/** @internal */
export const PqModeElastic$inboundSchema: z.ZodType<
  PqModeElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeElastic$outboundSchema: z.ZodType<
  PqModeElastic,
  z.ZodTypeDef,
  PqModeElastic
> = z.union([
  z.nativeEnum(PqModeElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionElastic$inboundSchema: z.ZodType<
  PqCompressionElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionElastic$outboundSchema: z.ZodType<
  PqCompressionElastic,
  z.ZodTypeDef,
  PqCompressionElastic
> = z.union([
  z.nativeEnum(PqCompressionElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsElastic$inboundSchema: z.ZodType<
  InputPqControlsElastic,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsElastic$Outbound = {};

/** @internal */
export const InputPqControlsElastic$outboundSchema: z.ZodType<
  InputPqControlsElastic$Outbound,
  z.ZodTypeDef,
  InputPqControlsElastic
> = z.object({});

export function inputPqControlsElasticToJSON(
  inputPqControlsElastic: InputPqControlsElastic,
): string {
  return JSON.stringify(
    InputPqControlsElastic$outboundSchema.parse(inputPqControlsElastic),
  );
}
export function inputPqControlsElasticFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsElastic' from JSON`,
  );
}

/** @internal */
export const PqElastic$inboundSchema: z.ZodType<
  PqElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeElastic$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionElastic$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsElastic$inboundSchema).optional(),
});
/** @internal */
export type PqElastic$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsElastic$Outbound | undefined;
};

/** @internal */
export const PqElastic$outboundSchema: z.ZodType<
  PqElastic$Outbound,
  z.ZodTypeDef,
  PqElastic
> = z.object({
  mode: PqModeElastic$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionElastic$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsElastic$outboundSchema).optional(),
});

export function pqElasticToJSON(pqElastic: PqElastic): string {
  return JSON.stringify(PqElastic$outboundSchema.parse(pqElastic));
}
export function pqElasticFromJSON(
  jsonString: string,
): SafeParseResult<PqElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqElastic' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionElastic$inboundSchema: z.ZodType<
  MinimumTLSVersionElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionElastic$outboundSchema: z.ZodType<
  MinimumTLSVersionElastic,
  z.ZodTypeDef,
  MinimumTLSVersionElastic
> = z.union([
  z.nativeEnum(MinimumTLSVersionElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionElastic$inboundSchema: z.ZodType<
  MaximumTLSVersionElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionElastic$outboundSchema: z.ZodType<
  MaximumTLSVersionElastic,
  z.ZodTypeDef,
  MaximumTLSVersionElastic
> = z.union([
  z.nativeEnum(MaximumTLSVersionElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideElastic$inboundSchema: z.ZodType<
  TLSSettingsServerSideElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionElastic$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionElastic$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideElastic$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideElastic$outboundSchema: z.ZodType<
  TLSSettingsServerSideElastic$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideElastic
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionElastic$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionElastic$outboundSchema.optional(),
});

export function tlsSettingsServerSideElasticToJSON(
  tlsSettingsServerSideElastic: TLSSettingsServerSideElastic,
): string {
  return JSON.stringify(
    TLSSettingsServerSideElastic$outboundSchema.parse(
      tlsSettingsServerSideElastic,
    ),
  );
}
export function tlsSettingsServerSideElasticFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideElastic' from JSON`,
  );
}

/** @internal */
export const AuthenticationTypeElastic$inboundSchema: z.ZodType<
  AuthenticationTypeElastic,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeElastic),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeElastic$outboundSchema: z.ZodType<
  AuthenticationTypeElastic,
  z.ZodTypeDef,
  AuthenticationTypeElastic
> = z.union([
  z.nativeEnum(AuthenticationTypeElastic),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputAPIVersion$inboundSchema: z.ZodType<
  InputAPIVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAPIVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAPIVersion$outboundSchema: z.ZodType<
  InputAPIVersion,
  z.ZodTypeDef,
  InputAPIVersion
> = z.union([
  z.nativeEnum(InputAPIVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputExtraHttpHeader$inboundSchema: z.ZodType<
  InputExtraHttpHeader,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});
/** @internal */
export type InputExtraHttpHeader$Outbound = {
  name?: string | undefined;
  value: string;
};

/** @internal */
export const InputExtraHttpHeader$outboundSchema: z.ZodType<
  InputExtraHttpHeader$Outbound,
  z.ZodTypeDef,
  InputExtraHttpHeader
> = z.object({
  name: z.string().optional(),
  value: z.string(),
});

export function inputExtraHttpHeaderToJSON(
  inputExtraHttpHeader: InputExtraHttpHeader,
): string {
  return JSON.stringify(
    InputExtraHttpHeader$outboundSchema.parse(inputExtraHttpHeader),
  );
}
export function inputExtraHttpHeaderFromJSON(
  jsonString: string,
): SafeParseResult<InputExtraHttpHeader, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputExtraHttpHeader$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputExtraHttpHeader' from JSON`,
  );
}

/** @internal */
export const MetadatumElastic$inboundSchema: z.ZodType<
  MetadatumElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumElastic$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumElastic$outboundSchema: z.ZodType<
  MetadatumElastic$Outbound,
  z.ZodTypeDef,
  MetadatumElastic
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumElasticToJSON(
  metadatumElastic: MetadatumElastic,
): string {
  return JSON.stringify(
    MetadatumElastic$outboundSchema.parse(metadatumElastic),
  );
}
export function metadatumElasticFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumElastic' from JSON`,
  );
}

/** @internal */
export const ProxyModeAuthenticationMethod$inboundSchema: z.ZodType<
  ProxyModeAuthenticationMethod,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ProxyModeAuthenticationMethod),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ProxyModeAuthenticationMethod$outboundSchema: z.ZodType<
  ProxyModeAuthenticationMethod,
  z.ZodTypeDef,
  ProxyModeAuthenticationMethod
> = z.union([
  z.nativeEnum(ProxyModeAuthenticationMethod),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const ProxyModeElastic$inboundSchema: z.ZodType<
  ProxyModeElastic,
  z.ZodTypeDef,
  unknown
> = z.object({
  enabled: z.boolean().default(false),
  authType: ProxyModeAuthenticationMethod$inboundSchema.default("none"),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  url: z.string().optional(),
  rejectUnauthorized: z.boolean().default(false),
  removeHeaders: z.array(z.string()).optional(),
  timeoutSec: z.number().default(60),
});
/** @internal */
export type ProxyModeElastic$Outbound = {
  enabled: boolean;
  authType: string;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  url?: string | undefined;
  rejectUnauthorized: boolean;
  removeHeaders?: Array<string> | undefined;
  timeoutSec: number;
};

/** @internal */
export const ProxyModeElastic$outboundSchema: z.ZodType<
  ProxyModeElastic$Outbound,
  z.ZodTypeDef,
  ProxyModeElastic
> = z.object({
  enabled: z.boolean().default(false),
  authType: ProxyModeAuthenticationMethod$outboundSchema.default("none"),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  url: z.string().optional(),
  rejectUnauthorized: z.boolean().default(false),
  removeHeaders: z.array(z.string()).optional(),
  timeoutSec: z.number().default(60),
});

export function proxyModeElasticToJSON(
  proxyModeElastic: ProxyModeElastic,
): string {
  return JSON.stringify(
    ProxyModeElastic$outboundSchema.parse(proxyModeElastic),
  );
}
export function proxyModeElasticFromJSON(
  jsonString: string,
): SafeParseResult<ProxyModeElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ProxyModeElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ProxyModeElastic' from JSON`,
  );
}

/** @internal */
export const InputElastic$inboundSchema: z.ZodType<
  InputElastic,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeElastic$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionElastic$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqElastic$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideElastic$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    elasticAPI: z.string().default("/"),
    authType: AuthenticationTypeElastic$inboundSchema.default("none"),
    apiVersion: InputAPIVersion$inboundSchema.default("8.3.2"),
    extraHttpHeaders: z.array(z.lazy(() => InputExtraHttpHeader$inboundSchema))
      .optional(),
    metadata: z.array(z.lazy(() => MetadatumElastic$inboundSchema)).optional(),
    proxyMode: z.lazy(() => ProxyModeElastic$inboundSchema).optional(),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    credentialsSecret: z.string().optional(),
    authTokens: z.array(z.string()).optional(),
    customAPIVersion: z.string().default(
      "{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}",
    ),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputElastic$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionElastic$Outbound> | undefined;
  pq?: PqElastic$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideElastic$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  elasticAPI: string;
  authType: string;
  apiVersion: string;
  extraHttpHeaders?: Array<InputExtraHttpHeader$Outbound> | undefined;
  metadata?: Array<MetadatumElastic$Outbound> | undefined;
  proxyMode?: ProxyModeElastic$Outbound | undefined;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  credentialsSecret?: string | undefined;
  authTokens?: Array<string> | undefined;
  customAPIVersion: string;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputElastic$outboundSchema: z.ZodType<
  InputElastic$Outbound,
  z.ZodTypeDef,
  InputElastic
> = z.object({
  id: z.string().optional(),
  type: InputTypeElastic$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionElastic$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqElastic$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideElastic$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  elasticAPI: z.string().default("/"),
  authType: AuthenticationTypeElastic$outboundSchema.default("none"),
  apiVersion: InputAPIVersion$outboundSchema.default("8.3.2"),
  extraHttpHeaders: z.array(z.lazy(() => InputExtraHttpHeader$outboundSchema))
    .optional(),
  metadata: z.array(z.lazy(() => MetadatumElastic$outboundSchema)).optional(),
  proxyMode: z.lazy(() => ProxyModeElastic$outboundSchema).optional(),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  credentialsSecret: z.string().optional(),
  authTokens: z.array(z.string()).optional(),
  customAPIVersion: z.string().default(
    "{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}",
  ),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputElasticToJSON(inputElastic: InputElastic): string {
  return JSON.stringify(InputElastic$outboundSchema.parse(inputElastic));
}
export function inputElasticFromJSON(
  jsonString: string,
): SafeParseResult<InputElastic, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputElastic$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputElastic' from JSON`,
  );
}

/** @internal */
export const InputTypeAzureBlob$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeAzureBlob
> = z.nativeEnum(InputTypeAzureBlob);
/** @internal */
export const InputTypeAzureBlob$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeAzureBlob
> = InputTypeAzureBlob$inboundSchema;

/** @internal */
export const ConnectionAzureBlob$inboundSchema: z.ZodType<
  ConnectionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionAzureBlob$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionAzureBlob$outboundSchema: z.ZodType<
  ConnectionAzureBlob$Outbound,
  z.ZodTypeDef,
  ConnectionAzureBlob
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionAzureBlobToJSON(
  connectionAzureBlob: ConnectionAzureBlob,
): string {
  return JSON.stringify(
    ConnectionAzureBlob$outboundSchema.parse(connectionAzureBlob),
  );
}
export function connectionAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionAzureBlob' from JSON`,
  );
}

/** @internal */
export const ModeAzureBlob$inboundSchema: z.ZodType<
  ModeAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeAzureBlob$outboundSchema: z.ZodType<
  ModeAzureBlob,
  z.ZodTypeDef,
  ModeAzureBlob
> = z.union([
  z.nativeEnum(ModeAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionAzureBlob$inboundSchema: z.ZodType<
  PqCompressionAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionAzureBlob$outboundSchema: z.ZodType<
  PqCompressionAzureBlob,
  z.ZodTypeDef,
  PqCompressionAzureBlob
> = z.union([
  z.nativeEnum(PqCompressionAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsAzureBlob$inboundSchema: z.ZodType<
  PqControlsAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsAzureBlob$Outbound = {};

/** @internal */
export const PqControlsAzureBlob$outboundSchema: z.ZodType<
  PqControlsAzureBlob$Outbound,
  z.ZodTypeDef,
  PqControlsAzureBlob
> = z.object({});

export function pqControlsAzureBlobToJSON(
  pqControlsAzureBlob: PqControlsAzureBlob,
): string {
  return JSON.stringify(
    PqControlsAzureBlob$outboundSchema.parse(pqControlsAzureBlob),
  );
}
export function pqControlsAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsAzureBlob' from JSON`,
  );
}

/** @internal */
export const PqAzureBlob$inboundSchema: z.ZodType<
  PqAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeAzureBlob$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionAzureBlob$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsAzureBlob$inboundSchema).optional(),
});
/** @internal */
export type PqAzureBlob$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsAzureBlob$Outbound | undefined;
};

/** @internal */
export const PqAzureBlob$outboundSchema: z.ZodType<
  PqAzureBlob$Outbound,
  z.ZodTypeDef,
  PqAzureBlob
> = z.object({
  mode: ModeAzureBlob$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionAzureBlob$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsAzureBlob$outboundSchema).optional(),
});

export function pqAzureBlobToJSON(pqAzureBlob: PqAzureBlob): string {
  return JSON.stringify(PqAzureBlob$outboundSchema.parse(pqAzureBlob));
}
export function pqAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<PqAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqAzureBlob' from JSON`,
  );
}

/** @internal */
export const MetadatumAzureBlob$inboundSchema: z.ZodType<
  MetadatumAzureBlob,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumAzureBlob$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumAzureBlob$outboundSchema: z.ZodType<
  MetadatumAzureBlob$Outbound,
  z.ZodTypeDef,
  MetadatumAzureBlob
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumAzureBlobToJSON(
  metadatumAzureBlob: MetadatumAzureBlob,
): string {
  return JSON.stringify(
    MetadatumAzureBlob$outboundSchema.parse(metadatumAzureBlob),
  );
}
export function metadatumAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumAzureBlob' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodAzureBlob$inboundSchema: z.ZodType<
  InputAuthenticationMethodAzureBlob,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodAzureBlob),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodAzureBlob$outboundSchema: z.ZodType<
  InputAuthenticationMethodAzureBlob,
  z.ZodTypeDef,
  InputAuthenticationMethodAzureBlob
> = z.union([
  z.nativeEnum(InputAuthenticationMethodAzureBlob),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputCertificate$inboundSchema: z.ZodType<
  InputCertificate,
  z.ZodTypeDef,
  unknown
> = z.object({
  certificateName: z.string(),
});
/** @internal */
export type InputCertificate$Outbound = {
  certificateName: string;
};

/** @internal */
export const InputCertificate$outboundSchema: z.ZodType<
  InputCertificate$Outbound,
  z.ZodTypeDef,
  InputCertificate
> = z.object({
  certificateName: z.string(),
});

export function inputCertificateToJSON(
  inputCertificate: InputCertificate,
): string {
  return JSON.stringify(
    InputCertificate$outboundSchema.parse(inputCertificate),
  );
}
export function inputCertificateFromJSON(
  jsonString: string,
): SafeParseResult<InputCertificate, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCertificate$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCertificate' from JSON`,
  );
}

/** @internal */
export const InputAzureBlob$inboundSchema: z.ZodType<
  InputAzureBlob,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeAzureBlob$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionAzureBlob$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqAzureBlob$inboundSchema).optional(),
    queueName: z.string(),
    fileFilter: z.string().default("/.*/"),
    visibilityTimeout: z.number().default(600),
    numReceivers: z.number().default(1),
    maxMessages: z.number().default(1),
    servicePeriodSecs: z.number().default(5),
    skipOnError: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumAzureBlob$inboundSchema))
      .optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    parquetChunkSizeMB: z.number().default(5),
    parquetChunkDownloadTimeout: z.number().default(600),
    authType: InputAuthenticationMethodAzureBlob$inboundSchema.default(
      "manual",
    ),
    description: z.string().optional(),
    connectionString: z.string().optional(),
    textSecret: z.string().optional(),
    storageAccountName: z.string().optional(),
    tenantId: z.string().optional(),
    clientId: z.string().optional(),
    azureCloud: z.string().optional(),
    endpointSuffix: z.string().optional(),
    clientTextSecret: z.string().optional(),
    certificate: z.lazy(() => InputCertificate$inboundSchema).optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputAzureBlob$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionAzureBlob$Outbound> | undefined;
  pq?: PqAzureBlob$Outbound | undefined;
  queueName: string;
  fileFilter: string;
  visibilityTimeout: number;
  numReceivers: number;
  maxMessages: number;
  servicePeriodSecs: number;
  skipOnError: boolean;
  metadata?: Array<MetadatumAzureBlob$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  parquetChunkSizeMB: number;
  parquetChunkDownloadTimeout: number;
  authType: string;
  description?: string | undefined;
  connectionString?: string | undefined;
  textSecret?: string | undefined;
  storageAccountName?: string | undefined;
  tenantId?: string | undefined;
  clientId?: string | undefined;
  azureCloud?: string | undefined;
  endpointSuffix?: string | undefined;
  clientTextSecret?: string | undefined;
  certificate?: InputCertificate$Outbound | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputAzureBlob$outboundSchema: z.ZodType<
  InputAzureBlob$Outbound,
  z.ZodTypeDef,
  InputAzureBlob
> = z.object({
  id: z.string().optional(),
  type: InputTypeAzureBlob$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionAzureBlob$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqAzureBlob$outboundSchema).optional(),
  queueName: z.string(),
  fileFilter: z.string().default("/.*/"),
  visibilityTimeout: z.number().default(600),
  numReceivers: z.number().default(1),
  maxMessages: z.number().default(1),
  servicePeriodSecs: z.number().default(5),
  skipOnError: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumAzureBlob$outboundSchema)).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  parquetChunkSizeMB: z.number().default(5),
  parquetChunkDownloadTimeout: z.number().default(600),
  authType: InputAuthenticationMethodAzureBlob$outboundSchema.default("manual"),
  description: z.string().optional(),
  connectionString: z.string().optional(),
  textSecret: z.string().optional(),
  storageAccountName: z.string().optional(),
  tenantId: z.string().optional(),
  clientId: z.string().optional(),
  azureCloud: z.string().optional(),
  endpointSuffix: z.string().optional(),
  clientTextSecret: z.string().optional(),
  certificate: z.lazy(() => InputCertificate$outboundSchema).optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputAzureBlobToJSON(inputAzureBlob: InputAzureBlob): string {
  return JSON.stringify(InputAzureBlob$outboundSchema.parse(inputAzureBlob));
}
export function inputAzureBlobFromJSON(
  jsonString: string,
): SafeParseResult<InputAzureBlob, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAzureBlob$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAzureBlob' from JSON`,
  );
}

/** @internal */
export const InputTypeSplunkHec$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeSplunkHec
> = z.nativeEnum(InputTypeSplunkHec);
/** @internal */
export const InputTypeSplunkHec$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeSplunkHec
> = InputTypeSplunkHec$inboundSchema;

/** @internal */
export const ConnectionSplunkHec$inboundSchema: z.ZodType<
  ConnectionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSplunkHec$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSplunkHec$outboundSchema: z.ZodType<
  ConnectionSplunkHec$Outbound,
  z.ZodTypeDef,
  ConnectionSplunkHec
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSplunkHecToJSON(
  connectionSplunkHec: ConnectionSplunkHec,
): string {
  return JSON.stringify(
    ConnectionSplunkHec$outboundSchema.parse(connectionSplunkHec),
  );
}
export function connectionSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSplunkHec' from JSON`,
  );
}

/** @internal */
export const PqModeSplunkHec$inboundSchema: z.ZodType<
  PqModeSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeSplunkHec$outboundSchema: z.ZodType<
  PqModeSplunkHec,
  z.ZodTypeDef,
  PqModeSplunkHec
> = z.union([
  z.nativeEnum(PqModeSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionSplunkHec$inboundSchema: z.ZodType<
  PqCompressionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionSplunkHec$outboundSchema: z.ZodType<
  PqCompressionSplunkHec,
  z.ZodTypeDef,
  PqCompressionSplunkHec
> = z.union([
  z.nativeEnum(PqCompressionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsSplunkHec$inboundSchema: z.ZodType<
  InputPqControlsSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsSplunkHec$Outbound = {};

/** @internal */
export const InputPqControlsSplunkHec$outboundSchema: z.ZodType<
  InputPqControlsSplunkHec$Outbound,
  z.ZodTypeDef,
  InputPqControlsSplunkHec
> = z.object({});

export function inputPqControlsSplunkHecToJSON(
  inputPqControlsSplunkHec: InputPqControlsSplunkHec,
): string {
  return JSON.stringify(
    InputPqControlsSplunkHec$outboundSchema.parse(inputPqControlsSplunkHec),
  );
}
export function inputPqControlsSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsSplunkHec' from JSON`,
  );
}

/** @internal */
export const PqSplunkHec$inboundSchema: z.ZodType<
  PqSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeSplunkHec$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionSplunkHec$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsSplunkHec$inboundSchema).optional(),
});
/** @internal */
export type PqSplunkHec$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsSplunkHec$Outbound | undefined;
};

/** @internal */
export const PqSplunkHec$outboundSchema: z.ZodType<
  PqSplunkHec$Outbound,
  z.ZodTypeDef,
  PqSplunkHec
> = z.object({
  mode: PqModeSplunkHec$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionSplunkHec$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsSplunkHec$outboundSchema).optional(),
});

export function pqSplunkHecToJSON(pqSplunkHec: PqSplunkHec): string {
  return JSON.stringify(PqSplunkHec$outboundSchema.parse(pqSplunkHec));
}
export function pqSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<PqSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSplunkHec' from JSON`,
  );
}

/** @internal */
export const AuthTokenAuthenticationMethodSplunkHec$inboundSchema: z.ZodType<
  AuthTokenAuthenticationMethodSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthTokenAuthenticationMethodSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthTokenAuthenticationMethodSplunkHec$outboundSchema: z.ZodType<
  AuthTokenAuthenticationMethodSplunkHec,
  z.ZodTypeDef,
  AuthTokenAuthenticationMethodSplunkHec
> = z.union([
  z.nativeEnum(AuthTokenAuthenticationMethodSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const AuthTokenMetadatumSplunkHec$inboundSchema: z.ZodType<
  AuthTokenMetadatumSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokenMetadatumSplunkHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokenMetadatumSplunkHec$outboundSchema: z.ZodType<
  AuthTokenMetadatumSplunkHec$Outbound,
  z.ZodTypeDef,
  AuthTokenMetadatumSplunkHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokenMetadatumSplunkHecToJSON(
  authTokenMetadatumSplunkHec: AuthTokenMetadatumSplunkHec,
): string {
  return JSON.stringify(
    AuthTokenMetadatumSplunkHec$outboundSchema.parse(
      authTokenMetadatumSplunkHec,
    ),
  );
}
export function authTokenMetadatumSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenMetadatumSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenMetadatumSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenMetadatumSplunkHec' from JSON`,
  );
}

/** @internal */
export const AuthTokenSplunkHec$inboundSchema: z.ZodType<
  AuthTokenSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  authType: AuthTokenAuthenticationMethodSplunkHec$inboundSchema.default(
    "manual",
  ),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(z.lazy(() => AuthTokenMetadatumSplunkHec$inboundSchema))
    .optional(),
});
/** @internal */
export type AuthTokenSplunkHec$Outbound = {
  authType: string;
  tokenSecret?: any | undefined;
  token?: any | undefined;
  enabled: boolean;
  description?: string | undefined;
  allowedIndexesAtToken?: Array<string> | undefined;
  metadata?: Array<AuthTokenMetadatumSplunkHec$Outbound> | undefined;
};

/** @internal */
export const AuthTokenSplunkHec$outboundSchema: z.ZodType<
  AuthTokenSplunkHec$Outbound,
  z.ZodTypeDef,
  AuthTokenSplunkHec
> = z.object({
  authType: AuthTokenAuthenticationMethodSplunkHec$outboundSchema.default(
    "manual",
  ),
  tokenSecret: z.any().optional(),
  token: z.any().optional(),
  enabled: z.boolean().default(true),
  description: z.string().optional(),
  allowedIndexesAtToken: z.array(z.string()).optional(),
  metadata: z.array(z.lazy(() => AuthTokenMetadatumSplunkHec$outboundSchema))
    .optional(),
});

export function authTokenSplunkHecToJSON(
  authTokenSplunkHec: AuthTokenSplunkHec,
): string {
  return JSON.stringify(
    AuthTokenSplunkHec$outboundSchema.parse(authTokenSplunkHec),
  );
}
export function authTokenSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenSplunkHec' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionSplunkHec$inboundSchema: z.ZodType<
  InputMinimumTLSVersionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionSplunkHec$outboundSchema: z.ZodType<
  InputMinimumTLSVersionSplunkHec,
  z.ZodTypeDef,
  InputMinimumTLSVersionSplunkHec
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionSplunkHec$inboundSchema: z.ZodType<
  InputMaximumTLSVersionSplunkHec,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionSplunkHec),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionSplunkHec$outboundSchema: z.ZodType<
  InputMaximumTLSVersionSplunkHec,
  z.ZodTypeDef,
  InputMaximumTLSVersionSplunkHec
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionSplunkHec),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideSplunkHec$inboundSchema: z.ZodType<
  TLSSettingsServerSideSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionSplunkHec$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionSplunkHec$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideSplunkHec$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideSplunkHec$outboundSchema: z.ZodType<
  TLSSettingsServerSideSplunkHec$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideSplunkHec
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionSplunkHec$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionSplunkHec$outboundSchema.optional(),
});

export function tlsSettingsServerSideSplunkHecToJSON(
  tlsSettingsServerSideSplunkHec: TLSSettingsServerSideSplunkHec,
): string {
  return JSON.stringify(
    TLSSettingsServerSideSplunkHec$outboundSchema.parse(
      tlsSettingsServerSideSplunkHec,
    ),
  );
}
export function tlsSettingsServerSideSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideSplunkHec' from JSON`,
  );
}

/** @internal */
export const MetadatumSplunkHec$inboundSchema: z.ZodType<
  MetadatumSplunkHec,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSplunkHec$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSplunkHec$outboundSchema: z.ZodType<
  MetadatumSplunkHec$Outbound,
  z.ZodTypeDef,
  MetadatumSplunkHec
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSplunkHecToJSON(
  metadatumSplunkHec: MetadatumSplunkHec,
): string {
  return JSON.stringify(
    MetadatumSplunkHec$outboundSchema.parse(metadatumSplunkHec),
  );
}
export function metadatumSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSplunkHec' from JSON`,
  );
}

/** @internal */
export const InputInputSplunkHec$inboundSchema: z.ZodType<
  InputInputSplunkHec,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeSplunkHec$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSplunkHec$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSplunkHec$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.lazy(() => AuthTokenSplunkHec$inboundSchema))
      .optional(),
    tls: z.lazy(() => TLSSettingsServerSideSplunkHec$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.any().optional(),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    splunkHecAPI: z.string().default("/services/collector"),
    metadata: z.array(z.lazy(() => MetadatumSplunkHec$inboundSchema))
      .optional(),
    allowedIndexes: z.array(z.string()).optional(),
    splunkHecAcks: z.boolean().default(false),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    useFwdTimezone: z.boolean().default(true),
    dropControlFields: z.boolean().default(true),
    extractMetrics: z.boolean().default(false),
    accessControlAllowOrigin: z.array(z.string()).optional(),
    accessControlAllowHeaders: z.array(z.string()).optional(),
    emitTokenMetrics: z.boolean().default(false),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputInputSplunkHec$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSplunkHec$Outbound> | undefined;
  pq?: PqSplunkHec$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<AuthTokenSplunkHec$Outbound> | undefined;
  tls?: TLSSettingsServerSideSplunkHec$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck?: any | undefined;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  splunkHecAPI: string;
  metadata?: Array<MetadatumSplunkHec$Outbound> | undefined;
  allowedIndexes?: Array<string> | undefined;
  splunkHecAcks: boolean;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  useFwdTimezone: boolean;
  dropControlFields: boolean;
  extractMetrics: boolean;
  accessControlAllowOrigin?: Array<string> | undefined;
  accessControlAllowHeaders?: Array<string> | undefined;
  emitTokenMetrics: boolean;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputInputSplunkHec$outboundSchema: z.ZodType<
  InputInputSplunkHec$Outbound,
  z.ZodTypeDef,
  InputInputSplunkHec
> = z.object({
  id: z.string().optional(),
  type: InputTypeSplunkHec$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSplunkHec$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSplunkHec$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.lazy(() => AuthTokenSplunkHec$outboundSchema))
    .optional(),
  tls: z.lazy(() => TLSSettingsServerSideSplunkHec$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.any().optional(),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  splunkHecAPI: z.string().default("/services/collector"),
  metadata: z.array(z.lazy(() => MetadatumSplunkHec$outboundSchema)).optional(),
  allowedIndexes: z.array(z.string()).optional(),
  splunkHecAcks: z.boolean().default(false),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  useFwdTimezone: z.boolean().default(true),
  dropControlFields: z.boolean().default(true),
  extractMetrics: z.boolean().default(false),
  accessControlAllowOrigin: z.array(z.string()).optional(),
  accessControlAllowHeaders: z.array(z.string()).optional(),
  emitTokenMetrics: z.boolean().default(false),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputInputSplunkHecToJSON(
  inputInputSplunkHec: InputInputSplunkHec,
): string {
  return JSON.stringify(
    InputInputSplunkHec$outboundSchema.parse(inputInputSplunkHec),
  );
}
export function inputInputSplunkHecFromJSON(
  jsonString: string,
): SafeParseResult<InputInputSplunkHec, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputInputSplunkHec$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputInputSplunkHec' from JSON`,
  );
}

/** @internal */
export const TypeSplunkSearch$inboundSchema: z.ZodNativeEnum<
  typeof TypeSplunkSearch
> = z.nativeEnum(TypeSplunkSearch);
/** @internal */
export const TypeSplunkSearch$outboundSchema: z.ZodNativeEnum<
  typeof TypeSplunkSearch
> = TypeSplunkSearch$inboundSchema;

/** @internal */
export const ConnectionSplunkSearch$inboundSchema: z.ZodType<
  ConnectionSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSplunkSearch$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSplunkSearch$outboundSchema: z.ZodType<
  ConnectionSplunkSearch$Outbound,
  z.ZodTypeDef,
  ConnectionSplunkSearch
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSplunkSearchToJSON(
  connectionSplunkSearch: ConnectionSplunkSearch,
): string {
  return JSON.stringify(
    ConnectionSplunkSearch$outboundSchema.parse(connectionSplunkSearch),
  );
}
export function connectionSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSplunkSearch' from JSON`,
  );
}

/** @internal */
export const ModeSplunkSearch$inboundSchema: z.ZodType<
  ModeSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeSplunkSearch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeSplunkSearch$outboundSchema: z.ZodType<
  ModeSplunkSearch,
  z.ZodTypeDef,
  ModeSplunkSearch
> = z.union([
  z.nativeEnum(ModeSplunkSearch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionSplunkSearch$inboundSchema: z.ZodType<
  CompressionSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionSplunkSearch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionSplunkSearch$outboundSchema: z.ZodType<
  CompressionSplunkSearch,
  z.ZodTypeDef,
  CompressionSplunkSearch
> = z.union([
  z.nativeEnum(CompressionSplunkSearch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsSplunkSearch$inboundSchema: z.ZodType<
  PqControlsSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsSplunkSearch$Outbound = {};

/** @internal */
export const PqControlsSplunkSearch$outboundSchema: z.ZodType<
  PqControlsSplunkSearch$Outbound,
  z.ZodTypeDef,
  PqControlsSplunkSearch
> = z.object({});

export function pqControlsSplunkSearchToJSON(
  pqControlsSplunkSearch: PqControlsSplunkSearch,
): string {
  return JSON.stringify(
    PqControlsSplunkSearch$outboundSchema.parse(pqControlsSplunkSearch),
  );
}
export function pqControlsSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsSplunkSearch' from JSON`,
  );
}

/** @internal */
export const PqSplunkSearch$inboundSchema: z.ZodType<
  PqSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeSplunkSearch$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSplunkSearch$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSplunkSearch$inboundSchema).optional(),
});
/** @internal */
export type PqSplunkSearch$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsSplunkSearch$Outbound | undefined;
};

/** @internal */
export const PqSplunkSearch$outboundSchema: z.ZodType<
  PqSplunkSearch$Outbound,
  z.ZodTypeDef,
  PqSplunkSearch
> = z.object({
  mode: ModeSplunkSearch$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionSplunkSearch$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsSplunkSearch$outboundSchema).optional(),
});

export function pqSplunkSearchToJSON(pqSplunkSearch: PqSplunkSearch): string {
  return JSON.stringify(PqSplunkSearch$outboundSchema.parse(pqSplunkSearch));
}
export function pqSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<PqSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSplunkSearch' from JSON`,
  );
}

/** @internal */
export const OutputMode$inboundSchema: z.ZodType<
  OutputMode,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(OutputMode),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const OutputMode$outboundSchema: z.ZodType<
  OutputMode,
  z.ZodTypeDef,
  OutputMode
> = z.union([
  z.nativeEnum(OutputMode),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const EndpointParam$inboundSchema: z.ZodType<
  EndpointParam,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type EndpointParam$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const EndpointParam$outboundSchema: z.ZodType<
  EndpointParam$Outbound,
  z.ZodTypeDef,
  EndpointParam
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function endpointParamToJSON(endpointParam: EndpointParam): string {
  return JSON.stringify(EndpointParam$outboundSchema.parse(endpointParam));
}
export function endpointParamFromJSON(
  jsonString: string,
): SafeParseResult<EndpointParam, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => EndpointParam$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'EndpointParam' from JSON`,
  );
}

/** @internal */
export const EndpointHeader$inboundSchema: z.ZodType<
  EndpointHeader,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type EndpointHeader$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const EndpointHeader$outboundSchema: z.ZodType<
  EndpointHeader$Outbound,
  z.ZodTypeDef,
  EndpointHeader
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function endpointHeaderToJSON(endpointHeader: EndpointHeader): string {
  return JSON.stringify(EndpointHeader$outboundSchema.parse(endpointHeader));
}
export function endpointHeaderFromJSON(
  jsonString: string,
): SafeParseResult<EndpointHeader, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => EndpointHeader$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'EndpointHeader' from JSON`,
  );
}

/** @internal */
export const LogLevelSplunkSearch$inboundSchema: z.ZodType<
  LogLevelSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(LogLevelSplunkSearch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const LogLevelSplunkSearch$outboundSchema: z.ZodType<
  LogLevelSplunkSearch,
  z.ZodTypeDef,
  LogLevelSplunkSearch
> = z.union([
  z.nativeEnum(LogLevelSplunkSearch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MetadatumSplunkSearch$inboundSchema: z.ZodType<
  MetadatumSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSplunkSearch$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSplunkSearch$outboundSchema: z.ZodType<
  MetadatumSplunkSearch$Outbound,
  z.ZodTypeDef,
  MetadatumSplunkSearch
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSplunkSearchToJSON(
  metadatumSplunkSearch: MetadatumSplunkSearch,
): string {
  return JSON.stringify(
    MetadatumSplunkSearch$outboundSchema.parse(metadatumSplunkSearch),
  );
}
export function metadatumSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSplunkSearch' from JSON`,
  );
}

/** @internal */
export const RetryTypeSplunkSearch$inboundSchema: z.ZodType<
  RetryTypeSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(RetryTypeSplunkSearch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const RetryTypeSplunkSearch$outboundSchema: z.ZodType<
  RetryTypeSplunkSearch,
  z.ZodTypeDef,
  RetryTypeSplunkSearch
> = z.union([
  z.nativeEnum(RetryTypeSplunkSearch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const RetryRulesSplunkSearch$inboundSchema: z.ZodType<
  RetryRulesSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  type: RetryTypeSplunkSearch$inboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});
/** @internal */
export type RetryRulesSplunkSearch$Outbound = {
  type: string;
  interval: number;
  limit: number;
  multiplier: number;
  codes?: Array<number> | undefined;
  enableHeader: boolean;
  retryConnectTimeout: boolean;
  retryConnectReset: boolean;
};

/** @internal */
export const RetryRulesSplunkSearch$outboundSchema: z.ZodType<
  RetryRulesSplunkSearch$Outbound,
  z.ZodTypeDef,
  RetryRulesSplunkSearch
> = z.object({
  type: RetryTypeSplunkSearch$outboundSchema.default("backoff"),
  interval: z.number().default(1000),
  limit: z.number().default(5),
  multiplier: z.number().default(2),
  codes: z.array(z.number()).optional(),
  enableHeader: z.boolean().default(true),
  retryConnectTimeout: z.boolean().default(false),
  retryConnectReset: z.boolean().default(false),
});

export function retryRulesSplunkSearchToJSON(
  retryRulesSplunkSearch: RetryRulesSplunkSearch,
): string {
  return JSON.stringify(
    RetryRulesSplunkSearch$outboundSchema.parse(retryRulesSplunkSearch),
  );
}
export function retryRulesSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<RetryRulesSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => RetryRulesSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'RetryRulesSplunkSearch' from JSON`,
  );
}

/** @internal */
export const AuthenticationTypeSplunkSearch$inboundSchema: z.ZodType<
  AuthenticationTypeSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(AuthenticationTypeSplunkSearch),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const AuthenticationTypeSplunkSearch$outboundSchema: z.ZodType<
  AuthenticationTypeSplunkSearch,
  z.ZodTypeDef,
  AuthenticationTypeSplunkSearch
> = z.union([
  z.nativeEnum(AuthenticationTypeSplunkSearch),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const OauthParamSplunkSearch$inboundSchema: z.ZodType<
  OauthParamSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthParamSplunkSearch$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthParamSplunkSearch$outboundSchema: z.ZodType<
  OauthParamSplunkSearch$Outbound,
  z.ZodTypeDef,
  OauthParamSplunkSearch
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthParamSplunkSearchToJSON(
  oauthParamSplunkSearch: OauthParamSplunkSearch,
): string {
  return JSON.stringify(
    OauthParamSplunkSearch$outboundSchema.parse(oauthParamSplunkSearch),
  );
}
export function oauthParamSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<OauthParamSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthParamSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthParamSplunkSearch' from JSON`,
  );
}

/** @internal */
export const OauthHeaderSplunkSearch$inboundSchema: z.ZodType<
  OauthHeaderSplunkSearch,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type OauthHeaderSplunkSearch$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const OauthHeaderSplunkSearch$outboundSchema: z.ZodType<
  OauthHeaderSplunkSearch$Outbound,
  z.ZodTypeDef,
  OauthHeaderSplunkSearch
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function oauthHeaderSplunkSearchToJSON(
  oauthHeaderSplunkSearch: OauthHeaderSplunkSearch,
): string {
  return JSON.stringify(
    OauthHeaderSplunkSearch$outboundSchema.parse(oauthHeaderSplunkSearch),
  );
}
export function oauthHeaderSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<OauthHeaderSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => OauthHeaderSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'OauthHeaderSplunkSearch' from JSON`,
  );
}

/** @internal */
export const InputSplunkSearch$inboundSchema: z.ZodType<
  InputSplunkSearch,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeSplunkSearch$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSplunkSearch$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSplunkSearch$inboundSchema).optional(),
    searchHead: z.string().default("https://localhost:8089"),
    search: z.string(),
    earliest: z.string().default("-16m@m"),
    latest: z.string().default("-1m@m"),
    cronSchedule: z.string().default("*/15 * * * *"),
    endpoint: z.string().default("/services/search/v2/jobs/export"),
    outputMode: OutputMode$inboundSchema.default("json"),
    endpointParams: z.array(z.lazy(() => EndpointParam$inboundSchema))
      .optional(),
    endpointHeaders: z.array(z.lazy(() => EndpointHeader$inboundSchema))
      .optional(),
    logLevel: LogLevelSplunkSearch$inboundSchema.optional(),
    requestTimeout: z.number().default(0),
    useRoundRobinDns: z.boolean().default(false),
    rejectUnauthorized: z.boolean().default(false),
    encoding: z.string().optional(),
    keepAliveTime: z.number().default(30),
    jobTimeout: z.string().default("0"),
    maxMissedKeepAlives: z.number().default(3),
    ttl: z.string().default("4h"),
    ignoreGroupJobsLimit: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumSplunkSearch$inboundSchema))
      .optional(),
    retryRules: z.lazy(() => RetryRulesSplunkSearch$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    authType: AuthenticationTypeSplunkSearch$inboundSchema.default("basic"),
    description: z.string().optional(),
    username: z.string().optional(),
    password: z.string().optional(),
    token: z.string().optional(),
    credentialsSecret: z.string().optional(),
    textSecret: z.string().optional(),
    loginUrl: z.string().optional(),
    secretParamName: z.string().optional(),
    secret: z.string().optional(),
    tokenAttributeName: z.string().optional(),
    authHeaderExpr: z.string().default("`Bearer ${token}`"),
    tokenTimeoutSecs: z.number().default(3600),
    oauthParams: z.array(z.lazy(() => OauthParamSplunkSearch$inboundSchema))
      .optional(),
    oauthHeaders: z.array(z.lazy(() => OauthHeaderSplunkSearch$inboundSchema))
      .optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSplunkSearch$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSplunkSearch$Outbound> | undefined;
  pq?: PqSplunkSearch$Outbound | undefined;
  searchHead: string;
  search: string;
  earliest: string;
  latest: string;
  cronSchedule: string;
  endpoint: string;
  outputMode: string;
  endpointParams?: Array<EndpointParam$Outbound> | undefined;
  endpointHeaders?: Array<EndpointHeader$Outbound> | undefined;
  logLevel?: string | undefined;
  requestTimeout: number;
  useRoundRobinDns: boolean;
  rejectUnauthorized: boolean;
  encoding?: string | undefined;
  keepAliveTime: number;
  jobTimeout: string;
  maxMissedKeepAlives: number;
  ttl: string;
  ignoreGroupJobsLimit: boolean;
  metadata?: Array<MetadatumSplunkSearch$Outbound> | undefined;
  retryRules?: RetryRulesSplunkSearch$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  authType: string;
  description?: string | undefined;
  username?: string | undefined;
  password?: string | undefined;
  token?: string | undefined;
  credentialsSecret?: string | undefined;
  textSecret?: string | undefined;
  loginUrl?: string | undefined;
  secretParamName?: string | undefined;
  secret?: string | undefined;
  tokenAttributeName?: string | undefined;
  authHeaderExpr: string;
  tokenTimeoutSecs: number;
  oauthParams?: Array<OauthParamSplunkSearch$Outbound> | undefined;
  oauthHeaders?: Array<OauthHeaderSplunkSearch$Outbound> | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSplunkSearch$outboundSchema: z.ZodType<
  InputSplunkSearch$Outbound,
  z.ZodTypeDef,
  InputSplunkSearch
> = z.object({
  id: z.string().optional(),
  type: TypeSplunkSearch$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSplunkSearch$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSplunkSearch$outboundSchema).optional(),
  searchHead: z.string().default("https://localhost:8089"),
  search: z.string(),
  earliest: z.string().default("-16m@m"),
  latest: z.string().default("-1m@m"),
  cronSchedule: z.string().default("*/15 * * * *"),
  endpoint: z.string().default("/services/search/v2/jobs/export"),
  outputMode: OutputMode$outboundSchema.default("json"),
  endpointParams: z.array(z.lazy(() => EndpointParam$outboundSchema))
    .optional(),
  endpointHeaders: z.array(z.lazy(() => EndpointHeader$outboundSchema))
    .optional(),
  logLevel: LogLevelSplunkSearch$outboundSchema.optional(),
  requestTimeout: z.number().default(0),
  useRoundRobinDns: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(false),
  encoding: z.string().optional(),
  keepAliveTime: z.number().default(30),
  jobTimeout: z.string().default("0"),
  maxMissedKeepAlives: z.number().default(3),
  ttl: z.string().default("4h"),
  ignoreGroupJobsLimit: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumSplunkSearch$outboundSchema))
    .optional(),
  retryRules: z.lazy(() => RetryRulesSplunkSearch$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  authType: AuthenticationTypeSplunkSearch$outboundSchema.default("basic"),
  description: z.string().optional(),
  username: z.string().optional(),
  password: z.string().optional(),
  token: z.string().optional(),
  credentialsSecret: z.string().optional(),
  textSecret: z.string().optional(),
  loginUrl: z.string().optional(),
  secretParamName: z.string().optional(),
  secret: z.string().optional(),
  tokenAttributeName: z.string().optional(),
  authHeaderExpr: z.string().default("`Bearer ${token}`"),
  tokenTimeoutSecs: z.number().default(3600),
  oauthParams: z.array(z.lazy(() => OauthParamSplunkSearch$outboundSchema))
    .optional(),
  oauthHeaders: z.array(z.lazy(() => OauthHeaderSplunkSearch$outboundSchema))
    .optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSplunkSearchToJSON(
  inputSplunkSearch: InputSplunkSearch,
): string {
  return JSON.stringify(
    InputSplunkSearch$outboundSchema.parse(inputSplunkSearch),
  );
}
export function inputSplunkSearchFromJSON(
  jsonString: string,
): SafeParseResult<InputSplunkSearch, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSplunkSearch$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSplunkSearch' from JSON`,
  );
}

/** @internal */
export const InputTypeSplunk$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeSplunk
> = z.nativeEnum(InputTypeSplunk);
/** @internal */
export const InputTypeSplunk$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeSplunk
> = InputTypeSplunk$inboundSchema;

/** @internal */
export const ConnectionSplunk$inboundSchema: z.ZodType<
  ConnectionSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionSplunk$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionSplunk$outboundSchema: z.ZodType<
  ConnectionSplunk$Outbound,
  z.ZodTypeDef,
  ConnectionSplunk
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionSplunkToJSON(
  connectionSplunk: ConnectionSplunk,
): string {
  return JSON.stringify(
    ConnectionSplunk$outboundSchema.parse(connectionSplunk),
  );
}
export function connectionSplunkFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionSplunk' from JSON`,
  );
}

/** @internal */
export const PqModeSplunk$inboundSchema: z.ZodType<
  PqModeSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeSplunk$outboundSchema: z.ZodType<
  PqModeSplunk,
  z.ZodTypeDef,
  PqModeSplunk
> = z.union([
  z.nativeEnum(PqModeSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionSplunk$inboundSchema: z.ZodType<
  PqCompressionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionSplunk$outboundSchema: z.ZodType<
  PqCompressionSplunk,
  z.ZodTypeDef,
  PqCompressionSplunk
> = z.union([
  z.nativeEnum(PqCompressionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsSplunk$inboundSchema: z.ZodType<
  InputPqControlsSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsSplunk$Outbound = {};

/** @internal */
export const InputPqControlsSplunk$outboundSchema: z.ZodType<
  InputPqControlsSplunk$Outbound,
  z.ZodTypeDef,
  InputPqControlsSplunk
> = z.object({});

export function inputPqControlsSplunkToJSON(
  inputPqControlsSplunk: InputPqControlsSplunk,
): string {
  return JSON.stringify(
    InputPqControlsSplunk$outboundSchema.parse(inputPqControlsSplunk),
  );
}
export function inputPqControlsSplunkFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsSplunk' from JSON`,
  );
}

/** @internal */
export const PqSplunk$inboundSchema: z.ZodType<
  PqSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: PqModeSplunk$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionSplunk$inboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsSplunk$inboundSchema).optional(),
});
/** @internal */
export type PqSplunk$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsSplunk$Outbound | undefined;
};

/** @internal */
export const PqSplunk$outboundSchema: z.ZodType<
  PqSplunk$Outbound,
  z.ZodTypeDef,
  PqSplunk
> = z.object({
  mode: PqModeSplunk$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionSplunk$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsSplunk$outboundSchema).optional(),
});

export function pqSplunkToJSON(pqSplunk: PqSplunk): string {
  return JSON.stringify(PqSplunk$outboundSchema.parse(pqSplunk));
}
export function pqSplunkFromJSON(
  jsonString: string,
): SafeParseResult<PqSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqSplunk' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionSplunk$inboundSchema: z.ZodType<
  InputMinimumTLSVersionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionSplunk$outboundSchema: z.ZodType<
  InputMinimumTLSVersionSplunk,
  z.ZodTypeDef,
  InputMinimumTLSVersionSplunk
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionSplunk$inboundSchema: z.ZodType<
  InputMaximumTLSVersionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionSplunk$outboundSchema: z.ZodType<
  InputMaximumTLSVersionSplunk,
  z.ZodTypeDef,
  InputMaximumTLSVersionSplunk
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideSplunk$inboundSchema: z.ZodType<
  TLSSettingsServerSideSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionSplunk$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionSplunk$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideSplunk$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideSplunk$outboundSchema: z.ZodType<
  TLSSettingsServerSideSplunk$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideSplunk
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: InputMinimumTLSVersionSplunk$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionSplunk$outboundSchema.optional(),
});

export function tlsSettingsServerSideSplunkToJSON(
  tlsSettingsServerSideSplunk: TLSSettingsServerSideSplunk,
): string {
  return JSON.stringify(
    TLSSettingsServerSideSplunk$outboundSchema.parse(
      tlsSettingsServerSideSplunk,
    ),
  );
}
export function tlsSettingsServerSideSplunkFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideSplunk' from JSON`,
  );
}

/** @internal */
export const MetadatumSplunk$inboundSchema: z.ZodType<
  MetadatumSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumSplunk$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumSplunk$outboundSchema: z.ZodType<
  MetadatumSplunk$Outbound,
  z.ZodTypeDef,
  MetadatumSplunk
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumSplunkToJSON(
  metadatumSplunk: MetadatumSplunk,
): string {
  return JSON.stringify(MetadatumSplunk$outboundSchema.parse(metadatumSplunk));
}
export function metadatumSplunkFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumSplunk' from JSON`,
  );
}

/** @internal */
export const AuthTokenSplunk$inboundSchema: z.ZodType<
  AuthTokenSplunk,
  z.ZodTypeDef,
  unknown
> = z.object({
  token: z.string(),
  description: z.string().optional(),
});
/** @internal */
export type AuthTokenSplunk$Outbound = {
  token: string;
  description?: string | undefined;
};

/** @internal */
export const AuthTokenSplunk$outboundSchema: z.ZodType<
  AuthTokenSplunk$Outbound,
  z.ZodTypeDef,
  AuthTokenSplunk
> = z.object({
  token: z.string(),
  description: z.string().optional(),
});

export function authTokenSplunkToJSON(
  authTokenSplunk: AuthTokenSplunk,
): string {
  return JSON.stringify(AuthTokenSplunk$outboundSchema.parse(authTokenSplunk));
}
export function authTokenSplunkFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokenSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokenSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokenSplunk' from JSON`,
  );
}

/** @internal */
export const InputMaxS2SVersion$inboundSchema: z.ZodType<
  InputMaxS2SVersion,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaxS2SVersion),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaxS2SVersion$outboundSchema: z.ZodType<
  InputMaxS2SVersion,
  z.ZodTypeDef,
  InputMaxS2SVersion
> = z.union([
  z.nativeEnum(InputMaxS2SVersion),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputCompressionSplunk$inboundSchema: z.ZodType<
  InputCompressionSplunk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputCompressionSplunk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputCompressionSplunk$outboundSchema: z.ZodType<
  InputCompressionSplunk,
  z.ZodTypeDef,
  InputCompressionSplunk
> = z.union([
  z.nativeEnum(InputCompressionSplunk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSplunk$inboundSchema: z.ZodType<
  InputSplunk,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeSplunk$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionSplunk$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqSplunk$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    tls: z.lazy(() => TLSSettingsServerSideSplunk$inboundSchema).optional(),
    ipWhitelistRegex: z.string().default("/.*/"),
    maxActiveCxn: z.number().default(1000),
    socketIdleTimeout: z.number().default(0),
    socketEndingMaxWait: z.number().default(30),
    socketMaxLifespan: z.number().default(0),
    enableProxyHeader: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumSplunk$inboundSchema)).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    authTokens: z.array(z.lazy(() => AuthTokenSplunk$inboundSchema)).optional(),
    maxS2Sversion: InputMaxS2SVersion$inboundSchema.default("v3"),
    description: z.string().optional(),
    useFwdTimezone: z.boolean().default(true),
    dropControlFields: z.boolean().default(true),
    extractMetrics: z.boolean().default(false),
    compress: InputCompressionSplunk$inboundSchema.default("disabled"),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputSplunk$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionSplunk$Outbound> | undefined;
  pq?: PqSplunk$Outbound | undefined;
  host: string;
  port: number;
  tls?: TLSSettingsServerSideSplunk$Outbound | undefined;
  ipWhitelistRegex: string;
  maxActiveCxn: number;
  socketIdleTimeout: number;
  socketEndingMaxWait: number;
  socketMaxLifespan: number;
  enableProxyHeader: boolean;
  metadata?: Array<MetadatumSplunk$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  authTokens?: Array<AuthTokenSplunk$Outbound> | undefined;
  maxS2Sversion: string;
  description?: string | undefined;
  useFwdTimezone: boolean;
  dropControlFields: boolean;
  extractMetrics: boolean;
  compress: string;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputSplunk$outboundSchema: z.ZodType<
  InputSplunk$Outbound,
  z.ZodTypeDef,
  InputSplunk
> = z.object({
  id: z.string().optional(),
  type: InputTypeSplunk$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionSplunk$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqSplunk$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  tls: z.lazy(() => TLSSettingsServerSideSplunk$outboundSchema).optional(),
  ipWhitelistRegex: z.string().default("/.*/"),
  maxActiveCxn: z.number().default(1000),
  socketIdleTimeout: z.number().default(0),
  socketEndingMaxWait: z.number().default(30),
  socketMaxLifespan: z.number().default(0),
  enableProxyHeader: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumSplunk$outboundSchema)).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  authTokens: z.array(z.lazy(() => AuthTokenSplunk$outboundSchema)).optional(),
  maxS2Sversion: InputMaxS2SVersion$outboundSchema.default("v3"),
  description: z.string().optional(),
  useFwdTimezone: z.boolean().default(true),
  dropControlFields: z.boolean().default(true),
  extractMetrics: z.boolean().default(false),
  compress: InputCompressionSplunk$outboundSchema.default("disabled"),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputSplunkToJSON(inputSplunk: InputSplunk): string {
  return JSON.stringify(InputSplunk$outboundSchema.parse(inputSplunk));
}
export function inputSplunkFromJSON(
  jsonString: string,
): SafeParseResult<InputSplunk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSplunk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSplunk' from JSON`,
  );
}

/** @internal */
export const TypeHTTP$inboundSchema: z.ZodNativeEnum<typeof TypeHTTP> = z
  .nativeEnum(TypeHTTP);
/** @internal */
export const TypeHTTP$outboundSchema: z.ZodNativeEnum<typeof TypeHTTP> =
  TypeHTTP$inboundSchema;

/** @internal */
export const ConnectionHTTP$inboundSchema: z.ZodType<
  ConnectionHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionHTTP$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionHTTP$outboundSchema: z.ZodType<
  ConnectionHTTP$Outbound,
  z.ZodTypeDef,
  ConnectionHTTP
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionHTTPToJSON(connectionHTTP: ConnectionHTTP): string {
  return JSON.stringify(ConnectionHTTP$outboundSchema.parse(connectionHTTP));
}
export function connectionHTTPFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionHTTP' from JSON`,
  );
}

/** @internal */
export const ModeHTTP$inboundSchema: z.ZodType<
  ModeHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeHTTP$outboundSchema: z.ZodType<
  ModeHTTP,
  z.ZodTypeDef,
  ModeHTTP
> = z.union([
  z.nativeEnum(ModeHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionHTTP$inboundSchema: z.ZodType<
  CompressionHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionHTTP$outboundSchema: z.ZodType<
  CompressionHTTP,
  z.ZodTypeDef,
  CompressionHTTP
> = z.union([
  z.nativeEnum(CompressionHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsHTTP$inboundSchema: z.ZodType<
  PqControlsHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsHTTP$Outbound = {};

/** @internal */
export const PqControlsHTTP$outboundSchema: z.ZodType<
  PqControlsHTTP$Outbound,
  z.ZodTypeDef,
  PqControlsHTTP
> = z.object({});

export function pqControlsHTTPToJSON(pqControlsHTTP: PqControlsHTTP): string {
  return JSON.stringify(PqControlsHTTP$outboundSchema.parse(pqControlsHTTP));
}
export function pqControlsHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsHTTP' from JSON`,
  );
}

/** @internal */
export const PqHTTP$inboundSchema: z.ZodType<PqHTTP, z.ZodTypeDef, unknown> = z
  .object({
    mode: ModeHTTP$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: CompressionHTTP$inboundSchema.default("none"),
    pqControls: z.lazy(() => PqControlsHTTP$inboundSchema).optional(),
  });
/** @internal */
export type PqHTTP$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsHTTP$Outbound | undefined;
};

/** @internal */
export const PqHTTP$outboundSchema: z.ZodType<
  PqHTTP$Outbound,
  z.ZodTypeDef,
  PqHTTP
> = z.object({
  mode: ModeHTTP$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionHTTP$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsHTTP$outboundSchema).optional(),
});

export function pqHTTPToJSON(pqHTTP: PqHTTP): string {
  return JSON.stringify(PqHTTP$outboundSchema.parse(pqHTTP));
}
export function pqHTTPFromJSON(
  jsonString: string,
): SafeParseResult<PqHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqHTTP' from JSON`,
  );
}

/** @internal */
export const MinimumTLSVersionHTTP$inboundSchema: z.ZodType<
  MinimumTLSVersionHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MinimumTLSVersionHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MinimumTLSVersionHTTP$outboundSchema: z.ZodType<
  MinimumTLSVersionHTTP,
  z.ZodTypeDef,
  MinimumTLSVersionHTTP
> = z.union([
  z.nativeEnum(MinimumTLSVersionHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const MaximumTLSVersionHTTP$inboundSchema: z.ZodType<
  MaximumTLSVersionHTTP,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(MaximumTLSVersionHTTP),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const MaximumTLSVersionHTTP$outboundSchema: z.ZodType<
  MaximumTLSVersionHTTP,
  z.ZodTypeDef,
  MaximumTLSVersionHTTP
> = z.union([
  z.nativeEnum(MaximumTLSVersionHTTP),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const TLSSettingsServerSideHTTP$inboundSchema: z.ZodType<
  TLSSettingsServerSideHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionHTTP$inboundSchema.optional(),
  maxVersion: MaximumTLSVersionHTTP$inboundSchema.optional(),
});
/** @internal */
export type TLSSettingsServerSideHTTP$Outbound = {
  disabled: boolean;
  requestCert: boolean;
  rejectUnauthorized: boolean;
  commonNameRegex: string;
  certificateName?: string | undefined;
  privKeyPath?: string | undefined;
  passphrase?: string | undefined;
  certPath?: string | undefined;
  caPath?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const TLSSettingsServerSideHTTP$outboundSchema: z.ZodType<
  TLSSettingsServerSideHTTP$Outbound,
  z.ZodTypeDef,
  TLSSettingsServerSideHTTP
> = z.object({
  disabled: z.boolean().default(true),
  requestCert: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  commonNameRegex: z.string().default("/.*/"),
  certificateName: z.string().optional(),
  privKeyPath: z.string().optional(),
  passphrase: z.string().optional(),
  certPath: z.string().optional(),
  caPath: z.string().optional(),
  minVersion: MinimumTLSVersionHTTP$outboundSchema.optional(),
  maxVersion: MaximumTLSVersionHTTP$outboundSchema.optional(),
});

export function tlsSettingsServerSideHTTPToJSON(
  tlsSettingsServerSideHTTP: TLSSettingsServerSideHTTP,
): string {
  return JSON.stringify(
    TLSSettingsServerSideHTTP$outboundSchema.parse(tlsSettingsServerSideHTTP),
  );
}
export function tlsSettingsServerSideHTTPFromJSON(
  jsonString: string,
): SafeParseResult<TLSSettingsServerSideHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => TLSSettingsServerSideHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'TLSSettingsServerSideHTTP' from JSON`,
  );
}

/** @internal */
export const MetadatumHTTP$inboundSchema: z.ZodType<
  MetadatumHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumHTTP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumHTTP$outboundSchema: z.ZodType<
  MetadatumHTTP$Outbound,
  z.ZodTypeDef,
  MetadatumHTTP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumHTTPToJSON(metadatumHTTP: MetadatumHTTP): string {
  return JSON.stringify(MetadatumHTTP$outboundSchema.parse(metadatumHTTP));
}
export function metadatumHTTPFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumHTTP' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtMetadatumHTTP$inboundSchema: z.ZodType<
  AuthTokensExtMetadatumHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type AuthTokensExtMetadatumHTTP$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const AuthTokensExtMetadatumHTTP$outboundSchema: z.ZodType<
  AuthTokensExtMetadatumHTTP$Outbound,
  z.ZodTypeDef,
  AuthTokensExtMetadatumHTTP
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function authTokensExtMetadatumHTTPToJSON(
  authTokensExtMetadatumHTTP: AuthTokensExtMetadatumHTTP,
): string {
  return JSON.stringify(
    AuthTokensExtMetadatumHTTP$outboundSchema.parse(authTokensExtMetadatumHTTP),
  );
}
export function authTokensExtMetadatumHTTPFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtMetadatumHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtMetadatumHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtMetadatumHTTP' from JSON`,
  );
}

/** @internal */
export const AuthTokensExtHTTP$inboundSchema: z.ZodType<
  AuthTokensExtHTTP,
  z.ZodTypeDef,
  unknown
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(z.lazy(() => AuthTokensExtMetadatumHTTP$inboundSchema))
    .optional(),
});
/** @internal */
export type AuthTokensExtHTTP$Outbound = {
  token: string;
  description?: string | undefined;
  metadata?: Array<AuthTokensExtMetadatumHTTP$Outbound> | undefined;
};

/** @internal */
export const AuthTokensExtHTTP$outboundSchema: z.ZodType<
  AuthTokensExtHTTP$Outbound,
  z.ZodTypeDef,
  AuthTokensExtHTTP
> = z.object({
  token: z.string(),
  description: z.string().optional(),
  metadata: z.array(z.lazy(() => AuthTokensExtMetadatumHTTP$outboundSchema))
    .optional(),
});

export function authTokensExtHTTPToJSON(
  authTokensExtHTTP: AuthTokensExtHTTP,
): string {
  return JSON.stringify(
    AuthTokensExtHTTP$outboundSchema.parse(authTokensExtHTTP),
  );
}
export function authTokensExtHTTPFromJSON(
  jsonString: string,
): SafeParseResult<AuthTokensExtHTTP, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => AuthTokensExtHTTP$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'AuthTokensExtHTTP' from JSON`,
  );
}

/** @internal */
export const InputHttp$inboundSchema: z.ZodType<
  InputHttp,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: TypeHTTP$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionHTTP$inboundSchema)).optional(),
    pq: z.lazy(() => PqHTTP$inboundSchema).optional(),
    host: z.string().default("0.0.0.0"),
    port: z.number(),
    authTokens: z.array(z.string()).optional(),
    tls: z.lazy(() => TLSSettingsServerSideHTTP$inboundSchema).optional(),
    maxActiveReq: z.number().default(256),
    maxRequestsPerSocket: z.number().int().default(0),
    enableProxyHeader: z.boolean().default(false),
    captureHeaders: z.boolean().default(false),
    activityLogSampleRate: z.number().default(100),
    requestTimeout: z.number().default(0),
    socketTimeout: z.number().default(0),
    keepAliveTimeout: z.number().default(5),
    enableHealthCheck: z.boolean().default(false),
    ipAllowlistRegex: z.string().default("/.*/"),
    ipDenylistRegex: z.string().default("/^$/"),
    criblAPI: z.string().default("/cribl"),
    elasticAPI: z.string().default("/elastic"),
    splunkHecAPI: z.string().default("/services/collector"),
    splunkHecAcks: z.boolean().default(false),
    metadata: z.array(z.lazy(() => MetadatumHTTP$inboundSchema)).optional(),
    authTokensExt: z.array(z.lazy(() => AuthTokensExtHTTP$inboundSchema))
      .optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputHttp$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionHTTP$Outbound> | undefined;
  pq?: PqHTTP$Outbound | undefined;
  host: string;
  port: number;
  authTokens?: Array<string> | undefined;
  tls?: TLSSettingsServerSideHTTP$Outbound | undefined;
  maxActiveReq: number;
  maxRequestsPerSocket: number;
  enableProxyHeader: boolean;
  captureHeaders: boolean;
  activityLogSampleRate: number;
  requestTimeout: number;
  socketTimeout: number;
  keepAliveTimeout: number;
  enableHealthCheck: boolean;
  ipAllowlistRegex: string;
  ipDenylistRegex: string;
  criblAPI: string;
  elasticAPI: string;
  splunkHecAPI: string;
  splunkHecAcks: boolean;
  metadata?: Array<MetadatumHTTP$Outbound> | undefined;
  authTokensExt?: Array<AuthTokensExtHTTP$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputHttp$outboundSchema: z.ZodType<
  InputHttp$Outbound,
  z.ZodTypeDef,
  InputHttp
> = z.object({
  id: z.string().optional(),
  type: TypeHTTP$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionHTTP$outboundSchema)).optional(),
  pq: z.lazy(() => PqHTTP$outboundSchema).optional(),
  host: z.string().default("0.0.0.0"),
  port: z.number(),
  authTokens: z.array(z.string()).optional(),
  tls: z.lazy(() => TLSSettingsServerSideHTTP$outboundSchema).optional(),
  maxActiveReq: z.number().default(256),
  maxRequestsPerSocket: z.number().int().default(0),
  enableProxyHeader: z.boolean().default(false),
  captureHeaders: z.boolean().default(false),
  activityLogSampleRate: z.number().default(100),
  requestTimeout: z.number().default(0),
  socketTimeout: z.number().default(0),
  keepAliveTimeout: z.number().default(5),
  enableHealthCheck: z.boolean().default(false),
  ipAllowlistRegex: z.string().default("/.*/"),
  ipDenylistRegex: z.string().default("/^$/"),
  criblAPI: z.string().default("/cribl"),
  elasticAPI: z.string().default("/elastic"),
  splunkHecAPI: z.string().default("/services/collector"),
  splunkHecAcks: z.boolean().default(false),
  metadata: z.array(z.lazy(() => MetadatumHTTP$outboundSchema)).optional(),
  authTokensExt: z.array(z.lazy(() => AuthTokensExtHTTP$outboundSchema))
    .optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputHttpToJSON(inputHttp: InputHttp): string {
  return JSON.stringify(InputHttp$outboundSchema.parse(inputHttp));
}
export function inputHttpFromJSON(
  jsonString: string,
): SafeParseResult<InputHttp, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputHttp$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputHttp' from JSON`,
  );
}

/** @internal */
export const InputTypeMsk$inboundSchema: z.ZodNativeEnum<typeof InputTypeMsk> =
  z.nativeEnum(InputTypeMsk);
/** @internal */
export const InputTypeMsk$outboundSchema: z.ZodNativeEnum<typeof InputTypeMsk> =
  InputTypeMsk$inboundSchema;

/** @internal */
export const ConnectionMsk$inboundSchema: z.ZodType<
  ConnectionMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionMsk$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionMsk$outboundSchema: z.ZodType<
  ConnectionMsk$Outbound,
  z.ZodTypeDef,
  ConnectionMsk
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionMskToJSON(connectionMsk: ConnectionMsk): string {
  return JSON.stringify(ConnectionMsk$outboundSchema.parse(connectionMsk));
}
export function connectionMskFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionMsk' from JSON`,
  );
}

/** @internal */
export const PqModeMsk$inboundSchema: z.ZodType<
  PqModeMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeMsk$outboundSchema: z.ZodType<
  PqModeMsk,
  z.ZodTypeDef,
  PqModeMsk
> = z.union([
  z.nativeEnum(PqModeMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionMsk$inboundSchema: z.ZodType<
  PqCompressionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionMsk$outboundSchema: z.ZodType<
  PqCompressionMsk,
  z.ZodTypeDef,
  PqCompressionMsk
> = z.union([
  z.nativeEnum(PqCompressionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsMsk$inboundSchema: z.ZodType<
  InputPqControlsMsk,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsMsk$Outbound = {};

/** @internal */
export const InputPqControlsMsk$outboundSchema: z.ZodType<
  InputPqControlsMsk$Outbound,
  z.ZodTypeDef,
  InputPqControlsMsk
> = z.object({});

export function inputPqControlsMskToJSON(
  inputPqControlsMsk: InputPqControlsMsk,
): string {
  return JSON.stringify(
    InputPqControlsMsk$outboundSchema.parse(inputPqControlsMsk),
  );
}
export function inputPqControlsMskFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsMsk' from JSON`,
  );
}

/** @internal */
export const PqMsk$inboundSchema: z.ZodType<PqMsk, z.ZodTypeDef, unknown> = z
  .object({
    mode: PqModeMsk$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionMsk$inboundSchema.default("none"),
    pqControls: z.lazy(() => InputPqControlsMsk$inboundSchema).optional(),
  });
/** @internal */
export type PqMsk$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsMsk$Outbound | undefined;
};

/** @internal */
export const PqMsk$outboundSchema: z.ZodType<
  PqMsk$Outbound,
  z.ZodTypeDef,
  PqMsk
> = z.object({
  mode: PqModeMsk$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionMsk$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsMsk$outboundSchema).optional(),
});

export function pqMskToJSON(pqMsk: PqMsk): string {
  return JSON.stringify(PqMsk$outboundSchema.parse(pqMsk));
}
export function pqMskFromJSON(
  jsonString: string,
): SafeParseResult<PqMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqMsk' from JSON`,
  );
}

/** @internal */
export const MetadatumMsk$inboundSchema: z.ZodType<
  MetadatumMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumMsk$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumMsk$outboundSchema: z.ZodType<
  MetadatumMsk$Outbound,
  z.ZodTypeDef,
  MetadatumMsk
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumMskToJSON(metadatumMsk: MetadatumMsk): string {
  return JSON.stringify(MetadatumMsk$outboundSchema.parse(metadatumMsk));
}
export function metadatumMskFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumMsk' from JSON`,
  );
}

/** @internal */
export const InputAuthMsk$inboundSchema: z.ZodType<
  InputAuthMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type InputAuthMsk$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const InputAuthMsk$outboundSchema: z.ZodType<
  InputAuthMsk$Outbound,
  z.ZodTypeDef,
  InputAuthMsk
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function inputAuthMskToJSON(inputAuthMsk: InputAuthMsk): string {
  return JSON.stringify(InputAuthMsk$outboundSchema.parse(inputAuthMsk));
}
export function inputAuthMskFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthMsk' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionMsk$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionMsk,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionMsk),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionMsk$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionMsk,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMinimumTLSVersionMsk
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionMsk),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionMsk$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionMsk,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionMsk),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionMsk$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionMsk,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMaximumTLSVersionMsk
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionMsk),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: InputKafkaSchemaRegistryMinimumTLSVersionMsk$inboundSchema
      .optional(),
    maxVersion: InputKafkaSchemaRegistryMaximumTLSVersionMsk$inboundSchema
      .optional(),
  });
/** @internal */
export type InputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: InputKafkaSchemaRegistryMinimumTLSVersionMsk$outboundSchema
      .optional(),
    maxVersion: InputKafkaSchemaRegistryMaximumTLSVersionMsk$outboundSchema
      .optional(),
  });

export function inputKafkaSchemaRegistryTLSSettingsClientSideMskToJSON(
  inputKafkaSchemaRegistryTLSSettingsClientSideMsk:
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema.parse(
      inputKafkaSchemaRegistryTLSSettingsClientSideMsk,
    ),
  );
}
export function inputKafkaSchemaRegistryTLSSettingsClientSideMskFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryTLSSettingsClientSideMsk,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKafkaSchemaRegistryTLSSettingsClientSideMsk' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationMsk$inboundSchema: z.ZodType<
  InputKafkaSchemaRegistryAuthenticationMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  schemaRegistryURL: z.string().default("http://localhost:8081"),
  connectionTimeout: z.number().default(30000),
  requestTimeout: z.number().default(30000),
  maxRetries: z.number().default(1),
  auth: z.lazy(() => InputAuthMsk$inboundSchema).optional(),
  tls: z.lazy(() =>
    InputKafkaSchemaRegistryTLSSettingsClientSideMsk$inboundSchema
  ).optional(),
});
/** @internal */
export type InputKafkaSchemaRegistryAuthenticationMsk$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: InputAuthMsk$Outbound | undefined;
  tls?: InputKafkaSchemaRegistryTLSSettingsClientSideMsk$Outbound | undefined;
};

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationMsk$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryAuthenticationMsk$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryAuthenticationMsk
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => InputAuthMsk$outboundSchema).optional(),
    tls: z.lazy(() =>
      InputKafkaSchemaRegistryTLSSettingsClientSideMsk$outboundSchema
    ).optional(),
  });

export function inputKafkaSchemaRegistryAuthenticationMskToJSON(
  inputKafkaSchemaRegistryAuthenticationMsk:
    InputKafkaSchemaRegistryAuthenticationMsk,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryAuthenticationMsk$outboundSchema.parse(
      inputKafkaSchemaRegistryAuthenticationMsk,
    ),
  );
}
export function inputKafkaSchemaRegistryAuthenticationMskFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryAuthenticationMsk,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryAuthenticationMsk$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKafkaSchemaRegistryAuthenticationMsk' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodMsk$inboundSchema: z.ZodType<
  InputAuthenticationMethodMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodMsk$outboundSchema: z.ZodType<
  InputAuthenticationMethodMsk,
  z.ZodTypeDef,
  InputAuthenticationMethodMsk
> = z.union([
  z.nativeEnum(InputAuthenticationMethodMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSignatureVersionMsk$inboundSchema: z.ZodType<
  InputSignatureVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSignatureVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSignatureVersionMsk$outboundSchema: z.ZodType<
  InputSignatureVersionMsk,
  z.ZodTypeDef,
  InputSignatureVersionMsk
> = z.union([
  z.nativeEnum(InputSignatureVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMinimumTLSVersionMsk$inboundSchema: z.ZodType<
  InputMinimumTLSVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionMsk$outboundSchema: z.ZodType<
  InputMinimumTLSVersionMsk,
  z.ZodTypeDef,
  InputMinimumTLSVersionMsk
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionMsk$inboundSchema: z.ZodType<
  InputMaximumTLSVersionMsk,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionMsk),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionMsk$outboundSchema: z.ZodType<
  InputMaximumTLSVersionMsk,
  z.ZodTypeDef,
  InputMaximumTLSVersionMsk
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionMsk),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputTLSSettingsClientSideMsk$inboundSchema: z.ZodType<
  InputTLSSettingsClientSideMsk,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionMsk$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionMsk$inboundSchema.optional(),
});
/** @internal */
export type InputTLSSettingsClientSideMsk$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputTLSSettingsClientSideMsk$outboundSchema: z.ZodType<
  InputTLSSettingsClientSideMsk$Outbound,
  z.ZodTypeDef,
  InputTLSSettingsClientSideMsk
> = z.object({
  disabled: z.boolean().default(false),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionMsk$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionMsk$outboundSchema.optional(),
});

export function inputTLSSettingsClientSideMskToJSON(
  inputTLSSettingsClientSideMsk: InputTLSSettingsClientSideMsk,
): string {
  return JSON.stringify(
    InputTLSSettingsClientSideMsk$outboundSchema.parse(
      inputTLSSettingsClientSideMsk,
    ),
  );
}
export function inputTLSSettingsClientSideMskFromJSON(
  jsonString: string,
): SafeParseResult<InputTLSSettingsClientSideMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputTLSSettingsClientSideMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputTLSSettingsClientSideMsk' from JSON`,
  );
}

/** @internal */
export const InputMsk$inboundSchema: z.ZodType<
  InputMsk,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeMsk$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionMsk$inboundSchema)).optional(),
    pq: z.lazy(() => PqMsk$inboundSchema).optional(),
    brokers: z.array(z.string()),
    topics: z.array(z.string()),
    groupId: z.string().default("Cribl"),
    fromBeginning: z.boolean().default(true),
    sessionTimeout: z.number().default(30000),
    rebalanceTimeout: z.number().default(60000),
    heartbeatInterval: z.number().default(3000),
    metadata: z.array(z.lazy(() => MetadatumMsk$inboundSchema)).optional(),
    kafkaSchemaRegistry: z.lazy(() =>
      InputKafkaSchemaRegistryAuthenticationMsk$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    awsAuthenticationMethod: InputAuthenticationMethodMsk$inboundSchema.default(
      "auto",
    ),
    awsSecretKey: z.string().optional(),
    region: z.string(),
    endpoint: z.string().optional(),
    signatureVersion: InputSignatureVersionMsk$inboundSchema.default("v4"),
    reuseConnections: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    enableAssumeRole: z.boolean().default(false),
    assumeRoleArn: z.string().optional(),
    assumeRoleExternalId: z.string().optional(),
    durationSeconds: z.number().default(3600),
    tls: z.lazy(() => InputTLSSettingsClientSideMsk$inboundSchema).optional(),
    autoCommitInterval: z.number().optional(),
    autoCommitThreshold: z.number().optional(),
    maxBytesPerPartition: z.number().default(1048576),
    maxBytes: z.number().default(10485760),
    maxSocketErrors: z.number().default(0),
    description: z.string().optional(),
    awsApiKey: z.string().optional(),
    awsSecret: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputMsk$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionMsk$Outbound> | undefined;
  pq?: PqMsk$Outbound | undefined;
  brokers: Array<string>;
  topics: Array<string>;
  groupId: string;
  fromBeginning: boolean;
  sessionTimeout: number;
  rebalanceTimeout: number;
  heartbeatInterval: number;
  metadata?: Array<MetadatumMsk$Outbound> | undefined;
  kafkaSchemaRegistry?:
    | InputKafkaSchemaRegistryAuthenticationMsk$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  awsAuthenticationMethod: string;
  awsSecretKey?: string | undefined;
  region: string;
  endpoint?: string | undefined;
  signatureVersion: string;
  reuseConnections: boolean;
  rejectUnauthorized: boolean;
  enableAssumeRole: boolean;
  assumeRoleArn?: string | undefined;
  assumeRoleExternalId?: string | undefined;
  durationSeconds: number;
  tls?: InputTLSSettingsClientSideMsk$Outbound | undefined;
  autoCommitInterval?: number | undefined;
  autoCommitThreshold?: number | undefined;
  maxBytesPerPartition: number;
  maxBytes: number;
  maxSocketErrors: number;
  description?: string | undefined;
  awsApiKey?: string | undefined;
  awsSecret?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputMsk$outboundSchema: z.ZodType<
  InputMsk$Outbound,
  z.ZodTypeDef,
  InputMsk
> = z.object({
  id: z.string().optional(),
  type: InputTypeMsk$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionMsk$outboundSchema)).optional(),
  pq: z.lazy(() => PqMsk$outboundSchema).optional(),
  brokers: z.array(z.string()),
  topics: z.array(z.string()),
  groupId: z.string().default("Cribl"),
  fromBeginning: z.boolean().default(true),
  sessionTimeout: z.number().default(30000),
  rebalanceTimeout: z.number().default(60000),
  heartbeatInterval: z.number().default(3000),
  metadata: z.array(z.lazy(() => MetadatumMsk$outboundSchema)).optional(),
  kafkaSchemaRegistry: z.lazy(() =>
    InputKafkaSchemaRegistryAuthenticationMsk$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  awsAuthenticationMethod: InputAuthenticationMethodMsk$outboundSchema.default(
    "auto",
  ),
  awsSecretKey: z.string().optional(),
  region: z.string(),
  endpoint: z.string().optional(),
  signatureVersion: InputSignatureVersionMsk$outboundSchema.default("v4"),
  reuseConnections: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  enableAssumeRole: z.boolean().default(false),
  assumeRoleArn: z.string().optional(),
  assumeRoleExternalId: z.string().optional(),
  durationSeconds: z.number().default(3600),
  tls: z.lazy(() => InputTLSSettingsClientSideMsk$outboundSchema).optional(),
  autoCommitInterval: z.number().optional(),
  autoCommitThreshold: z.number().optional(),
  maxBytesPerPartition: z.number().default(1048576),
  maxBytes: z.number().default(10485760),
  maxSocketErrors: z.number().default(0),
  description: z.string().optional(),
  awsApiKey: z.string().optional(),
  awsSecret: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputMskToJSON(inputMsk: InputMsk): string {
  return JSON.stringify(InputMsk$outboundSchema.parse(inputMsk));
}
export function inputMskFromJSON(
  jsonString: string,
): SafeParseResult<InputMsk, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputMsk$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputMsk' from JSON`,
  );
}

/** @internal */
export const InputTypeKafka$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeKafka
> = z.nativeEnum(InputTypeKafka);
/** @internal */
export const InputTypeKafka$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeKafka
> = InputTypeKafka$inboundSchema;

/** @internal */
export const ConnectionKafka$inboundSchema: z.ZodType<
  ConnectionKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionKafka$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionKafka$outboundSchema: z.ZodType<
  ConnectionKafka$Outbound,
  z.ZodTypeDef,
  ConnectionKafka
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionKafkaToJSON(
  connectionKafka: ConnectionKafka,
): string {
  return JSON.stringify(ConnectionKafka$outboundSchema.parse(connectionKafka));
}
export function connectionKafkaFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionKafka' from JSON`,
  );
}

/** @internal */
export const PqModeKafka$inboundSchema: z.ZodType<
  PqModeKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqModeKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqModeKafka$outboundSchema: z.ZodType<
  PqModeKafka,
  z.ZodTypeDef,
  PqModeKafka
> = z.union([
  z.nativeEnum(PqModeKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqCompressionKafka$inboundSchema: z.ZodType<
  PqCompressionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(PqCompressionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const PqCompressionKafka$outboundSchema: z.ZodType<
  PqCompressionKafka,
  z.ZodTypeDef,
  PqCompressionKafka
> = z.union([
  z.nativeEnum(PqCompressionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputPqControlsKafka$inboundSchema: z.ZodType<
  InputPqControlsKafka,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type InputPqControlsKafka$Outbound = {};

/** @internal */
export const InputPqControlsKafka$outboundSchema: z.ZodType<
  InputPqControlsKafka$Outbound,
  z.ZodTypeDef,
  InputPqControlsKafka
> = z.object({});

export function inputPqControlsKafkaToJSON(
  inputPqControlsKafka: InputPqControlsKafka,
): string {
  return JSON.stringify(
    InputPqControlsKafka$outboundSchema.parse(inputPqControlsKafka),
  );
}
export function inputPqControlsKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputPqControlsKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputPqControlsKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputPqControlsKafka' from JSON`,
  );
}

/** @internal */
export const PqKafka$inboundSchema: z.ZodType<PqKafka, z.ZodTypeDef, unknown> =
  z.object({
    mode: PqModeKafka$inboundSchema.default("always"),
    maxBufferSize: z.number().default(1000),
    commitFrequency: z.number().default(42),
    maxFileSize: z.string().default("1 MB"),
    maxSize: z.string().default("5GB"),
    path: z.string().default("$CRIBL_HOME/state/queues"),
    compress: PqCompressionKafka$inboundSchema.default("none"),
    pqControls: z.lazy(() => InputPqControlsKafka$inboundSchema).optional(),
  });
/** @internal */
export type PqKafka$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: InputPqControlsKafka$Outbound | undefined;
};

/** @internal */
export const PqKafka$outboundSchema: z.ZodType<
  PqKafka$Outbound,
  z.ZodTypeDef,
  PqKafka
> = z.object({
  mode: PqModeKafka$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: PqCompressionKafka$outboundSchema.default("none"),
  pqControls: z.lazy(() => InputPqControlsKafka$outboundSchema).optional(),
});

export function pqKafkaToJSON(pqKafka: PqKafka): string {
  return JSON.stringify(PqKafka$outboundSchema.parse(pqKafka));
}
export function pqKafkaFromJSON(
  jsonString: string,
): SafeParseResult<PqKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqKafka' from JSON`,
  );
}

/** @internal */
export const InputAuthKafka$inboundSchema: z.ZodType<
  InputAuthKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});
/** @internal */
export type InputAuthKafka$Outbound = {
  disabled: boolean;
  credentialsSecret?: string | undefined;
};

/** @internal */
export const InputAuthKafka$outboundSchema: z.ZodType<
  InputAuthKafka$Outbound,
  z.ZodTypeDef,
  InputAuthKafka
> = z.object({
  disabled: z.boolean().default(true),
  credentialsSecret: z.string().optional(),
});

export function inputAuthKafkaToJSON(inputAuthKafka: InputAuthKafka): string {
  return JSON.stringify(InputAuthKafka$outboundSchema.parse(inputAuthKafka));
}
export function inputAuthKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthKafka' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionKafka$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionKafka,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionKafka),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMinimumTLSVersionKafka$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMinimumTLSVersionKafka,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMinimumTLSVersionKafka
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMinimumTLSVersionKafka),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionKafka$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionKafka,
    z.ZodTypeDef,
    unknown
  > = z
    .union([
      z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionKafka),
      z.string().transform(catchUnrecognizedEnum),
    ]);
/** @internal */
export const InputKafkaSchemaRegistryMaximumTLSVersionKafka$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryMaximumTLSVersionKafka,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryMaximumTLSVersionKafka
  > = z.union([
    z.nativeEnum(InputKafkaSchemaRegistryMaximumTLSVersionKafka),
    z.string().and(z.custom<Unrecognized<string>>()),
  ]);

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideKafka,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: InputKafkaSchemaRegistryMinimumTLSVersionKafka$inboundSchema
      .optional(),
    maxVersion: InputKafkaSchemaRegistryMaximumTLSVersionKafka$inboundSchema
      .optional(),
  });
/** @internal */
export type InputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryTLSSettingsClientSideKafka
  > = z.object({
    disabled: z.boolean().default(true),
    rejectUnauthorized: z.boolean().default(true),
    servername: z.string().optional(),
    certificateName: z.string().optional(),
    caPath: z.string().optional(),
    privKeyPath: z.string().optional(),
    certPath: z.string().optional(),
    passphrase: z.string().optional(),
    minVersion: InputKafkaSchemaRegistryMinimumTLSVersionKafka$outboundSchema
      .optional(),
    maxVersion: InputKafkaSchemaRegistryMaximumTLSVersionKafka$outboundSchema
      .optional(),
  });

export function inputKafkaSchemaRegistryTLSSettingsClientSideKafkaToJSON(
  inputKafkaSchemaRegistryTLSSettingsClientSideKafka:
    InputKafkaSchemaRegistryTLSSettingsClientSideKafka,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema.parse(
      inputKafkaSchemaRegistryTLSSettingsClientSideKafka,
    ),
  );
}
export function inputKafkaSchemaRegistryTLSSettingsClientSideKafkaFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryTLSSettingsClientSideKafka,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKafkaSchemaRegistryTLSSettingsClientSideKafka' from JSON`,
  );
}

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationKafka$inboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryAuthenticationKafka,
    z.ZodTypeDef,
    unknown
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => InputAuthKafka$inboundSchema).optional(),
    tls: z.lazy(() =>
      InputKafkaSchemaRegistryTLSSettingsClientSideKafka$inboundSchema
    ).optional(),
  });
/** @internal */
export type InputKafkaSchemaRegistryAuthenticationKafka$Outbound = {
  disabled: boolean;
  schemaRegistryURL: string;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  auth?: InputAuthKafka$Outbound | undefined;
  tls?: InputKafkaSchemaRegistryTLSSettingsClientSideKafka$Outbound | undefined;
};

/** @internal */
export const InputKafkaSchemaRegistryAuthenticationKafka$outboundSchema:
  z.ZodType<
    InputKafkaSchemaRegistryAuthenticationKafka$Outbound,
    z.ZodTypeDef,
    InputKafkaSchemaRegistryAuthenticationKafka
  > = z.object({
    disabled: z.boolean().default(true),
    schemaRegistryURL: z.string().default("http://localhost:8081"),
    connectionTimeout: z.number().default(30000),
    requestTimeout: z.number().default(30000),
    maxRetries: z.number().default(1),
    auth: z.lazy(() => InputAuthKafka$outboundSchema).optional(),
    tls: z.lazy(() =>
      InputKafkaSchemaRegistryTLSSettingsClientSideKafka$outboundSchema
    ).optional(),
  });

export function inputKafkaSchemaRegistryAuthenticationKafkaToJSON(
  inputKafkaSchemaRegistryAuthenticationKafka:
    InputKafkaSchemaRegistryAuthenticationKafka,
): string {
  return JSON.stringify(
    InputKafkaSchemaRegistryAuthenticationKafka$outboundSchema.parse(
      inputKafkaSchemaRegistryAuthenticationKafka,
    ),
  );
}
export function inputKafkaSchemaRegistryAuthenticationKafkaFromJSON(
  jsonString: string,
): SafeParseResult<
  InputKafkaSchemaRegistryAuthenticationKafka,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputKafkaSchemaRegistryAuthenticationKafka$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputKafkaSchemaRegistryAuthenticationKafka' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationMethodKafka$inboundSchema: z.ZodType<
  InputAuthenticationMethodKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputAuthenticationMethodKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputAuthenticationMethodKafka$outboundSchema: z.ZodType<
  InputAuthenticationMethodKafka,
  z.ZodTypeDef,
  InputAuthenticationMethodKafka
> = z.union([
  z.nativeEnum(InputAuthenticationMethodKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputSASLMechanismKafka$inboundSchema: z.ZodType<
  InputSASLMechanismKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputSASLMechanismKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputSASLMechanismKafka$outboundSchema: z.ZodType<
  InputSASLMechanismKafka,
  z.ZodTypeDef,
  InputSASLMechanismKafka
> = z.union([
  z.nativeEnum(InputSASLMechanismKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputOauthParamKafka$inboundSchema: z.ZodType<
  InputOauthParamKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputOauthParamKafka$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputOauthParamKafka$outboundSchema: z.ZodType<
  InputOauthParamKafka$Outbound,
  z.ZodTypeDef,
  InputOauthParamKafka
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputOauthParamKafkaToJSON(
  inputOauthParamKafka: InputOauthParamKafka,
): string {
  return JSON.stringify(
    InputOauthParamKafka$outboundSchema.parse(inputOauthParamKafka),
  );
}
export function inputOauthParamKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputOauthParamKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputOauthParamKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputOauthParamKafka' from JSON`,
  );
}

/** @internal */
export const InputSaslExtensionKafka$inboundSchema: z.ZodType<
  InputSaslExtensionKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type InputSaslExtensionKafka$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const InputSaslExtensionKafka$outboundSchema: z.ZodType<
  InputSaslExtensionKafka$Outbound,
  z.ZodTypeDef,
  InputSaslExtensionKafka
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function inputSaslExtensionKafkaToJSON(
  inputSaslExtensionKafka: InputSaslExtensionKafka,
): string {
  return JSON.stringify(
    InputSaslExtensionKafka$outboundSchema.parse(inputSaslExtensionKafka),
  );
}
export function inputSaslExtensionKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputSaslExtensionKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputSaslExtensionKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputSaslExtensionKafka' from JSON`,
  );
}

/** @internal */
export const InputAuthenticationKafka$inboundSchema: z.ZodType<
  InputAuthenticationKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: InputAuthenticationMethodKafka$inboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  mechanism: InputSASLMechanismKafka$inboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(z.lazy(() => InputOauthParamKafka$inboundSchema))
    .optional(),
  saslExtensions: z.array(z.lazy(() => InputSaslExtensionKafka$inboundSchema))
    .optional(),
});
/** @internal */
export type InputAuthenticationKafka$Outbound = {
  disabled: boolean;
  username?: string | undefined;
  password?: string | undefined;
  authType: string;
  credentialsSecret?: string | undefined;
  mechanism: string;
  keytabLocation?: string | undefined;
  principal?: string | undefined;
  brokerServiceClass?: string | undefined;
  oauthEnabled: boolean;
  tokenUrl?: string | undefined;
  clientId?: string | undefined;
  oauthSecretType: string;
  clientTextSecret?: string | undefined;
  oauthParams?: Array<InputOauthParamKafka$Outbound> | undefined;
  saslExtensions?: Array<InputSaslExtensionKafka$Outbound> | undefined;
};

/** @internal */
export const InputAuthenticationKafka$outboundSchema: z.ZodType<
  InputAuthenticationKafka$Outbound,
  z.ZodTypeDef,
  InputAuthenticationKafka
> = z.object({
  disabled: z.boolean().default(true),
  username: z.string().optional(),
  password: z.string().optional(),
  authType: InputAuthenticationMethodKafka$outboundSchema.default("manual"),
  credentialsSecret: z.string().optional(),
  mechanism: InputSASLMechanismKafka$outboundSchema.default("plain"),
  keytabLocation: z.string().optional(),
  principal: z.string().optional(),
  brokerServiceClass: z.string().optional(),
  oauthEnabled: z.boolean().default(false),
  tokenUrl: z.string().optional(),
  clientId: z.string().optional(),
  oauthSecretType: z.string().default("secret"),
  clientTextSecret: z.string().optional(),
  oauthParams: z.array(z.lazy(() => InputOauthParamKafka$outboundSchema))
    .optional(),
  saslExtensions: z.array(z.lazy(() => InputSaslExtensionKafka$outboundSchema))
    .optional(),
});

export function inputAuthenticationKafkaToJSON(
  inputAuthenticationKafka: InputAuthenticationKafka,
): string {
  return JSON.stringify(
    InputAuthenticationKafka$outboundSchema.parse(inputAuthenticationKafka),
  );
}
export function inputAuthenticationKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputAuthenticationKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputAuthenticationKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputAuthenticationKafka' from JSON`,
  );
}

/** @internal */
export const InputMinimumTLSVersionKafka$inboundSchema: z.ZodType<
  InputMinimumTLSVersionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMinimumTLSVersionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMinimumTLSVersionKafka$outboundSchema: z.ZodType<
  InputMinimumTLSVersionKafka,
  z.ZodTypeDef,
  InputMinimumTLSVersionKafka
> = z.union([
  z.nativeEnum(InputMinimumTLSVersionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputMaximumTLSVersionKafka$inboundSchema: z.ZodType<
  InputMaximumTLSVersionKafka,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(InputMaximumTLSVersionKafka),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const InputMaximumTLSVersionKafka$outboundSchema: z.ZodType<
  InputMaximumTLSVersionKafka,
  z.ZodTypeDef,
  InputMaximumTLSVersionKafka
> = z.union([
  z.nativeEnum(InputMaximumTLSVersionKafka),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const InputTLSSettingsClientSideKafka$inboundSchema: z.ZodType<
  InputTLSSettingsClientSideKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionKafka$inboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionKafka$inboundSchema.optional(),
});
/** @internal */
export type InputTLSSettingsClientSideKafka$Outbound = {
  disabled: boolean;
  rejectUnauthorized: boolean;
  servername?: string | undefined;
  certificateName?: string | undefined;
  caPath?: string | undefined;
  privKeyPath?: string | undefined;
  certPath?: string | undefined;
  passphrase?: string | undefined;
  minVersion?: string | undefined;
  maxVersion?: string | undefined;
};

/** @internal */
export const InputTLSSettingsClientSideKafka$outboundSchema: z.ZodType<
  InputTLSSettingsClientSideKafka$Outbound,
  z.ZodTypeDef,
  InputTLSSettingsClientSideKafka
> = z.object({
  disabled: z.boolean().default(true),
  rejectUnauthorized: z.boolean().default(true),
  servername: z.string().optional(),
  certificateName: z.string().optional(),
  caPath: z.string().optional(),
  privKeyPath: z.string().optional(),
  certPath: z.string().optional(),
  passphrase: z.string().optional(),
  minVersion: InputMinimumTLSVersionKafka$outboundSchema.optional(),
  maxVersion: InputMaximumTLSVersionKafka$outboundSchema.optional(),
});

export function inputTLSSettingsClientSideKafkaToJSON(
  inputTLSSettingsClientSideKafka: InputTLSSettingsClientSideKafka,
): string {
  return JSON.stringify(
    InputTLSSettingsClientSideKafka$outboundSchema.parse(
      inputTLSSettingsClientSideKafka,
    ),
  );
}
export function inputTLSSettingsClientSideKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputTLSSettingsClientSideKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputTLSSettingsClientSideKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputTLSSettingsClientSideKafka' from JSON`,
  );
}

/** @internal */
export const MetadatumKafka$inboundSchema: z.ZodType<
  MetadatumKafka,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumKafka$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumKafka$outboundSchema: z.ZodType<
  MetadatumKafka$Outbound,
  z.ZodTypeDef,
  MetadatumKafka
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumKafkaToJSON(metadatumKafka: MetadatumKafka): string {
  return JSON.stringify(MetadatumKafka$outboundSchema.parse(metadatumKafka));
}
export function metadatumKafkaFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumKafka' from JSON`,
  );
}

/** @internal */
export const InputKafka$inboundSchema: z.ZodType<
  InputKafka,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeKafka$inboundSchema,
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionKafka$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqKafka$inboundSchema).optional(),
    brokers: z.array(z.string()),
    topics: z.array(z.string()),
    groupId: z.string().default("Cribl"),
    fromBeginning: z.boolean().default(true),
    kafkaSchemaRegistry: z.lazy(() =>
      InputKafkaSchemaRegistryAuthenticationKafka$inboundSchema
    ).optional(),
    connectionTimeout: z.number().default(10000),
    requestTimeout: z.number().default(60000),
    maxRetries: z.number().default(5),
    maxBackOff: z.number().default(30000),
    initialBackoff: z.number().default(300),
    backoffRate: z.number().default(2),
    authenticationTimeout: z.number().default(10000),
    reauthenticationThreshold: z.number().default(10000),
    sasl: z.lazy(() => InputAuthenticationKafka$inboundSchema).optional(),
    tls: z.lazy(() => InputTLSSettingsClientSideKafka$inboundSchema).optional(),
    sessionTimeout: z.number().default(30000),
    rebalanceTimeout: z.number().default(60000),
    heartbeatInterval: z.number().default(3000),
    autoCommitInterval: z.number().optional(),
    autoCommitThreshold: z.number().optional(),
    maxBytesPerPartition: z.number().default(1048576),
    maxBytes: z.number().default(10485760),
    maxSocketErrors: z.number().default(0),
    metadata: z.array(z.lazy(() => MetadatumKafka$inboundSchema)).optional(),
    description: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputKafka$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionKafka$Outbound> | undefined;
  pq?: PqKafka$Outbound | undefined;
  brokers: Array<string>;
  topics: Array<string>;
  groupId: string;
  fromBeginning: boolean;
  kafkaSchemaRegistry?:
    | InputKafkaSchemaRegistryAuthenticationKafka$Outbound
    | undefined;
  connectionTimeout: number;
  requestTimeout: number;
  maxRetries: number;
  maxBackOff: number;
  initialBackoff: number;
  backoffRate: number;
  authenticationTimeout: number;
  reauthenticationThreshold: number;
  sasl?: InputAuthenticationKafka$Outbound | undefined;
  tls?: InputTLSSettingsClientSideKafka$Outbound | undefined;
  sessionTimeout: number;
  rebalanceTimeout: number;
  heartbeatInterval: number;
  autoCommitInterval?: number | undefined;
  autoCommitThreshold?: number | undefined;
  maxBytesPerPartition: number;
  maxBytes: number;
  maxSocketErrors: number;
  metadata?: Array<MetadatumKafka$Outbound> | undefined;
  description?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputKafka$outboundSchema: z.ZodType<
  InputKafka$Outbound,
  z.ZodTypeDef,
  InputKafka
> = z.object({
  id: z.string().optional(),
  type: InputTypeKafka$outboundSchema,
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionKafka$outboundSchema)).optional(),
  pq: z.lazy(() => PqKafka$outboundSchema).optional(),
  brokers: z.array(z.string()),
  topics: z.array(z.string()),
  groupId: z.string().default("Cribl"),
  fromBeginning: z.boolean().default(true),
  kafkaSchemaRegistry: z.lazy(() =>
    InputKafkaSchemaRegistryAuthenticationKafka$outboundSchema
  ).optional(),
  connectionTimeout: z.number().default(10000),
  requestTimeout: z.number().default(60000),
  maxRetries: z.number().default(5),
  maxBackOff: z.number().default(30000),
  initialBackoff: z.number().default(300),
  backoffRate: z.number().default(2),
  authenticationTimeout: z.number().default(10000),
  reauthenticationThreshold: z.number().default(10000),
  sasl: z.lazy(() => InputAuthenticationKafka$outboundSchema).optional(),
  tls: z.lazy(() => InputTLSSettingsClientSideKafka$outboundSchema).optional(),
  sessionTimeout: z.number().default(30000),
  rebalanceTimeout: z.number().default(60000),
  heartbeatInterval: z.number().default(3000),
  autoCommitInterval: z.number().optional(),
  autoCommitThreshold: z.number().optional(),
  maxBytesPerPartition: z.number().default(1048576),
  maxBytes: z.number().default(10485760),
  maxSocketErrors: z.number().default(0),
  metadata: z.array(z.lazy(() => MetadatumKafka$outboundSchema)).optional(),
  description: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputKafkaToJSON(inputKafka: InputKafka): string {
  return JSON.stringify(InputKafka$outboundSchema.parse(inputKafka));
}
export function inputKafkaFromJSON(
  jsonString: string,
): SafeParseResult<InputKafka, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputKafka$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputKafka' from JSON`,
  );
}

/** @internal */
export const InputTypeCollection$inboundSchema: z.ZodNativeEnum<
  typeof InputTypeCollection
> = z.nativeEnum(InputTypeCollection);
/** @internal */
export const InputTypeCollection$outboundSchema: z.ZodNativeEnum<
  typeof InputTypeCollection
> = InputTypeCollection$inboundSchema;

/** @internal */
export const ConnectionCollection$inboundSchema: z.ZodType<
  ConnectionCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});
/** @internal */
export type ConnectionCollection$Outbound = {
  pipeline?: string | undefined;
  output: string;
};

/** @internal */
export const ConnectionCollection$outboundSchema: z.ZodType<
  ConnectionCollection$Outbound,
  z.ZodTypeDef,
  ConnectionCollection
> = z.object({
  pipeline: z.string().optional(),
  output: z.string(),
});

export function connectionCollectionToJSON(
  connectionCollection: ConnectionCollection,
): string {
  return JSON.stringify(
    ConnectionCollection$outboundSchema.parse(connectionCollection),
  );
}
export function connectionCollectionFromJSON(
  jsonString: string,
): SafeParseResult<ConnectionCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => ConnectionCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'ConnectionCollection' from JSON`,
  );
}

/** @internal */
export const ModeCollection$inboundSchema: z.ZodType<
  ModeCollection,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(ModeCollection),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const ModeCollection$outboundSchema: z.ZodType<
  ModeCollection,
  z.ZodTypeDef,
  ModeCollection
> = z.union([
  z.nativeEnum(ModeCollection),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const CompressionCollection$inboundSchema: z.ZodType<
  CompressionCollection,
  z.ZodTypeDef,
  unknown
> = z
  .union([
    z.nativeEnum(CompressionCollection),
    z.string().transform(catchUnrecognizedEnum),
  ]);
/** @internal */
export const CompressionCollection$outboundSchema: z.ZodType<
  CompressionCollection,
  z.ZodTypeDef,
  CompressionCollection
> = z.union([
  z.nativeEnum(CompressionCollection),
  z.string().and(z.custom<Unrecognized<string>>()),
]);

/** @internal */
export const PqControlsCollection$inboundSchema: z.ZodType<
  PqControlsCollection,
  z.ZodTypeDef,
  unknown
> = z.object({});
/** @internal */
export type PqControlsCollection$Outbound = {};

/** @internal */
export const PqControlsCollection$outboundSchema: z.ZodType<
  PqControlsCollection$Outbound,
  z.ZodTypeDef,
  PqControlsCollection
> = z.object({});

export function pqControlsCollectionToJSON(
  pqControlsCollection: PqControlsCollection,
): string {
  return JSON.stringify(
    PqControlsCollection$outboundSchema.parse(pqControlsCollection),
  );
}
export function pqControlsCollectionFromJSON(
  jsonString: string,
): SafeParseResult<PqControlsCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqControlsCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqControlsCollection' from JSON`,
  );
}

/** @internal */
export const PqCollection$inboundSchema: z.ZodType<
  PqCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  mode: ModeCollection$inboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCollection$inboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCollection$inboundSchema).optional(),
});
/** @internal */
export type PqCollection$Outbound = {
  mode: string;
  maxBufferSize: number;
  commitFrequency: number;
  maxFileSize: string;
  maxSize: string;
  path: string;
  compress: string;
  pqControls?: PqControlsCollection$Outbound | undefined;
};

/** @internal */
export const PqCollection$outboundSchema: z.ZodType<
  PqCollection$Outbound,
  z.ZodTypeDef,
  PqCollection
> = z.object({
  mode: ModeCollection$outboundSchema.default("always"),
  maxBufferSize: z.number().default(1000),
  commitFrequency: z.number().default(42),
  maxFileSize: z.string().default("1 MB"),
  maxSize: z.string().default("5GB"),
  path: z.string().default("$CRIBL_HOME/state/queues"),
  compress: CompressionCollection$outboundSchema.default("none"),
  pqControls: z.lazy(() => PqControlsCollection$outboundSchema).optional(),
});

export function pqCollectionToJSON(pqCollection: PqCollection): string {
  return JSON.stringify(PqCollection$outboundSchema.parse(pqCollection));
}
export function pqCollectionFromJSON(
  jsonString: string,
): SafeParseResult<PqCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PqCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PqCollection' from JSON`,
  );
}

/** @internal */
export const PreprocessCollection$inboundSchema: z.ZodType<
  PreprocessCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});
/** @internal */
export type PreprocessCollection$Outbound = {
  disabled: boolean;
  command?: string | undefined;
  args?: Array<string> | undefined;
};

/** @internal */
export const PreprocessCollection$outboundSchema: z.ZodType<
  PreprocessCollection$Outbound,
  z.ZodTypeDef,
  PreprocessCollection
> = z.object({
  disabled: z.boolean().default(true),
  command: z.string().optional(),
  args: z.array(z.string()).optional(),
});

export function preprocessCollectionToJSON(
  preprocessCollection: PreprocessCollection,
): string {
  return JSON.stringify(
    PreprocessCollection$outboundSchema.parse(preprocessCollection),
  );
}
export function preprocessCollectionFromJSON(
  jsonString: string,
): SafeParseResult<PreprocessCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => PreprocessCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'PreprocessCollection' from JSON`,
  );
}

/** @internal */
export const MetadatumCollection$inboundSchema: z.ZodType<
  MetadatumCollection,
  z.ZodTypeDef,
  unknown
> = z.object({
  name: z.string(),
  value: z.string(),
});
/** @internal */
export type MetadatumCollection$Outbound = {
  name: string;
  value: string;
};

/** @internal */
export const MetadatumCollection$outboundSchema: z.ZodType<
  MetadatumCollection$Outbound,
  z.ZodTypeDef,
  MetadatumCollection
> = z.object({
  name: z.string(),
  value: z.string(),
});

export function metadatumCollectionToJSON(
  metadatumCollection: MetadatumCollection,
): string {
  return JSON.stringify(
    MetadatumCollection$outboundSchema.parse(metadatumCollection),
  );
}
export function metadatumCollectionFromJSON(
  jsonString: string,
): SafeParseResult<MetadatumCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => MetadatumCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'MetadatumCollection' from JSON`,
  );
}

/** @internal */
export const InputCollection$inboundSchema: z.ZodType<
  InputCollection,
  z.ZodTypeDef,
  unknown
> = collectExtraKeys$(
  z.object({
    id: z.string().optional(),
    type: InputTypeCollection$inboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(z.lazy(() => ConnectionCollection$inboundSchema))
      .optional(),
    pq: z.lazy(() => PqCollection$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: z.lazy(() => PreprocessCollection$inboundSchema).optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(z.lazy(() => MetadatumCollection$inboundSchema))
      .optional(),
    output: z.string().optional(),
  }).catchall(z.any()),
  "additionalProperties",
  true,
);
/** @internal */
export type InputCollection$Outbound = {
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionCollection$Outbound> | undefined;
  pq?: PqCollection$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessCollection$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<MetadatumCollection$Outbound> | undefined;
  output?: string | undefined;
  [additionalProperties: string]: unknown;
};

/** @internal */
export const InputCollection$outboundSchema: z.ZodType<
  InputCollection$Outbound,
  z.ZodTypeDef,
  InputCollection
> = z.object({
  id: z.string().optional(),
  type: InputTypeCollection$outboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(z.lazy(() => ConnectionCollection$outboundSchema))
    .optional(),
  pq: z.lazy(() => PqCollection$outboundSchema).optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: z.lazy(() => PreprocessCollection$outboundSchema).optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(z.lazy(() => MetadatumCollection$outboundSchema))
    .optional(),
  output: z.string().optional(),
  additionalProperties: z.record(z.any()).optional(),
}).transform((v) => {
  return {
    ...v.additionalProperties,
    ...remap$(v, {
      additionalProperties: null,
    }),
  };
});

export function inputCollectionToJSON(
  inputCollection: InputCollection,
): string {
  return JSON.stringify(InputCollection$outboundSchema.parse(inputCollection));
}
export function inputCollectionFromJSON(
  jsonString: string,
): SafeParseResult<InputCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollection' from JSON`,
  );
}

/** @internal */
export const Input$inboundSchema: z.ZodType<Input, z.ZodTypeDef, unknown> = z
  .union([
    z.lazy(() => InputMsk$inboundSchema).and(
      z.object({ type: z.literal("msk") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputWiz$inboundSchema).and(
      z.object({ type: z.literal("wiz") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputKafka$inboundSchema).and(
      z.object({ type: z.literal("kafka") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputConfluentCloud$inboundSchema).and(
      z.object({ type: z.literal("confluent_cloud") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputOffice365Mgmt$inboundSchema).and(
      z.object({ type: z.literal("office365_mgmt") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputOffice365Service$inboundSchema).and(
      z.object({ type: z.literal("office365_service") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputEventhub$inboundSchema).and(
      z.object({ type: z.literal("eventhub") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputKinesis$inboundSchema).and(
      z.object({ type: z.literal("kinesis") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSqs$inboundSchema).and(
      z.object({ type: z.literal("sqs") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputJournalFiles$inboundSchema).and(
      z.object({ type: z.literal("journal_files") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCloudflareHec$inboundSchema).and(
      z.object({ type: z.literal("cloudflare_hec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputHttp$inboundSchema).and(
      z.object({ type: z.literal("http") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSplunk$inboundSchema).and(
      z.object({ type: z.literal("splunk") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSplunkSearch$inboundSchema).and(
      z.object({ type: z.literal("splunk_search") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputInputSplunkHec$inboundSchema).and(
      z.object({ type: z.literal("splunk_hec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputAzureBlob$inboundSchema).and(
      z.object({ type: z.literal("azure_blob") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputElastic$inboundSchema).and(
      z.object({ type: z.literal("elastic") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputLoki$inboundSchema).and(
      z.object({ type: z.literal("loki") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputPrometheusRw$inboundSchema).and(
      z.object({ type: z.literal("prometheus_rw") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputExec$inboundSchema).and(
      z.object({ type: z.literal("exec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputFirehose$inboundSchema).and(
      z.object({ type: z.literal("firehose") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputGooglePubsub$inboundSchema).and(
      z.object({ type: z.literal("google_pubsub") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCriblTcp$inboundSchema).and(
      z.object({ type: z.literal("cribl_tcp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCriblHttp$inboundSchema).and(
      z.object({ type: z.literal("cribl_http") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCriblLakeHttp$inboundSchema).and(
      z.object({ type: z.literal("cribl_lake_http") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputTcpjson$inboundSchema).and(
      z.object({ type: z.literal("tcpjson") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCrowdstrike$inboundSchema).and(
      z.object({ type: z.literal("crowdstrike") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputDatadogAgent$inboundSchema).and(
      z.object({ type: z.literal("datadog_agent") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputDatagen$inboundSchema).and(
      z.object({ type: z.literal("datagen") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputHttpRaw$inboundSchema).and(
      z.object({ type: z.literal("http_raw") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputS3$inboundSchema).and(
      z.object({ type: z.literal("s3") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputS3Inventory$inboundSchema).and(
      z.object({ type: z.literal("s3_inventory") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputTcp$inboundSchema).and(
      z.object({ type: z.literal("tcp") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputWef$inboundSchema).and(
      z.object({ type: z.literal("wef") }).transform((v) => ({ type: v.type })),
    ),
    z.lazy(() => InputWinEventLogs$inboundSchema).and(
      z.object({ type: z.literal("win_event_logs") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputRawUdp$inboundSchema).and(
      z.object({ type: z.literal("raw_udp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputWizWebhook$inboundSchema).and(
      z.object({ type: z.literal("wiz_webhook") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSecurityLake$inboundSchema).and(
      z.object({ type: z.literal("security_lake") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputZscalerHec$inboundSchema).and(
      z.object({ type: z.literal("zscaler_hec") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputPrometheus$inboundSchema).and(
      z.object({ type: z.literal("prometheus") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputEdgePrometheus$inboundSchema).and(
      z.object({ type: z.literal("edge_prometheus") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputOffice365MsgTrace$inboundSchema).and(
      z.object({ type: z.literal("office365_msg_trace") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCribl$inboundSchema).and(
      z.object({ type: z.literal("cribl") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSystemMetrics$inboundSchema).and(
      z.object({ type: z.literal("system_metrics") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSystemState$inboundSchema).and(
      z.object({ type: z.literal("system_state") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputKubeMetrics$inboundSchema).and(
      z.object({ type: z.literal("kube_metrics") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputKubeLogs$inboundSchema).and(
      z.object({ type: z.literal("kube_logs") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputKubeEvents$inboundSchema).and(
      z.object({ type: z.literal("kube_events") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputWindowsMetrics$inboundSchema).and(
      z.object({ type: z.literal("windows_metrics") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCriblmetrics$inboundSchema).and(
      z.object({ type: z.literal("criblmetrics") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputMetrics$inboundSchema).and(
      z.object({ type: z.literal("metrics") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputSnmp$inboundSchema).and(
      z.object({ type: z.literal("snmp") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputOpenTelemetry$inboundSchema).and(
      z.object({ type: z.literal("open_telemetry") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputModelDrivenTelemetry$inboundSchema).and(
      z.object({ type: z.literal("model_driven_telemetry") }).transform((
        v,
      ) => ({ type: v.type })),
    ),
    z.lazy(() => InputFile$inboundSchema).and(
      z.object({ type: z.literal("file") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputAppscope$inboundSchema).and(
      z.object({ type: z.literal("appscope") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputNetflow$inboundSchema).and(
      z.object({ type: z.literal("netflow") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.lazy(() => InputCollection$inboundSchema).and(
      z.object({ type: z.literal("collection") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.union([
      z.lazy(() => InputGrafanaGrafana1$inboundSchema),
      z.lazy(() => InputGrafanaGrafana2$inboundSchema),
    ]).and(
      z.object({ type: z.literal("grafana") }).transform((v) => ({
        type: v.type,
      })),
    ),
    z.union([
      z.lazy(() => InputSyslogSyslog1$inboundSchema),
      z.lazy(() => InputSyslogSyslog2$inboundSchema),
    ]).and(
      z.object({ type: z.literal("syslog") }).transform((v) => ({
        type: v.type,
      })),
    ),
  ]);
/** @internal */
export type Input$Outbound =
  | (InputMsk$Outbound & { type: "msk" })
  | (InputWiz$Outbound & { type: "wiz" })
  | (InputKafka$Outbound & { type: "kafka" })
  | (InputConfluentCloud$Outbound & { type: "confluent_cloud" })
  | (InputOffice365Mgmt$Outbound & { type: "office365_mgmt" })
  | (InputOffice365Service$Outbound & { type: "office365_service" })
  | (InputEventhub$Outbound & { type: "eventhub" })
  | (InputKinesis$Outbound & { type: "kinesis" })
  | (InputSqs$Outbound & { type: "sqs" })
  | (InputJournalFiles$Outbound & { type: "journal_files" })
  | (InputCloudflareHec$Outbound & { type: "cloudflare_hec" })
  | (InputHttp$Outbound & { type: "http" })
  | (InputSplunk$Outbound & { type: "splunk" })
  | (InputSplunkSearch$Outbound & { type: "splunk_search" })
  | (InputInputSplunkHec$Outbound & { type: "splunk_hec" })
  | (InputAzureBlob$Outbound & { type: "azure_blob" })
  | (InputElastic$Outbound & { type: "elastic" })
  | (InputLoki$Outbound & { type: "loki" })
  | (InputPrometheusRw$Outbound & { type: "prometheus_rw" })
  | (InputExec$Outbound & { type: "exec" })
  | (InputFirehose$Outbound & { type: "firehose" })
  | (InputGooglePubsub$Outbound & { type: "google_pubsub" })
  | (InputCriblTcp$Outbound & { type: "cribl_tcp" })
  | (InputCriblHttp$Outbound & { type: "cribl_http" })
  | (InputCriblLakeHttp$Outbound & { type: "cribl_lake_http" })
  | (InputTcpjson$Outbound & { type: "tcpjson" })
  | (InputCrowdstrike$Outbound & { type: "crowdstrike" })
  | (InputDatadogAgent$Outbound & { type: "datadog_agent" })
  | (InputDatagen$Outbound & { type: "datagen" })
  | (InputHttpRaw$Outbound & { type: "http_raw" })
  | (InputS3$Outbound & { type: "s3" })
  | (InputS3Inventory$Outbound & { type: "s3_inventory" })
  | (InputTcp$Outbound & { type: "tcp" })
  | (InputWef$Outbound & { type: "wef" })
  | (InputWinEventLogs$Outbound & { type: "win_event_logs" })
  | (InputRawUdp$Outbound & { type: "raw_udp" })
  | (InputWizWebhook$Outbound & { type: "wiz_webhook" })
  | (InputSecurityLake$Outbound & { type: "security_lake" })
  | (InputZscalerHec$Outbound & { type: "zscaler_hec" })
  | (InputPrometheus$Outbound & { type: "prometheus" })
  | (InputEdgePrometheus$Outbound & { type: "edge_prometheus" })
  | (InputOffice365MsgTrace$Outbound & { type: "office365_msg_trace" })
  | (InputCribl$Outbound & { type: "cribl" })
  | (InputSystemMetrics$Outbound & { type: "system_metrics" })
  | (InputSystemState$Outbound & { type: "system_state" })
  | (InputKubeMetrics$Outbound & { type: "kube_metrics" })
  | (InputKubeLogs$Outbound & { type: "kube_logs" })
  | (InputKubeEvents$Outbound & { type: "kube_events" })
  | (InputWindowsMetrics$Outbound & { type: "windows_metrics" })
  | (InputCriblmetrics$Outbound & { type: "criblmetrics" })
  | (InputMetrics$Outbound & { type: "metrics" })
  | (InputSnmp$Outbound & { type: "snmp" })
  | (InputOpenTelemetry$Outbound & { type: "open_telemetry" })
  | (InputModelDrivenTelemetry$Outbound & { type: "model_driven_telemetry" })
  | (InputFile$Outbound & { type: "file" })
  | (InputAppscope$Outbound & { type: "appscope" })
  | (InputNetflow$Outbound & { type: "netflow" })
  | (InputCollection$Outbound & { type: "collection" })
  | (
    | InputGrafanaGrafana1$Outbound
    | InputGrafanaGrafana2$Outbound & { type: "grafana" }
  )
  | (
    | InputSyslogSyslog1$Outbound
    | InputSyslogSyslog2$Outbound & { type: "syslog" }
  );

/** @internal */
export const Input$outboundSchema: z.ZodType<
  Input$Outbound,
  z.ZodTypeDef,
  Input
> = z.union([
  z.lazy(() => InputMsk$outboundSchema).and(
    z.object({ type: z.literal("msk") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputWiz$outboundSchema).and(
    z.object({ type: z.literal("wiz") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputKafka$outboundSchema).and(
    z.object({ type: z.literal("kafka") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputConfluentCloud$outboundSchema).and(
    z.object({ type: z.literal("confluent_cloud") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputOffice365Mgmt$outboundSchema).and(
    z.object({ type: z.literal("office365_mgmt") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputOffice365Service$outboundSchema).and(
    z.object({ type: z.literal("office365_service") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputEventhub$outboundSchema).and(
    z.object({ type: z.literal("eventhub") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputKinesis$outboundSchema).and(
    z.object({ type: z.literal("kinesis") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputSqs$outboundSchema).and(
    z.object({ type: z.literal("sqs") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputJournalFiles$outboundSchema).and(
    z.object({ type: z.literal("journal_files") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCloudflareHec$outboundSchema).and(
    z.object({ type: z.literal("cloudflare_hec") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputHttp$outboundSchema).and(
    z.object({ type: z.literal("http") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputSplunk$outboundSchema).and(
    z.object({ type: z.literal("splunk") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputSplunkSearch$outboundSchema).and(
    z.object({ type: z.literal("splunk_search") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputInputSplunkHec$outboundSchema).and(
    z.object({ type: z.literal("splunk_hec") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputAzureBlob$outboundSchema).and(
    z.object({ type: z.literal("azure_blob") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputElastic$outboundSchema).and(
    z.object({ type: z.literal("elastic") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputLoki$outboundSchema).and(
    z.object({ type: z.literal("loki") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputPrometheusRw$outboundSchema).and(
    z.object({ type: z.literal("prometheus_rw") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputExec$outboundSchema).and(
    z.object({ type: z.literal("exec") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputFirehose$outboundSchema).and(
    z.object({ type: z.literal("firehose") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputGooglePubsub$outboundSchema).and(
    z.object({ type: z.literal("google_pubsub") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCriblTcp$outboundSchema).and(
    z.object({ type: z.literal("cribl_tcp") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCriblHttp$outboundSchema).and(
    z.object({ type: z.literal("cribl_http") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCriblLakeHttp$outboundSchema).and(
    z.object({ type: z.literal("cribl_lake_http") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputTcpjson$outboundSchema).and(
    z.object({ type: z.literal("tcpjson") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCrowdstrike$outboundSchema).and(
    z.object({ type: z.literal("crowdstrike") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputDatadogAgent$outboundSchema).and(
    z.object({ type: z.literal("datadog_agent") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputDatagen$outboundSchema).and(
    z.object({ type: z.literal("datagen") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputHttpRaw$outboundSchema).and(
    z.object({ type: z.literal("http_raw") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputS3$outboundSchema).and(
    z.object({ type: z.literal("s3") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputS3Inventory$outboundSchema).and(
    z.object({ type: z.literal("s3_inventory") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputTcp$outboundSchema).and(
    z.object({ type: z.literal("tcp") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputWef$outboundSchema).and(
    z.object({ type: z.literal("wef") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputWinEventLogs$outboundSchema).and(
    z.object({ type: z.literal("win_event_logs") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputRawUdp$outboundSchema).and(
    z.object({ type: z.literal("raw_udp") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputWizWebhook$outboundSchema).and(
    z.object({ type: z.literal("wiz_webhook") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputSecurityLake$outboundSchema).and(
    z.object({ type: z.literal("security_lake") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputZscalerHec$outboundSchema).and(
    z.object({ type: z.literal("zscaler_hec") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputPrometheus$outboundSchema).and(
    z.object({ type: z.literal("prometheus") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputEdgePrometheus$outboundSchema).and(
    z.object({ type: z.literal("edge_prometheus") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputOffice365MsgTrace$outboundSchema).and(
    z.object({ type: z.literal("office365_msg_trace") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCribl$outboundSchema).and(
    z.object({ type: z.literal("cribl") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputSystemMetrics$outboundSchema).and(
    z.object({ type: z.literal("system_metrics") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputSystemState$outboundSchema).and(
    z.object({ type: z.literal("system_state") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputKubeMetrics$outboundSchema).and(
    z.object({ type: z.literal("kube_metrics") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputKubeLogs$outboundSchema).and(
    z.object({ type: z.literal("kube_logs") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputKubeEvents$outboundSchema).and(
    z.object({ type: z.literal("kube_events") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputWindowsMetrics$outboundSchema).and(
    z.object({ type: z.literal("windows_metrics") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCriblmetrics$outboundSchema).and(
    z.object({ type: z.literal("criblmetrics") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputMetrics$outboundSchema).and(
    z.object({ type: z.literal("metrics") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputSnmp$outboundSchema).and(
    z.object({ type: z.literal("snmp") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputOpenTelemetry$outboundSchema).and(
    z.object({ type: z.literal("open_telemetry") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputModelDrivenTelemetry$outboundSchema).and(
    z.object({ type: z.literal("model_driven_telemetry") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputFile$outboundSchema).and(
    z.object({ type: z.literal("file") }).transform((v) => ({ type: v.type })),
  ),
  z.lazy(() => InputAppscope$outboundSchema).and(
    z.object({ type: z.literal("appscope") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputNetflow$outboundSchema).and(
    z.object({ type: z.literal("netflow") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.lazy(() => InputCollection$outboundSchema).and(
    z.object({ type: z.literal("collection") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.union([
    z.lazy(() => InputGrafanaGrafana1$outboundSchema),
    z.lazy(() => InputGrafanaGrafana2$outboundSchema),
  ]).and(
    z.object({ type: z.literal("grafana") }).transform((v) => ({
      type: v.type,
    })),
  ),
  z.union([
    z.lazy(() => InputSyslogSyslog1$outboundSchema),
    z.lazy(() => InputSyslogSyslog2$outboundSchema),
  ]).and(
    z.object({ type: z.literal("syslog") }).transform((v) => ({
      type: v.type,
    })),
  ),
]);

export function inputToJSON(input: Input): string {
  return JSON.stringify(Input$outboundSchema.parse(input));
}
export function inputFromJSON(
  jsonString: string,
): SafeParseResult<Input, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => Input$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'Input' from JSON`,
  );
}
