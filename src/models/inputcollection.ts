/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import {
  ConnectionsType,
  ConnectionsType$inboundSchema,
  ConnectionsType$Outbound,
  ConnectionsType$outboundSchema,
} from "./connectionstype.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  Metadata1Type,
  Metadata1Type$inboundSchema,
  Metadata1Type$Outbound,
  Metadata1Type$outboundSchema,
} from "./metadata1type.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";
import {
  PreprocessType,
  PreprocessType$inboundSchema,
  PreprocessType$Outbound,
  PreprocessType$outboundSchema,
} from "./preprocesstype.js";

export const InputCollectionType4 = {
  Collection: "collection",
} as const;
export type InputCollectionType4 = ClosedEnum<typeof InputCollectionType4>;

export type InputCollectionCollection4 = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType4 | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq: PqType;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessType | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export const InputCollectionType3 = {
  Collection: "collection",
} as const;
export type InputCollectionType3 = ClosedEnum<typeof InputCollectionType3>;

export type InputCollectionCollection3 = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType3 | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq?: PqType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessType | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export const InputCollectionType2 = {
  Collection: "collection",
} as const;
export type InputCollectionType2 = ClosedEnum<typeof InputCollectionType2>;

export type InputCollectionCollection2 = {
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType2 | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline: string;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq?: PqType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessType | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  /**
   * Destination to send results to
   */
  output: string;
};

export const InputCollectionType1 = {
  Collection: "collection",
} as const;
export type InputCollectionType1 = ClosedEnum<typeof InputCollectionType1>;

export type InputCollectionCollection1 = {
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType1 | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline: string;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ConnectionsType> | undefined;
  pq?: PqType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessType | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<Metadata1Type> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export type InputCollection =
  | InputCollectionCollection2
  | InputCollectionCollection1
  | InputCollectionCollection4
  | InputCollectionCollection3;

/** @internal */
export const InputCollectionType4$inboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType4
> = z.nativeEnum(InputCollectionType4);
/** @internal */
export const InputCollectionType4$outboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType4
> = InputCollectionType4$inboundSchema;

/** @internal */
export const InputCollectionCollection4$inboundSchema: z.ZodType<
  InputCollectionCollection4,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputCollectionType4$inboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema,
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$inboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  output: z.string().optional(),
});
/** @internal */
export type InputCollectionCollection4$Outbound = {
  pqEnabled: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq: PqType$Outbound;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessType$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  output?: string | undefined;
};

/** @internal */
export const InputCollectionCollection4$outboundSchema: z.ZodType<
  InputCollectionCollection4$Outbound,
  z.ZodTypeDef,
  InputCollectionCollection4
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputCollectionType4$outboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema,
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$outboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  output: z.string().optional(),
});

export function inputCollectionCollection4ToJSON(
  inputCollectionCollection4: InputCollectionCollection4,
): string {
  return JSON.stringify(
    InputCollectionCollection4$outboundSchema.parse(inputCollectionCollection4),
  );
}
export function inputCollectionCollection4FromJSON(
  jsonString: string,
): SafeParseResult<InputCollectionCollection4, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollectionCollection4$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionCollection4' from JSON`,
  );
}

/** @internal */
export const InputCollectionType3$inboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType3
> = z.nativeEnum(InputCollectionType3);
/** @internal */
export const InputCollectionType3$outboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType3
> = InputCollectionType3$inboundSchema;

/** @internal */
export const InputCollectionCollection3$inboundSchema: z.ZodType<
  InputCollectionCollection3,
  z.ZodTypeDef,
  unknown
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputCollectionType3$inboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$inboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  output: z.string().optional(),
});
/** @internal */
export type InputCollectionCollection3$Outbound = {
  pqEnabled: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessType$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  output?: string | undefined;
};

/** @internal */
export const InputCollectionCollection3$outboundSchema: z.ZodType<
  InputCollectionCollection3$Outbound,
  z.ZodTypeDef,
  InputCollectionCollection3
> = z.object({
  pqEnabled: z.boolean().default(false),
  id: z.string().optional(),
  type: InputCollectionType3$outboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string().optional(),
  sendToRoutes: z.boolean().default(true),
  environment: z.string().optional(),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$outboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  output: z.string().optional(),
});

export function inputCollectionCollection3ToJSON(
  inputCollectionCollection3: InputCollectionCollection3,
): string {
  return JSON.stringify(
    InputCollectionCollection3$outboundSchema.parse(inputCollectionCollection3),
  );
}
export function inputCollectionCollection3FromJSON(
  jsonString: string,
): SafeParseResult<InputCollectionCollection3, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollectionCollection3$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionCollection3' from JSON`,
  );
}

/** @internal */
export const InputCollectionType2$inboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType2
> = z.nativeEnum(InputCollectionType2);
/** @internal */
export const InputCollectionType2$outboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType2
> = InputCollectionType2$inboundSchema;

/** @internal */
export const InputCollectionCollection2$inboundSchema: z.ZodType<
  InputCollectionCollection2,
  z.ZodTypeDef,
  unknown
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputCollectionType2$inboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$inboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  output: z.string(),
});
/** @internal */
export type InputCollectionCollection2$Outbound = {
  sendToRoutes: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline: string;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessType$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  output: string;
};

/** @internal */
export const InputCollectionCollection2$outboundSchema: z.ZodType<
  InputCollectionCollection2$Outbound,
  z.ZodTypeDef,
  InputCollectionCollection2
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputCollectionType2$outboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$outboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  output: z.string(),
});

export function inputCollectionCollection2ToJSON(
  inputCollectionCollection2: InputCollectionCollection2,
): string {
  return JSON.stringify(
    InputCollectionCollection2$outboundSchema.parse(inputCollectionCollection2),
  );
}
export function inputCollectionCollection2FromJSON(
  jsonString: string,
): SafeParseResult<InputCollectionCollection2, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollectionCollection2$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionCollection2' from JSON`,
  );
}

/** @internal */
export const InputCollectionType1$inboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType1
> = z.nativeEnum(InputCollectionType1);
/** @internal */
export const InputCollectionType1$outboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType1
> = InputCollectionType1$inboundSchema;

/** @internal */
export const InputCollectionCollection1$inboundSchema: z.ZodType<
  InputCollectionCollection1,
  z.ZodTypeDef,
  unknown
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputCollectionType1$inboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$inboundSchema).optional(),
  pq: PqType$inboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$inboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$inboundSchema).optional(),
  output: z.string().optional(),
});
/** @internal */
export type InputCollectionCollection1$Outbound = {
  sendToRoutes: boolean;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline: string;
  environment?: string | undefined;
  pqEnabled: boolean;
  streamtags?: Array<string> | undefined;
  connections?: Array<ConnectionsType$Outbound> | undefined;
  pq?: PqType$Outbound | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessType$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<Metadata1Type$Outbound> | undefined;
  output?: string | undefined;
};

/** @internal */
export const InputCollectionCollection1$outboundSchema: z.ZodType<
  InputCollectionCollection1$Outbound,
  z.ZodTypeDef,
  InputCollectionCollection1
> = z.object({
  sendToRoutes: z.boolean().default(true),
  id: z.string().optional(),
  type: InputCollectionType1$outboundSchema.default("collection"),
  disabled: z.boolean().default(false),
  pipeline: z.string(),
  environment: z.string().optional(),
  pqEnabled: z.boolean().default(false),
  streamtags: z.array(z.string()).optional(),
  connections: z.array(ConnectionsType$outboundSchema).optional(),
  pq: PqType$outboundSchema.optional(),
  breakerRulesets: z.array(z.string()).optional(),
  staleChannelFlushMs: z.number().default(10000),
  preprocess: PreprocessType$outboundSchema.optional(),
  throttleRatePerSec: z.string().default("0"),
  metadata: z.array(Metadata1Type$outboundSchema).optional(),
  output: z.string().optional(),
});

export function inputCollectionCollection1ToJSON(
  inputCollectionCollection1: InputCollectionCollection1,
): string {
  return JSON.stringify(
    InputCollectionCollection1$outboundSchema.parse(inputCollectionCollection1),
  );
}
export function inputCollectionCollection1FromJSON(
  jsonString: string,
): SafeParseResult<InputCollectionCollection1, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollectionCollection1$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionCollection1' from JSON`,
  );
}

/** @internal */
export const InputCollection$inboundSchema: z.ZodType<
  InputCollection,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() => InputCollectionCollection2$inboundSchema),
  z.lazy(() => InputCollectionCollection1$inboundSchema),
  z.lazy(() => InputCollectionCollection4$inboundSchema),
  z.lazy(() => InputCollectionCollection3$inboundSchema),
]);
/** @internal */
export type InputCollection$Outbound =
  | InputCollectionCollection2$Outbound
  | InputCollectionCollection1$Outbound
  | InputCollectionCollection4$Outbound
  | InputCollectionCollection3$Outbound;

/** @internal */
export const InputCollection$outboundSchema: z.ZodType<
  InputCollection$Outbound,
  z.ZodTypeDef,
  InputCollection
> = z.union([
  z.lazy(() => InputCollectionCollection2$outboundSchema),
  z.lazy(() => InputCollectionCollection1$outboundSchema),
  z.lazy(() => InputCollectionCollection4$outboundSchema),
  z.lazy(() => InputCollectionCollection3$outboundSchema),
]);

export function inputCollectionToJSON(
  inputCollection: InputCollection,
): string {
  return JSON.stringify(InputCollection$outboundSchema.parse(inputCollection));
}
export function inputCollectionFromJSON(
  jsonString: string,
): SafeParseResult<InputCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollection' from JSON`,
  );
}
