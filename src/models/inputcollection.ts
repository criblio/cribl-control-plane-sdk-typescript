/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod/v3";
import { safeParse } from "../lib/schemas.js";
import { ClosedEnum } from "../types/enums.js";
import { Result as SafeParseResult } from "../types/fp.js";
import { SDKValidationError } from "./errors/sdkvalidationerror.js";
import {
  ItemsTypeConnections,
  ItemsTypeConnections$inboundSchema,
  ItemsTypeConnections$Outbound,
  ItemsTypeConnections$outboundSchema,
} from "./itemstypeconnections.js";
import {
  ItemsTypeNotificationMetadata,
  ItemsTypeNotificationMetadata$inboundSchema,
  ItemsTypeNotificationMetadata$Outbound,
  ItemsTypeNotificationMetadata$outboundSchema,
} from "./itemstypenotificationmetadata.js";
import {
  PqType,
  PqType$inboundSchema,
  PqType$Outbound,
  PqType$outboundSchema,
} from "./pqtype.js";
import {
  PreprocessTypeSavedJobCollectionInput,
  PreprocessTypeSavedJobCollectionInput$inboundSchema,
  PreprocessTypeSavedJobCollectionInput$Outbound,
  PreprocessTypeSavedJobCollectionInput$outboundSchema,
} from "./preprocesstypesavedjobcollectioninput.js";

export const InputCollectionType = {
  Collection: "collection",
} as const;
export type InputCollectionType = ClosedEnum<typeof InputCollectionType>;

export type InputCollectionPqEnabledTrueWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessTypeSavedJobCollectionInput | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export type InputCollectionPqEnabledFalseWithPqConstraint = {
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  pq?: PqType | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessTypeSavedJobCollectionInput | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export type InputCollectionSendToRoutesFalseWithConnectionsConstraint = {
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessTypeSavedJobCollectionInput | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export type InputCollectionSendToRoutesTrueWithConnectionsConstraint = {
  /**
   * Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
   */
  sendToRoutes?: boolean | undefined;
  /**
   * Direct connections to Destinations, and optionally via a Pipeline or a Pack
   */
  connections?: Array<ItemsTypeConnections> | undefined;
  /**
   * Unique ID for this input
   */
  id?: string | undefined;
  type?: InputCollectionType | undefined;
  disabled?: boolean | undefined;
  /**
   * Pipeline to process results
   */
  pipeline?: string | undefined;
  /**
   * Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
   */
  environment?: string | undefined;
  /**
   * Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
   */
  pqEnabled?: boolean | undefined;
  /**
   * Tags for filtering and grouping in @{product}
   */
  streamtags?: Array<string> | undefined;
  pq?: PqType | undefined;
  /**
   * A list of event-breaking rulesets that will be applied, in order, to the input data stream
   */
  breakerRulesets?: Array<string> | undefined;
  /**
   * How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
   */
  staleChannelFlushMs?: number | undefined;
  preprocess?: PreprocessTypeSavedJobCollectionInput | undefined;
  /**
   * Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
   */
  throttleRatePerSec?: string | undefined;
  /**
   * Fields to add to events from this input
   */
  metadata?: Array<ItemsTypeNotificationMetadata> | undefined;
  /**
   * Destination to send results to
   */
  output?: string | undefined;
};

export type InputCollection =
  | InputCollectionSendToRoutesTrueWithConnectionsConstraint
  | InputCollectionSendToRoutesFalseWithConnectionsConstraint
  | InputCollectionPqEnabledFalseWithPqConstraint
  | InputCollectionPqEnabledTrueWithPqConstraint;

/** @internal */
export const InputCollectionType$inboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType
> = z.nativeEnum(InputCollectionType);
/** @internal */
export const InputCollectionType$outboundSchema: z.ZodNativeEnum<
  typeof InputCollectionType
> = InputCollectionType$inboundSchema;

/** @internal */
export const InputCollectionPqEnabledTrueWithPqConstraint$inboundSchema:
  z.ZodType<
    InputCollectionPqEnabledTrueWithPqConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$inboundSchema.optional(),
    id: z.string().optional(),
    type: InputCollectionType$inboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$inboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    output: z.string().optional(),
  });
/** @internal */
export type InputCollectionPqEnabledTrueWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessTypeSavedJobCollectionInput$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  output?: string | undefined;
};

/** @internal */
export const InputCollectionPqEnabledTrueWithPqConstraint$outboundSchema:
  z.ZodType<
    InputCollectionPqEnabledTrueWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputCollectionPqEnabledTrueWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputCollectionType$outboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$outboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    output: z.string().optional(),
  });

export function inputCollectionPqEnabledTrueWithPqConstraintToJSON(
  inputCollectionPqEnabledTrueWithPqConstraint:
    InputCollectionPqEnabledTrueWithPqConstraint,
): string {
  return JSON.stringify(
    InputCollectionPqEnabledTrueWithPqConstraint$outboundSchema.parse(
      inputCollectionPqEnabledTrueWithPqConstraint,
    ),
  );
}
export function inputCollectionPqEnabledTrueWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputCollectionPqEnabledTrueWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputCollectionPqEnabledTrueWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputCollectionPqEnabledTrueWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputCollectionPqEnabledFalseWithPqConstraint$inboundSchema:
  z.ZodType<
    InputCollectionPqEnabledFalseWithPqConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$inboundSchema.optional(),
    id: z.string().optional(),
    type: InputCollectionType$inboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$inboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    output: z.string().optional(),
  });
/** @internal */
export type InputCollectionPqEnabledFalseWithPqConstraint$Outbound = {
  pqEnabled: boolean;
  pq?: PqType$Outbound | undefined;
  id?: string | undefined;
  type: string;
  disabled: boolean;
  pipeline?: string | undefined;
  sendToRoutes: boolean;
  environment?: string | undefined;
  streamtags?: Array<string> | undefined;
  connections?: Array<ItemsTypeConnections$Outbound> | undefined;
  breakerRulesets?: Array<string> | undefined;
  staleChannelFlushMs: number;
  preprocess?: PreprocessTypeSavedJobCollectionInput$Outbound | undefined;
  throttleRatePerSec: string;
  metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
  output?: string | undefined;
};

/** @internal */
export const InputCollectionPqEnabledFalseWithPqConstraint$outboundSchema:
  z.ZodType<
    InputCollectionPqEnabledFalseWithPqConstraint$Outbound,
    z.ZodTypeDef,
    InputCollectionPqEnabledFalseWithPqConstraint
  > = z.object({
    pqEnabled: z.boolean().default(false),
    pq: PqType$outboundSchema.optional(),
    id: z.string().optional(),
    type: InputCollectionType$outboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    sendToRoutes: z.boolean().default(true),
    environment: z.string().optional(),
    streamtags: z.array(z.string()).optional(),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$outboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    output: z.string().optional(),
  });

export function inputCollectionPqEnabledFalseWithPqConstraintToJSON(
  inputCollectionPqEnabledFalseWithPqConstraint:
    InputCollectionPqEnabledFalseWithPqConstraint,
): string {
  return JSON.stringify(
    InputCollectionPqEnabledFalseWithPqConstraint$outboundSchema.parse(
      inputCollectionPqEnabledFalseWithPqConstraint,
    ),
  );
}
export function inputCollectionPqEnabledFalseWithPqConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputCollectionPqEnabledFalseWithPqConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputCollectionPqEnabledFalseWithPqConstraint$inboundSchema.parse(
        JSON.parse(x),
      ),
    `Failed to parse 'InputCollectionPqEnabledFalseWithPqConstraint' from JSON`,
  );
}

/** @internal */
export const InputCollectionSendToRoutesFalseWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputCollectionSendToRoutesFalseWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputCollectionType$inboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$inboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    output: z.string().optional(),
  });
/** @internal */
export type InputCollectionSendToRoutesFalseWithConnectionsConstraint$Outbound =
  {
    sendToRoutes: boolean;
    connections?: Array<ItemsTypeConnections$Outbound> | undefined;
    id?: string | undefined;
    type: string;
    disabled: boolean;
    pipeline?: string | undefined;
    environment?: string | undefined;
    pqEnabled: boolean;
    streamtags?: Array<string> | undefined;
    pq?: PqType$Outbound | undefined;
    breakerRulesets?: Array<string> | undefined;
    staleChannelFlushMs: number;
    preprocess?: PreprocessTypeSavedJobCollectionInput$Outbound | undefined;
    throttleRatePerSec: string;
    metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
    output?: string | undefined;
  };

/** @internal */
export const InputCollectionSendToRoutesFalseWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputCollectionSendToRoutesFalseWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputCollectionSendToRoutesFalseWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputCollectionType$outboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$outboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    output: z.string().optional(),
  });

export function inputCollectionSendToRoutesFalseWithConnectionsConstraintToJSON(
  inputCollectionSendToRoutesFalseWithConnectionsConstraint:
    InputCollectionSendToRoutesFalseWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputCollectionSendToRoutesFalseWithConnectionsConstraint$outboundSchema
      .parse(inputCollectionSendToRoutesFalseWithConnectionsConstraint),
  );
}
export function inputCollectionSendToRoutesFalseWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputCollectionSendToRoutesFalseWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputCollectionSendToRoutesFalseWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionSendToRoutesFalseWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputCollectionSendToRoutesTrueWithConnectionsConstraint$inboundSchema:
  z.ZodType<
    InputCollectionSendToRoutesTrueWithConnectionsConstraint,
    z.ZodTypeDef,
    unknown
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$inboundSchema).optional(),
    id: z.string().optional(),
    type: InputCollectionType$inboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$inboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$inboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$inboundSchema).optional(),
    output: z.string().optional(),
  });
/** @internal */
export type InputCollectionSendToRoutesTrueWithConnectionsConstraint$Outbound =
  {
    sendToRoutes: boolean;
    connections?: Array<ItemsTypeConnections$Outbound> | undefined;
    id?: string | undefined;
    type: string;
    disabled: boolean;
    pipeline?: string | undefined;
    environment?: string | undefined;
    pqEnabled: boolean;
    streamtags?: Array<string> | undefined;
    pq?: PqType$Outbound | undefined;
    breakerRulesets?: Array<string> | undefined;
    staleChannelFlushMs: number;
    preprocess?: PreprocessTypeSavedJobCollectionInput$Outbound | undefined;
    throttleRatePerSec: string;
    metadata?: Array<ItemsTypeNotificationMetadata$Outbound> | undefined;
    output?: string | undefined;
  };

/** @internal */
export const InputCollectionSendToRoutesTrueWithConnectionsConstraint$outboundSchema:
  z.ZodType<
    InputCollectionSendToRoutesTrueWithConnectionsConstraint$Outbound,
    z.ZodTypeDef,
    InputCollectionSendToRoutesTrueWithConnectionsConstraint
  > = z.object({
    sendToRoutes: z.boolean().default(true),
    connections: z.array(ItemsTypeConnections$outboundSchema).optional(),
    id: z.string().optional(),
    type: InputCollectionType$outboundSchema.default("collection"),
    disabled: z.boolean().default(false),
    pipeline: z.string().optional(),
    environment: z.string().optional(),
    pqEnabled: z.boolean().default(false),
    streamtags: z.array(z.string()).optional(),
    pq: PqType$outboundSchema.optional(),
    breakerRulesets: z.array(z.string()).optional(),
    staleChannelFlushMs: z.number().default(10000),
    preprocess: PreprocessTypeSavedJobCollectionInput$outboundSchema.optional(),
    throttleRatePerSec: z.string().default("0"),
    metadata: z.array(ItemsTypeNotificationMetadata$outboundSchema).optional(),
    output: z.string().optional(),
  });

export function inputCollectionSendToRoutesTrueWithConnectionsConstraintToJSON(
  inputCollectionSendToRoutesTrueWithConnectionsConstraint:
    InputCollectionSendToRoutesTrueWithConnectionsConstraint,
): string {
  return JSON.stringify(
    InputCollectionSendToRoutesTrueWithConnectionsConstraint$outboundSchema
      .parse(inputCollectionSendToRoutesTrueWithConnectionsConstraint),
  );
}
export function inputCollectionSendToRoutesTrueWithConnectionsConstraintFromJSON(
  jsonString: string,
): SafeParseResult<
  InputCollectionSendToRoutesTrueWithConnectionsConstraint,
  SDKValidationError
> {
  return safeParse(
    jsonString,
    (x) =>
      InputCollectionSendToRoutesTrueWithConnectionsConstraint$inboundSchema
        .parse(JSON.parse(x)),
    `Failed to parse 'InputCollectionSendToRoutesTrueWithConnectionsConstraint' from JSON`,
  );
}

/** @internal */
export const InputCollection$inboundSchema: z.ZodType<
  InputCollection,
  z.ZodTypeDef,
  unknown
> = z.union([
  z.lazy(() =>
    InputCollectionSendToRoutesTrueWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() =>
    InputCollectionSendToRoutesFalseWithConnectionsConstraint$inboundSchema
  ),
  z.lazy(() => InputCollectionPqEnabledFalseWithPqConstraint$inboundSchema),
  z.lazy(() => InputCollectionPqEnabledTrueWithPqConstraint$inboundSchema),
]);
/** @internal */
export type InputCollection$Outbound =
  | InputCollectionSendToRoutesTrueWithConnectionsConstraint$Outbound
  | InputCollectionSendToRoutesFalseWithConnectionsConstraint$Outbound
  | InputCollectionPqEnabledFalseWithPqConstraint$Outbound
  | InputCollectionPqEnabledTrueWithPqConstraint$Outbound;

/** @internal */
export const InputCollection$outboundSchema: z.ZodType<
  InputCollection$Outbound,
  z.ZodTypeDef,
  InputCollection
> = z.union([
  z.lazy(() =>
    InputCollectionSendToRoutesTrueWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() =>
    InputCollectionSendToRoutesFalseWithConnectionsConstraint$outboundSchema
  ),
  z.lazy(() => InputCollectionPqEnabledFalseWithPqConstraint$outboundSchema),
  z.lazy(() => InputCollectionPqEnabledTrueWithPqConstraint$outboundSchema),
]);

export function inputCollectionToJSON(
  inputCollection: InputCollection,
): string {
  return JSON.stringify(InputCollection$outboundSchema.parse(inputCollection));
}
export function inputCollectionFromJSON(
  jsonString: string,
): SafeParseResult<InputCollection, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => InputCollection$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'InputCollection' from JSON`,
  );
}
